  I0502 08:09:39.144359      23 e2e.go:109] Starting e2e run "1e8eb09b-6877-4925-80e2-315df5ad7200" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1714637378 - will randomize all specs

Will run 402 of 7197 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0502 08:09:39.269168 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:09:39.269730 23 helper.go:48] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0502 08:09:39.341162 23 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0502 08:09:39.373124 23 e2e.go:153] 6 / 6 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  I0502 08:09:39.373141 23 e2e.go:153] 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  I0502 08:09:39.373150 23 e2e.go:245] e2e test version: v1.30.0
  I0502 08:09:39.374063 23 e2e.go:254] kube-apiserver version: v1.30.0
  I0502 08:09:39.374117 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:09:39.379454 23 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.110 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 05/02/24 08:09:39.443
  I0502 08:09:39.443588 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-webhook @ 05/02/24 08:09:39.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:09:39.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:09:39.523
  STEP: Setting up server cert @ 05/02/24 08:09:39.526
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/02/24 08:09:39.994
  STEP: Deploying the custom resource conversion webhook pod @ 05/02/24 08:09:40.005
  STEP: Wait for the deployment to be ready @ 05/02/24 08:09:40.021
  I0502 08:09:40.033066 23 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  I0502 08:09:42.041517 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-6c44f5d846\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0502 08:09:44.045766 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-6c44f5d846\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0502 08:09:46.045946 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 9, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-6c44f5d846\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 05/02/24 08:09:48.048
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:09:48.064
  I0502 08:09:49.064126 23 util.go:427] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0502 08:09:49.070287 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Creating a v1 custom resource @ 05/02/24 08:09:51.622
  STEP: v2 custom resource should be converted @ 05/02/24 08:09:51.628
  I0502 08:09:52.225631 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-2254" for this suite. @ 05/02/24 08:09:52.23
• [13.010 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 05/02/24 08:09:52.453
  I0502 08:09:52.453844 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 08:09:52.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:09:52.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:09:52.477
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/02/24 08:09:52.479
  STEP: Saw pod success @ 05/02/24 08:09:56.497
  I0502 08:09:56.499733 23 output.go:196] Trying to get logs from node mini-1 pod pod-3f755022-4bc6-4fa6-8469-74f5a6b963e6 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 08:09:56.51
  I0502 08:09:56.525135 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2836" for this suite. @ 05/02/24 08:09:56.528
• [4.081 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 05/02/24 08:09:56.534
  I0502 08:09:56.534437 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:09:56.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:09:56.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:09:56.554
  STEP: Creating the pod @ 05/02/24 08:09:56.556
  I0502 08:10:07.168043 23 pod_client.go:141] Successfully updated pod "annotationupdatefc97c036-6a09-46db-b3b3-a5ef37147e16"
  I0502 08:10:09.202063 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4125" for this suite. @ 05/02/24 08:10:09.205
• [12.677 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 05/02/24 08:10:09.211
  I0502 08:10:09.212001 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename endpointslicemirroring @ 05/02/24 08:10:09.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:10:09.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:10:09.232
  STEP: mirroring a new custom Endpoint @ 05/02/24 08:10:09.249
  STEP: mirroring an update to a custom Endpoint @ 05/02/24 08:10:09.26
  I0502 08:10:09.275904 23 endpointslicemirroring.go:171] Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  STEP: mirroring deletion of a custom Endpoint @ 05/02/24 08:10:11.28
  I0502 08:10:11.293012 23 endpointslicemirroring.go:194] Waiting for 0 EndpointSlices to exist, got 1
  I0502 08:10:13.300552 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-5711" for this suite. @ 05/02/24 08:10:13.304
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 05/02/24 08:10:13.311
  I0502 08:10:13.311363 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename init-container @ 05/02/24 08:10:13.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:10:13.33
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:10:13.332
  STEP: creating the pod @ 05/02/24 08:10:13.334
  I0502 08:10:13.334876 23 init_container.go:213] PodSpec: initContainers in spec.initContainers
  I0502 08:10:20.409534 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9224" for this suite. @ 05/02/24 08:10:20.413
• [7.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 05/02/24 08:10:20.42
  I0502 08:10:20.420800 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename deployment @ 05/02/24 08:10:20.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:10:20.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:10:20.443
  STEP: creating a Deployment @ 05/02/24 08:10:20.449
  I0502 08:10:20.449243 23 deployment.go:507] Creating simple deployment test-deployment-9v5x7
  I0502 08:10:20.460122 23 deployment.go:222] deployment "test-deployment-9v5x7" doesn't have the required revision set
  I0502 08:10:22.470785 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 10, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 10, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 10, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 10, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-9v5x7-c8586b885\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0502 08:10:24.474389 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 10, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 10, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 10, 20, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 10, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-9v5x7-c8586b885\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Getting /status @ 05/02/24 08:10:26.478
  I0502 08:10:26.483824 23 deployment.go:532] Deployment test-deployment-9v5x7 has Conditions: [{Available True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9v5x7-c8586b885" has successfully progressed.}]
  STEP: updating Deployment Status @ 05/02/24 08:10:26.483
  I0502 08:10:26.499679 23 deployment.go:552] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 10, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 10, 26, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 10, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 10, 20, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-9v5x7-c8586b885\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 05/02/24 08:10:26.499
  I0502 08:10:26.501280 23 deployment.go:579] Observed &Deployment event: ADDED
  I0502 08:10:26.501312 23 deployment.go:575] Observed Deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9v5x7-c8586b885"}
  I0502 08:10:26.501364 23 deployment.go:579] Observed &Deployment event: MODIFIED
  I0502 08:10:26.501375 23 deployment.go:575] Observed Deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9v5x7-c8586b885"}
  I0502 08:10:26.501384 23 deployment.go:575] Observed Deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0502 08:10:26.501437 23 deployment.go:579] Observed &Deployment event: MODIFIED
  I0502 08:10:26.501450 23 deployment.go:575] Observed Deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0502 08:10:26.501457 23 deployment.go:575] Observed Deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9v5x7-c8586b885" is progressing.}
  I0502 08:10:26.501502 23 deployment.go:579] Observed &Deployment event: MODIFIED
  I0502 08:10:26.501523 23 deployment.go:575] Observed Deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0502 08:10:26.501539 23 deployment.go:575] Observed Deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9v5x7-c8586b885" has successfully progressed.}
  I0502 08:10:26.501607 23 deployment.go:579] Observed &Deployment event: MODIFIED
  I0502 08:10:26.501633 23 deployment.go:575] Observed Deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0502 08:10:26.501655 23 deployment.go:575] Observed Deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9v5x7-c8586b885" has successfully progressed.}
  I0502 08:10:26.501671 23 deployment.go:572] Found Deployment test-deployment-9v5x7 in namespace deployment-724 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0502 08:10:26.501686 23 deployment.go:583] Deployment test-deployment-9v5x7 has an updated status
  STEP: patching the Statefulset Status @ 05/02/24 08:10:26.501
  I0502 08:10:26.501715 23 deployment.go:587] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0502 08:10:26.507798 23 deployment.go:591] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 05/02/24 08:10:26.507
  I0502 08:10:26.509509 23 deployment.go:616] Observed &Deployment event: ADDED
  I0502 08:10:26.509524 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9v5x7-c8586b885"}
  I0502 08:10:26.509584 23 deployment.go:616] Observed &Deployment event: MODIFIED
  I0502 08:10:26.509598 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-9v5x7-c8586b885"}
  I0502 08:10:26.509606 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0502 08:10:26.509655 23 deployment.go:616] Observed &Deployment event: MODIFIED
  I0502 08:10:26.509667 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0502 08:10:26.509674 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:20 +0000 UTC 2024-05-02 08:10:20 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-9v5x7-c8586b885" is progressing.}
  I0502 08:10:26.509722 23 deployment.go:616] Observed &Deployment event: MODIFIED
  I0502 08:10:26.509739 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0502 08:10:26.509747 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9v5x7-c8586b885" has successfully progressed.}
  I0502 08:10:26.509807 23 deployment.go:616] Observed &Deployment event: MODIFIED
  I0502 08:10:26.509834 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0502 08:10:26.509843 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-02 08:10:26 +0000 UTC 2024-05-02 08:10:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-9v5x7-c8586b885" has successfully progressed.}
  I0502 08:10:26.509850 23 deployment.go:612] Observed deployment test-deployment-9v5x7 in namespace deployment-724 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0502 08:10:26.509916 23 deployment.go:616] Observed &Deployment event: MODIFIED
  I0502 08:10:26.509930 23 deployment.go:609] Found deployment test-deployment-9v5x7 in namespace deployment-724 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0502 08:10:26.509936 23 deployment.go:620] Deployment test-deployment-9v5x7 has a patched status
  I0502 08:10:26.517565 23 deployment.go:633] Deployment "test-deployment-9v5x7":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-9v5x7",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-724",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f68f4cf4-f603-440f-9cc1-ac94b4265c04",
      ResourceVersion: (string) (len=4) "4913",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234220,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234226,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234226,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234226,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234226,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=55) "Found new replica set \"test-deployment-9v5x7-c8586b885\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0502 08:10:26.521026 23 deployment.go:39] New ReplicaSet "test-deployment-9v5x7-c8586b885" of Deployment "test-deployment-9v5x7":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-9v5x7-c8586b885",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-724",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c644f75c-5562-4dda-a171-f1ef6cf3f612",
      ResourceVersion: (string) (len=4) "4909",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234220,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885",
        (string) (len=3) "e2e": (string) (len=7) "testing"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-9v5x7",
          UID: (types.UID) (len=36) "f68f4cf4-f603-440f-9cc1-ac94b4265c04",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 66 36 38  |k:{\"uid\":\"f68|
              00000120  66 34 63 66 34 2d 66 36  30 33 2d 34 34 30 66 2d  |f4cf4-f603-440f-|
              00000130  39 63 63 31 2d 61 63 39  34 62 34 32 36 35 63 30  |9cc1-ac94b4265c0|
              00000140  34 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |4\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234226,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885",
            (string) (len=3) "e2e": (string) (len=7) "testing"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:10:26.525973 23 deployment.go:67] Pod "test-deployment-9v5x7-c8586b885-bwr8q" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "test-deployment-9v5x7-c8586b885-bwr8q",
      GenerateName: (string) (len=32) "test-deployment-9v5x7-c8586b885-",
      Namespace: (string) (len=14) "deployment-724",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9e055e5f-eca9-4e4d-9994-0ba0121a7ed1",
      ResourceVersion: (string) (len=4) "4908",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234220,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.158.132/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "98943f86feeb92453481250f2e657b38c89af4bb74f2c17dd82bf398553e66d6",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.158.132/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "test-deployment-9v5x7-c8586b885",
          UID: (types.UID) (len=36) "c644f75c-5562-4dda-a171-f1ef6cf3f612",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 63 36 34 34 66 37 35  63 2d 35 35 36 32 2d 34  |"c644f75c-5562-4|
              000000a0  64 64 61 2d 61 31 37 31  2d 66 31 65 66 36 63 66  |dda-a171-f1ef6cf|
              000000b0  33 66 36 31 32 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |3f612\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234226,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  38 2e 31 33 32 5c 22 7d  |2.168.158.132\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6bk28",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6bk28",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234226,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234226,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234226,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234220,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) (len=15) "192.168.158.132",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.158.132"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234220,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234226,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://e075dcc2a8c5ca621bdc8566357154952c0a3b012d4e6934ec9a909e607fa8e1",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:10:26.527405 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-724" for this suite. @ 05/02/24 08:10:26.531
• [6.118 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 05/02/24 08:10:26.538
  I0502 08:10:26.538567 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:10:26.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:10:26.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:10:26.558
  STEP: Creating projection with secret that has name projected-secret-test-2398b58d-069e-4ff8-8bd4-313e5be97061 @ 05/02/24 08:10:26.56
  STEP: Creating a pod to test consume secrets @ 05/02/24 08:10:26.565
  STEP: Saw pod success @ 05/02/24 08:10:30.586
  I0502 08:10:30.589768 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-secrets-c6514b1b-7e85-43f5-a831-1c3a4435ee23 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 08:10:30.595
  I0502 08:10:30.607109 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2300" for this suite. @ 05/02/24 08:10:30.61
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:237
  STEP: Creating a kubernetes client @ 05/02/24 08:10:30.616
  I0502 08:10:30.616328 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/02/24 08:10:30.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:10:30.634
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:10:30.637
  I0502 08:10:30.639021 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/02/24 08:10:33.89
  I0502 08:10:33.890898 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-2931 --namespace=crd-publish-openapi-2931 create -f -'
  I0502 08:10:33.952746 23 builder.go:146] stderr: ""
  I0502 08:10:33.952771 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8084-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0502 08:10:33.952800 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-2931 --namespace=crd-publish-openapi-2931 delete e2e-test-crd-publish-openapi-8084-crds test-cr'
  I0502 08:10:33.993464 23 builder.go:146] stderr: ""
  I0502 08:10:33.993491 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8084-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I0502 08:10:33.993518 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-2931 --namespace=crd-publish-openapi-2931 apply -f -'
  I0502 08:10:34.039528 23 builder.go:146] stderr: ""
  I0502 08:10:34.039554 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8084-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0502 08:10:34.039585 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-2931 --namespace=crd-publish-openapi-2931 delete e2e-test-crd-publish-openapi-8084-crds test-cr'
  I0502 08:10:34.093169 23 builder.go:146] stderr: ""
  I0502 08:10:34.093197 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8084-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/02/24 08:10:34.093
  I0502 08:10:34.093258 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-2931 explain e2e-test-crd-publish-openapi-8084-crds'
  I0502 08:10:34.130703 23 builder.go:146] stderr: ""
  I0502 08:10:34.130745 23 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-8084-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  I0502 08:10:36.549452 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2931" for this suite. @ 05/02/24 08:10:36.556
• [5.948 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 05/02/24 08:10:36.564
  I0502 08:10:36.564115 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pod-network-test @ 05/02/24 08:10:36.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:10:36.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:10:36.583
  STEP: Performing setup for networking test in namespace pod-network-test-9990 @ 05/02/24 08:10:36.585
  STEP: creating a selector @ 05/02/24 08:10:36.585
  STEP: Creating the service pods in kubernetes @ 05/02/24 08:10:36.585
  I0502 08:10:36.585452 23 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 05/02/24 08:10:58.679
  I0502 08:11:00.694830 23 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0502 08:11:00.694864 23 networking.go:42] Breadth first check of 192.168.125.198 on host 10.221.190.31...
  I0502 08:11:00.698550 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.125.199:9080/dial?request=hostname&protocol=udp&host=192.168.125.198&port=8081&tries=1'] Namespace:pod-network-test-9990 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:11:00.698564 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:11:00.698852 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:11:00.698901 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9990/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.125.199%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.125.198%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0502 08:11:00.743382 23 utils.go:331] Waiting for responses: map[]
  I0502 08:11:00.743408 23 utils.go:335] reached 192.168.125.198 after 0/1 tries
  I0502 08:11:00.743414 23 networking.go:42] Breadth first check of 192.168.158.133 on host 10.221.190.32...
  I0502 08:11:00.746802 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.125.199:9080/dial?request=hostname&protocol=udp&host=192.168.158.133&port=8081&tries=1'] Namespace:pod-network-test-9990 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:11:00.746814 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:11:00.747131 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:11:00.747184 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9990/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.125.199%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.158.133%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0502 08:11:00.780270 23 utils.go:331] Waiting for responses: map[]
  I0502 08:11:00.780283 23 utils.go:335] reached 192.168.158.133 after 0/1 tries
  I0502 08:11:00.780303 23 networking.go:42] Breadth first check of 192.168.32.3 on host 10.221.190.33...
  I0502 08:11:00.783487 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.125.199:9080/dial?request=hostname&protocol=udp&host=192.168.32.3&port=8081&tries=1'] Namespace:pod-network-test-9990 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:11:00.783499 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:11:00.783810 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:11:00.783850 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9990/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.125.199%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.32.3%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0502 08:11:00.818322 23 utils.go:331] Waiting for responses: map[]
  I0502 08:11:00.818335 23 utils.go:335] reached 192.168.32.3 after 0/1 tries
  I0502 08:11:00.818342 23 networking.go:53] Going to retry 0 out of 3 pods....
  I0502 08:11:00.818379 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9990" for this suite. @ 05/02/24 08:11:00.822
• [24.267 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 05/02/24 08:11:00.831
  I0502 08:11:00.831494 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename watch @ 05/02/24 08:11:00.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:11:00.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:11:00.854
  STEP: getting a starting resourceVersion @ 05/02/24 08:11:00.857
  STEP: starting a background goroutine to produce watch events @ 05/02/24 08:11:00.86
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 05/02/24 08:11:00.86
  I0502 08:11:03.638017 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3951" for this suite. @ 05/02/24 08:11:03.686
• [2.909 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 05/02/24 08:11:03.74
  I0502 08:11:03.740451 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename statefulset @ 05/02/24 08:11:03.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:11:03.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:11:03.761
  STEP: Creating service test in namespace statefulset-4485 @ 05/02/24 08:11:03.763
  STEP: Creating stateful set ss in namespace statefulset-4485 @ 05/02/24 08:11:03.768
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4485 @ 05/02/24 08:11:03.782
  I0502 08:11:03.798507 23 wait.go:40] Found 0 stateful pods, waiting for 1
  I0502 08:11:13.814148 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 05/02/24 08:11:13.814
  I0502 08:11:13.820655 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-4485 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 08:11:13.942411 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 08:11:13.942434 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 08:11:13.942442 23 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0502 08:11:13.952104 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  I0502 08:11:23.946842 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0502 08:11:23.946878 23 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0502 08:11:23.969270 23 resource.go:168] POD   NODE    PHASE    GRACE  CONDITIONS
  I0502 08:11:23.969325 23 resource.go:175] ss-0  mini-2  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:05 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:03 +0000 UTC  }]
  I0502 08:11:23.969331 23 resource.go:175] ss-2          Pending         []
  I0502 08:11:23.969336 23 resource.go:178] 
  I0502 08:11:23.969341 23 statefulset.go:2147] StatefulSet ss has not reached scale 3, at 2
  I0502 08:11:24.975383 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 8.988397059s
  I0502 08:11:25.979269 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 7.983309011s
  I0502 08:11:26.982922 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 6.979465681s
  I0502 08:11:27.987743 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 5.97483303s
  I0502 08:11:28.991980 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 4.971022282s
  I0502 08:11:29.995821 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 3.966740426s
  I0502 08:11:31.000064 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 2.962491665s
  I0502 08:11:32.003754 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 1.958635354s
  I0502 08:11:33.007630 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 954.928427ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4485 @ 05/02/24 08:11:34.007
  I0502 08:11:34.012228 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-4485 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0502 08:11:34.088425 23 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0502 08:11:34.088450 23 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0502 08:11:34.088458 23 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0502 08:11:34.088483 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-4485 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0502 08:11:34.175199 23 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0502 08:11:34.175224 23 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0502 08:11:34.175232 23 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0502 08:11:34.175259 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-4485 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0502 08:11:34.256280 23 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0502 08:11:34.256304 23 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0502 08:11:34.256313 23 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0502 08:11:34.260187 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0502 08:11:34.260203 23 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0502 08:11:34.260209 23 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 05/02/24 08:11:34.26
  I0502 08:11:34.262960 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-4485 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 08:11:34.335003 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 08:11:34.335025 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 08:11:34.335034 23 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0502 08:11:34.335058 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-4485 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 08:11:34.429526 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 08:11:34.429548 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 08:11:34.429556 23 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0502 08:11:34.429582 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-4485 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 08:11:34.524215 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 08:11:34.524238 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 08:11:34.524246 23 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0502 08:11:34.524252 23 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0502 08:11:34.527320 23 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  I0502 08:11:44.531774 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0502 08:11:44.531792 23 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0502 08:11:44.531798 23 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0502 08:11:44.543705 23 resource.go:168] POD   NODE    PHASE    GRACE  CONDITIONS
  I0502 08:11:44.543743 23 resource.go:175] ss-0  mini-2  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:05 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:03 +0000 UTC  }]
  I0502 08:11:44.543772 23 resource.go:175] ss-1  mini-3  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:30 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:23 +0000 UTC  }]
  I0502 08:11:44.543784 23 resource.go:175] ss-2  mini-1  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:30 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:23 +0000 UTC  }]
  I0502 08:11:44.543795 23 resource.go:178] 
  I0502 08:11:44.543800 23 statefulset.go:2147] StatefulSet ss has not reached scale 0, at 3
  I0502 08:11:45.547816 23 resource.go:168] POD   NODE    PHASE      GRACE  CONDITIONS
  I0502 08:11:45.547854 23 resource.go:175] ss-2  mini-1  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:45 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:23 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:35 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:35 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:11:23 +0000 UTC  }]
  I0502 08:11:45.547874 23 resource.go:178] 
  I0502 08:11:45.547879 23 statefulset.go:2147] StatefulSet ss has not reached scale 0, at 1
  I0502 08:11:46.551216 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 7.99166167s
  I0502 08:11:47.554345 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 6.988376429s
  I0502 08:11:48.557482 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 5.98518928s
  I0502 08:11:49.560821 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 4.981865602s
  I0502 08:11:50.564860 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 3.97871426s
  I0502 08:11:51.568581 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 2.974686338s
  I0502 08:11:52.571913 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 1.970935497s
  I0502 08:11:53.575984 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 967.640653ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4485 @ 05/02/24 08:11:54.576
  I0502 08:11:54.579991 23 rest.go:150] Scaling statefulset ss to 0
  I0502 08:11:54.588824 23 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0502 08:11:54.591589 23 statefulset.go:135] Deleting all statefulset in ns statefulset-4485
  I0502 08:11:54.594206 23 rest.go:150] Scaling statefulset ss to 0
  I0502 08:11:54.603572 23 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0502 08:11:54.606071 23 rest.go:88] Deleting statefulset ss
  I0502 08:11:54.620998 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4485" for this suite. @ 05/02/24 08:11:54.624
• [50.891 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 05/02/24 08:11:54.631
  I0502 08:11:54.631529 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 08:11:54.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:11:54.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:11:54.651
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/02/24 08:11:54.653
  STEP: Saw pod success @ 05/02/24 08:11:58.683
  I0502 08:11:58.686313 23 output.go:196] Trying to get logs from node mini-2 pod pod-44dc6692-321a-454b-b66c-4214ebdb7f95 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 08:11:58.695
  I0502 08:11:58.714469 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6210" for this suite. @ 05/02/24 08:11:58.718
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:866
  STEP: Creating a kubernetes client @ 05/02/24 08:11:58.725
  I0502 08:11:58.725433 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:11:58.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:11:58.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:11:58.743
  STEP: Setting up server cert @ 05/02/24 08:11:58.77
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:11:59.388
  STEP: Deploying the webhook pod @ 05/02/24 08:11:59.4
  STEP: Wait for the deployment to be ready @ 05/02/24 08:11:59.413
  I0502 08:11:59.423707 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/02/24 08:12:01.434
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:12:01.448
  I0502 08:12:02.448718 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 05/02/24 08:12:02.454
  STEP: create the configmap with a random name @ 05/02/24 08:12:02.473
  STEP: verify the configmap is mutated @ 05/02/24 08:12:02.488
  STEP: create the configmap with 'skip-me' name @ 05/02/24 08:12:02.488
  I0502 08:12:02.579850 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-992" for this suite. @ 05/02/24 08:12:02.586
  STEP: Destroying namespace "webhook-markers-1625" for this suite. @ 05/02/24 08:12:02.595
• [3.878 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 05/02/24 08:12:02.603
  I0502 08:12:02.603086 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:12:02.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:12:02.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:12:02.624
  STEP: Creating projection with secret that has name projected-secret-test-32523fba-526d-4002-a20a-7054918c1f25 @ 05/02/24 08:12:02.627
  STEP: Creating a pod to test consume secrets @ 05/02/24 08:12:02.632
  STEP: Saw pod success @ 05/02/24 08:12:06.652
  I0502 08:12:06.655648 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-secrets-c8eead9c-34bb-49e4-8d09-56994817365e container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 08:12:06.664
  I0502 08:12:06.677594 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4847" for this suite. @ 05/02/24 08:12:06.681
• [4.086 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 05/02/24 08:12:06.688
  I0502 08:12:06.689003 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename gc @ 05/02/24 08:12:06.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:12:06.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:12:06.713
  STEP: create the rc @ 05/02/24 08:12:06.719
  W0502 08:12:06.724296      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 05/02/24 08:12:12.728
  STEP: wait for the rc to be deleted @ 05/02/24 08:12:12.733
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 05/02/24 08:12:17.739
  STEP: Gathering metrics @ 05/02/24 08:12:47.752
  I0502 08:12:47.819757 23 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0502 08:12:47.819838 23 delete.go:95] Deleting pod "simpletest.rc-2jwjz" in namespace "gc-8068"
  I0502 08:12:47.834446 23 delete.go:95] Deleting pod "simpletest.rc-2r4c6" in namespace "gc-8068"
  I0502 08:12:47.845049 23 delete.go:95] Deleting pod "simpletest.rc-479hs" in namespace "gc-8068"
  I0502 08:12:47.872144 23 delete.go:95] Deleting pod "simpletest.rc-4bm8j" in namespace "gc-8068"
  I0502 08:12:47.890637 23 delete.go:95] Deleting pod "simpletest.rc-4wx69" in namespace "gc-8068"
  I0502 08:12:47.911350 23 delete.go:95] Deleting pod "simpletest.rc-52zqz" in namespace "gc-8068"
  I0502 08:12:47.937068 23 delete.go:95] Deleting pod "simpletest.rc-55fcn" in namespace "gc-8068"
  I0502 08:12:47.947765 23 delete.go:95] Deleting pod "simpletest.rc-5946g" in namespace "gc-8068"
  I0502 08:12:47.958376 23 delete.go:95] Deleting pod "simpletest.rc-59dhs" in namespace "gc-8068"
  I0502 08:12:47.971053 23 delete.go:95] Deleting pod "simpletest.rc-5rhzt" in namespace "gc-8068"
  I0502 08:12:47.989702 23 delete.go:95] Deleting pod "simpletest.rc-5snnf" in namespace "gc-8068"
  I0502 08:12:48.003828 23 delete.go:95] Deleting pod "simpletest.rc-72c96" in namespace "gc-8068"
  I0502 08:12:48.015517 23 delete.go:95] Deleting pod "simpletest.rc-76vdd" in namespace "gc-8068"
  I0502 08:12:48.025079 23 delete.go:95] Deleting pod "simpletest.rc-77hjv" in namespace "gc-8068"
  I0502 08:12:48.039370 23 delete.go:95] Deleting pod "simpletest.rc-7dvx6" in namespace "gc-8068"
  I0502 08:12:48.050303 23 delete.go:95] Deleting pod "simpletest.rc-7vb9c" in namespace "gc-8068"
  I0502 08:12:48.069024 23 delete.go:95] Deleting pod "simpletest.rc-8s6f7" in namespace "gc-8068"
  I0502 08:12:48.081070 23 delete.go:95] Deleting pod "simpletest.rc-94pgt" in namespace "gc-8068"
  I0502 08:12:48.094950 23 delete.go:95] Deleting pod "simpletest.rc-9lhbw" in namespace "gc-8068"
  I0502 08:12:48.105523 23 delete.go:95] Deleting pod "simpletest.rc-9q48f" in namespace "gc-8068"
  I0502 08:12:48.116730 23 delete.go:95] Deleting pod "simpletest.rc-9vf62" in namespace "gc-8068"
  I0502 08:12:48.126944 23 delete.go:95] Deleting pod "simpletest.rc-9wf4z" in namespace "gc-8068"
  I0502 08:12:48.141943 23 delete.go:95] Deleting pod "simpletest.rc-b2bzm" in namespace "gc-8068"
  I0502 08:12:48.152373 23 delete.go:95] Deleting pod "simpletest.rc-bhr55" in namespace "gc-8068"
  I0502 08:12:48.166937 23 delete.go:95] Deleting pod "simpletest.rc-c68cj" in namespace "gc-8068"
  I0502 08:12:48.179260 23 delete.go:95] Deleting pod "simpletest.rc-cbgdx" in namespace "gc-8068"
  I0502 08:12:48.189142 23 delete.go:95] Deleting pod "simpletest.rc-cn7pc" in namespace "gc-8068"
  I0502 08:12:48.198793 23 delete.go:95] Deleting pod "simpletest.rc-crskk" in namespace "gc-8068"
  I0502 08:12:48.211410 23 delete.go:95] Deleting pod "simpletest.rc-ddlkb" in namespace "gc-8068"
  I0502 08:12:48.228384 23 delete.go:95] Deleting pod "simpletest.rc-dfkfq" in namespace "gc-8068"
  I0502 08:12:48.245712 23 delete.go:95] Deleting pod "simpletest.rc-dg6vl" in namespace "gc-8068"
  I0502 08:12:48.258267 23 delete.go:95] Deleting pod "simpletest.rc-dhh22" in namespace "gc-8068"
  I0502 08:12:48.273928 23 delete.go:95] Deleting pod "simpletest.rc-dksqv" in namespace "gc-8068"
  I0502 08:12:48.299349 23 delete.go:95] Deleting pod "simpletest.rc-dlhw2" in namespace "gc-8068"
  I0502 08:12:48.316849 23 delete.go:95] Deleting pod "simpletest.rc-f7l69" in namespace "gc-8068"
  I0502 08:12:48.328484 23 delete.go:95] Deleting pod "simpletest.rc-fdnd2" in namespace "gc-8068"
  I0502 08:12:48.339154 23 delete.go:95] Deleting pod "simpletest.rc-fh2xd" in namespace "gc-8068"
  I0502 08:12:48.357198 23 delete.go:95] Deleting pod "simpletest.rc-fvm7j" in namespace "gc-8068"
  I0502 08:12:48.372709 23 delete.go:95] Deleting pod "simpletest.rc-fxqqx" in namespace "gc-8068"
  I0502 08:12:48.383216 23 delete.go:95] Deleting pod "simpletest.rc-g7gpw" in namespace "gc-8068"
  I0502 08:12:48.399956 23 delete.go:95] Deleting pod "simpletest.rc-gm7rg" in namespace "gc-8068"
  I0502 08:12:48.418598 23 delete.go:95] Deleting pod "simpletest.rc-gtbw6" in namespace "gc-8068"
  I0502 08:12:48.441956 23 delete.go:95] Deleting pod "simpletest.rc-h5pbr" in namespace "gc-8068"
  I0502 08:12:48.458627 23 delete.go:95] Deleting pod "simpletest.rc-hqt22" in namespace "gc-8068"
  I0502 08:12:48.479254 23 delete.go:95] Deleting pod "simpletest.rc-jnld9" in namespace "gc-8068"
  I0502 08:12:48.509173 23 delete.go:95] Deleting pod "simpletest.rc-jxshv" in namespace "gc-8068"
  I0502 08:12:48.531959 23 delete.go:95] Deleting pod "simpletest.rc-k58pt" in namespace "gc-8068"
  I0502 08:12:48.570948 23 delete.go:95] Deleting pod "simpletest.rc-k9cj2" in namespace "gc-8068"
  I0502 08:12:48.588400 23 delete.go:95] Deleting pod "simpletest.rc-kkprm" in namespace "gc-8068"
  I0502 08:12:48.608509 23 delete.go:95] Deleting pod "simpletest.rc-km84r" in namespace "gc-8068"
  I0502 08:12:48.695559 23 delete.go:95] Deleting pod "simpletest.rc-kt587" in namespace "gc-8068"
  I0502 08:12:48.749737 23 delete.go:95] Deleting pod "simpletest.rc-l7tkc" in namespace "gc-8068"
  I0502 08:12:48.849458 23 delete.go:95] Deleting pod "simpletest.rc-lhwk4" in namespace "gc-8068"
  I0502 08:12:48.874182 23 delete.go:95] Deleting pod "simpletest.rc-lj7fn" in namespace "gc-8068"
  I0502 08:12:48.895658 23 delete.go:95] Deleting pod "simpletest.rc-lkrfv" in namespace "gc-8068"
  I0502 08:12:48.937257 23 delete.go:95] Deleting pod "simpletest.rc-llvvl" in namespace "gc-8068"
  I0502 08:12:48.951318 23 delete.go:95] Deleting pod "simpletest.rc-lvcc5" in namespace "gc-8068"
  I0502 08:12:48.974566 23 delete.go:95] Deleting pod "simpletest.rc-lvpr8" in namespace "gc-8068"
  I0502 08:12:48.995462 23 delete.go:95] Deleting pod "simpletest.rc-m266c" in namespace "gc-8068"
  I0502 08:12:49.009966 23 delete.go:95] Deleting pod "simpletest.rc-mjscm" in namespace "gc-8068"
  I0502 08:12:49.038520 23 delete.go:95] Deleting pod "simpletest.rc-mrdk6" in namespace "gc-8068"
  I0502 08:12:49.052369 23 delete.go:95] Deleting pod "simpletest.rc-n45ln" in namespace "gc-8068"
  I0502 08:12:49.062254 23 delete.go:95] Deleting pod "simpletest.rc-n6sg4" in namespace "gc-8068"
  I0502 08:12:49.086024 23 delete.go:95] Deleting pod "simpletest.rc-n6zx7" in namespace "gc-8068"
  I0502 08:12:49.108493 23 delete.go:95] Deleting pod "simpletest.rc-nbmx9" in namespace "gc-8068"
  I0502 08:12:49.138658 23 delete.go:95] Deleting pod "simpletest.rc-nk28d" in namespace "gc-8068"
  I0502 08:12:49.148921 23 delete.go:95] Deleting pod "simpletest.rc-nr9tp" in namespace "gc-8068"
  I0502 08:12:49.161728 23 delete.go:95] Deleting pod "simpletest.rc-nrkw2" in namespace "gc-8068"
  I0502 08:12:49.200732 23 delete.go:95] Deleting pod "simpletest.rc-phsbm" in namespace "gc-8068"
  I0502 08:12:49.223259 23 delete.go:95] Deleting pod "simpletest.rc-png55" in namespace "gc-8068"
  I0502 08:12:49.250492 23 delete.go:95] Deleting pod "simpletest.rc-q6qt4" in namespace "gc-8068"
  I0502 08:12:49.389952 23 delete.go:95] Deleting pod "simpletest.rc-q98lx" in namespace "gc-8068"
  I0502 08:12:49.431716 23 delete.go:95] Deleting pod "simpletest.rc-r7982" in namespace "gc-8068"
  I0502 08:12:49.480093 23 delete.go:95] Deleting pod "simpletest.rc-r9qjp" in namespace "gc-8068"
  I0502 08:12:49.497297 23 delete.go:95] Deleting pod "simpletest.rc-rfpfb" in namespace "gc-8068"
  I0502 08:12:49.511787 23 delete.go:95] Deleting pod "simpletest.rc-rrjjv" in namespace "gc-8068"
  I0502 08:12:49.545569 23 delete.go:95] Deleting pod "simpletest.rc-rxg4z" in namespace "gc-8068"
  I0502 08:12:49.564788 23 delete.go:95] Deleting pod "simpletest.rc-rxl6z" in namespace "gc-8068"
  I0502 08:12:49.581779 23 delete.go:95] Deleting pod "simpletest.rc-sdn8g" in namespace "gc-8068"
  I0502 08:12:49.595421 23 delete.go:95] Deleting pod "simpletest.rc-svbmv" in namespace "gc-8068"
  I0502 08:12:49.607904 23 delete.go:95] Deleting pod "simpletest.rc-t2hd9" in namespace "gc-8068"
  I0502 08:12:49.656425 23 delete.go:95] Deleting pod "simpletest.rc-tb4fr" in namespace "gc-8068"
  I0502 08:12:49.687694 23 delete.go:95] Deleting pod "simpletest.rc-tqf9x" in namespace "gc-8068"
  I0502 08:12:49.701341 23 delete.go:95] Deleting pod "simpletest.rc-tvjb4" in namespace "gc-8068"
  I0502 08:12:49.715580 23 delete.go:95] Deleting pod "simpletest.rc-tvmcs" in namespace "gc-8068"
  I0502 08:12:49.762223 23 delete.go:95] Deleting pod "simpletest.rc-vrf2h" in namespace "gc-8068"
  I0502 08:12:49.779055 23 delete.go:95] Deleting pod "simpletest.rc-vzvvq" in namespace "gc-8068"
  I0502 08:12:49.822300 23 delete.go:95] Deleting pod "simpletest.rc-xckkv" in namespace "gc-8068"
  I0502 08:12:49.857342 23 delete.go:95] Deleting pod "simpletest.rc-xfwk6" in namespace "gc-8068"
  I0502 08:12:49.909166 23 delete.go:95] Deleting pod "simpletest.rc-xncdg" in namespace "gc-8068"
  I0502 08:12:49.958668 23 delete.go:95] Deleting pod "simpletest.rc-xnfdf" in namespace "gc-8068"
  I0502 08:12:50.006199 23 delete.go:95] Deleting pod "simpletest.rc-xssxd" in namespace "gc-8068"
  I0502 08:12:50.092765 23 delete.go:95] Deleting pod "simpletest.rc-z2sk2" in namespace "gc-8068"
  I0502 08:12:50.176408 23 delete.go:95] Deleting pod "simpletest.rc-z6dr4" in namespace "gc-8068"
  I0502 08:12:50.233022 23 delete.go:95] Deleting pod "simpletest.rc-z7v5s" in namespace "gc-8068"
  I0502 08:12:50.277835 23 delete.go:95] Deleting pod "simpletest.rc-zg28f" in namespace "gc-8068"
  I0502 08:12:50.305369 23 delete.go:95] Deleting pod "simpletest.rc-zj2tj" in namespace "gc-8068"
  I0502 08:12:50.325942 23 delete.go:95] Deleting pod "simpletest.rc-zqdns" in namespace "gc-8068"
  I0502 08:12:50.356865 23 delete.go:95] Deleting pod "simpletest.rc-zrgfn" in namespace "gc-8068"
  I0502 08:12:50.418656 23 delete.go:95] Deleting pod "simpletest.rc-zxd77" in namespace "gc-8068"
  I0502 08:12:50.506030 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8068" for this suite. @ 05/02/24 08:12:50.517
• [43.866 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 05/02/24 08:12:50.555
  I0502 08:12:50.555163 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:12:50.555
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:12:50.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:12:50.591
  STEP: Creating configMap with name projected-configmap-test-volume-map-a67ddac7-2a03-47c4-b24a-9acf03448a0e @ 05/02/24 08:12:50.593
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:12:50.597
  STEP: Saw pod success @ 05/02/24 08:12:54.622
  I0502 08:12:54.625252 23 output.go:196] Trying to get logs from node mini-2 pod pod-projected-configmaps-f2e09c4c-0aa0-4d74-beb0-bccd2fbf376d container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:12:54.629
  I0502 08:12:54.644922 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7647" for this suite. @ 05/02/24 08:12:54.648
• [4.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 05/02/24 08:12:54.662
  I0502 08:12:54.662629 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename podtemplate @ 05/02/24 08:12:54.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:12:54.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:12:54.689
  STEP: Create a pod template @ 05/02/24 08:12:54.69
  STEP: Replace a pod template @ 05/02/24 08:12:54.697
  I0502 08:12:54.705062 23 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I0502 08:12:54.705113 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9465" for this suite. @ 05/02/24 08:12:54.711
• [0.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 05/02/24 08:12:54.723
  I0502 08:12:54.723315 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replication-controller @ 05/02/24 08:12:54.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:12:54.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:12:54.753
  STEP: creating a ReplicationController @ 05/02/24 08:12:54.758
  STEP: waiting for RC to be added @ 05/02/24 08:12:54.763
  STEP: waiting for available Replicas @ 05/02/24 08:12:54.763
  STEP: patching ReplicationController @ 05/02/24 08:12:56.918
  STEP: waiting for RC to be modified @ 05/02/24 08:12:56.927
  STEP: patching ReplicationController status @ 05/02/24 08:12:56.927
  STEP: waiting for RC to be modified @ 05/02/24 08:12:56.934
  STEP: waiting for available Replicas @ 05/02/24 08:12:56.934
  STEP: fetching ReplicationController status @ 05/02/24 08:12:56.938
  STEP: patching ReplicationController scale @ 05/02/24 08:12:56.941
  STEP: waiting for RC to be modified @ 05/02/24 08:12:56.949
  STEP: waiting for ReplicationController's scale to be the max amount @ 05/02/24 08:12:56.949
  STEP: fetching ReplicationController; ensuring that it's patched @ 05/02/24 08:12:58.79
  STEP: updating ReplicationController status @ 05/02/24 08:12:58.793
  STEP: waiting for RC to be modified @ 05/02/24 08:12:58.8
  STEP: listing all ReplicationControllers @ 05/02/24 08:12:58.8
  STEP: checking that ReplicationController has expected values @ 05/02/24 08:12:58.803
  STEP: deleting ReplicationControllers by collection @ 05/02/24 08:12:58.803
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 05/02/24 08:12:58.812
  I0502 08:12:58.872270 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0502 08:12:58.872339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-1065" for this suite. @ 05/02/24 08:12:58.876
• [4.160 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 05/02/24 08:12:58.883
  I0502 08:12:58.883324 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename field-validation @ 05/02/24 08:12:58.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:12:58.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:12:58.905
  I0502 08:12:58.907814 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:12:59.872429      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:00.873020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0502 08:13:01.448365      23 warnings.go:70] unknown field "alpha"
  W0502 08:13:01.448393      23 warnings.go:70] unknown field "beta"
  W0502 08:13:01.448396      23 warnings.go:70] unknown field "delta"
  W0502 08:13:01.448399      23 warnings.go:70] unknown field "epsilon"
  W0502 08:13:01.448402      23 warnings.go:70] unknown field "gamma"
  E0502 08:13:01.873127      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:13:01.981979 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4618" for this suite. @ 05/02/24 08:13:01.987
• [3.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 05/02/24 08:13:01.993
  I0502 08:13:01.993645 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:13:01.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:13:02.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:13:02.015
  STEP: creating a ConfigMap @ 05/02/24 08:13:02.016
  STEP: fetching the ConfigMap @ 05/02/24 08:13:02.035
  STEP: patching the ConfigMap @ 05/02/24 08:13:02.038
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 05/02/24 08:13:02.043
  STEP: deleting the ConfigMap by collection with a label selector @ 05/02/24 08:13:02.046
  STEP: listing all ConfigMaps in test namespace @ 05/02/24 08:13:02.052
  I0502 08:13:02.058114 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7475" for this suite. @ 05/02/24 08:13:02.061
• [0.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 05/02/24 08:13:02.07
  I0502 08:13:02.070566 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 08:13:02.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:13:02.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:13:02.092
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 08:13:02.094
  E0502 08:13:02.874019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:03.874393      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:04.874818      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:05.875007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:13:06.114
  I0502 08:13:06.116913 23 output.go:196] Trying to get logs from node mini-1 pod downwardapi-volume-126e5595-8629-4773-9f1a-fbc34ab1697c container client-container: <nil>
  STEP: delete the pod @ 05/02/24 08:13:06.121
  I0502 08:13:06.133146 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6782" for this suite. @ 05/02/24 08:13:06.136
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 05/02/24 08:13:06.143
  I0502 08:13:06.143536 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:13:06.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:13:06.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:13:06.166
  STEP: Setting up server cert @ 05/02/24 08:13:06.189
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:13:06.419
  STEP: Deploying the webhook pod @ 05/02/24 08:13:06.427
  STEP: Wait for the deployment to be ready @ 05/02/24 08:13:06.437
  I0502 08:13:06.447630 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:13:06.875029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:07.875255      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:13:08.456762 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 13, 6, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 13, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 13, 6, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 13, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:13:08.875303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:09.876072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:13:10.46
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:13:10.476
  E0502 08:13:10.876941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:13:11.476601 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/02/24 08:13:11.533
  STEP: Creating a configMap that should be mutated @ 05/02/24 08:13:11.542
  STEP: Deleting the collection of validation webhooks @ 05/02/24 08:13:11.568
  STEP: Creating a configMap that should not be mutated @ 05/02/24 08:13:11.619
  I0502 08:13:11.681013 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-403" for this suite. @ 05/02/24 08:13:11.687
  STEP: Destroying namespace "webhook-markers-1761" for this suite. @ 05/02/24 08:13:11.697
• [5.561 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
  STEP: Creating a kubernetes client @ 05/02/24 08:13:11.705
  I0502 08:13:11.705044 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:13:11.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:13:11.721
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:13:11.723
  I0502 08:13:11.724806 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-2786 version'
  I0502 08:13:11.757355 23 builder.go:146] stderr: ""
  I0502 08:13:11.757378 23 builder.go:147] stdout: "Client Version: v1.30.0\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.30.0\n"
  I0502 08:13:11.757487 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2786" for this suite. @ 05/02/24 08:13:11.761
• [0.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:697
  STEP: Creating a kubernetes client @ 05/02/24 08:13:11.77
  I0502 08:13:11.770435 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename job @ 05/02/24 08:13:11.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:13:11.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:13:11.794
  STEP: Creating a job @ 05/02/24 08:13:11.797
  STEP: Ensuring active pods == parallelism @ 05/02/24 08:13:11.803
  E0502 08:13:11.877872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:12.878130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:13.879081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:14.879264      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:15.879501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:16.879663      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 05/02/24 08:13:17.807
  E0502 08:13:17.879670      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:13:18.322180 23 pod_client.go:141] Successfully updated pod "adopt-release-nldk2"
  STEP: Checking that the Job readopts the Pod @ 05/02/24 08:13:18.322
  E0502 08:13:18.879758      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:19.880072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 05/02/24 08:13:20.334
  I0502 08:13:20.845505 23 pod_client.go:141] Successfully updated pod "adopt-release-nldk2"
  STEP: Checking that the Job releases the Pod @ 05/02/24 08:13:20.845
  E0502 08:13:20.880143      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:21.880301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:13:22.856426 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3019" for this suite. @ 05/02/24 08:13:22.86
• [11.097 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 05/02/24 08:13:22.867
  I0502 08:13:22.867834 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:13:22.868
  E0502 08:13:22.881260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:13:22.885
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:13:22.887
  STEP: Setting up server cert @ 05/02/24 08:13:22.909
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:13:23.441
  STEP: Deploying the webhook pod @ 05/02/24 08:13:23.446
  STEP: Wait for the deployment to be ready @ 05/02/24 08:13:23.456
  I0502 08:13:23.464484 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:13:23.881932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:24.882265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:13:25.473510 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 13, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 13, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 13, 23, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 13, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:13:25.882948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:26.883101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:13:27.477
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:13:27.489
  E0502 08:13:27.883150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:13:28.489915 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 05/02/24 08:13:28.496
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 05/02/24 08:13:28.51
  STEP: Creating a configMap that should not be mutated @ 05/02/24 08:13:28.515
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 05/02/24 08:13:28.523
  STEP: Creating a configMap that should be mutated @ 05/02/24 08:13:28.528
  I0502 08:13:28.597495 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2474" for this suite. @ 05/02/24 08:13:28.606
  STEP: Destroying namespace "webhook-markers-3582" for this suite. @ 05/02/24 08:13:28.621
• [5.762 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 05/02/24 08:13:28.63
  I0502 08:13:28.630124 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-preemption @ 05/02/24 08:13:28.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:13:28.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:13:28.7
  I0502 08:13:28.715448 23 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0502 08:13:28.883722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:29.884096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:30.884664      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:31.884834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:32.885842      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:33.886646      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:34.887590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:35.887725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:36.888008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:37.888123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:38.889116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:39.889460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:40.889767      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:41.889963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:42.890286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:43.890414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:44.890955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:45.891099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:46.891686      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:47.892103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:48.892410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:49.892701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:50.893414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:51.893602      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:52.894117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:53.894261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:54.895260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:55.895411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:56.895456      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:57.895604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:58.896225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:13:59.897095      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:00.897503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:01.897665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:02.898723      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:03.898914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:04.899558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:05.899700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:06.900636      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:07.901160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:08.901344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:09.901652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:10.902313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:11.903037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:12.903430      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:13.903560      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:14.904517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:15.904655      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:16.904785      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:17.905548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:18.906496      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:19.906819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:20.906860      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:21.906980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:22.907565      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:23.907665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:24.908486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:25.909059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:26.909198      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:27.909338      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:14:28.721403 23 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/02/24 08:14:28.725
  I0502 08:14:28.750931 23 preemption.go:178] Created pod: pod0-0-sched-preemption-low-priority
  I0502 08:14:28.763121 23 preemption.go:178] Created pod: pod0-1-sched-preemption-medium-priority
  I0502 08:14:28.802534 23 preemption.go:178] Created pod: pod1-0-sched-preemption-medium-priority
  I0502 08:14:28.813923 23 preemption.go:178] Created pod: pod1-1-sched-preemption-medium-priority
  I0502 08:14:28.849262 23 preemption.go:178] Created pod: pod2-0-sched-preemption-medium-priority
  I0502 08:14:28.878232 23 preemption.go:178] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/02/24 08:14:28.878
  E0502 08:14:28.909581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:29.909839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:30.910220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:31.910373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:32.910499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:33.911275      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:34.911470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 05/02/24 08:14:34.917
  E0502 08:14:35.912149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:36.912297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:37.913002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:38.913359      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:14:39.010182 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2718" for this suite. @ 05/02/24 08:14:39.014
• [70.393 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 05/02/24 08:14:39.023
  I0502 08:14:39.023321 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replication-controller @ 05/02/24 08:14:39.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:14:39.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:14:39.047
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 05/02/24 08:14:39.049
  E0502 08:14:39.914249      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:40.914383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 05/02/24 08:14:41.075
  STEP: Then the orphan pod is adopted @ 05/02/24 08:14:41.081
  E0502 08:14:41.915101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:14:42.089325 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6386" for this suite. @ 05/02/24 08:14:42.093
• [3.079 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 05/02/24 08:14:42.102
  I0502 08:14:42.102136 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/02/24 08:14:42.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:14:42.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:14:42.124
  STEP: creating a target pod @ 05/02/24 08:14:42.126
  E0502 08:14:42.915794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:43.915920      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:44.916034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:45.916190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 05/02/24 08:14:46.169
  E0502 08:14:46.917054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:47.917380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:48.918270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:49.918478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 05/02/24 08:14:50.196
  I0502 08:14:50.196321 23 exec_util.go:55] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-8452 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:14:50.196348 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:14:50.196694 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:14:50.196726 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-8452/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0502 08:14:50.247210 23 exec_util.go:106] Exec stderr: ""
  I0502 08:14:50.258480 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-8452" for this suite. @ 05/02/24 08:14:50.263
• [8.170 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 05/02/24 08:14:50.271
  I0502 08:14:50.271955 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 08:14:50.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:14:50.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:14:50.292
  STEP: Creating secret with name secret-test-map-c8e77dc0-67db-4859-96d3-ec4977b9dcfd @ 05/02/24 08:14:50.294
  STEP: Creating a pod to test consume secrets @ 05/02/24 08:14:50.3
  E0502 08:14:50.919492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:51.919647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:52.919791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:53.919958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:14:54.324
  I0502 08:14:54.327697 23 output.go:196] Trying to get logs from node mini-1 pod pod-secrets-b8f6e79c-6dc6-4bdb-a4bf-c22890980724 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 08:14:54.337
  I0502 08:14:54.354672 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5518" for this suite. @ 05/02/24 08:14:54.358
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 05/02/24 08:14:54.366
  I0502 08:14:54.366375 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename hostport @ 05/02/24 08:14:54.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:14:54.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:14:54.392
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 05/02/24 08:14:54.398
  E0502 08:14:54.920909      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:55.921043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.221.190.32 on the node which pod1 resides and expect scheduled @ 05/02/24 08:14:56.426
  E0502 08:14:56.921802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:57.921963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:58.922866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:14:59.923178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.221.190.32 but use UDP protocol on the node which pod2 resides @ 05/02/24 08:15:00.449
  E0502 08:15:00.923560      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:01.923703      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:02.923887      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:03.924036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 05/02/24 08:15:04.489
  I0502 08:15:04.489321 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.221.190.32 http://127.0.0.1:54323/hostname] Namespace:hostport-868 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:15:04.489346 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:15:04.489659 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:15:04.489718 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-868/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.221.190.32+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.221.190.32, port: 54323 @ 05/02/24 08:15:04.523
  I0502 08:15:04.523031 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.221.190.32:54323/hostname] Namespace:hostport-868 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:15:04.523039 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:15:04.523343 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:15:04.523381 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-868/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.221.190.32%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.221.190.32, port: 54323 UDP @ 05/02/24 08:15:04.56
  I0502 08:15:04.560623 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.221.190.32 54323] Namespace:hostport-868 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:15:04.560633 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:15:04.560840 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:15:04.560904 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-868/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.221.190.32+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0502 08:15:04.924324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:05.924451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:06.924607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:07.925510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:08.925804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:09.602780 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-868" for this suite. @ 05/02/24 08:15:09.608
• [15.251 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 05/02/24 08:15:09.617
  I0502 08:15:09.617713 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename dns @ 05/02/24 08:15:09.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:15:09.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:15:09.639
  STEP: Creating a test headless service @ 05/02/24 08:15:09.641
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local;sleep 1; done
   @ 05/02/24 08:15:09.646
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-76.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-76.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local;sleep 1; done
   @ 05/02/24 08:15:09.646
  STEP: creating a pod to probe DNS @ 05/02/24 08:15:09.646
  STEP: submitting the pod to kubernetes @ 05/02/24 08:15:09.646
  E0502 08:15:09.926238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:10.926472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:11.926956      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:12.927098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:13.928097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:14.928346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:15.929298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:16.929462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/02/24 08:15:17.685
  STEP: looking for the results for each expected name from probers @ 05/02/24 08:15:17.688
  I0502 08:15:17.692687 23 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:17.696011 23 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:17.699220 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:17.702168 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:17.704853 23 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:17.707792 23 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:17.710935 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:17.713966 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:17.713977 23 dns_common.go:489] Lookups using dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local]

  I0502 08:15:17.720931 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 08:15:17.725920 23 dns_common.go:495] Pod client logs for querier: 
  I0502 08:15:17.731126 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 08:15:17.930426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:18.930699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:19.931001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:20.931461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:21.931627      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:22.694258 23 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:22.698095 23 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:22.701776 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:22.704870 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:22.707959 23 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:22.711200 23 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:22.714395 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:22.717303 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:22.717315 23 dns_common.go:489] Lookups using dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local]

  I0502 08:15:22.722119 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 08:15:22.726857 23 dns_common.go:495] Pod client logs for querier: 
  I0502 08:15:22.731404 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 08:15:22.931705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:23.931836      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:24.932176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:25.933065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:26.933333      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:27.694001 23 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:27.697383 23 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:27.700873 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:27.704227 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:27.707997 23 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:27.711279 23 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:27.714462 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:27.717290 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:27.717331 23 dns_common.go:489] Lookups using dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local]

  I0502 08:15:27.722379 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 08:15:27.726514 23 dns_common.go:495] Pod client logs for querier: 
  I0502 08:15:27.730927 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 08:15:27.934218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:28.934566      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:29.934788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:30.934930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:31.935073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:32.704273 23 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:32.709750 23 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:32.715063 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:32.718524 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:32.721927 23 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:32.725403 23 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:32.728545 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:32.731811 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:32.731837 23 dns_common.go:489] Lookups using dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local]

  I0502 08:15:32.736818 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 08:15:32.741621 23 dns_common.go:495] Pod client logs for querier: 
  I0502 08:15:32.746366 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 08:15:32.935690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:33.935897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:34.936929      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:35.937072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:36.937298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:37.693396 23 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:37.696938 23 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:37.700271 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:37.703305 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:37.706328 23 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:37.709737 23 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:37.712741 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:37.716260 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:37.716288 23 dns_common.go:489] Lookups using dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local wheezy_udp@dns-test-service-2.dns-76.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local jessie_udp@dns-test-service-2.dns-76.svc.cluster.local jessie_tcp@dns-test-service-2.dns-76.svc.cluster.local]

  I0502 08:15:37.721815 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 08:15:37.727710 23 dns_common.go:495] Pod client logs for querier: 
  I0502 08:15:37.732917 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 08:15:37.938278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:38.939292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:39.939498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:40.939638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:41.939785      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:42.693643 23 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local from pod dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2: the server could not find the requested resource (get pods dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2)
  I0502 08:15:42.720489 23 dns_common.go:489] Lookups using dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-76.svc.cluster.local]

  I0502 08:15:42.725874 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 08:15:42.730747 23 dns_common.go:495] Pod client logs for querier: 
  I0502 08:15:42.735015 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 08:15:42.940411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:43.940583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:44.940965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:45.941106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:46.941365      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:47.719574 23 dns_common.go:527] DNS probes using dns-76/dns-test-f0fbd38b-ab46-46ac-ad62-298ee8869aa2 succeeded

  STEP: deleting the pod @ 05/02/24 08:15:47.719
  STEP: deleting the test headless service @ 05/02/24 08:15:47.733
  I0502 08:15:47.760931 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-76" for this suite. @ 05/02/24 08:15:47.766
• [38.163 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 05/02/24 08:15:47.781
  I0502 08:15:47.781105 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename deployment @ 05/02/24 08:15:47.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:15:47.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:15:47.808
  STEP: creating a Deployment @ 05/02/24 08:15:47.815
  STEP: waiting for Deployment to be created @ 05/02/24 08:15:47.821
  STEP: waiting for all Replicas to be Ready @ 05/02/24 08:15:47.823
  I0502 08:15:47.824654 23 deployment.go:246] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0502 08:15:47.824665 23 deployment.go:248] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0502 08:15:47.832690 23 deployment.go:246] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0502 08:15:47.832727 23 deployment.go:248] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0502 08:15:47.855229 23 deployment.go:246] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0502 08:15:47.855240 23 deployment.go:248] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0502 08:15:47.892215 23 deployment.go:246] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0502 08:15:47.892231 23 deployment.go:248] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0502 08:15:47.942354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:48.942969      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:49.054130 23 deployment.go:246] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0502 08:15:49.054150 23 deployment.go:248] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0502 08:15:49.197393 23 deployment.go:248] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 05/02/24 08:15:49.197
  I0502 08:15:49.211729 23 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 05/02/24 08:15:49.211
  I0502 08:15:49.213278 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0
  I0502 08:15:49.213290 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0
  I0502 08:15:49.213298 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0
  I0502 08:15:49.213303 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0
  I0502 08:15:49.213309 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0
  I0502 08:15:49.213313 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0
  I0502 08:15:49.213343 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0
  I0502 08:15:49.213354 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 0
  I0502 08:15:49.213386 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:49.213395 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:49.213400 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:49.213404 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:49.213410 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:49.213415 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:49.221687 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:49.221699 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:49.251699 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:49.251709 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:49.288044 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:49.288067 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:49.295956 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:49.295979 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  E0502 08:15:49.943755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:50.943935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:51.070194 23 deployment.go:309] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:51.070220 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:51.091948 23 deployment.go:311] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  STEP: listing Deployments @ 05/02/24 08:15:51.091
  I0502 08:15:51.095982 23 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 05/02/24 08:15:51.096
  I0502 08:15:51.104550 23 deployment.go:360] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 05/02/24 08:15:51.104
  I0502 08:15:51.110926 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0502 08:15:51.117785 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0502 08:15:51.138041 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0502 08:15:51.160980 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0502 08:15:51.166044 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0502 08:15:51.944930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:52.915443 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0502 08:15:52.945091 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0502 08:15:52.945142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:52.958500 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0502 08:15:52.966369 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0502 08:15:53.946173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:54.946592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:15:55.079500 23 deployment.go:389] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 05/02/24 08:15:55.111
  STEP: fetching the DeploymentStatus @ 05/02/24 08:15:55.121
  I0502 08:15:55.127561 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:55.127600 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:55.127611 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:55.127650 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:55.127662 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 1
  I0502 08:15:55.127669 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:55.127719 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:55.127730 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:55.127736 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 2
  I0502 08:15:55.127782 23 deployment.go:449] observed Deployment test-deployment in namespace deployment-7752 with ReadyReplicas 3
  STEP: deleting the Deployment @ 05/02/24 08:15:55.127
  I0502 08:15:55.136151 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136215 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136231 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136282 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136292 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136299 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136320 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136371 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136384 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136391 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136447 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136460 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.136469 23 deployment.go:475] observed event type MODIFIED
  I0502 08:15:55.141094 23 deployment.go:650] Log out all the ReplicaSets if there is no deployment created
  I0502 08:15:55.146416 23 deployment.go:657] ReplicaSet "test-deployment-65fbf5b65d":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-65fbf5b65d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7752",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "487d37d2-307b-461f-9a6d-c117e17c4227",
      ResourceVersion: (string) (len=5) "10213",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "0e6bfe28-9987-45b4-a08b-03a5e8aa93f2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 30 65 36 62  66 65 32 38 2d 39 39 38  |":\"0e6bfe28-998|
              00000130  37 2d 34 35 62 34 2d 61  30 38 62 2d 30 33 61 35  |7-45b4-a08b-03a5|
              00000140  65 38 61 61 39 33 66 32  5c 22 7d 22 3a 7b 7d 7d  |e8aa93f2\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=22) "test-deployment-static": (string) (len=4) "true",
            (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=25) "registry.k8s.io/pause:3.9",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0502 08:15:55.151843 23 deployment.go:669] pod: "test-deployment-65fbf5b65d-c48xg":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-65fbf5b65d-c48xg",
      GenerateName: (string) (len=27) "test-deployment-65fbf5b65d-",
      Namespace: (string) (len=15) "deployment-7752",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f5927d7c-394c-4a56-affa-f4c09dee207a",
      ResourceVersion: (string) (len=5) "10200",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234554,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "663182aa634b87b15b44332908324dfdbaf49b54cb15dce179eb71a05eb7fb2c",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) "",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) ""
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-65fbf5b65d",
          UID: (types.UID) (len=36) "487d37d2-307b-461f-9a6d-c117e17c4227",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  34 38 37 64 33 37 64 32  |uid\":\"487d37d2|
              000000a0  2d 33 30 37 62 2d 34 36  31 66 2d 39 61 36 64 2d  |-307b-461f-9a6d-|
              000000b0  63 31 31 37 65 31 37 63  34 32 32 37 5c 22 7d 22  |c117e17c4227\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=621) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 72 65 61 73 6f 6e  |me":{},"f:reason|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000090  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              000000a0  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 49  |"k:{\"type\":\"I|
              000000b0  6e 69 74 69 61 6c 69 7a  65 64 5c 22 7d 22 3a 7b  |nitialized\"}":{|
              000000c0  22 2e 22 3a 7b 7d 2c 22  66 3a 6c 61 73 74 50 72  |".":{},"f:lastPr|
              000000d0  6f 62 65 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |obeTime":{},"f:l|
              000000e0  61 73 74 54 72 61 6e 73  69 74 69 6f 6e 54 69 6d  |astTransitionTim|
              000000f0  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000100  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000110  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              00000120  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 50 6f  |k:{\"type\":\"Po|
              00000130  64 52 65 61 64 79 54 6f  53 74 61 72 74 43 6f 6e  |dReadyToStartCon|
              00000140  74 61 69 6e 65 72 73 5c  22 7d 22 3a 7b 22 2e 22  |tainers\"}":{"."|
              00000150  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000160  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000170  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000180  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000190  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 2c 22 6b  |,"f:type":{}},"k|
              000001a0  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 52 65 61  |:{\"type\":\"Rea|
              000001b0  64 79 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |dy\"}":{".":{},"|
              000001c0  66 3a 6c 61 73 74 50 72  6f 62 65 54 69 6d 65 22  |f:lastProbeTime"|
              000001d0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 54 72 61 6e 73  |:{},"f:lastTrans|
              000001e0  69 74 69 6f 6e 54 69 6d  65 22 3a 7b 7d 2c 22 66  |itionTime":{},"f|
              000001f0  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000200  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000210  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000220  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000230  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000240  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000250  3a 70 68 61 73 65 22 3a  7b 7d 2c 22 66 3a 73 74  |:phase":{},"f:st|
              00000260  61 72 74 54 69 6d 65 22  3a 7b 7d 7d 7d           |artTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n9tc7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n9tc7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=9) "Succeeded",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=12) "PodCompleted",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=12) "PodCompleted",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=12) "PodCompleted",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)({
              ExitCode: (int32) 0,
              Signal: (int32) 0,
              Reason: (string) (len=9) "Completed",
              Message: (string) "",
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234552,
                  loc: (*time.Location)(<already shown>)
                }
              },
              FinishedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234554,
                  loc: (*time.Location)(<already shown>)
                }
              },
              ContainerID: (string) (len=77) "containerd://7a0bd51ad0227453f33db03e15f17e635702ebf0d99c31f38752ae4ae270f207"
            })
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=77) "containerd://7a0bd51ad0227453f33db03e15f17e635702ebf0d99c31f38752ae4ae270f207",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0502 08:15:55.153708 23 deployment.go:669] pod: "test-deployment-65fbf5b65d-fvkfh":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-65fbf5b65d-fvkfh",
      GenerateName: (string) (len=27) "test-deployment-65fbf5b65d-",
      Namespace: (string) (len=15) "deployment-7752",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0a5c32a8-3118-4545-a72d-955233ef84c7",
      ResourceVersion: (string) (len=5) "10209",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234557,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "ebbe8ada9b314d60bda343162e268c40cdf129cc6a401f702cc26b73c0fbd756",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.125.249/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.125.249/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-65fbf5b65d",
          UID: (types.UID) (len=36) "487d37d2-307b-461f-9a6d-c117e17c4227",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  34 38 37 64 33 37 64 32  |uid\":\"487d37d2|
              000000a0  2d 33 30 37 62 2d 34 36  31 66 2d 39 61 36 64 2d  |-307b-461f-9a6d-|
              000000b0  63 31 31 37 65 31 37 63  34 32 32 37 5c 22 7d 22  |c117e17c4227\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  35 2e 32 34 39 5c 22 7d  |2.168.125.249\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rhxq9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rhxq9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234549,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) (len=15) "192.168.125.249",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.125.249"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234549,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234550,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=77) "containerd://646aa06d681c8532c2ed9be9b0260bf37fc8101fd78ec9c55373be1f3a274a5a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0502 08:15:55.155432 23 deployment.go:657] ReplicaSet "test-deployment-6b9f8f4d48":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-6b9f8f4d48",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7752",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b67ce417-749d-4133-b676-5bb3c6400429",
      ResourceVersion: (string) (len=5) "10205",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "0e6bfe28-9987-45b4-a08b-03a5e8aa93f2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234552,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 30 65 36 62  66 65 32 38 2d 39 39 38  |":\"0e6bfe28-998|
              00000130  37 2d 34 35 62 34 2d 61  30 38 62 2d 30 33 61 35  |7-45b4-a08b-03a5|
              00000140  65 38 61 61 39 33 66 32  5c 22 7d 22 3a 7b 7d 7d  |e8aa93f2\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0502 08:15:55.161928 23 deployment.go:669] pod: "test-deployment-6b9f8f4d48-n5fpk":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6b9f8f4d48-n5fpk",
      GenerateName: (string) (len=27) "test-deployment-6b9f8f4d48-",
      Namespace: (string) (len=15) "deployment-7752",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bc3b05df-b1df-44b8-b039-6a255cfc7b82",
      ResourceVersion: (string) (len=5) "10147",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "192.168.32.40/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "192.168.32.40/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "109e2794169dda6a39f9fbe8219252cf2222ecb3af4ec09d91f484652a81fcf5"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6b9f8f4d48",
          UID: (types.UID) (len=36) "b67ce417-749d-4133-b676-5bb3c6400429",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  62 36 37 63 65 34 31 37  |uid\":\"b67ce417|
              000000a0  2d 37 34 39 64 2d 34 31  33 33 2d 62 36 37 36 2d  |-749d-4133-b676-|
              000000b0  35 62 62 33 63 36 34 30  30 34 32 39 5c 22 7d 22  |5bb3c6400429\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234552,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 32  2e 34 30 5c 22 7d 22 3a  |2.168.32.40\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-v6jrw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-v6jrw",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234552,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234552,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234552,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234551,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.33",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.33"
        }
      },
      PodIP: (string) (len=13) "192.168.32.40",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.32.40"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234551,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234552,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://6b30946066a49dae14a072a22724cc14fe3c1bc9d6c03b065198185134aec536",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0502 08:15:55.163758 23 deployment.go:669] pod: "test-deployment-6b9f8f4d48-vhz46":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6b9f8f4d48-vhz46",
      GenerateName: (string) (len=27) "test-deployment-6b9f8f4d48-",
      Namespace: (string) (len=15) "deployment-7752",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d019e6bb-f3d4-4387-aac8-ee4a4f69fa42",
      ResourceVersion: (string) (len=5) "10204",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234552,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "74a36f1f249438d07b578182da2140c43e3171cee0f02c1edbcf24cb4714610c",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.125.250/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.125.250/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6b9f8f4d48",
          UID: (types.UID) (len=36) "b67ce417-749d-4133-b676-5bb3c6400429",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234552,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  62 36 37 63 65 34 31 37  |uid\":\"b67ce417|
              000000a0  2d 37 34 39 64 2d 34 31  33 33 2d 62 36 37 36 2d  |-749d-4133-b676-|
              000000b0  35 62 62 33 63 36 34 30  30 34 32 39 5c 22 7d 22  |5bb3c6400429\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234553,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  35 2e 32 35 30 5c 22 7d  |2.168.125.250\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nxm69",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nxm69",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234552,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234555,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234552,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) (len=15) "192.168.125.250",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.125.250"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234552,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234554,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://6e8a2fbad8ec330330e43be8a54a93df993a6743f9102eef45899a6cc75fed0b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0502 08:15:55.165335 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7752" for this suite. @ 05/02/24 08:15:55.17
• [7.398 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 05/02/24 08:15:55.179
  I0502 08:15:55.179722 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 08:15:55.18
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:15:55.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:15:55.203
  STEP: Create a pod @ 05/02/24 08:15:55.206
  E0502 08:15:55.946986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:56.947252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 05/02/24 08:15:57.227
  I0502 08:15:57.239251 23 pods.go:1124] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0502 08:15:57.239321 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4280" for this suite. @ 05/02/24 08:15:57.244
• [2.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 05/02/24 08:15:57.253
  I0502 08:15:57.253059 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename deployment @ 05/02/24 08:15:57.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:15:57.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:15:57.476
  I0502 08:15:57.488123 23 resource.go:87] Pod name cleanup-pod: Found 0 pods out of 1
  E0502 08:15:57.947870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:58.948875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:15:59.949230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:00.949377      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:01.949560      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:02.492213 23 resource.go:87] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/02/24 08:16:02.492
  I0502 08:16:02.492273 23 deployment.go:841] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 05/02/24 08:16:02.503
  I0502 08:16:02.521327 23 deployment.go:633] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9935",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "73532e90-826e-4b53-ad9c-aec7a2021ce5",
      ResourceVersion: (string) (len=5) "10369",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234562,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0502 08:16:02.528396 23 deployment.go:39] New ReplicaSet "test-cleanup-deployment-7c4d497584" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-7c4d497584",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9935",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9420cb32-fcd4-411b-9588-89238baa1ccf",
      ResourceVersion: (string) (len=5) "10373",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234562,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "73532e90-826e-4b53-ad9c-aec7a2021ce5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 33 35 33 32 65  39 30 2d 38 32 36 65 2d  |\"73532e90-826e-|
              00000120  34 62 35 33 2d 61 64 39  63 2d 61 65 63 37 61 32  |4b53-ad9c-aec7a2|
              00000130  30 32 31 63 65 35 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |021ce5\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 0,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:16:02.529151 23 deployment.go:44] All old ReplicaSets of Deployment "test-cleanup-deployment":
  I0502 08:16:02.529272 23 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9935",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ef4248d0-8ef8-4cdc-aeaa-181d36b63638",
      ResourceVersion: (string) (len=5) "10371",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234557,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "73532e90-826e-4b53-ad9c-aec7a2021ce5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234557,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234559,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 37 33 35 33 32 65 39  |"uid\":\"73532e9|
              00000040  30 2d 38 32 36 65 2d 34  62 35 33 2d 61 64 39 63  |0-826e-4b53-ad9c|
              00000050  2d 61 65 63 37 61 32 30  32 31 63 65 35 5c 22 7d  |-aec7a2021ce5\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=5) "httpd",
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:16:02.546070 23 deployment.go:67] Pod "test-cleanup-controller-vg82h" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-vg82h",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-9935",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "faf6b288-35d2-4d85-b997-5c382d195ca7",
      ResourceVersion: (string) (len=5) "10303",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234557,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "76e8afeea46768c957591b70b6ff4154e8f5e7b39ff243973351899c217e38ba",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.125.251/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.125.251/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "ef4248d0-8ef8-4cdc-aeaa-181d36b63638",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234557,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234557,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  65 66 34 32 34 38 64 30  |uid\":\"ef4248d0|
              00000080  2d 38 65 66 38 2d 34 63  64 63 2d 61 65 61 61 2d  |-8ef8-4cdc-aeaa-|
              00000090  31 38 31 64 33 36 62 36  33 36 33 38 5c 22 7d 22  |181d36b63638\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234559,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  35 2e 32 35 31 5c 22 7d  |2.168.125.251\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w2qzv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w2qzv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234559,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234557,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234559,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234559,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234557,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) (len=15) "192.168.125.251",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.125.251"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234557,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234558,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://92b34a22e8bba0b24af43ee80d57f9fa8526ae9c9a8c7821f38f7af245e59bfa",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:16:02.547754 23 deployment.go:67] Pod "test-cleanup-deployment-7c4d497584-95dlp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-7c4d497584-95dlp",
      GenerateName: (string) (len=35) "test-cleanup-deployment-7c4d497584-",
      Namespace: (string) (len=15) "deployment-9935",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7ae05609-d95f-4e0b-9ba3-383cd61bb00b",
      ResourceVersion: (string) (len=5) "10376",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234562,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-7c4d497584",
          UID: (types.UID) (len=36) "9420cb32-fcd4-411b-9588-89238baa1ccf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 34  32 30 63 62 33 32 2d 66  |d\":\"9420cb32-f|
              00000090  63 64 34 2d 34 31 31 62  2d 39 35 38 38 2d 38 39  |cd4-411b-9588-89|
              000000a0  32 33 38 62 61 61 31 63  63 66 5c 22 7d 22 3a 7b  |238baa1ccf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vs29c",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vs29c",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:16:02.548624 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9935" for this suite. @ 05/02/24 08:16:02.575
• [5.340 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 05/02/24 08:16:02.593
  I0502 08:16:02.593508 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 08:16:02.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:16:02.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:16:02.699
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 08:16:02.701
  E0502 08:16:02.949614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:03.949768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:04.950323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:05.951083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:16:06.737
  I0502 08:16:06.740252 23 output.go:196] Trying to get logs from node mini-2 pod downwardapi-volume-b1d6a968-3707-40cc-99d2-2d6edddbfe0a container client-container: <nil>
  STEP: delete the pod @ 05/02/24 08:16:06.748
  I0502 08:16:06.765655 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1628" for this suite. @ 05/02/24 08:16:06.769
• [4.186 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1459
  STEP: Creating a kubernetes client @ 05/02/24 08:16:06.779
  I0502 08:16:06.779727 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 08:16:06.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:16:06.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:16:06.8
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1166 @ 05/02/24 08:16:06.802
  STEP: changing the ExternalName service to type=NodePort @ 05/02/24 08:16:06.807
  STEP: creating replication controller externalname-service in namespace services-1166 @ 05/02/24 08:16:06.834
  I0502 08:16:06.847251      23 runners.go:198] Created replication controller with name: externalname-service, namespace: services-1166, replica count: 2
  E0502 08:16:06.951358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:07.951553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:08.952356      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:09.897524      23 runners.go:198] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0502 08:16:09.897561 23 resource.go:361] Creating new exec pod
  E0502 08:16:09.953160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:10.953328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:11.953584      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:12.922703 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1166 exec execpod6c9hm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0502 08:16:12.954067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:13.009163 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0502 08:16:13.009183 23 builder.go:147] stdout: ""
  I0502 08:16:13.923210 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1166 exec execpod6c9hm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0502 08:16:13.954562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:14.024737 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0502 08:16:14.024760 23 builder.go:147] stdout: "externalname-service-mvvzw"
  I0502 08:16:14.024809 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1166 exec execpod6c9hm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.31.119 80'
  I0502 08:16:14.100421 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.98.31.119 80\nConnection to 10.98.31.119 80 port [tcp/http] succeeded!\n"
  I0502 08:16:14.100446 23 builder.go:147] stdout: "externalname-service-84vkg"
  I0502 08:16:14.100488 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1166 exec execpod6c9hm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.31 32281'
  I0502 08:16:14.177914 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.31 32281\nConnection to 10.221.190.31 32281 port [tcp/*] succeeded!\n"
  I0502 08:16:14.177939 23 builder.go:147] stdout: "externalname-service-84vkg"
  I0502 08:16:14.177978 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1166 exec execpod6c9hm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 32281'
  I0502 08:16:14.248439 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 32281\nConnection to 10.221.190.32 32281 port [tcp/*] succeeded!\n"
  I0502 08:16:14.248462 23 builder.go:147] stdout: ""
  E0502 08:16:14.955245      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:15.178663 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1166 exec execpod6c9hm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 32281'
  I0502 08:16:15.264784 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 32281\nConnection to 10.221.190.32 32281 port [tcp/*] succeeded!\n"
  I0502 08:16:15.264808 23 builder.go:147] stdout: ""
  E0502 08:16:15.955550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:16.178929 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1166 exec execpod6c9hm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 32281'
  I0502 08:16:16.258002 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 32281\nConnection to 10.221.190.32 32281 port [tcp/*] succeeded!\n"
  I0502 08:16:16.258051 23 builder.go:147] stdout: ""
  E0502 08:16:16.955806      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:17.178141 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1166 exec execpod6c9hm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 32281'
  I0502 08:16:17.249449 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 32281\nConnection to 10.221.190.32 32281 port [tcp/*] succeeded!\n"
  I0502 08:16:17.249516 23 builder.go:147] stdout: ""
  E0502 08:16:17.956217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:18.178646 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1166 exec execpod6c9hm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 32281'
  I0502 08:16:18.250775 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 32281\nConnection to 10.221.190.32 32281 port [tcp/*] succeeded!\n"
  I0502 08:16:18.250800 23 builder.go:147] stdout: "externalname-service-mvvzw"
  I0502 08:16:18.250866 23 service.go:1468] Cleaning up the ExternalName to NodePort test service
  I0502 08:16:18.291450 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1166" for this suite. @ 05/02/24 08:16:18.296
• [11.527 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 05/02/24 08:16:18.307
  I0502 08:16:18.307247 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename svcaccounts @ 05/02/24 08:16:18.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:16:18.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:16:18.332
  I0502 08:16:18.358614 23 service_accounts.go:253] created pod pod-service-account-defaultsa
  I0502 08:16:18.358626 23 service_accounts.go:267] pod pod-service-account-defaultsa service account token volume mount: true
  I0502 08:16:18.369783 23 service_accounts.go:253] created pod pod-service-account-mountsa
  I0502 08:16:18.369800 23 service_accounts.go:267] pod pod-service-account-mountsa service account token volume mount: true
  I0502 08:16:18.376702 23 service_accounts.go:253] created pod pod-service-account-nomountsa
  I0502 08:16:18.376715 23 service_accounts.go:267] pod pod-service-account-nomountsa service account token volume mount: false
  I0502 08:16:18.387317 23 service_accounts.go:253] created pod pod-service-account-defaultsa-mountspec
  I0502 08:16:18.387330 23 service_accounts.go:267] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0502 08:16:18.404861 23 service_accounts.go:253] created pod pod-service-account-mountsa-mountspec
  I0502 08:16:18.404874 23 service_accounts.go:267] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0502 08:16:18.415625 23 service_accounts.go:253] created pod pod-service-account-nomountsa-mountspec
  I0502 08:16:18.415636 23 service_accounts.go:267] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0502 08:16:18.428981 23 service_accounts.go:253] created pod pod-service-account-defaultsa-nomountspec
  I0502 08:16:18.428992 23 service_accounts.go:267] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0502 08:16:18.441680 23 service_accounts.go:253] created pod pod-service-account-mountsa-nomountspec
  I0502 08:16:18.441691 23 service_accounts.go:267] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0502 08:16:18.452434 23 service_accounts.go:253] created pod pod-service-account-nomountsa-nomountspec
  I0502 08:16:18.452445 23 service_accounts.go:267] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0502 08:16:18.452490 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7897" for this suite. @ 05/02/24 08:16:18.483
• [0.197 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 05/02/24 08:16:18.504
  I0502 08:16:18.504538 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 08:16:18.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:16:18.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:16:18.546
  STEP: Creating pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717 @ 05/02/24 08:16:18.549
  E0502 08:16:18.956461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:19.956859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:20.957841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:21.957999      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/02/24 08:16:22.576
  I0502 08:16:22.579923 23 container_probe.go:1749] Initial restart count of pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 is 0
  I0502 08:16:22.583597 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:22.958026      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:23.959013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:24.587655 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:24.960098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:25.960255      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:26.593271 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:26.960614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:27.960789      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:28.598533 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:28.961120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:29.961370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:30.602971 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:30.962375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:31.962541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:32.607176 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:32.962541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:33.962667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:34.612084 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:34.963563      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:35.963754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:36.616718 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:36.964086      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:37.964239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:38.621334 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:38.964825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:39.965105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:40.626290 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:40.965676      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:41.966096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:42.630996 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:42.966369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:43.966522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:44.635316 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:44.966670      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:45.966841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:46.639055 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:46.967445      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:47.967588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:48.644268 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:48.967714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:49.968039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:50.648802 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:50.968998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:51.970031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:52.654501 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:52.970930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:53.971400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:54.660560 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:54.972111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:55.972245      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:56.665648 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:56.973058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:57.973230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:16:58.671095 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:16:58.973471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:16:59.973757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:00.676285 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:00.974633      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:01.974771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:02.680788 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:02.974962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:03.975008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:04.684532 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:04.975931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:05.975984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:06.688851 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:06.976076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:07.977081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:08.693363 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:08.977846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:09.977991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:10.697706 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:10.978034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:11.978172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:12.702519 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:12.978926      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:13.979054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:14.706950 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:14.979224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:15.979344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:16.712067 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:16.979424      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:17.979587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:18.717104 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:18.980473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:19.980716      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:20.722033 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:20.981052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:21.981206      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:22.727177 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:22.981375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:23.981540      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:24.732185 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:24.982538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:25.982693      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:26.736641 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:26.982812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:27.982950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:28.740802 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:28.983229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:29.983427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:30.745314 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:30.983511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:31.983640      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:32.750562 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:32.983831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:33.983959      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:34.756752 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:34.984996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:35.986010      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:36.762154 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:36.986495      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:37.986659      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:38.766776 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:38.987072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:39.987366      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:40.770979 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:40.988291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:41.989064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:42.776436 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:42.989744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:43.990032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:44.782215 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:44.990561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:45.990721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:46.786854 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:46.991068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:47.991441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:48.791475 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:48.991954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:49.992232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:50.796271 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:50.992420      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:51.992612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:52.801731 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:52.992941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:53.993098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:54.806454 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:54.993744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:55.993899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:56.811387 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:56.994638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:57.994814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:17:58.815997 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:17:58.995372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:17:59.995674      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:00.821339 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:00.996657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:01.996828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:02.826342 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:02.997379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:03.997949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:04.830599 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:04.998891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:05.999005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:06.834827 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:06.999991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:08.000154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:08.840020 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:09.000226      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:10.000475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:10.844635 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:11.000854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:12.000978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:12.849346 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:13.001598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:14.001717      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:14.853758 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:15.001978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:16.002120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:16.858148 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:17.002279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:18.002427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:18.863261 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:19.003489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:20.004258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:20.867701 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:21.005014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:22.005210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:22.872320 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:23.005515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:24.005669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:24.888408 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:25.006603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:26.007053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:26.893667 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:27.007895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:28.008055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:28.898680 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:29.008882      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:30.009210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:30.903511 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:31.009650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:32.009826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:32.907700 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:33.009799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:34.010021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:34.912160 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:35.010347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:36.010483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:36.916836 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:37.011060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:38.012071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:38.922730 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:39.012933      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:40.013023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:40.926879 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:41.014020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:42.014188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:42.931458 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:43.014593      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:44.015064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:44.935765 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:45.015918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:46.016058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:46.939784 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:47.016927      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:48.017040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:48.944273 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:49.017456      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:50.017679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:50.948175 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:51.018368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:52.018516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:52.952825 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:53.018953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:54.019058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:54.957027 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:55.019018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:56.019141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:56.961343 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:57.019486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:18:58.019619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:18:58.966019 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:18:59.020115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:00.020372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:00.971756 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:01.020882      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:02.021032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:02.976067 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:03.021151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:04.021290      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:04.980458 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:05.021603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:06.021736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:06.984960 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:07.022090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:08.022282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:08.989963 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:09.023143      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:10.023382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:10.994164 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:11.024281      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:12.024401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:12.998607 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:13.024778      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:14.024959      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:15.002940 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:15.025088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:16.025259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:17.007497 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:17.025612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:18.025746      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:19.012089 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:19.026194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:20.026644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:21.016322 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:21.027437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:22.027587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:23.020196 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:23.028281      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:24.028413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:25.024182 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:25.029362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:26.029500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:27.029288 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:27.030322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:28.030477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:29.030891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:29.034082 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:30.031247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:31.031409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:31.038292 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:32.032342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:33.032849      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:33.042376 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:34.033405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:35.034153      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:35.047093 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:36.035119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:37.035253      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:37.051438 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:38.035421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:39.035490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:39.055552 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:40.035967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:41.036145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:41.060367 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:42.036383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:43.036666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:43.064653 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:44.037024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:45.037138      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:45.068982 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:46.037930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:47.038076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:47.073600 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:48.038541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:49.038745      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:49.077529 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:50.039599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:51.039833      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:51.081538 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:52.039952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:53.040110      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:53.085667 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:54.040616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:55.040989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:55.089537 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:56.041529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:57.041682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:57.093237 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:19:58.042252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:19:59.042577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:19:59.097747 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:00.042879      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:01.043070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:01.101462 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:02.043377      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:03.043683      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:03.106288 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:04.044242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:05.045019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:05.111029 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:06.046038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:07.046217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:07.114863 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:08.046900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:09.047238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:09.119639 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:10.047694      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:11.047814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:11.123691 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:12.048698      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:13.048841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:13.127806 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:14.049744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:15.050015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:15.131932 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:16.050872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:17.051056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:17.136191 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:18.051125      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:19.051541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:19.140598 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:20.051692      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:21.051824      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:21.145760 23 container_probe.go:1759] Get pod test-webserver-375b62f6-4fb2-45d1-b744-501a07981881 in namespace container-probe-5717
  E0502 08:20:22.052675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:23.052826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/02/24 08:20:23.146
  I0502 08:20:23.157086 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5717" for this suite. @ 05/02/24 08:20:23.161
• [244.667 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 05/02/24 08:20:23.172
  I0502 08:20:23.172065 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replicaset @ 05/02/24 08:20:23.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:20:23.195
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:20:23.198
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 05/02/24 08:20:23.2
  I0502 08:20:23.209173 23 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0502 08:20:24.053092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:25.053386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:26.053547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:27.053682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:28.053824      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:28.213377 23 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/02/24 08:20:28.213
  STEP: getting scale subresource @ 05/02/24 08:20:28.213
  STEP: updating a scale subresource @ 05/02/24 08:20:28.217
  STEP: verifying the replicaset Spec.Replicas was modified @ 05/02/24 08:20:28.223
  STEP: Patch a scale subresource @ 05/02/24 08:20:28.227
  I0502 08:20:28.242850 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2259" for this suite. @ 05/02/24 08:20:28.252
• [5.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:277
  STEP: Creating a kubernetes client @ 05/02/24 08:20:28.28
  I0502 08:20:28.280238 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/02/24 08:20:28.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:20:28.309
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:20:28.312
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 05/02/24 08:20:28.314
  I0502 08:20:28.314769 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:20:29.053914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:30.054025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:30.919711 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:20:31.054635      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:32.055299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:33.055999      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:34.056246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:35.056710      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:36.057224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:37.057846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:38.057956      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:39.058260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:39.469682 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7816" for this suite. @ 05/02/24 08:20:39.477
• [11.417 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 05/02/24 08:20:39.697
  I0502 08:20:39.697415 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 08:20:39.697
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:20:39.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:20:39.72
  STEP: creating the pod @ 05/02/24 08:20:39.722
  STEP: setting up watch @ 05/02/24 08:20:39.722
  STEP: submitting the pod to kubernetes @ 05/02/24 08:20:39.825
  STEP: verifying the pod is in kubernetes @ 05/02/24 08:20:39.831
  STEP: verifying pod creation was observed @ 05/02/24 08:20:39.833
  E0502 08:20:40.058853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:41.058953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/02/24 08:20:41.843
  STEP: verifying pod deletion was observed @ 05/02/24 08:20:41.85
  E0502 08:20:42.059548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:43.060053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:44.060862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:44.590156 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6104" for this suite. @ 05/02/24 08:20:44.593
• [4.903 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 05/02/24 08:20:44.6
  I0502 08:20:44.600416 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 08:20:44.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:20:44.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:20:44.62
  STEP: Counting existing ResourceQuota @ 05/02/24 08:20:44.622
  E0502 08:20:45.060997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:46.061023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:47.061048      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:48.061295      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:49.062097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/02/24 08:20:49.625
  STEP: Ensuring resource quota status is calculated @ 05/02/24 08:20:49.629
  E0502 08:20:50.063047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:51.063165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 05/02/24 08:20:51.633
  STEP: Ensuring ResourceQuota status captures the pod usage @ 05/02/24 08:20:51.645
  E0502 08:20:52.063450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:53.063597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 05/02/24 08:20:53.648
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 05/02/24 08:20:53.65
  STEP: Ensuring a pod cannot update its resource requirements @ 05/02/24 08:20:53.652
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 05/02/24 08:20:53.655
  E0502 08:20:54.064045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:55.065030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/02/24 08:20:55.658
  STEP: Ensuring resource quota status released the pod usage @ 05/02/24 08:20:55.669
  E0502 08:20:56.065152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:57.065310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:20:57.673331 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1420" for this suite. @ 05/02/24 08:20:57.677
• [13.083 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1833
  STEP: Creating a kubernetes client @ 05/02/24 08:20:57.683
  I0502 08:20:57.683715 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:20:57.684
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:20:57.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:20:57.701
  STEP: starting the proxy server @ 05/02/24 08:20:57.703
  I0502 08:20:57.703386 23 util.go:592] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-7178 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 05/02/24 08:20:57.729
  I0502 08:20:57.733903 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0502 08:20:57.734890 23 kubectl.go:2228] kubectl proxy stderr: W0502 08:20:57.728780     363 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  I0502 08:20:57.734891 23 kubectl.go:2223] kubectl proxy stdout: Starting to serve on 127.0.0.1:44383

  STEP: Destroying namespace "kubectl-7178" for this suite. @ 05/02/24 08:20:57.737
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 05/02/24 08:20:57.743
  I0502 08:20:57.743342 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:20:57.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:20:57.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:20:57.761
  STEP: Creating configMap with name configmap-test-volume-map-c0a15972-c576-44d5-9fe0-b57820825dd6 @ 05/02/24 08:20:57.763
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:20:57.769
  E0502 08:20:58.065491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:20:59.065950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:00.066332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:01.066739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:21:01.785
  I0502 08:21:01.788440 23 output.go:196] Trying to get logs from node mini-1 pod pod-configmaps-d0340877-f1bf-4c45-bffd-1673b4af549a container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:21:01.798
  I0502 08:21:01.813866 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9793" for this suite. @ 05/02/24 08:21:01.816
• [4.080 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 05/02/24 08:21:01.823
  I0502 08:21:01.823476 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 08:21:01.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:21:01.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:21:01.84
  STEP: Counting existing ResourceQuota @ 05/02/24 08:21:01.842
  E0502 08:21:02.067583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:03.067970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:04.068664      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:05.068986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:06.069945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/02/24 08:21:06.844
  STEP: Ensuring resource quota status is calculated @ 05/02/24 08:21:06.848
  E0502 08:21:07.070089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:08.071064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:21:08.852344 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8945" for this suite. @ 05/02/24 08:21:08.855
• [7.039 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 05/02/24 08:21:08.862
  I0502 08:21:08.862431 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename events @ 05/02/24 08:21:08.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:21:08.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:21:08.882
  STEP: creating a test event @ 05/02/24 08:21:08.884
  STEP: listing all events in all namespaces @ 05/02/24 08:21:08.887
  STEP: patching the test event @ 05/02/24 08:21:08.899
  STEP: fetching the test event @ 05/02/24 08:21:08.904
  STEP: updating the test event @ 05/02/24 08:21:08.906
  STEP: getting the test event @ 05/02/24 08:21:08.913
  STEP: deleting the test event @ 05/02/24 08:21:08.915
  STEP: listing all events in all namespaces @ 05/02/24 08:21:08.92
  I0502 08:21:08.930109 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1334" for this suite. @ 05/02/24 08:21:08.933
• [0.077 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 05/02/24 08:21:08.939
  I0502 08:21:08.939979 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename runtimeclass @ 05/02/24 08:21:08.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:21:08.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:21:08.954
  STEP: getting /apis @ 05/02/24 08:21:08.956
  STEP: getting /apis/node.k8s.io @ 05/02/24 08:21:08.958
  STEP: getting /apis/node.k8s.io/v1 @ 05/02/24 08:21:08.959
  STEP: creating @ 05/02/24 08:21:08.96
  STEP: watching @ 05/02/24 08:21:08.971
  I0502 08:21:08.971076 23 runtimeclass.go:275] starting watch
  STEP: getting @ 05/02/24 08:21:08.975
  STEP: listing @ 05/02/24 08:21:08.977
  STEP: patching @ 05/02/24 08:21:08.979
  STEP: updating @ 05/02/24 08:21:08.982
  I0502 08:21:08.985619 23 runtimeclass.go:305] waiting for watch events with expected annotations
  STEP: deleting @ 05/02/24 08:21:08.985
  STEP: deleting a collection @ 05/02/24 08:21:08.992
  I0502 08:21:09.005422 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7238" for this suite. @ 05/02/24 08:21:09.008
• [0.075 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 05/02/24 08:21:09.015
  I0502 08:21:09.015610 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sysctl @ 05/02/24 08:21:09.016
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:21:09.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:21:09.045
  STEP: Creating a pod with one valid and two invalid sysctls @ 05/02/24 08:21:09.064
  I0502 08:21:09.067626 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9539" for this suite. @ 05/02/24 08:21:09.07
  E0502 08:21:09.071303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 05/02/24 08:21:09.077
  I0502 08:21:09.077320 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename deployment @ 05/02/24 08:21:09.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:21:09.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:21:09.093
  I0502 08:21:09.094860 23 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0502 08:21:09.104651 23 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0502 08:21:10.071785      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:11.071964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:12.072120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:13.072257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:14.072370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:21:14.111097 23 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/02/24 08:21:14.111
  I0502 08:21:14.111132 23 deployment.go:763] Creating deployment "test-rolling-update-deployment"
  I0502 08:21:14.118429 23 deployment.go:769] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0502 08:21:14.131213 23 deployment.go:222] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0502 08:21:15.073315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:16.073481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:21:16.136808 23 deployment.go:773] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0502 08:21:16.139221 23 deployment.go:778] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0502 08:21:16.145833 23 deployment.go:633] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4602",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "76a5665d-5311-4d60-bcd4-351520e048f8",
      ResourceVersion: (string) (len=5) "11887",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234874,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-6f4b778cd6\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0502 08:21:16.149240 23 deployment.go:39] New ReplicaSet "test-rolling-update-deployment-6f4b778cd6" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-6f4b778cd6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4602",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3e083097-6d96-4d2c-a896-bdff1555bd9b",
      ResourceVersion: (string) (len=5) "11877",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234874,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "76a5665d-5311-4d60-bcd4-351520e048f8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 36 61 35 36 36  35 64 2d 35 33 31 31 2d  |\"76a5665d-5311-|
              00000120  34 64 36 30 2d 62 63 64  34 2d 33 35 31 35 32 30  |4d60-bcd4-351520|
              00000130  65 30 34 38 66 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e048f8\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:21:16.150016 23 deployment.go:44] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0502 08:21:16.150238 23 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4602",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "680cd023-6112-4668-8b0c-c3d938447bf1",
      ResourceVersion: (string) (len=5) "11886",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234869,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "76a5665d-5311-4d60-bcd4-351520e048f8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234869,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 37 36 61 35 36 36 35  |"uid\":\"76a5665|
              000000b0  64 2d 35 33 31 31 2d 34  64 36 30 2d 62 63 64 34  |d-5311-4d60-bcd4|
              000000c0  2d 33 35 31 35 32 30 65  30 34 38 66 38 5c 22 7d  |-351520e048f8\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=5) "httpd",
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:21:16.153621 23 deployment.go:67] Pod "test-rolling-update-deployment-6f4b778cd6-jx94p" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-6f4b778cd6-jx94p",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-6f4b778cd6-",
      Namespace: (string) (len=15) "deployment-4602",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "77ecb862-59cb-4e50-a30a-0485f6df46cf",
      ResourceVersion: (string) (len=5) "11876",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234874,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "2a378d3b3417f83402734eae16b650b19053aa2cb736638fa19fed7401d344cd",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.125.195/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.125.195/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-6f4b778cd6",
          UID: (types.UID) (len=36) "3e083097-6d96-4d2c-a896-bdff1555bd9b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 65  30 38 33 30 39 37 2d 36  |d\":\"3e083097-6|
              00000090  64 39 36 2d 34 64 32 63  2d 61 38 39 36 2d 62 64  |d96-4d2c-a896-bd|
              000000a0  66 66 31 35 35 35 62 64  39 62 5c 22 7d 22 3a 7b  |ff1555bd9b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  35 2e 31 39 35 5c 22 7d  |2.168.125.195\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pth49",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pth49",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234875,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234874,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) (len=15) "192.168.125.195",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.125.195"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234874,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234875,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://37745ccbcd771a6c3af1fa6ef08389cf308ae90525d3b6d4a8daeb68ee0f6da2",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:21:16.155223 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4602" for this suite. @ 05/02/24 08:21:16.159
• [7.088 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 05/02/24 08:21:16.165
  I0502 08:21:16.165798 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename var-expansion @ 05/02/24 08:21:16.166
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:21:16.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:21:16.184
  STEP: Creating a pod to test substitution in volume subpath @ 05/02/24 08:21:16.185
  E0502 08:21:17.074493      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:18.074650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:19.075177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:20.075496      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:21:20.204
  I0502 08:21:20.207716 23 output.go:196] Trying to get logs from node mini-1 pod var-expansion-79b5ccc6-2263-4fa6-86a1-f9068976f2be container dapi-container: <nil>
  STEP: delete the pod @ 05/02/24 08:21:20.212
  I0502 08:21:20.225538 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5339" for this suite. @ 05/02/24 08:21:20.228
• [4.069 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 05/02/24 08:21:20.235
  I0502 08:21:20.235133 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:21:20.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:21:20.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:21:20.257
  STEP: Creating configMap with name cm-test-opt-del-66f42a35-0a19-42d2-af41-978e9d3d5f5c @ 05/02/24 08:21:20.264
  STEP: Creating configMap with name cm-test-opt-upd-85b99776-9fd6-4a2a-affe-52c59fb679b8 @ 05/02/24 08:21:20.267
  STEP: Creating the pod @ 05/02/24 08:21:20.271
  E0502 08:21:21.075604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:22.075776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:23.076217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:24.076381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-66f42a35-0a19-42d2-af41-978e9d3d5f5c @ 05/02/24 08:21:24.308
  STEP: Updating configmap cm-test-opt-upd-85b99776-9fd6-4a2a-affe-52c59fb679b8 @ 05/02/24 08:21:24.313
  STEP: Creating configMap with name cm-test-opt-create-c67798b1-db45-4aa4-bb66-9b3409125c1d @ 05/02/24 08:21:24.317
  STEP: waiting to observe update in volume @ 05/02/24 08:21:24.32
  E0502 08:21:25.076809      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:26.076964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:27.077176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:28.077357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:29.077387      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:30.077716      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:31.078089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:32.078258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:33.079216      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:34.079373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:35.080051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:36.080227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:37.080353      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:38.080518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:39.080956      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:40.081297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:41.081991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:42.082158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:43.083131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:44.083270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:45.084164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:46.084341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:47.084743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:48.084918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:49.085701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:50.086009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:51.086209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:52.086355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:53.087225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:54.087360      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:55.087957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:56.088137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:57.088145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:58.088305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:21:59.088683      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:00.088990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:01.089522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:02.089673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:03.090667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:04.090854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:05.090859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:06.091028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:07.091013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:08.091160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:09.091231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:10.091527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:11.091876      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:12.092049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:13.092275      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:14.092435      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:15.093126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:16.093311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:17.093983      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:18.094150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:19.094312      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:20.094629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:21.094967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:22.095022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:23.095082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:24.095258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:25.096062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:26.096180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:27.096519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:28.096654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:29.097301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:30.097594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:31.098377      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:32.099026      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:33.099282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:34.099425      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:22:34.590670 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6483" for this suite. @ 05/02/24 08:22:34.594
• [74.367 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 05/02/24 08:22:34.601
  I0502 08:22:34.601916 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replication-controller @ 05/02/24 08:22:34.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:22:34.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:22:34.626
  STEP: Given a ReplicationController is created @ 05/02/24 08:22:34.628
  STEP: When the matched label of one of its pods change @ 05/02/24 08:22:34.632
  I0502 08:22:34.635937 23 resource.go:87] Pod name pod-release: Found 0 pods out of 1
  E0502 08:22:35.099508      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:36.099661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:37.099825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:38.100014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:39.100317      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:22:39.639565 23 resource.go:87] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/02/24 08:22:39.659
  E0502 08:22:40.101239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:22:40.671074 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1963" for this suite. @ 05/02/24 08:22:40.674
• [6.079 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 05/02/24 08:22:40.68
  I0502 08:22:40.680649 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl-logs @ 05/02/24 08:22:40.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:22:40.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:22:40.701
  STEP: creating an pod @ 05/02/24 08:22:40.703
  I0502 08:22:40.703565 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-logs-1393 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I0502 08:22:40.750169 23 builder.go:146] stderr: ""
  I0502 08:22:40.750204 23 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 05/02/24 08:22:40.75
  I0502 08:22:40.750298 23 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0502 08:22:41.102077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:42.102781      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:22:42.759625 23 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 05/02/24 08:22:42.759
  I0502 08:22:42.759698 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-logs-1393 logs logs-generator logs-generator'
  I0502 08:22:42.800581 23 builder.go:146] stderr: ""
  I0502 08:22:42.800609 23 builder.go:147] stdout: "I0502 08:22:41.832758       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/dfkd 443\nI0502 08:22:42.033148       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/zhhd 209\nI0502 08:22:42.233527       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/7zg 550\nI0502 08:22:42.433659       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9vc 487\nI0502 08:22:42.632910       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/s58 577\n"
  STEP: limiting log lines @ 05/02/24 08:22:42.8
  I0502 08:22:42.800653 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-logs-1393 logs logs-generator logs-generator --tail=1'
  I0502 08:22:42.851843 23 builder.go:146] stderr: ""
  I0502 08:22:42.851866 23 builder.go:147] stdout: "I0502 08:22:42.833288       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/9pcs 571\n"
  I0502 08:22:42.851874 23 logs.go:127] got output "I0502 08:22:42.833288       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/9pcs 571\n"
  STEP: limiting log bytes @ 05/02/24 08:22:42.851
  I0502 08:22:42.851928 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-logs-1393 logs logs-generator logs-generator --limit-bytes=1'
  I0502 08:22:42.892319 23 builder.go:146] stderr: ""
  I0502 08:22:42.892342 23 builder.go:147] stdout: "I"
  I0502 08:22:42.892349 23 logs.go:133] got output "I"
  STEP: exposing timestamps @ 05/02/24 08:22:42.892
  I0502 08:22:42.892394 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-logs-1393 logs logs-generator logs-generator --tail=1 --timestamps'
  I0502 08:22:42.933179 23 builder.go:146] stderr: ""
  I0502 08:22:42.933204 23 builder.go:147] stdout: "2024-05-02T08:22:42.833390081Z I0502 08:22:42.833288       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/9pcs 571\n"
  I0502 08:22:42.933212 23 logs.go:139] got output "2024-05-02T08:22:42.833390081Z I0502 08:22:42.833288       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/9pcs 571\n"
  STEP: restricting to a time range @ 05/02/24 08:22:42.933
  E0502 08:22:43.103527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:44.103678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:45.104027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:22:45.433462 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-logs-1393 logs logs-generator logs-generator --since=1s'
  I0502 08:22:45.477799 23 builder.go:146] stderr: ""
  I0502 08:22:45.477825 23 builder.go:147] stdout: "I0502 08:22:44.632922       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/qb4 317\nI0502 08:22:44.833253       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/kh76 438\nI0502 08:22:45.033587       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/nd6r 318\nI0502 08:22:45.232846       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/x6n6 265\nI0502 08:22:45.433184       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/mzj 408\n"
  I0502 08:22:45.477853 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-logs-1393 logs logs-generator logs-generator --since=24h'
  I0502 08:22:45.525765 23 builder.go:146] stderr: ""
  I0502 08:22:45.525803 23 builder.go:147] stdout: "I0502 08:22:41.832758       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/dfkd 443\nI0502 08:22:42.033148       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/zhhd 209\nI0502 08:22:42.233527       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/7zg 550\nI0502 08:22:42.433659       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9vc 487\nI0502 08:22:42.632910       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/s58 577\nI0502 08:22:42.833288       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/9pcs 571\nI0502 08:22:43.033618       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/tm9d 224\nI0502 08:22:43.232886       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/rnrp 223\nI0502 08:22:43.433224       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/8b6g 512\nI0502 08:22:43.633549       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/rfgz 539\nI0502 08:22:43.832817       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/v6ps 435\nI0502 08:22:44.033121       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/xkm 283\nI0502 08:22:44.233373       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/8m5 303\nI0502 08:22:44.433692       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/j99 493\nI0502 08:22:44.632922       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/qb4 317\nI0502 08:22:44.833253       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/kh76 438\nI0502 08:22:45.033587       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/nd6r 318\nI0502 08:22:45.232846       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/x6n6 265\nI0502 08:22:45.433184       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/mzj 408\n"
  I0502 08:22:45.525868 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-logs-1393 delete pod logs-generator'
  E0502 08:22:46.104184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:22:46.643689 23 builder.go:146] stderr: ""
  I0502 08:22:46.643712 23 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I0502 08:22:46.643765 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-1393" for this suite. @ 05/02/24 08:22:46.647
• [5.974 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 05/02/24 08:22:46.654
  I0502 08:22:46.654762 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename namespaces @ 05/02/24 08:22:46.655
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:22:46.675
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:22:46.677
  STEP: Creating a test namespace @ 05/02/24 08:22:46.679
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:22:46.697
  STEP: Creating a service in the namespace @ 05/02/24 08:22:46.7
  STEP: Deleting the namespace @ 05/02/24 08:22:46.713
  STEP: Waiting for the namespace to be removed. @ 05/02/24 08:22:46.726
  E0502 08:22:47.104998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:48.106076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:49.106555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:50.106680      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:51.107696      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:52.108548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/02/24 08:22:52.729
  STEP: Verifying there is no service in the namespace @ 05/02/24 08:22:52.744
  I0502 08:22:52.746566 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2184" for this suite. @ 05/02/24 08:22:52.749
  STEP: Destroying namespace "nsdeletetest-7057" for this suite. @ 05/02/24 08:22:52.756
  I0502 08:22:52.759235 23 framework.go:370] Namespace nsdeletetest-7057 was already deleted
  STEP: Destroying namespace "nsdeletetest-7650" for this suite. @ 05/02/24 08:22:52.759
• [6.114 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 05/02/24 08:22:52.769
  I0502 08:22:52.769215 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename deployment @ 05/02/24 08:22:52.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:22:52.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:22:52.787
  I0502 08:22:52.788748 23 deployment.go:792] Creating deployment "test-recreate-deployment"
  I0502 08:22:52.792935 23 deployment.go:798] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0502 08:22:52.805469 23 deployment.go:222] deployment "test-recreate-deployment" doesn't have the required revision set
  E0502 08:22:53.108808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:54.108942      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:22:54.813446 23 deployment.go:802] Waiting deployment "test-recreate-deployment" to complete
  I0502 08:22:54.815647 23 deployment.go:807] Triggering a new rollout for deployment "test-recreate-deployment"
  I0502 08:22:54.822154 23 deployment.go:313] Updating deployment test-recreate-deployment
  I0502 08:22:54.822166 23 deployment.go:814] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0502 08:22:54.897693 23 deployment.go:633] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2156",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "932f336e-1ff3-4747-a7ec-32438969300a",
      ResourceVersion: (string) (len=5) "12446",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234972,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234972,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=64) "ReplicaSet \"test-recreate-deployment-66b65d9f8f\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0502 08:22:54.901175 23 deployment.go:39] New ReplicaSet "test-recreate-deployment-66b65d9f8f" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-66b65d9f8f",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2156",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7f82643a-c94d-4217-80bb-745ccdb78943",
      ResourceVersion: (string) (len=5) "12445",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "932f336e-1ff3-4747-a7ec-32438969300a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 33 32 66 33 33  36 65 2d 31 66 66 33 2d  |\"932f336e-1ff3-|
              00000120  34 37 34 37 2d 61 37 65  63 2d 33 32 34 33 38 39  |4747-a7ec-324389|
              00000130  36 39 33 30 30 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |69300a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f",
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:22:54.901737 23 deployment.go:44] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0502 08:22:54.901871 23 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-6b6d9cd7b6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2156",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0bf6b9a8-ea52-46c1-ba9c-3e1b91d84fd7",
      ResourceVersion: (string) (len=5) "12433",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234972,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6",
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "932f336e-1ff3-4747-a7ec-32438969300a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 33 32 66 33 33  36 65 2d 31 66 66 33 2d  |\"932f336e-1ff3-|
              00000120  34 37 34 37 2d 61 37 65  63 2d 33 32 34 33 38 39  |4747-a7ec-324389|
              00000130  36 39 33 30 30 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |69300a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:22:54.906214 23 deployment.go:67] Pod "test-recreate-deployment-66b65d9f8f-5rs92" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-recreate-deployment-66b65d9f8f-5rs92",
      GenerateName: (string) (len=36) "test-recreate-deployment-66b65d9f8f-",
      Namespace: (string) (len=15) "deployment-2156",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8e4b4424-34aa-4004-84e4-a610da0f966a",
      ResourceVersion: (string) (len=5) "12444",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-recreate-deployment-66b65d9f8f",
          UID: (types.UID) (len=36) "7f82643a-c94d-4217-80bb-745ccdb78943",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 66  38 32 36 34 33 61 2d 63  |d\":\"7f82643a-c|
              00000090  39 34 64 2d 34 32 31 37  2d 38 30 62 62 2d 37 34  |94d-4217-80bb-74|
              000000a0  35 63 63 64 62 37 38 39  34 33 5c 22 7d 22 3a 7b  |5ccdb78943\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sf98g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sf98g",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:22:54.907729 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2156" for this suite. @ 05/02/24 08:22:54.911
• [2.149 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 05/02/24 08:22:54.917
  I0502 08:22:54.917980 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename deployment @ 05/02/24 08:22:54.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:22:54.943
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:22:54.947
  I0502 08:22:54.950285 23 deployment.go:1196] Creating deployment "webserver-deployment"
  I0502 08:22:54.954111 23 deployment.go:1200] Waiting for observed generation 1
  E0502 08:22:55.109054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:56.109174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:22:56.962456 23 deployment.go:1205] Waiting for all required pods to come up
  I0502 08:22:56.966008 23 resource.go:87] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 05/02/24 08:22:56.966
  E0502 08:22:57.109260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:22:58.109430      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:22:58.978558 23 deployment.go:1209] Waiting for deployment "webserver-deployment" to complete
  I0502 08:22:58.982267 23 deployment.go:1218] Updating deployment "webserver-deployment" with a non-existent image
  I0502 08:22:58.988660 23 deployment.go:313] Updating deployment webserver-deployment
  I0502 08:22:58.988674 23 deployment.go:1224] Waiting for observed generation 2
  E0502 08:22:59.109926      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:00.110238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:23:00.998932 23 deployment.go:1234] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I0502 08:23:01.001237 23 deployment.go:1239] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0502 08:23:01.003255 23 deployment.go:1244] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0502 08:23:01.012135 23 deployment.go:1258] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0502 08:23:01.012164 23 deployment.go:1263] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0502 08:23:01.014195 23 deployment.go:1268] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0502 08:23:01.017443 23 deployment.go:1275] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0502 08:23:01.017468 23 deployment.go:1283] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0502 08:23:01.023321 23 deployment.go:313] Updating deployment webserver-deployment
  I0502 08:23:01.023347 23 deployment.go:1289] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0502 08:23:01.035591 23 deployment.go:1297] Verifying that first rollout's replicaset has .spec.replicas = 20
  I0502 08:23:01.044470 23 deployment.go:1303] Verifying that second rollout's replicaset has .spec.replicas = 13
  I0502 08:23:01.086961 23 deployment.go:633] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d32097df-53b8-4fea-acc3-2e3a84a7bddf",
      ResourceVersion: (string) (len=5) "12750",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-67c89d485c\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0502 08:23:01.107414 23 deployment.go:39] New ReplicaSet "webserver-deployment-67c89d485c" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-67c89d485c",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
      ResourceVersion: (string) (len=5) "12745",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234978,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "d32097df-53b8-4fea-acc3-2e3a84a7bddf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 33 32 30 39 37  64 66 2d 35 33 62 38 2d  |\"d32097df-53b8-|
              00000120  34 66 65 61 2d 61 63 63  33 2d 32 65 33 61 38 34  |4fea-acc3-2e3a84|
              00000130  61 37 62 64 64 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a7bddf\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:23:01.107992 23 deployment.go:44] All old ReplicaSets of Deployment "webserver-deployment":
  I0502 08:23:01.108114 23 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-77db57d8df",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
      ResourceVersion: (string) (len=5) "12742",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "d32097df-53b8-4fea-acc3-2e3a84a7bddf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 33 32 30 39 37  64 66 2d 35 33 62 38 2d  |\"d32097df-53b8-|
              00000120  34 66 65 61 2d 61 63 63  33 2d 32 65 33 61 38 34  |4fea-acc3-2e3a84|
              00000130  61 37 62 64 64 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a7bddf\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  E0502 08:23:01.110335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:23:01.119698 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-6vrxf" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-6vrxf",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aa7ad874-6400-461d-9f92-1ddfa60d5e7c",
      ResourceVersion: (string) (len=5) "12685",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "7355783214d4b79f01f58f6bdf1650f87bbb62a55887cab2bfd4b19fd5a06459",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.125.223/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.125.223/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bqt8k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bqt8k",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.121477 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-9gmjl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-9gmjl",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "70fa9349-e7f8-4ba5-bb8b-8a316de4e3ca",
      ResourceVersion: (string) (len=5) "12735",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "b3c88616a6104d3617b336111f81412afda06cd3a7bfbef28d392b35e1ef6226",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.125.208/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.125.208/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234980,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 32 35 2e 32  30 38 5c 22 7d 22 3a 7b  |68.125.208\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w2rk4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w2rk4",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234980,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) (len=15) "192.168.125.208",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.125.208"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.123201 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-bsv69" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-bsv69",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1b86e21b-d015-4b7c-a64d-a8f180f6701c",
      ResourceVersion: (string) (len=5) "12785",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rx2dv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rx2dv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.124318 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-d8l9v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-d8l9v",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7c07d0dc-f11f-4b07-a9fc-6d445ab47fcb",
      ResourceVersion: (string) (len=5) "12726",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "30f67b474dd7a0a25fb06731a46a428107037f377dcfb5a027f74e4ee1caa22f",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "192.168.32.47/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "192.168.32.47/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234980,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=707) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 33 32 2e 34 37  5c 22 7d 22 3a 7b 22 2e  |68.32.47\"}":{".|
              000002a0  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              000002b0  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              000002c0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s65mk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s65mk",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234980,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.33",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.33"
        }
      },
      PodIP: (string) (len=13) "192.168.32.47",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.32.47"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.126014 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-tvp7z" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-tvp7z",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1c9e6ee2-3823-4fe8-9a7e-2642cef5345a",
      ResourceVersion: (string) (len=5) "12788",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cncd6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cncd6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.126978 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-v87tk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-v87tk",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "93090e67-f1b9-46a2-b851-eec26e91c600",
      ResourceVersion: (string) (len=5) "12789",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j2z5v",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j2z5v",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.128074 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-vb5vb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-vb5vb",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ed9289ef-9198-46ca-bba2-79a9dffc2e96",
      ResourceVersion: (string) (len=5) "12686",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "3a31442894bb7807912c38715a44da5772f8b810b50e18f69ea7fc8a2c6ad454",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.158.133/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.158.133/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7pdk2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7pdk2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.129752 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-wc9qf" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-wc9qf",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3b5354c6-f401-40ba-abd9-c5a7057e42c6",
      ResourceVersion: (string) (len=5) "12784",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zkbtn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zkbtn",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.130718 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-x8b24" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-x8b24",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "740965e6-c1dd-4357-a71e-4ef9fbb62834",
      ResourceVersion: (string) (len=5) "12765",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-blzq7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-blzq7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.131747 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-z6h2v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-z6h2v",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dd25502e-b0c2-4b62-b7f8-88770f9331ff",
      ResourceVersion: (string) (len=5) "12783",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kfctf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kfctf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.132838 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-zd94m" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-zd94m",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cc530f3f-29c0-488c-a9cf-bbaa409148da",
      ResourceVersion: (string) (len=5) "12739",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.158.132/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.158.132/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "6fe6a349a61358b9494dd53944b88cfebf2faf0db9762590d60b491a3051451a"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234980,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 35 38 2e 31  33 32 5c 22 7d 22 3a 7b  |68.158.132\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5876x",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5876x",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234980,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234979,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) (len=15) "192.168.158.132",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.158.132"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234979,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.134535 23 deployment.go:67] Pod "webserver-deployment-67c89d485c-zhl6b" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-zhl6b",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4bd1fcef-bfb8-40d0-b10e-35d80636b298",
      ResourceVersion: (string) (len=5) "12790",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "cfb15ff3-f3f9-4e7a-bbe8-412f42b5d1d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 63 66  62 31 35 66 66 33 2d 66  |d\":\"cfb15ff3-f|
              00000090  33 66 39 2d 34 65 37 61  2d 62 62 65 38 2d 34 31  |3f9-4e7a-bbe8-41|
              000000a0  32 66 34 32 62 35 64 31  64 35 5c 22 7d 22 3a 7b  |2f42b5d1d5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pp8b5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pp8b5",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.135505 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-262jg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-262jg",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "012c8914-68ac-4f9a-8eee-bdf433a6c681",
      ResourceVersion: (string) (len=5) "12779",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jlvl2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jlvl2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.136614 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-2cggr" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-2cggr",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "771a5c4f-5227-4509-bd43-4e7492777730",
      ResourceVersion: (string) (len=5) "12598",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.125.199/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.125.199/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "f5c2d9b5cb8665f3a816b3284c46419f69c846d0fda82d42d72e7d7cb4d4fd05"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  35 2e 31 39 39 5c 22 7d  |2.168.125.199\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-db9tj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-db9tj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) (len=15) "192.168.125.199",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.125.199"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234976,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://bc0dde88ed97a9cd63445989feb06769a6ff2e98fd76b23a4d0bd9cadb67b89e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.138434 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-4vd88" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-4vd88",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8434a4b8-f477-439f-ab25-4088bd6f3b40",
      ResourceVersion: (string) (len=5) "12607",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "be890a003568b039d2637082667d5d7a6d17924c63b034d188446f035cb6961b",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.158.131/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.158.131/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  38 2e 31 33 31 5c 22 7d  |2.168.158.131\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nbrpx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nbrpx",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) (len=15) "192.168.158.131",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.158.131"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234975,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234976,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://fda6562684eeaa5e0a345c3e1fcaf3a2ad0c20c4f875ebb5dbb2725e7de61d46",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.140258 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-6j94z" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-6j94z",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b3bdc220-468a-4fc8-896b-d97978859308",
      ResourceVersion: (string) (len=5) "12774",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t9mgg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t9mgg",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.141960 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-6vs4x" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-6vs4x",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0948ddf9-343c-4715-b755-3faf3594fe87",
      ResourceVersion: (string) (len=5) "12585",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "b35939618ea2b8f20f311b86c2f89c3de367da6c58bf5560bd6efe9cddc4ad4a",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "192.168.32.44/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "192.168.32.44/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 32  2e 34 34 5c 22 7d 22 3a  |2.168.32.44\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5qcds",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5qcds",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.33",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.33"
        }
      },
      PodIP: (string) (len=13) "192.168.32.44",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.32.44"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234975,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234976,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://2899e5acee9a6ba88bb81d9fe421f2e0c4fbc3a6cc728b8be6c3d722f10c5c07",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.143823 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-9hz49" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-9hz49",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b668bd4a-4ffe-47dc-a21c-267a57ed6975",
      ResourceVersion: (string) (len=5) "12588",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "192.168.32.46/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "192.168.32.46/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "bfd0ee1ba598f9999ba2feb7dff2a52cd1da3f7c525c8101c5ab04f63abcab5f"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 32  2e 34 36 5c 22 7d 22 3a  |2.168.32.46\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-klrm5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-klrm5",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.33",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.33"
        }
      },
      PodIP: (string) (len=13) "192.168.32.46",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.32.46"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234975,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234976,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://c5602f2be8cc5692d864a67b46a51c5518c10c70be27ff933b6db9a1f780ce71",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.145594 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-9mk54" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-9mk54",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "30fb4b0a-73e1-4531-879e-dfaed5b91c8f",
      ResourceVersion: (string) (len=5) "12761",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-99hs2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-99hs2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.146720 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-b9z7v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-b9z7v",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1e96a5de-7757-4cae-9814-f9f9be489da4",
      ResourceVersion: (string) (len=5) "12775",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6npts",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6npts",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.33",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.33"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.148441 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-ggvnv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-ggvnv",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0b094d84-1168-4dc0-ad06-507531a1576a",
      ResourceVersion: (string) (len=5) "12590",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=16) "192.168.32.45/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=16) "192.168.32.45/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "c7738404b0dc6f86c2175bd35c97ce56962294cd45f7024714694a060e096a67"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 32  2e 34 35 5c 22 7d 22 3a  |2.168.32.45\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bg4wp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bg4wp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.33",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.33"
        }
      },
      PodIP: (string) (len=13) "192.168.32.45",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.32.45"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234975,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234976,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d7e83951f071af01920430c5cd0dbd8a287a5e8f73b29e70de9b3a062e3550c6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.150700 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-grczs" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-grczs",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bebc87fa-35cd-4ba5-8f17-cd913c7ca24b",
      ResourceVersion: (string) (len=5) "12595",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "3d7f8731319af5bf3c5af177008279679b431c7bd809eb988d1a0a68a0640094",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.125.200/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.125.200/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  35 2e 32 30 30 5c 22 7d  |2.168.125.200\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-k88gb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-k88gb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234977,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) (len=15) "192.168.125.200",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.125.200"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234975,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234977,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://a046cf372e52401ea047419be52001d1680271c5d7c24c9c7997cc88825fe6fd",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.152486 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-htbnr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-htbnr",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4c2eab1a-4fea-4dbe-abd6-92eb94ecff78",
      ResourceVersion: (string) (len=5) "12786",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wvk6t",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wvk6t",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.153583 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-j9kvm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-j9kvm",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bd8cc5ba-ca17-40c2-b1f4-4bd4e0e51a5f",
      ResourceVersion: (string) (len=5) "12780",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ngjnz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ngjnz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.154418 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-jr6hx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-jr6hx",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9fe58256-ee0c-4f99-ad20-9933f10fe751",
      ResourceVersion: (string) (len=5) "12787",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5gjrr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5gjrr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.155315 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-krgbf" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-krgbf",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7473ff85-f2b9-4c40-a011-e9861bc3a009",
      ResourceVersion: (string) (len=5) "12760",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dr99j",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dr99j",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.156524 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-p5srw" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-p5srw",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "be2ab834-d1dd-4305-8302-fb57150dd0bb",
      ResourceVersion: (string) (len=5) "12773",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-84pzs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-84pzs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.157598 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-tk7vx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-tk7vx",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ab4418c6-a8fa-4176-8f1c-d081f38eea6b",
      ResourceVersion: (string) (len=5) "12565",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.158.190/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "48b4a892e1e5bc49f2db2e2315ad9c0f04cd1bb13a52a104782e40ce8a88c541",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.158.190/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234976,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  38 2e 31 39 30 5c 22 7d  |2.168.158.190\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s9kcj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s9kcj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234976,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234976,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234976,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234974,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) (len=15) "192.168.158.190",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.158.190"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234974,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234976,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://211d716d3e387c71bca4d655bd181dcf8e815b4d342768b1166bf627d9ad9c10",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.158905 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-ttprp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-ttprp",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9dbbfebc-9218-47d9-9a17-2b1bc497517b",
      ResourceVersion: (string) (len=5) "12772",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bbgdb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bbgdb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.159859 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-wdp5f" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-wdp5f",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a6ddb785-56e2-474f-9f4f-023f093e2ca0",
      ResourceVersion: (string) (len=5) "12782",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wfvtg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wfvtg",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.160712 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-wg9jr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-wg9jr",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2307d9e8-c7e0-45a6-b319-db2ba3b4143a",
      ResourceVersion: (string) (len=5) "12763",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9v5b9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9v5b9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.161569 23 deployment.go:67] Pod "webserver-deployment-77db57d8df-zs2sp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-zs2sp",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5529",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b50eebe0-7d49-4c0d-9cd8-d0f82bd55e6d",
      ResourceVersion: (string) (len=5) "12568",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234975,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "73128c0c40d7b2aa33643b8112da35a77f0b162c58bf1b23a6e1435b519c6c5a",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.158.191/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.158.191/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "334116c2-62fd-4fc4-8884-fc556aa4bf24",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 33  34 31 31 36 63 32 2d 36  |d\":\"334116c2-6|
              00000090  32 66 64 2d 34 66 63 34  2d 38 38 38 34 2d 66 63  |2fd-4fc4-8884-fc|
              000000a0  35 35 36 61 61 34 62 66  32 34 5c 22 7d 22 3a 7b  |556aa4bf24\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234976,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  38 2e 31 39 31 5c 22 7d  |2.168.158.191\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-blz97",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-blz97",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234976,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234976,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234976,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850234975,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) (len=15) "192.168.158.191",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.158.191"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850234975,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850234976,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://86a338201515c752dcffab62d800a5678d226d362cb239b69c46544a7ea07f96",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:23:01.162755 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5529" for this suite. @ 05/02/24 08:23:01.177
• [6.278 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 05/02/24 08:23:01.196
  I0502 08:23:01.196666 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 08:23:01.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:23:01.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:23:01.235
  STEP: Creating a pod to test downward api env vars @ 05/02/24 08:23:01.241
  E0502 08:23:02.111259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:03.111419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:04.111706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:05.111985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:23:05.266
  I0502 08:23:05.269200 23 output.go:196] Trying to get logs from node mini-1 pod downward-api-3959f779-bdf6-40b7-958d-dfb4eeb18137 container dapi-container: <nil>
  STEP: delete the pod @ 05/02/24 08:23:05.274
  I0502 08:23:05.286680 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9096" for this suite. @ 05/02/24 08:23:05.289
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 05/02/24 08:23:05.296
  I0502 08:23:05.296382 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 08:23:05.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:23:05.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:23:05.316
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/02/24 08:23:05.318
  E0502 08:23:06.112431      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:07.113016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:08.113438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:09.113683      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:23:09.338
  I0502 08:23:09.340509 23 output.go:196] Trying to get logs from node mini-2 pod pod-d6ed39ee-159f-47a7-945e-97a254c503f0 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 08:23:09.35
  I0502 08:23:09.368781 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4407" for this suite. @ 05/02/24 08:23:09.376
• [4.088 seconds]
------------------------------
SSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 05/02/24 08:23:09.384
  I0502 08:23:09.384449 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename endpointslice @ 05/02/24 08:23:09.384
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:23:09.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:23:09.426
  I0502 08:23:09.439200 23 endpointslice.go:1045] Endpoints addresses: [10.221.190.5 10.221.190.6 10.221.190.7] , ports: [6443]
  I0502 08:23:09.439228 23 endpointslice.go:1075] EndpointSlices addresses: [10.221.190.5 10.221.190.6 10.221.190.7] , ports: [6443]
  I0502 08:23:09.439257 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-980" for this suite. @ 05/02/24 08:23:09.442
• [0.066 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 05/02/24 08:23:09.45
  I0502 08:23:09.450328 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pod-network-test @ 05/02/24 08:23:09.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:23:09.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:23:09.472
  STEP: Performing setup for networking test in namespace pod-network-test-4121 @ 05/02/24 08:23:09.475
  STEP: creating a selector @ 05/02/24 08:23:09.475
  STEP: Creating the service pods in kubernetes @ 05/02/24 08:23:09.475
  I0502 08:23:09.475116 23 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0502 08:23:10.113908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:11.114012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:12.114044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:13.114209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:14.114559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:15.114799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:16.115402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:17.115526      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:18.116178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:19.116485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:20.116984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:21.117090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:22.118164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:23.118341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:24.118382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:25.118729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:26.119489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:27.119618      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:28.119782      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:29.120007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:30.120606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:31.120718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/02/24 08:23:31.559
  E0502 08:23:32.121735      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:33.121902      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:23:33.574323 23 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0502 08:23:33.574339 23 networking.go:42] Breadth first check of 192.168.125.206 on host 10.221.190.31...
  I0502 08:23:33.576249 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.125.220:9080/dial?request=hostname&protocol=http&host=192.168.125.206&port=8083&tries=1'] Namespace:pod-network-test-4121 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:23:33.576276 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:23:33.576603 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:23:33.576657 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4121/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.125.220%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.125.206%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0502 08:23:33.618140 23 utils.go:331] Waiting for responses: map[]
  I0502 08:23:33.618166 23 utils.go:335] reached 192.168.125.206 after 0/1 tries
  I0502 08:23:33.618173 23 networking.go:42] Breadth first check of 192.168.158.135 on host 10.221.190.32...
  I0502 08:23:33.621064 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.125.220:9080/dial?request=hostname&protocol=http&host=192.168.158.135&port=8083&tries=1'] Namespace:pod-network-test-4121 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:23:33.621076 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:23:33.621409 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:23:33.621473 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4121/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.125.220%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.158.135%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0502 08:23:33.656238 23 utils.go:331] Waiting for responses: map[]
  I0502 08:23:33.656251 23 utils.go:335] reached 192.168.158.135 after 0/1 tries
  I0502 08:23:33.656257 23 networking.go:42] Breadth first check of 192.168.32.48 on host 10.221.190.33...
  I0502 08:23:33.659272 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.125.220:9080/dial?request=hostname&protocol=http&host=192.168.32.48&port=8083&tries=1'] Namespace:pod-network-test-4121 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:23:33.659283 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:23:33.659537 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:23:33.659576 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4121/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.125.220%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.32.48%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0502 08:23:33.692971 23 utils.go:331] Waiting for responses: map[]
  I0502 08:23:33.692985 23 utils.go:335] reached 192.168.32.48 after 0/1 tries
  I0502 08:23:33.693014 23 networking.go:53] Going to retry 0 out of 3 pods....
  I0502 08:23:33.693052 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4121" for this suite. @ 05/02/24 08:23:33.696
• [24.252 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 05/02/24 08:23:33.702
  I0502 08:23:33.702625 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 08:23:33.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:23:33.721
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:23:33.723
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/02/24 08:23:33.724
  E0502 08:23:34.122536      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:35.122833      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:36.123262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:37.123470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:23:37.744
  I0502 08:23:37.746592 23 output.go:196] Trying to get logs from node mini-1 pod pod-040d7010-68d8-4137-840f-e1bd0af89565 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 08:23:37.75
  I0502 08:23:37.764538 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4995" for this suite. @ 05/02/24 08:23:37.768
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 05/02/24 08:23:37.773
  I0502 08:23:37.773980 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename cronjob @ 05/02/24 08:23:37.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:23:37.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:23:37.789
  STEP: Creating a ForbidConcurrent cronjob @ 05/02/24 08:23:37.791
  STEP: Ensuring a job is scheduled @ 05/02/24 08:23:37.795
  E0502 08:23:38.124150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:39.124342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:40.125468      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:41.125633      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:42.126613      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:43.127008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:44.127996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:45.128252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:46.128806      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:47.128958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:48.129170      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:49.129401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:50.129455      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:51.129561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:52.129706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:53.129828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:54.129946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:55.130039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:56.130552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:57.130666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:58.131319      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:23:59.131516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:00.132028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:01.132221      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 05/02/24 08:24:01.799
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/02/24 08:24:01.801
  STEP: Ensuring no more jobs are scheduled @ 05/02/24 08:24:01.803
  STEP: Removing cronjob @ 05/02/24 08:24:01.805
  I0502 08:24:01.809962 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8712" for this suite. @ 05/02/24 08:24:01.816
• [24.049 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 05/02/24 08:24:01.823
  I0502 08:24:01.823870 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-runtime @ 05/02/24 08:24:01.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:24:01.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:24:01.852
  STEP: create the container @ 05/02/24 08:24:01.853
  W0502 08:24:01.859115      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/02/24 08:24:01.859
  E0502 08:24:02.132288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:03.132522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:04.133207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:05.133754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/02/24 08:24:05.875
  STEP: the container should be terminated @ 05/02/24 08:24:05.878
  STEP: the termination message should be set @ 05/02/24 08:24:05.878
  I0502 08:24:05.878212 23 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 05/02/24 08:24:05.878
  I0502 08:24:05.889080 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9053" for this suite. @ 05/02/24 08:24:05.892
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 05/02/24 08:24:05.897
  I0502 08:24:05.897815 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replicaset @ 05/02/24 08:24:05.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:24:05.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:24:05.917
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 05/02/24 08:24:05.919
  E0502 08:24:06.134096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:07.135020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 05/02/24 08:24:07.936
  STEP: Then the orphan pod is adopted @ 05/02/24 08:24:07.94
  E0502 08:24:08.135919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 05/02/24 08:24:08.946
  I0502 08:24:08.949237 23 resource.go:87] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/02/24 08:24:08.957
  E0502 08:24:09.136496      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:09.964183 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5381" for this suite. @ 05/02/24 08:24:09.967
• [4.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 05/02/24 08:24:09.973
  I0502 08:24:09.973681 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 08:24:09.974
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:24:09.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:24:09.994
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 08:24:09.996
  E0502 08:24:10.137431      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:11.137611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:12.138378      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:13.138510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:24:14.012
  I0502 08:24:14.014736 23 output.go:196] Trying to get logs from node mini-2 pod downwardapi-volume-dfea4a23-e059-4677-a1fe-a9e53a13c27e container client-container: <nil>
  STEP: delete the pod @ 05/02/24 08:24:14.018
  I0502 08:24:14.029088 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7213" for this suite. @ 05/02/24 08:24:14.032
• [4.064 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 05/02/24 08:24:14.037
  I0502 08:24:14.037899 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/02/24 08:24:14.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:24:14.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:24:14.058
  I0502 08:24:14.060584 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:24:14.139518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:15.140262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:16.140597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:17.141139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:18.141950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:19.142986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:20.143831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:20.587413 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7139" for this suite. @ 05/02/24 08:24:20.591
• [6.562 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 05/02/24 08:24:20.599
  I0502 08:24:20.599592 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:24:20.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:24:20.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:24:20.619
  STEP: Creating configMap with name configmap-test-volume-7f52d0bc-5aed-4db7-85c6-3e520b2653ee @ 05/02/24 08:24:20.621
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:24:20.625
  E0502 08:24:21.144623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:22.144776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:23.144931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:24.145108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:24:24.646
  I0502 08:24:24.649292 23 output.go:196] Trying to get logs from node mini-1 pod pod-configmaps-5b046fd0-fa55-4e69-b935-905de3014148 container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:24:24.662
  I0502 08:24:24.677457 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-129" for this suite. @ 05/02/24 08:24:24.681
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 05/02/24 08:24:24.697
  I0502 08:24:24.697117 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:24:24.697
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:24:24.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:24:24.735
  STEP: Setting up server cert @ 05/02/24 08:24:24.761
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:24:25.028
  STEP: Deploying the webhook pod @ 05/02/24 08:24:25.035
  STEP: Wait for the deployment to be ready @ 05/02/24 08:24:25.043
  I0502 08:24:25.051051 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:24:25.145121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:26.145733      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:24:27.059
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:24:27.072
  E0502 08:24:27.146709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:28.072699 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0502 08:24:28.077921 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:24:28.146789      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 05/02/24 08:24:28.588
  STEP: Creating a custom resource that should be denied by the webhook @ 05/02/24 08:24:28.599
  E0502 08:24:29.146852      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:30.147012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 05/02/24 08:24:30.605
  STEP: Updating the custom resource with disallowed data should be denied @ 05/02/24 08:24:30.612
  STEP: Deleting the custom resource should be denied @ 05/02/24 08:24:30.618
  STEP: Remove the offending key and value from the custom resource data @ 05/02/24 08:24:30.622
  STEP: Deleting the updated custom resource should be successful @ 05/02/24 08:24:30.628
  E0502 08:24:31.147284      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:31.233448 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9949" for this suite. @ 05/02/24 08:24:31.237
  STEP: Destroying namespace "webhook-markers-9155" for this suite. @ 05/02/24 08:24:31.243
• [6.553 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 05/02/24 08:24:31.25
  I0502 08:24:31.250617 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 08:24:31.251
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:24:31.265
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:24:31.267
  STEP: creating a secret @ 05/02/24 08:24:31.268
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 05/02/24 08:24:31.272
  STEP: patching the secret @ 05/02/24 08:24:31.28
  STEP: deleting the secret using a LabelSelector @ 05/02/24 08:24:31.289
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 05/02/24 08:24:31.294
  I0502 08:24:31.302072 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9152" for this suite. @ 05/02/24 08:24:31.304
• [0.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3656
  STEP: Creating a kubernetes client @ 05/02/24 08:24:31.314
  I0502 08:24:31.314199 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 08:24:31.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:24:31.332
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:24:31.335
  STEP: creating service multiprotocol-test in namespace services-500 @ 05/02/24 08:24:31.337
  STEP: creating pod pod1 in namespace services-500 @ 05/02/24 08:24:31.35
  STEP: Creating pod pod1 in namespace services-500 @ 05/02/24 08:24:31.35
  E0502 08:24:32.147448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:33.147676      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-500 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 05/02/24 08:24:33.373
  I0502 08:24:33.381318 23 service.go:4351] successfully validated that service multiprotocol-test in namespace services-500 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 05/02/24 08:24:33.381
  I0502 08:24:33.381355 23 resource.go:361] Creating new exec pod
  E0502 08:24:34.148274      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:35.148404      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:35.391693 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.64.42 80'
  I0502 08:24:35.464680 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.64.42 80\nConnection to 10.104.64.42 80 port [tcp/http] succeeded!\n"
  I0502 08:24:35.464704 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 08:24:35.464743 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.104.64.42 80'
  E0502 08:24:36.148620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:37.148746      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:38.148950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:39.149418      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:39.538513 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.104.64.42 80\nConnection to 10.104.64.42 80 port [udp/*] succeeded!\n"
  I0502 08:24:39.538547 23 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 05/02/24 08:24:39.538
  I0502 08:24:39.545554 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.64.42 80'
  I0502 08:24:39.644216 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.64.42 80\nConnection to 10.104.64.42 80 port [tcp/http] succeeded!\n"
  I0502 08:24:39.644242 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 08:24:39.644303 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.104.64.42 80'
  E0502 08:24:40.149479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:41.149619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:42.149701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:43.149857      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:43.720917 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.104.64.42 80\nConnection to 10.104.64.42 80 port [udp/*] succeeded!\n"
  I0502 08:24:43.720968 23 builder.go:147] stdout: ""
  I0502 08:24:43.721017 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.104.64.42 80'
  E0502 08:24:44.150578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:45.150720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:46.151682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:47.151749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:47.809218 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.104.64.42 80\nConnection to 10.104.64.42 80 port [udp/*] succeeded!\n"
  I0502 08:24:47.809244 23 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 05/02/24 08:24:47.809
  I0502 08:24:47.817897 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.104.64.42 80'
  E0502 08:24:48.152382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:49.152821      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:50.153520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:51.153673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:51.891457 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.104.64.42 80\nConnection to 10.104.64.42 80 port [udp/*] succeeded!\n"
  I0502 08:24:51.891507 23 builder.go:147] stdout: "pod1"
  I0502 08:24:51.891591 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.64.42 80'
  E0502 08:24:52.153756      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:53.153894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:53.981664 23 builder.go:135] rc: 1
  I0502 08:24:53.981751 23 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.64.42 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.104.64.42 80
  nc: connect to 10.104.64.42 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0502 08:24:53.981830 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.64.42 80'
  E0502 08:24:54.154779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:55.154941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:56.063704 23 builder.go:135] rc: 1
  I0502 08:24:56.063753 23 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.64.42 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.104.64.42 80
  nc: connect to 10.104.64.42 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0502 08:24:56.063825 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.64.42 80'
  E0502 08:24:56.155853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:24:57.156045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:24:58.139850 23 builder.go:135] rc: 1
  I0502 08:24:58.139890 23 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-500 exec execpodn557w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.64.42 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.104.64.42 80
  nc: connect to 10.104.64.42 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0502 08:24:58.139967 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-500" for this suite. @ 05/02/24 08:24:58.144
• [26.838 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 05/02/24 08:24:58.152
  I0502 08:24:58.152109 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 08:24:58.152
  E0502 08:24:58.156155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:24:58.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:24:58.17
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 08:24:58.172
  E0502 08:24:59.157237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:00.157394      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:01.157958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:02.158122      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:25:02.19
  I0502 08:25:02.192792 23 output.go:196] Trying to get logs from node mini-3 pod downwardapi-volume-c5cfa420-d5b3-4be0-8192-9fab1b9c2d27 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 08:25:02.204
  I0502 08:25:02.215999 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-775" for this suite. @ 05/02/24 08:25:02.219
• [4.074 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 05/02/24 08:25:02.225
  I0502 08:25:02.225907 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 08:25:02.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:25:02.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:25:02.243
  STEP: creating a Pod with a static label @ 05/02/24 08:25:02.254
  STEP: watching for Pod to be ready @ 05/02/24 08:25:02.286
  I0502 08:25:02.288063 23 pods.go:945] observed Pod pod-test in namespace pods-9070 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0502 08:25:02.316250 23 pods.go:945] observed Pod pod-test in namespace pods-9070 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC  }]
  I0502 08:25:02.337259 23 pods.go:945] observed Pod pod-test in namespace pods-9070 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC  }]
  I0502 08:25:02.731681 23 pods.go:945] observed Pod pod-test in namespace pods-9070 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC  }]
  E0502 08:25:03.158201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:25:03.848195 23 pods.go:948] Found Pod pod-test in namespace pods-9070 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:03 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-02 08:25:02 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 05/02/24 08:25:03.851
  STEP: getting the Pod and ensuring that it's patched @ 05/02/24 08:25:03.859
  STEP: replacing the Pod's status Ready condition to False @ 05/02/24 08:25:03.862
  STEP: check the Pod again to ensure its Ready conditions are False @ 05/02/24 08:25:03.871
  STEP: deleting the Pod via a Collection with a LabelSelector @ 05/02/24 08:25:03.871
  STEP: watching for the Pod to be deleted @ 05/02/24 08:25:03.877
  I0502 08:25:03.879328 23 pods.go:1058] observed event type MODIFIED
  I0502 08:25:03.909557 23 pods.go:1058] observed event type MODIFIED
  E0502 08:25:04.159174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:05.159337      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:25:06.012026 23 pods.go:1058] observed event type MODIFIED
  I0502 08:25:06.108606 23 pods.go:1058] observed event type MODIFIED
  E0502 08:25:06.159743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:25:06.849714 23 pods.go:1058] observed event type MODIFIED
  I0502 08:25:06.859029 23 pods.go:1058] observed event type MODIFIED
  I0502 08:25:06.866431 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9070" for this suite. @ 05/02/24 08:25:06.871
• [4.652 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 05/02/24 08:25:06.878
  I0502 08:25:06.878645 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename tables @ 05/02/24 08:25:06.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:25:06.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:25:06.897
  I0502 08:25:06.901681 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-2375" for this suite. @ 05/02/24 08:25:06.905
• [0.033 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:392
  STEP: Creating a kubernetes client @ 05/02/24 08:25:06.911
  I0502 08:25:06.911681 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/02/24 08:25:06.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:25:06.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:25:06.938
  STEP: set up a multi version CRD @ 05/02/24 08:25:06.94
  I0502 08:25:06.940440 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:25:07.160345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:08.161419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:09.161705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:10.162586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:11.163246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 05/02/24 08:25:11.591
  STEP: check the new version name is served @ 05/02/24 08:25:11.604
  E0502 08:25:12.163856      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 05/02/24 08:25:13.08
  E0502 08:25:13.164853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 05/02/24 08:25:14.079
  E0502 08:25:14.165104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:15.165856      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:16.166479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:17.166838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:25:17.798495 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7159" for this suite. @ 05/02/24 08:25:17.806
• [10.902 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 05/02/24 08:25:17.813
  I0502 08:25:17.813749 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename security-context-test @ 05/02/24 08:25:17.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:25:17.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:25:17.846
  E0502 08:25:18.167019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:19.167515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:20.168163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:21.168289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:22.168465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:23.168575      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:24.169225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:25.169822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:25:25.882928 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9817" for this suite. @ 05/02/24 08:25:25.886
• [8.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:882
  STEP: Creating a kubernetes client @ 05/02/24 08:25:25.892
  I0502 08:25:25.892240 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:25:25.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:25:25.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:25:25.914
  STEP: validating api versions @ 05/02/24 08:25:25.916
  I0502 08:25:25.916637 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-2123 api-versions'
  I0502 08:25:25.954662 23 builder.go:146] stderr: ""
  I0502 08:25:25.954709 23 builder.go:147] stdout: "acme.cert-manager.io/v1\nadmissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncert-manager.io/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nmetallb.io/v1alpha1\nmetallb.io/v1beta1\nmetallb.io/v1beta2\nmonitoring.coreos.com/v1\nmonitoring.coreos.com/v1alpha1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\norka.macstadium.com/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\ntraefik.containo.us/v1alpha1\ntraefik.io/v1alpha1\nv1\n"
  I0502 08:25:25.954777 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2123" for this suite. @ 05/02/24 08:25:25.958
• [0.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 05/02/24 08:25:25.965
  I0502 08:25:25.965426 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-preemption @ 05/02/24 08:25:25.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:25:25.982
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:25:25.985
  I0502 08:25:25.998590 23 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0502 08:25:26.169830      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:27.169986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:28.170606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:29.170946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:30.171918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:31.172073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:32.173074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:33.173242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:34.173277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:35.173434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:36.174406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:37.174606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:38.174657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:39.175707      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:40.175961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:41.176046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:42.176790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:43.177121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:44.177900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:45.178386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:46.178952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:47.179325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:48.179961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:49.180552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:50.181325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:51.181489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:52.182381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:53.182550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:54.182601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:55.182748      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:56.183486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:57.183622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:58.184081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:25:59.184637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:00.184718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:01.184868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:02.185348      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:03.186358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:04.187269      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:05.187408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:06.187994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:07.188695      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:08.189480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:09.189831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:10.190408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:11.190554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:12.191328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:13.191462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:14.192533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:15.192695      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:16.192923      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:17.193016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:18.193558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:19.193816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:20.194777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:21.195057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:22.195130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:23.195303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:24.196043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:25.196200      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:26:26.003785 23 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/02/24 08:26:26.006
  I0502 08:26:26.006611 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/02/24 08:26:26.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:26:26.023
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:26:26.026
  STEP: Finding an available node @ 05/02/24 08:26:26.028
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/02/24 08:26:26.028
  E0502 08:26:26.196470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:27.196608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:28.196784      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:29.197222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/02/24 08:26:30.046
  I0502 08:26:30.057028 23 preemption.go:583] found a healthy node: mini-2
  E0502 08:26:30.197400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:31.197564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:32.198144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:33.198335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:34.199294      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:35.199799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:26:36.111783 23 preemption.go:706] pods created so far: [1 1 1]
  I0502 08:26:36.111801 23 preemption.go:707] length of pods created so far: 3
  E0502 08:26:36.199871      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:37.200651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:26:38.133132 23 preemption.go:724] pods created so far: [2 2 1]
  E0502 08:26:38.201310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:39.201550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:40.201837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:41.201979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:42.202131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:43.202292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:44.202651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:26:45.199967 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0502 08:26:45.203009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "sched-preemption-path-4076" for this suite. @ 05/02/24 08:26:45.203
  I0502 08:26:45.211367 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2624" for this suite. @ 05/02/24 08:26:45.214
• [79.256 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 05/02/24 08:26:45.221
  I0502 08:26:45.221831 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename statefulset @ 05/02/24 08:26:45.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:26:45.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:26:45.245
  STEP: Creating service test in namespace statefulset-1999 @ 05/02/24 08:26:45.247
  STEP: Creating statefulset ss in namespace statefulset-1999 @ 05/02/24 08:26:45.252
  I0502 08:26:45.266760 23 wait.go:40] Found 0 stateful pods, waiting for 1
  E0502 08:26:46.203787      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:47.204038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:48.204195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:49.204781      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:50.204933      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:51.205071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:52.205256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:53.205326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:54.205685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:55.205785      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:26:55.266512 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 05/02/24 08:26:55.271
  STEP: updating a scale subresource @ 05/02/24 08:26:55.273
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/02/24 08:26:55.277
  STEP: Patch a scale subresource @ 05/02/24 08:26:55.283
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/02/24 08:26:55.301
  I0502 08:26:55.304608 23 statefulset.go:135] Deleting all statefulset in ns statefulset-1999
  I0502 08:26:55.307066 23 rest.go:150] Scaling statefulset ss to 0
  E0502 08:26:56.206627      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:57.207477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:58.207575      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:26:59.208066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:00.208191      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:01.208330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:02.208464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:03.208577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:04.208805      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:05.208988      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:27:05.321328 23 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0502 08:27:05.323646 23 rest.go:88] Deleting statefulset ss
  I0502 08:27:05.334731 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1999" for this suite. @ 05/02/24 08:27:05.338
• [20.122 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:715
  STEP: Creating a kubernetes client @ 05/02/24 08:27:05.344
  I0502 08:27:05.344362 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:27:05.344
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:27:05.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:27:05.367
  STEP: Setting up server cert @ 05/02/24 08:27:05.395
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:27:05.608
  STEP: Deploying the webhook pod @ 05/02/24 08:27:05.615
  STEP: Wait for the deployment to be ready @ 05/02/24 08:27:05.624
  I0502 08:27:05.630516 23 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0502 08:27:06.209216      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:07.209381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:27:07.638
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:27:07.648
  E0502 08:27:08.209917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:27:08.648479 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 05/02/24 08:27:08.653
  STEP: verifying the validating webhook match conditions @ 05/02/24 08:27:08.66
  STEP: updating the validating webhook match conditions @ 05/02/24 08:27:08.662
  STEP: verifying the validating webhook match conditions @ 05/02/24 08:27:08.668
  I0502 08:27:08.727257 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3316" for this suite. @ 05/02/24 08:27:08.73
  STEP: Destroying namespace "webhook-markers-4552" for this suite. @ 05/02/24 08:27:08.745
• [3.413 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 05/02/24 08:27:08.757
  I0502 08:27:08.757926 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename watch @ 05/02/24 08:27:08.758
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:27:08.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:27:08.78
  STEP: creating a watch on configmaps with label A @ 05/02/24 08:27:08.782
  STEP: creating a watch on configmaps with label B @ 05/02/24 08:27:08.783
  STEP: creating a watch on configmaps with label A or B @ 05/02/24 08:27:08.784
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 05/02/24 08:27:08.784
  I0502 08:27:08.788219 23 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1168  946d28cf-1dab-4a0e-88ce-4c1702c20b05 14854 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 08:27:08.788285 23 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1168  946d28cf-1dab-4a0e-88ce-4c1702c20b05 14854 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 05/02/24 08:27:08.788
  I0502 08:27:08.793526 23 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1168  946d28cf-1dab-4a0e-88ce-4c1702c20b05 14855 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 08:27:08.793569 23 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1168  946d28cf-1dab-4a0e-88ce-4c1702c20b05 14855 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 05/02/24 08:27:08.793
  I0502 08:27:08.799858 23 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1168  946d28cf-1dab-4a0e-88ce-4c1702c20b05 14856 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 08:27:08.799903 23 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1168  946d28cf-1dab-4a0e-88ce-4c1702c20b05 14856 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 05/02/24 08:27:08.799
  I0502 08:27:08.803827 23 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1168  946d28cf-1dab-4a0e-88ce-4c1702c20b05 14858 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 08:27:08.803851 23 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1168  946d28cf-1dab-4a0e-88ce-4c1702c20b05 14858 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 05/02/24 08:27:08.803
  I0502 08:27:08.806722 23 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1168  b272ef8a-08a6-4c7c-8030-c77d08c238f0 14859 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 08:27:08.806771 23 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1168  b272ef8a-08a6-4c7c-8030-c77d08c238f0 14859 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0502 08:27:09.210714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:10.210975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:11.211128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:12.211274      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:13.211422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:14.211921      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:15.212083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:16.212242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:17.212373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:18.212505      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 05/02/24 08:27:18.807
  I0502 08:27:18.812870 23 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1168  b272ef8a-08a6-4c7c-8030-c77d08c238f0 14923 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 08:27:18.812956 23 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1168  b272ef8a-08a6-4c7c-8030-c77d08c238f0 14923 0 2024-05-02 08:27:08 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-02 08:27:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0502 08:27:19.212760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:20.212919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:21.213050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:22.213221      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:23.213370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:24.213768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:25.214013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:26.214148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:27.214308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:28.214448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:27:28.813221 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1168" for this suite. @ 05/02/24 08:27:28.817
• [20.066 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 05/02/24 08:27:28.824
  I0502 08:27:28.824045 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:27:28.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:27:28.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:27:28.844
  STEP: Creating configMap with name cm-test-opt-del-ba6213d2-4a78-4d6a-9c80-e0899c0baecd @ 05/02/24 08:27:28.85
  STEP: Creating configMap with name cm-test-opt-upd-25080b5f-f58f-4273-aced-99b5502caddc @ 05/02/24 08:27:28.854
  STEP: Creating the pod @ 05/02/24 08:27:28.859
  E0502 08:27:29.214838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:30.215017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:31.215925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:32.216116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-ba6213d2-4a78-4d6a-9c80-e0899c0baecd @ 05/02/24 08:27:32.905
  STEP: Updating configmap cm-test-opt-upd-25080b5f-f58f-4273-aced-99b5502caddc @ 05/02/24 08:27:32.91
  STEP: Creating configMap with name cm-test-opt-create-e61f996a-d642-45b1-afbd-3f0d867a01ba @ 05/02/24 08:27:32.914
  STEP: waiting to observe update in volume @ 05/02/24 08:27:32.918
  E0502 08:27:33.216201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:34.216446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:35.216938      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:36.217075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:37.217366      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:38.217535      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:39.217751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:40.217938      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:41.218820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:42.218997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:43.219148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:44.219466      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:45.219597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:46.219771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:47.220008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:48.220163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:49.221103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:50.221245      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:51.221429      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:52.221598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:53.222524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:54.222822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:55.222958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:56.223138      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:57.223335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:58.223484      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:27:59.223991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:00.224145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:01.224497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:02.224966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:03.225953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:04.226212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:05.227024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:06.227302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:07.227721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:08.227859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:09.228757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:10.228928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:11.229230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:12.229384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:13.229483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:14.229827      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:15.230293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:16.230466      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:17.231241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:18.231396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:19.231652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:20.231792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:21.232084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:22.232254      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:23.232881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:24.233104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:25.233773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:26.234045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:27.234340      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:28.234500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:29.234765      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:30.234954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:31.236011      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:32.236686      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:33.237374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:34.237769      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:35.238308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:36.238486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:37.238787      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:38.238917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:39.239766      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:40.239919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:41.240765      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:42.240933      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:43.241634      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:44.241963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:28:45.147875 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3039" for this suite. @ 05/02/24 08:28:45.152
• [76.335 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 05/02/24 08:28:45.159
  I0502 08:28:45.159603 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 08:28:45.159
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:28:45.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:28:45.182
  STEP: Creating the pod @ 05/02/24 08:28:45.184
  E0502 08:28:45.242585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:46.242964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:47.243063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:48.243230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:49.243515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:28:49.725447 23 pod_client.go:141] Successfully updated pod "labelsupdate59b1dc55-200f-4e9a-ab6c-c38d4dd9a04a"
  E0502 08:28:50.243814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:51.243985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:28:51.736634 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5755" for this suite. @ 05/02/24 08:28:51.739
• [6.587 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 05/02/24 08:28:51.746
  I0502 08:28:51.746526 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:28:51.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:28:51.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:28:51.764
  STEP: Setting up server cert @ 05/02/24 08:28:51.794
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:28:52.094
  STEP: Deploying the webhook pod @ 05/02/24 08:28:52.101
  STEP: Wait for the deployment to be ready @ 05/02/24 08:28:52.113
  I0502 08:28:52.128271 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:28:52.244501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:53.244647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:28:54.137786 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 28, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 28, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 28, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 28, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:28:54.245209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:55.245367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:28:56.141
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:28:56.153
  E0502 08:28:56.246158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:28:57.154138 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/02/24 08:28:57.225
  E0502 08:28:57.247142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/02/24 08:28:57.257
  STEP: Deleting the collection of validation webhooks @ 05/02/24 08:28:57.281
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/02/24 08:28:57.328
  I0502 08:28:57.383032 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-150" for this suite. @ 05/02/24 08:28:57.387
  STEP: Destroying namespace "webhook-markers-3820" for this suite. @ 05/02/24 08:28:57.397
• [5.659 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 05/02/24 08:28:57.405
  I0502 08:28:57.405143 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename namespaces @ 05/02/24 08:28:57.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:28:57.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:28:57.422
  STEP: Creating a test namespace @ 05/02/24 08:28:57.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:28:57.438
  STEP: Creating a pod in the namespace @ 05/02/24 08:28:57.441
  STEP: Waiting for the pod to have running status @ 05/02/24 08:28:57.447
  E0502 08:28:58.247611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:28:59.247882      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 05/02/24 08:28:59.46
  STEP: Waiting for the namespace to be removed. @ 05/02/24 08:28:59.47
  E0502 08:29:00.248643      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:01.248715      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:02.249603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:03.249746      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:04.249938      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:05.250865      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:06.251175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:07.251652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:08.252652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:09.252992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:10.253257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/02/24 08:29:10.474
  STEP: Verifying there are no pods in the namespace @ 05/02/24 08:29:10.495
  I0502 08:29:10.498039 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9415" for this suite. @ 05/02/24 08:29:10.501
  STEP: Destroying namespace "nsdeletetest-7975" for this suite. @ 05/02/24 08:29:10.508
  I0502 08:29:10.511827 23 framework.go:370] Namespace nsdeletetest-7975 was already deleted
  STEP: Destroying namespace "nsdeletetest-1195" for this suite. @ 05/02/24 08:29:10.511
• [13.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 05/02/24 08:29:10.518
  I0502 08:29:10.518573 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubelet-test @ 05/02/24 08:29:10.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:10.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:10.535
  E0502 08:29:11.254031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:12.254259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:29:12.560363 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1499" for this suite. @ 05/02/24 08:29:12.563
• [2.053 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 05/02/24 08:29:12.571
  I0502 08:29:12.571289 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replication-controller @ 05/02/24 08:29:12.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:12.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:12.591
  STEP: Creating ReplicationController "e2e-rc-kcv8m" @ 05/02/24 08:29:12.593
  I0502 08:29:12.598329 23 rc.go:792] Get Replication Controller "e2e-rc-kcv8m" to confirm replicas
  E0502 08:29:13.254704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:29:13.599389 23 rc.go:792] Get Replication Controller "e2e-rc-kcv8m" to confirm replicas
  I0502 08:29:13.602625 23 rc.go:801] Found 1 replicas for "e2e-rc-kcv8m" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-kcv8m" @ 05/02/24 08:29:13.602
  STEP: Updating a scale subresource @ 05/02/24 08:29:13.605
  STEP: Verifying replicas where modified for replication controller "e2e-rc-kcv8m" @ 05/02/24 08:29:13.61
  I0502 08:29:13.610819 23 rc.go:792] Get Replication Controller "e2e-rc-kcv8m" to confirm replicas
  E0502 08:29:14.254794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:29:14.611304 23 rc.go:792] Get Replication Controller "e2e-rc-kcv8m" to confirm replicas
  I0502 08:29:14.614226 23 rc.go:801] Found 2 replicas for "e2e-rc-kcv8m" replication controller
  I0502 08:29:14.614318 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6570" for this suite. @ 05/02/24 08:29:14.617
• [2.052 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
  STEP: Creating a kubernetes client @ 05/02/24 08:29:14.623
  I0502 08:29:14.623155 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:29:14.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:14.637
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:14.639
  STEP: create deployment with httpd image @ 05/02/24 08:29:14.641
  I0502 08:29:14.641577 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8246 create -f -'
  I0502 08:29:14.709235 23 builder.go:146] stderr: ""
  I0502 08:29:14.709257 23 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 05/02/24 08:29:14.709
  I0502 08:29:14.709297 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8246 diff -f -'
  E0502 08:29:15.255009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:16.255131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:17.255349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:18.255531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:29:18.975486 23 builder.go:135] rc: 1
  I0502 08:29:18.975560 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8246 delete -f -'
  I0502 08:29:19.015061 23 builder.go:146] stderr: ""
  I0502 08:29:19.015084 23 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I0502 08:29:19.015164 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8246" for this suite. @ 05/02/24 08:29:19.018
• [4.403 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 05/02/24 08:29:19.026
  I0502 08:29:19.026812 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename containers @ 05/02/24 08:29:19.027
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:19.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:19.046
  E0502 08:29:19.255874      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:20.256029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:21.256523      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:22.256685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:29:23.067976 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6424" for this suite. @ 05/02/24 08:29:23.071
• [4.052 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 05/02/24 08:29:23.078
  I0502 08:29:23.078424 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:29:23.078
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:23.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:23.1
  I0502 08:29:23.131057 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3215" for this suite. @ 05/02/24 08:29:23.133
• [0.060 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 05/02/24 08:29:23.138
  I0502 08:29:23.138937 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubelet-test @ 05/02/24 08:29:23.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:23.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:23.171
  E0502 08:29:23.256650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:24.256929      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:25.257084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:26.257540      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:29:27.196376 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-246" for this suite. @ 05/02/24 08:29:27.199
• [4.067 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 05/02/24 08:29:27.205
  I0502 08:29:27.205860 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 08:29:27.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:27.22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:27.222
  STEP: Counting existing ResourceQuota @ 05/02/24 08:29:27.224
  E0502 08:29:27.257916      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:28.258168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:29.258524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:30.258586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:31.259127      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/02/24 08:29:32.228
  STEP: Ensuring resource quota status is calculated @ 05/02/24 08:29:32.235
  E0502 08:29:32.259721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:33.260446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 05/02/24 08:29:34.238
  STEP: Ensuring resource quota status captures replication controller creation @ 05/02/24 08:29:34.247
  E0502 08:29:34.260878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:35.260998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 05/02/24 08:29:36.251
  STEP: Ensuring resource quota status released usage @ 05/02/24 08:29:36.255
  E0502 08:29:36.261611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:37.261738      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:29:38.258639 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0502 08:29:38.261920      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "resourcequota-5799" for this suite. @ 05/02/24 08:29:38.261
• [11.062 seconds]
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 05/02/24 08:29:38.267
  I0502 08:29:38.267795 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/02/24 08:29:38.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:38.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:38.286
  I0502 08:29:38.290312 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-1667" for this suite. @ 05/02/24 08:29:38.293
• [0.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 05/02/24 08:29:38.298
  I0502 08:29:38.298458 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename limitrange @ 05/02/24 08:29:38.298
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:38.312
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:38.315
  STEP: Creating LimitRange "e2e-limitrange-566gp" in namespace "limitrange-3283" @ 05/02/24 08:29:38.317
  STEP: Creating another limitRange in another namespace @ 05/02/24 08:29:38.321
  I0502 08:29:38.339580 23 limit_range.go:299] Namespace "e2e-limitrange-566gp-4355" created
  I0502 08:29:38.339591 23 limit_range.go:300] Creating LimitRange "e2e-limitrange-566gp" in namespace "e2e-limitrange-566gp-4355"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-566gp" @ 05/02/24 08:29:38.343
  I0502 08:29:38.345523 23 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-566gp" in "limitrange-3283" namespace @ 05/02/24 08:29:38.345
  I0502 08:29:38.350705 23 limit_range.go:335] LimitRange "e2e-limitrange-566gp" has been patched
  STEP: Delete LimitRange "e2e-limitrange-566gp" by Collection with labelSelector: "e2e-limitrange-566gp=patched" @ 05/02/24 08:29:38.35
  STEP: Confirm that the limitRange "e2e-limitrange-566gp" has been deleted @ 05/02/24 08:29:38.355
  I0502 08:29:38.355532 23 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I0502 08:29:38.360833 23 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-566gp=patched"
  I0502 08:29:38.360846 23 limit_range.go:344] LimitRange "e2e-limitrange-566gp" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-566gp" @ 05/02/24 08:29:38.36
  I0502 08:29:38.363103 23 limit_range.go:350] Found 1 limitRange
  I0502 08:29:38.363139 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-3283" for this suite. @ 05/02/24 08:29:38.365
  STEP: Destroying namespace "e2e-limitrange-566gp-4355" for this suite. @ 05/02/24 08:29:38.371
• [0.079 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 05/02/24 08:29:38.377
  I0502 08:29:38.377385 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename limitrange @ 05/02/24 08:29:38.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:38.392
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:38.395
  STEP: Creating a LimitRange @ 05/02/24 08:29:38.396
  STEP: Setting up watch @ 05/02/24 08:29:38.396
  STEP: Submitting a LimitRange @ 05/02/24 08:29:38.499
  STEP: Verifying LimitRange creation was observed @ 05/02/24 08:29:38.504
  STEP: Fetching the LimitRange to ensure it has proper values @ 05/02/24 08:29:38.504
  I0502 08:29:38.507013 23 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0502 08:29:38.507029 23 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 05/02/24 08:29:38.507
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 05/02/24 08:29:38.511
  I0502 08:29:38.515290 23 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0502 08:29:38.515320 23 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 05/02/24 08:29:38.515
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 05/02/24 08:29:38.52
  I0502 08:29:38.527357 23 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0502 08:29:38.527398 23 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 05/02/24 08:29:38.527
  STEP: Failing to create a Pod with more than max resources @ 05/02/24 08:29:38.529
  STEP: Updating a LimitRange @ 05/02/24 08:29:38.532
  STEP: Verifying LimitRange updating is effective @ 05/02/24 08:29:38.536
  E0502 08:29:39.262587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:40.262722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 05/02/24 08:29:40.54
  STEP: Failing to create a Pod with more than max resources @ 05/02/24 08:29:40.545
  STEP: Deleting a LimitRange @ 05/02/24 08:29:40.547
  STEP: Verifying the LimitRange was deleted @ 05/02/24 08:29:40.553
  E0502 08:29:41.262973      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:42.263041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:43.264062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:44.264391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:45.264551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:29:45.556738 23 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 05/02/24 08:29:45.556
  I0502 08:29:45.563655 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-1236" for this suite. @ 05/02/24 08:29:45.568
• [7.200 seconds]
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 05/02/24 08:29:45.577
  I0502 08:29:45.577517 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-pred @ 05/02/24 08:29:45.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:45.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:45.597
  I0502 08:29:45.599563 23 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0502 08:29:45.605229 23 util.go:400] Waiting for terminating namespaces to be deleted...
  I0502 08:29:45.607405 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-1 before test
  I0502 08:29:45.614840 23 predicates.go:887] calico-node-74plz from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.614852 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 08:29:45.614858 23 predicates.go:887] kube-proxy-m56bg from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.614862 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 08:29:45.614868 23 predicates.go:887] pod-no-resources from limitrange-1236 started at 2024-05-02 08:29:38 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.614872 23 predicates.go:889] 	Container pause ready: true, restart count 0
  I0502 08:29:45.614876 23 predicates.go:887] helm-charts-fluent-bit-kxv24 from logging started at 2024-05-02 08:03:28 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.614881 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 08:29:45.614891 23 predicates.go:887] kps-prometheus-node-exporter-85b92 from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.614900 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 08:29:45.614905 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-qq8kg from sonobuoy started at 2024-05-02 08:09:23 +0000 UTC (2 container statuses recorded)
  I0502 08:29:45.614912 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:29:45.614915 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0502 08:29:45.614920 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-2 before test
  I0502 08:29:45.622446 23 predicates.go:887] calico-node-r29fd from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.622457 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 08:29:45.622463 23 predicates.go:887] kube-proxy-hmtzq from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.622467 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 08:29:45.622472 23 predicates.go:887] busybox-scheduling-3b3a8001-38c5-4cfd-9124-e4729d939f6a from kubelet-test-1499 started at 2024-05-02 08:29:10 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.622476 23 predicates.go:889] 	Container busybox-scheduling-3b3a8001-38c5-4cfd-9124-e4729d939f6a ready: true, restart count 0
  I0502 08:29:45.622480 23 predicates.go:887] pod-partial-resources from limitrange-1236 started at 2024-05-02 08:29:38 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.622484 23 predicates.go:889] 	Container pause ready: true, restart count 0
  I0502 08:29:45.622489 23 predicates.go:887] helm-charts-fluent-bit-hx6df from logging started at 2024-05-02 08:03:27 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.622493 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 08:29:45.622497 23 predicates.go:887] kps-prometheus-node-exporter-r49xh from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.622501 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 08:29:45.622506 23 predicates.go:887] sonobuoy from sonobuoy started at 2024-05-02 08:09:14 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.622510 23 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0502 08:29:45.622514 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-zq7p5 from sonobuoy started at 2024-05-02 08:09:23 +0000 UTC (2 container statuses recorded)
  I0502 08:29:45.622518 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:29:45.622522 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0502 08:29:45.622526 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-3 before test
  I0502 08:29:45.630513 23 predicates.go:887] calico-node-2k27s from kube-system started at 2024-05-02 08:02:51 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.630524 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 08:29:45.630530 23 predicates.go:887] kube-proxy-jxzqw from kube-system started at 2024-05-02 08:02:51 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.630534 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 08:29:45.630538 23 predicates.go:887] pfpod from limitrange-1236 started at 2024-05-02 08:29:40 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.630542 23 predicates.go:889] 	Container pause ready: true, restart count 0
  I0502 08:29:45.630546 23 predicates.go:887] pfpod2 from limitrange-1236 started at 2024-05-02 08:29:45 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.630550 23 predicates.go:889] 	Container pause ready: false, restart count 0
  I0502 08:29:45.630555 23 predicates.go:887] helm-charts-fluent-bit-hsj7q from logging started at 2024-05-02 08:03:28 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.630558 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 08:29:45.630563 23 predicates.go:887] kps-prometheus-node-exporter-mrb8g from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 08:29:45.630567 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 08:29:45.630571 23 predicates.go:887] sonobuoy-e2e-job-746b2c2b96604533 from sonobuoy started at 2024-05-02 08:09:22 +0000 UTC (2 container statuses recorded)
  I0502 08:29:45.630575 23 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0502 08:29:45.630579 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:29:45.630584 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-5zkb9 from sonobuoy started at 2024-05-02 08:09:22 +0000 UTC (2 container statuses recorded)
  I0502 08:29:45.630588 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:29:45.630591 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/02/24 08:29:45.63
  E0502 08:29:46.265015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:47.265279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/02/24 08:29:47.648
  STEP: Trying to apply a random label on the found node. @ 05/02/24 08:29:47.657
  STEP: verifying the node has the label kubernetes.io/e2e-f7ed2b67-11b7-46cf-9493-545f99deb44e 42 @ 05/02/24 08:29:47.669
  STEP: Trying to relaunch the pod, now with labels. @ 05/02/24 08:29:47.672
  E0502 08:29:48.265835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:49.266384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-f7ed2b67-11b7-46cf-9493-545f99deb44e off the node mini-1 @ 05/02/24 08:29:49.69
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-f7ed2b67-11b7-46cf-9493-545f99deb44e @ 05/02/24 08:29:49.702
  I0502 08:29:49.707204 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7757" for this suite. @ 05/02/24 08:29:49.713
• [4.143 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 05/02/24 08:29:49.72
  I0502 08:29:49.720153 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 08:29:49.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:49.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:49.744
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 05/02/24 08:29:49.747
  E0502 08:29:50.266900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:51.267094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:52.268081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:53.269082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:29:53.764
  I0502 08:29:53.766903 23 output.go:196] Trying to get logs from node mini-1 pod pod-1c80d81b-e43c-44e1-9dc4-d3959281c74e container test-container: <nil>
  STEP: delete the pod @ 05/02/24 08:29:53.77
  I0502 08:29:53.780959 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6404" for this suite. @ 05/02/24 08:29:53.784
• [4.069 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:348
  STEP: Creating a kubernetes client @ 05/02/24 08:29:53.79
  I0502 08:29:53.790757 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename disruption @ 05/02/24 08:29:53.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:29:53.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:29:53.81
  STEP: Creating a pdb that targets all three pods in a test replica set @ 05/02/24 08:29:53.812
  STEP: Waiting for the pdb to be processed @ 05/02/24 08:29:53.815
  E0502 08:29:54.269453      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:55.269623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 05/02/24 08:29:55.822
  STEP: Waiting for all pods to be running @ 05/02/24 08:29:55.822
  I0502 08:29:55.828906 23 disruption.go:567] pods: 0 < 3
  E0502 08:29:56.270558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:57.270713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/02/24 08:29:57.827
  STEP: Updating the pdb to allow a pod to be evicted @ 05/02/24 08:29:57.833
  STEP: Waiting for the pdb to be processed @ 05/02/24 08:29:57.839
  E0502 08:29:58.270814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:29:59.271180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/02/24 08:29:59.842
  STEP: Waiting for all pods to be running @ 05/02/24 08:29:59.842
  STEP: Waiting for the pdb to observed all healthy pods @ 05/02/24 08:29:59.845
  STEP: Patching the pdb to disallow a pod to be evicted @ 05/02/24 08:29:59.863
  STEP: Waiting for the pdb to be processed @ 05/02/24 08:29:59.88
  E0502 08:30:00.271513      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:01.271638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 05/02/24 08:30:01.887
  STEP: locating a running pod @ 05/02/24 08:30:01.89
  STEP: Deleting the pdb to allow a pod to be evicted @ 05/02/24 08:30:01.899
  STEP: Waiting for the pdb to be deleted @ 05/02/24 08:30:01.905
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/02/24 08:30:01.908
  STEP: Waiting for all pods to be running @ 05/02/24 08:30:01.908
  I0502 08:30:01.928059 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2602" for this suite. @ 05/02/24 08:30:01.935
• [8.174 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 05/02/24 08:30:01.964
  I0502 08:30:01.964811 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename certificates @ 05/02/24 08:30:01.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:01.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:01.993
  E0502 08:30:02.272153      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting /apis @ 05/02/24 08:30:02.352
  STEP: getting /apis/certificates.k8s.io @ 05/02/24 08:30:02.356
  STEP: getting /apis/certificates.k8s.io/v1 @ 05/02/24 08:30:02.357
  STEP: creating @ 05/02/24 08:30:02.358
  STEP: getting @ 05/02/24 08:30:02.379
  STEP: listing @ 05/02/24 08:30:02.385
  STEP: watching @ 05/02/24 08:30:02.39
  I0502 08:30:02.390149 23 certificates.go:316] starting watch
  STEP: patching @ 05/02/24 08:30:02.392
  STEP: updating @ 05/02/24 08:30:02.4
  I0502 08:30:02.409195 23 certificates.go:332] waiting for watch events with expected annotations
  I0502 08:30:02.409212 23 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 05/02/24 08:30:02.409
  STEP: patching /approval @ 05/02/24 08:30:02.412
  STEP: updating /approval @ 05/02/24 08:30:02.42
  STEP: getting /status @ 05/02/24 08:30:02.426
  STEP: patching /status @ 05/02/24 08:30:02.429
  STEP: updating /status @ 05/02/24 08:30:02.437
  STEP: deleting @ 05/02/24 08:30:02.444
  STEP: deleting a collection @ 05/02/24 08:30:02.458
  I0502 08:30:02.482669 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-9786" for this suite. @ 05/02/24 08:30:02.487
• [0.531 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 05/02/24 08:30:02.496
  I0502 08:30:02.496143 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:30:02.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:02.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:02.527
  STEP: Creating configMap with name projected-configmap-test-volume-17630130-1c25-4539-8fe4-cccc626a1e24 @ 05/02/24 08:30:02.53
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:30:02.542
  E0502 08:30:03.272309      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:04.272622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:05.273176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:06.273352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:30:06.579
  I0502 08:30:06.581406 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-configmaps-4591c99c-ef91-4fb7-b9b0-c4a4a88de287 container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:30:06.585
  I0502 08:30:06.597987 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8311" for this suite. @ 05/02/24 08:30:06.601
• [4.111 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 05/02/24 08:30:06.607
  I0502 08:30:06.607401 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 08:30:06.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:06.623
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:06.625
  STEP: creating the pod @ 05/02/24 08:30:06.626
  STEP: submitting the pod to kubernetes @ 05/02/24 08:30:06.626
  STEP: verifying QOS class is set on the pod @ 05/02/24 08:30:06.633
  I0502 08:30:06.639258 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5771" for this suite. @ 05/02/24 08:30:06.645
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 05/02/24 08:30:06.653
  I0502 08:30:06.653955 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename events @ 05/02/24 08:30:06.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:06.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:06.674
  STEP: Create set of events @ 05/02/24 08:30:06.677
  STEP: get a list of Events with a label in the current namespace @ 05/02/24 08:30:06.696
  STEP: delete a list of events @ 05/02/24 08:30:06.698
  I0502 08:30:06.698414 23 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/02/24 08:30:06.709
  I0502 08:30:06.711238 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8189" for this suite. @ 05/02/24 08:30:06.714
• [0.066 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 05/02/24 08:30:06.719
  I0502 08:30:06.719695 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/02/24 08:30:06.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:06.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:06.738
  STEP: creating @ 05/02/24 08:30:06.739
  STEP: getting @ 05/02/24 08:30:06.751
  STEP: listing in namespace @ 05/02/24 08:30:06.755
  STEP: patching @ 05/02/24 08:30:06.757
  STEP: deleting @ 05/02/24 08:30:06.763
  I0502 08:30:06.773427 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5624" for this suite. @ 05/02/24 08:30:06.776
• [0.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:927
  STEP: Creating a kubernetes client @ 05/02/24 08:30:06.784
  I0502 08:30:06.784514 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename job @ 05/02/24 08:30:06.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:06.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:06.8
  STEP: Creating a suspended job @ 05/02/24 08:30:06.803
  STEP: Patching the Job @ 05/02/24 08:30:06.807
  STEP: Watching for Job to be patched @ 05/02/24 08:30:06.818
  I0502 08:30:06.819129 23 job.go:1109] Event ADDED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7] and annotations: map[]
  I0502 08:30:06.819147 23 job.go:1112] Event MODIFIED found for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[]
  STEP: Updating the job @ 05/02/24 08:30:06.819
  STEP: Watching for Job to be updated @ 05/02/24 08:30:06.825
  I0502 08:30:06.827991 23 job.go:1112] Event MODIFIED found for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:06.828010 23 job.go:1005] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 05/02/24 08:30:06.828
  I0502 08:30:06.830776 23 job.go:1012] Job: e2e-t6st7 as labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched]
  STEP: Waiting for job to complete @ 05/02/24 08:30:06.83
  E0502 08:30:07.274077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:08.274847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:09.275622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:10.275824      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:11.276021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:12.276146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:13.276472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:14.277409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:15.277508      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:16.277741      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:17.278150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:18.278328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 05/02/24 08:30:18.833
  STEP: Watching for Job to be deleted @ 05/02/24 08:30:18.839
  I0502 08:30:18.843016 23 job.go:1109] Event MODIFIED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:18.843038 23 job.go:1109] Event MODIFIED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:18.843047 23 job.go:1109] Event MODIFIED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:18.843100 23 job.go:1109] Event MODIFIED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:18.843117 23 job.go:1109] Event MODIFIED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:18.843138 23 job.go:1109] Event MODIFIED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:18.843186 23 job.go:1109] Event MODIFIED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:18.843198 23 job.go:1109] Event MODIFIED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:18.843206 23 job.go:1109] Event MODIFIED observed for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  I0502 08:30:18.843243 23 job.go:1112] Event DELETED found for Job e2e-t6st7 in namespace job-1641 with labels: map[e2e-job-label:e2e-t6st7 e2e-t6st7:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 05/02/24 08:30:18.843
  I0502 08:30:18.847952 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1641" for this suite. @ 05/02/24 08:30:18.854
• [12.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 05/02/24 08:30:18.872
  I0502 08:30:18.872252 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/02/24 08:30:18.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:18.888
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:18.892
  I0502 08:30:18.896393 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:30:19.278409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:30:19.934683 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-8823" for this suite. @ 05/02/24 08:30:19.937
• [1.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 05/02/24 08:30:19.944
  I0502 08:30:19.944335 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 08:30:19.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:19.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:19.964
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 08:30:19.966
  E0502 08:30:20.279294      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:21.279450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:22.280231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:23.280388      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:30:23.984
  I0502 08:30:23.986564 23 output.go:196] Trying to get logs from node mini-2 pod downwardapi-volume-25eeca98-b7e3-430f-996c-4166c38dc7d0 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 08:30:23.991
  I0502 08:30:24.007831 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9614" for this suite. @ 05/02/24 08:30:24.011
• [4.075 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 05/02/24 08:30:24.019
  I0502 08:30:24.019632 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:30:24.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:24.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:24.039
  STEP: Creating projection with secret that has name projected-secret-test-31312335-9c1a-498f-a5f2-fcde4fdb0b49 @ 05/02/24 08:30:24.041
  STEP: Creating a pod to test consume secrets @ 05/02/24 08:30:24.044
  E0502 08:30:24.280478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:25.280644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:26.281450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:27.281592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:30:28.062
  I0502 08:30:28.067196 23 output.go:196] Trying to get logs from node mini-2 pod pod-projected-secrets-4aa9254c-d8fd-4a89-bd36-32e0b8862c46 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 08:30:28.071
  I0502 08:30:28.087240 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-493" for this suite. @ 05/02/24 08:30:28.091
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 05/02/24 08:30:28.099
  I0502 08:30:28.099239 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename server-version @ 05/02/24 08:30:28.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:28.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:28.118
  STEP: Request ServerVersion @ 05/02/24 08:30:28.12
  STEP: Confirm major version @ 05/02/24 08:30:28.121
  I0502 08:30:28.121310 23 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 05/02/24 08:30:28.121
  I0502 08:30:28.121325 23 server_version.go:58] cleanMinorVersion: 30
  I0502 08:30:28.121332 23 server_version.go:62] Minor version: 30
  I0502 08:30:28.121362 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-6216" for this suite. @ 05/02/24 08:30:28.124
• [0.032 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 05/02/24 08:30:28.131
  I0502 08:30:28.131394 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 08:30:28.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:28.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:28.149
  I0502 08:30:28.152228 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: creating the pod @ 05/02/24 08:30:28.152
  STEP: submitting the pod to kubernetes @ 05/02/24 08:30:28.152
  E0502 08:30:28.281844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:29.282260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:30.282611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:31.282770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:30:32.188930 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8782" for this suite. @ 05/02/24 08:30:32.193
• [4.068 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 05/02/24 08:30:32.199
  I0502 08:30:32.199699 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pod-network-test @ 05/02/24 08:30:32.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:30:32.22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:30:32.222
  STEP: Performing setup for networking test in namespace pod-network-test-3173 @ 05/02/24 08:30:32.224
  STEP: creating a selector @ 05/02/24 08:30:32.224
  STEP: Creating the service pods in kubernetes @ 05/02/24 08:30:32.224
  I0502 08:30:32.224373 23 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0502 08:30:32.283393      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:33.283689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:34.284347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:35.284529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:36.284931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:37.285088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:38.285627      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:39.285922      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:40.286064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:41.286238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:42.286855      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:43.287038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:44.288038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:45.288176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:46.288282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:47.288436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:48.288597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:49.288628      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:50.288765      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:51.289479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:52.289667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:53.290165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:54.290390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/02/24 08:30:54.316
  E0502 08:30:55.290893      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:56.291008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:57.291582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:30:58.291693      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:30:58.348510 23 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0502 08:30:58.348527 23 utils.go:472] Going to poll 192.168.125.228 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0502 08:30:58.350464 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.125.228 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3173 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:30:58.350490 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:30:58.350805 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:30:58.350858 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3173/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.125.228+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0502 08:30:59.292338      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:30:59.403716 23 utils.go:489] Found all 1 expected endpoints: [netserver-0]
  I0502 08:30:59.403734 23 utils.go:472] Going to poll 192.168.158.153 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0502 08:30:59.411687 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.158.153 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3173 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:30:59.411700 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:30:59.412008 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:30:59.412062 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3173/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.158.153+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0502 08:31:00.292933      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:00.474378 23 utils.go:489] Found all 1 expected endpoints: [netserver-1]
  I0502 08:31:00.474396 23 utils.go:472] Going to poll 192.168.32.54 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0502 08:31:00.477505 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.32.54 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3173 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:31:00.477530 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:31:00.477830 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:31:00.477889 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3173/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.32.54+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0502 08:31:01.293318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:01.527106 23 utils.go:489] Found all 1 expected endpoints: [netserver-2]
  I0502 08:31:01.527156 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3173" for this suite. @ 05/02/24 08:31:01.531
• [29.339 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 05/02/24 08:31:01.539
  I0502 08:31:01.539265 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename var-expansion @ 05/02/24 08:31:01.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:31:01.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:31:01.555
  STEP: Creating a pod to test env composition @ 05/02/24 08:31:01.557
  E0502 08:31:02.293711      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:03.293879      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:04.294341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:05.294538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:31:05.573
  I0502 08:31:05.576061 23 output.go:196] Trying to get logs from node mini-3 pod var-expansion-36c1c426-c887-4429-a48f-0e2cc6d93f77 container dapi-container: <nil>
  STEP: delete the pod @ 05/02/24 08:31:05.586
  I0502 08:31:05.600771 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7014" for this suite. @ 05/02/24 08:31:05.603
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 05/02/24 08:31:05.608
  I0502 08:31:05.608667 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 08:31:05.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:31:05.623
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:31:05.625
  STEP: Creating a ResourceQuota @ 05/02/24 08:31:05.628
  STEP: Getting a ResourceQuota @ 05/02/24 08:31:05.631
  STEP: Updating a ResourceQuota @ 05/02/24 08:31:05.635
  STEP: Verifying a ResourceQuota was modified @ 05/02/24 08:31:05.639
  STEP: Deleting a ResourceQuota @ 05/02/24 08:31:05.643
  STEP: Verifying the deleted ResourceQuota @ 05/02/24 08:31:05.647
  I0502 08:31:05.649592 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7636" for this suite. @ 05/02/24 08:31:05.652
• [0.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 05/02/24 08:31:05.658
  I0502 08:31:05.658244 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 08:31:05.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:31:05.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:31:05.675
  STEP: Creating pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617 @ 05/02/24 08:31:05.677
  E0502 08:31:06.295132      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:07.295261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/02/24 08:31:07.691
  I0502 08:31:07.695708 23 container_probe.go:1749] Initial restart count of pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e is 0
  I0502 08:31:07.699383 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:08.296106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:09.296189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:09.703043 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:10.296635      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:11.297042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:11.706657 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:12.297248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:13.297407      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:13.710230 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:14.297931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:15.298063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:15.714141 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:16.298848      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:17.298983      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:17.717382 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:18.300009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:19.300515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:19.722747 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:20.301380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:21.301516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:21.726336 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:22.301873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:23.302018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:23.729774 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:24.302684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:25.302819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:25.733630 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:26.303175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:27.304027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:27.737629 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:28.304146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:29.304727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:29.742377 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:30.304873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:31.305275      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:31.745610 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:32.306311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:33.306923      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:33.749800 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:34.307538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:35.307622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:35.752746 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:36.308036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:37.308204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:37.756759 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:38.308294      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:39.308774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:39.760646 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:40.309213      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:41.309375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:41.765081 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:42.309604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:43.309729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:43.768660 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:44.310381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:45.310518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:45.772588 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:46.311239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:47.312033      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:47.778072 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:48.312649      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:49.313100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:49.782005 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:50.313516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:51.314074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:51.786007 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:52.314574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:53.314759      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:53.788840 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:54.315666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:55.315828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:55.792743 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:56.316297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:57.316466      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:57.796423 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:31:58.316978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:31:59.317545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:31:59.801331 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:00.317753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:01.317911      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:01.804740 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:02.318236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:03.318367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:03.808788 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:04.318486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:05.318616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:05.811827 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:06.319450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:07.319564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:07.814793 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:08.320362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:09.320798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:09.818671 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:10.321203      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:11.322084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:11.822593 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:12.322185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:13.322310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:13.828072 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:14.322857      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:15.322954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:15.831482 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:16.323056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:17.323176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:17.834353 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:18.323929      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:19.324304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:19.838044 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:20.324594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:21.324738      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:21.841143 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:22.325796      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:23.325907      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:23.844730 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:24.326368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:25.327067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:25.849003 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:26.327538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:27.327657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:27.852327 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:28.327802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:29.328452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:29.856498 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:30.329009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:31.329163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:31.860772 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:32.329308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:33.329423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:33.864121 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:34.329853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:35.329979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:35.867576 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:36.330072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:37.330196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:37.870830 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:38.330323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:39.330761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:39.874779 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:40.331259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:41.331350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:41.878035 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:42.331510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:43.331638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:43.881480 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:44.332194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:45.332805      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:45.885718 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:46.332948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:47.333151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:47.888832 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:48.333348      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:49.333825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:49.893260 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:50.334770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:51.334977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:51.896637 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:52.335057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:53.335119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:53.900210 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:54.335934      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:55.336056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:55.903395 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:56.336967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:57.337126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:57.907281 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:32:58.337817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:32:59.338345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:32:59.911247 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:00.338459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:01.338583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:01.915788 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:02.339310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:03.339457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:03.919487 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:04.339868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:05.340011      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:05.922717 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:06.340145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:07.340450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:07.926284 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:08.340544      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:09.340894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:09.929567 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:10.341014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:11.341166      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:11.932823 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:12.342213      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:13.342375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:13.935668 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:14.343248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:15.343400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:15.939232 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:16.343522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:17.344073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:17.942142 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:18.344653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:19.344791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:19.945473 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:20.344865      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:21.345004      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:21.951783 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:22.345228      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:23.345955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:23.956469 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:24.346064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:25.346189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:25.959928 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:26.346303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:27.346490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:27.963767 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:28.347363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:29.347823      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:29.967841 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:30.348192      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:31.348354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:31.971498 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:32.348997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:33.349138      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:33.975204 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:34.349811      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:35.349950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:35.978373 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:36.350888      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:37.351056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:37.983836 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:38.351186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:39.351819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:39.989303 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:40.352794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:41.352944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:41.992799 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:42.353151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:43.353286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:43.996334 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:44.353785      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:45.354063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:45.999786 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:46.354226      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:47.354372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:48.003028 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:48.354432      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:49.354895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:50.009116 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:50.355644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:51.355790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:52.014410 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:52.356896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:53.357034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:54.017587 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:54.357152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:55.357281      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:56.020879 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:56.358035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:57.358192      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:33:58.024228 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:33:58.358658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:33:59.359082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:00.027865 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:00.359167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:01.360002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:02.032243 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:02.360282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:03.360689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:04.035562 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:04.361082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:05.361206      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:06.039770 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:06.362213      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:07.362372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:08.043849 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:08.363283      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:09.363886      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:10.048218 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:10.364672      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:11.364970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:12.053668 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:12.365030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:13.365136      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:14.058067 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:14.365509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:15.365653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:16.062412 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:16.365782      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:17.365943      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:18.065518 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:18.366967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:19.367530      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:20.071660 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:20.368090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:21.368212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:22.077021 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:22.368321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:23.368665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:24.081153 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:24.369681      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:25.369832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:26.084649 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:26.369964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:27.370142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:28.087946 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:28.370262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:29.370819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:30.091709 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:30.371049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:31.371229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:32.095656 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:32.372056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:33.372168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:34.098878 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:34.372286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:35.372440      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:36.102327 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:36.372670      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:37.372849      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:38.105820 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:38.373128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:39.373330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:40.109933 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:40.374298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:41.374441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:42.113512 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:42.374953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:43.375022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:44.117129 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:44.375707      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:45.376137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:46.121034 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:46.376292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:47.376450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:48.124845 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:48.377208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:49.377881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:50.128916 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:50.378272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:51.378400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:52.132310 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:52.378550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:53.378712      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:54.135344 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:54.378734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:55.378894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:56.139001 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:56.379376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:57.379529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:34:58.142304 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:34:58.379606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:34:59.380013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:00.146190 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:35:00.380539      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:01.380699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:02.149477 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:35:02.380709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:03.380998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:04.153045 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:35:04.381401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:05.381522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:06.156651 23 container_probe.go:1759] Get pod busybox-32b227d7-8ed7-4b2f-b927-4d3f95188c8e in namespace container-probe-3617
  E0502 08:35:06.382003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:07.382853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/02/24 08:35:08.156
  I0502 08:35:08.166152 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3617" for this suite. @ 05/02/24 08:35:08.17
  E0502 08:35:08.383040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
• [242.727 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 05/02/24 08:35:08.385
  I0502 08:35:08.385252 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:35:08.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:35:08.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:35:08.408
  STEP: Setting up server cert @ 05/02/24 08:35:08.43
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:35:08.551
  STEP: Deploying the webhook pod @ 05/02/24 08:35:08.557
  STEP: Wait for the deployment to be ready @ 05/02/24 08:35:08.565
  I0502 08:35:08.579177 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:35:09.383405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:10.383625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:35:10.586
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:35:10.597
  E0502 08:35:11.383679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:11.597989 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0502 08:35:11.603442 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1429-crds.webhook.example.com via the AdmissionRegistration API @ 05/02/24 08:35:12.112
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/02/24 08:35:12.124
  E0502 08:35:12.383664      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:13.383938      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:14.384534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:14.722664 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8237" for this suite. @ 05/02/24 08:35:14.727
  STEP: Destroying namespace "webhook-markers-4120" for this suite. @ 05/02/24 08:35:14.74
• [6.362 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 05/02/24 08:35:14.747
  I0502 08:35:14.747796 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:35:14.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:35:14.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:35:14.765
  STEP: Setting up server cert @ 05/02/24 08:35:14.787
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:35:15.079
  STEP: Deploying the webhook pod @ 05/02/24 08:35:15.084
  STEP: Wait for the deployment to be ready @ 05/02/24 08:35:15.093
  I0502 08:35:15.128728 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:35:15.385043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:16.385402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:35:17.136
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:35:17.147
  E0502 08:35:17.386008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:18.147847 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 05/02/24 08:35:18.153
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/02/24 08:35:18.153
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 05/02/24 08:35:18.163
  E0502 08:35:18.386911      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 05/02/24 08:35:19.172
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/02/24 08:35:19.172
  E0502 08:35:19.386974      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 05/02/24 08:35:20.193
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/02/24 08:35:20.193
  E0502 08:35:20.387927      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:21.388059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:22.388240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:23.388397      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:24.388832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 05/02/24 08:35:25.22
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/02/24 08:35:25.22
  E0502 08:35:25.389090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:26.389269      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:27.389438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:28.389594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:29.389971      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:30.317419 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8271" for this suite. @ 05/02/24 08:35:30.321
  STEP: Destroying namespace "webhook-markers-5343" for this suite. @ 05/02/24 08:35:30.328
• [15.590 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 05/02/24 08:35:30.338
  I0502 08:35:30.338156 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 08:35:30.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:35:30.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:35:30.36
  STEP: Creating pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968 @ 05/02/24 08:35:30.362
  E0502 08:35:30.390111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:31.390380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/02/24 08:35:32.382
  I0502 08:35:32.385702 23 container_probe.go:1749] Initial restart count of pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 is 0
  I0502 08:35:32.388117 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:32.391240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:33.391396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:34.391479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:34.391576 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:35.391646      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:36.391817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:36.394905 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:37.391965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:38.391982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:38.397822 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:39.392927      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:40.393071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:40.401512 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:41.393579      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:42.393720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:42.405722 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:43.394727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:44.394888      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:44.409566 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:45.395612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:46.396492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:46.413002 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:47.396963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:48.397072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:48.415761 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:49.398086      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:50.398294      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:50.420757 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:51.398772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:52.398929      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:52.424424 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:53.399321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:54.400031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:54.428356 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:55.400303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:56.400485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:56.432622 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:57.400576      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:35:58.400776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:35:58.435826 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:35:59.400999      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:00.401161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:00.440902 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:01.401901      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:02.402139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:02.444930 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:03.402851      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:04.403117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:04.448486 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:05.403461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:06.403626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:06.452506 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:07.404447      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:08.404562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:08.455685 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:09.404769      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:10.404937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:10.458588 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:11.405537      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:12.405700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:12.463465 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:13.406448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:14.406942      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:14.467480 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:15.407497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:16.407678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:16.471028 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:17.408056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:18.408199      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:18.474305 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:19.408685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:20.408812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:20.481098 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:21.409030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:22.409199      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:22.484558 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:23.409543      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:24.409817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:24.487842 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:25.409892      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:26.410050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:26.491635 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:27.410649      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:28.410776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:28.495448 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:29.410846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:30.410990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:30.499772 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:31.411750      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:32.411894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:32.503476 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:33.412387      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:34.412679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:34.506819 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:35.412746      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:36.412896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:36.510798 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:37.413755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:38.413912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:38.514407 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:39.414877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:40.415017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:40.518547 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:41.415494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:42.415673      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:42.522349 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:43.415979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:44.416266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:44.525490 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:45.416372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:46.416553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:46.529411 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:47.417309      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:48.417448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:48.533190 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:49.418537      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:50.418671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:50.536920 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:51.418778      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:52.418941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:52.541753 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:53.419660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:54.419908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:54.545169 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:55.420019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:56.420185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:56.548521 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:57.420331      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:36:58.420480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:36:58.554286 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:36:59.421507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:00.421648      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:00.559948 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:01.421824      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:02.421980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:02.564749 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:03.422592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:04.422932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:04.570134 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:05.422989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:06.423098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:06.575434 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:07.423265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:08.423396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:08.580490 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:09.423843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:10.423984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:10.584548 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:11.424382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:12.424537      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:12.590153 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:13.424994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:14.425256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:14.595958 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:15.425710      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:16.425847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:16.601672 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:17.426500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:18.426645      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:18.605139 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:19.427449      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:20.427588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:20.609066 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:21.427879      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:22.428036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:22.612811 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:23.428625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:24.428972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:24.616336 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:25.429188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:26.429344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:26.620410 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:27.430299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:28.430436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:28.624262 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:29.431434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:30.431601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:30.627930 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:31.431706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:32.431858      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:32.631376 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:33.432172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:34.432474      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:34.634517 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:35.433430      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:36.433598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:36.638288 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:37.434078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:38.434237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:38.641403 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:39.434519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:40.434671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:40.645094 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:41.434895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:42.435079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:42.648773 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:43.435554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:44.435868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:44.653583 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:45.436384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:46.436509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:46.657439 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:47.437234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:48.437379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:48.660569 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:49.437686      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:50.437832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:50.664656 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:51.438419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:52.438580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:52.668510 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:53.439258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:54.439509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:54.676344 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:55.440149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:56.440314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:56.679908 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:57.440684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:37:58.440830      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:37:58.683322 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:37:59.441545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:00.441706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:00.687363 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:01.442147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:02.442491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:02.690477 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:03.443287      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:04.443574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:04.695802 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:05.444636      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:06.444766      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:06.699386 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:07.444891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:08.445055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:08.702359 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:09.445624      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:10.445732      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:10.706153 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:11.445834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:12.446017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:12.709483 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:13.446328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:14.446658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:14.713180 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:15.446900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:16.446992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:16.716648 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:17.447402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:18.447529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:18.719792 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:19.448626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:20.448757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:20.723331 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:21.448854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:22.449018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:22.726448 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:23.449203      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:24.450015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:24.730619 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:25.450300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:26.450423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:26.734063 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:27.450761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:28.450909      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:28.737168 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:29.451430      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:30.451510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:30.740976 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:31.452013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:32.452184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:32.745078 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:33.452780      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:34.452901      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:34.748168 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:35.453950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:36.454085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:36.751167 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:37.455017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:38.455097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:38.754541 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:39.455711      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:40.455867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:40.759145 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:41.456911      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:42.457047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:42.762513 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:43.457149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:44.457424      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:44.767256 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:45.457962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:46.458073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:46.771013 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:47.458678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:48.458841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:48.774311 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:49.459490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:50.459597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:50.778119 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:51.459725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:52.459907      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:52.780986 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:53.460794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:54.461090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:54.784638 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:55.461317      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:56.461444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:56.787746 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:57.462525      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:38:58.462665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:38:58.790830 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:38:59.462796      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:00.462955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:00.794659 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:01.463431      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:02.463574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:02.798052 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:03.463794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:04.464042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:04.801806 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:05.464446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:06.464532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:06.805382 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:07.465027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:08.465171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:08.808411 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:09.465555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:10.465749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:10.812324 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:11.465963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:12.466134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:12.816432 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:13.467003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:14.467301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:14.819987 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:15.467681      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:16.467814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:16.823502 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:17.468166      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:18.468317      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:18.827078 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:19.469061      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:20.469209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:20.832073 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:21.469686      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:22.469850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:22.835039 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:23.470819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:24.471102      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:24.838461 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:25.471152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:26.471286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:26.842246 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:27.471876      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:28.472036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:28.846493 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:29.472330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:30.472612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:30.850521 23 container_probe.go:1759] Get pod liveness-8aaaa4d7-d0da-494a-9d14-24fc7681dd09 in namespace container-probe-8968
  E0502 08:39:31.473108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:32.473272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/02/24 08:39:32.85
  I0502 08:39:32.861022 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8968" for this suite. @ 05/02/24 08:39:32.865
• [242.537 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:397
  STEP: Creating a kubernetes client @ 05/02/24 08:39:32.875
  I0502 08:39:32.875530 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:39:32.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:39:32.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:39:32.903
  STEP: creating all guestbook components @ 05/02/24 08:39:32.905
  I0502 08:39:32.905075 23 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0502 08:39:32.905151 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 create -f -'
  I0502 08:39:32.998798 23 builder.go:146] stderr: ""
  I0502 08:39:32.998822 23 builder.go:147] stdout: "service/agnhost-replica created\n"
  I0502 08:39:32.998850 23 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0502 08:39:32.999598 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 create -f -'
  I0502 08:39:33.083007 23 builder.go:146] stderr: ""
  I0502 08:39:33.083030 23 builder.go:147] stdout: "service/agnhost-primary created\n"
  I0502 08:39:33.083057 23 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0502 08:39:33.083105 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 create -f -'
  I0502 08:39:33.164232 23 builder.go:146] stderr: ""
  I0502 08:39:33.164259 23 builder.go:147] stdout: "service/frontend created\n"
  I0502 08:39:33.164302 23 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0502 08:39:33.164372 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 create -f -'
  I0502 08:39:33.222468 23 builder.go:146] stderr: ""
  I0502 08:39:33.222495 23 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I0502 08:39:33.222527 23 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0502 08:39:33.222598 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 create -f -'
  I0502 08:39:33.281921 23 builder.go:146] stderr: ""
  I0502 08:39:33.281944 23 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I0502 08:39:33.281976 23 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0502 08:39:33.282049 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 create -f -'
  I0502 08:39:33.340033 23 builder.go:146] stderr: ""
  I0502 08:39:33.340056 23 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 05/02/24 08:39:33.34
  I0502 08:39:33.340079 23 kubectl.go:2271] Waiting for all frontend pods to be Running.
  E0502 08:39:33.473542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:34.474368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:35.475195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:36.475414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:37.475614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:38.390627 23 kubectl.go:2275] Waiting for frontend to serve content.
  I0502 08:39:38.397616 23 kubectl.go:2280] Trying to add a new entry to the guestbook.
  I0502 08:39:38.404180 23 kubectl.go:2285] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 05/02/24 08:39:38.409
  I0502 08:39:38.409594 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 delete --grace-period=0 --force -f -'
  E0502 08:39:38.475967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:38.484656 23 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0502 08:39:38.484701 23 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 05/02/24 08:39:38.484
  I0502 08:39:38.484793 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 delete --grace-period=0 --force -f -'
  I0502 08:39:38.546245 23 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0502 08:39:38.546268 23 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/02/24 08:39:38.546
  I0502 08:39:38.546330 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 delete --grace-period=0 --force -f -'
  I0502 08:39:38.605857 23 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0502 08:39:38.605882 23 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/02/24 08:39:38.605
  I0502 08:39:38.605986 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 delete --grace-period=0 --force -f -'
  I0502 08:39:38.644137 23 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0502 08:39:38.644160 23 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/02/24 08:39:38.644
  I0502 08:39:38.644226 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 delete --grace-period=0 --force -f -'
  I0502 08:39:38.684125 23 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0502 08:39:38.684155 23 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/02/24 08:39:38.684
  I0502 08:39:38.684248 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-3466 delete --grace-period=0 --force -f -'
  I0502 08:39:38.725054 23 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0502 08:39:38.725078 23 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I0502 08:39:38.725131 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3466" for this suite. @ 05/02/24 08:39:38.728
• [5.860 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 05/02/24 08:39:38.735
  I0502 08:39:38.735583 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:39:38.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:39:38.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:39:38.763
  STEP: Setting up server cert @ 05/02/24 08:39:38.786
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:39:39.065
  STEP: Deploying the webhook pod @ 05/02/24 08:39:39.082
  STEP: Wait for the deployment to be ready @ 05/02/24 08:39:39.096
  I0502 08:39:39.108415 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:39:39.476032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:40.476223      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:41.120792 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 39, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 39, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 39, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 39, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:39:41.477239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:42.477416      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:39:43.124
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:39:43.138
  E0502 08:39:43.478091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:44.138830 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0502 08:39:44.143662 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:39:44.478879      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7408-crds.webhook.example.com via the AdmissionRegistration API @ 05/02/24 08:39:44.652
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/02/24 08:39:44.67
  E0502 08:39:45.479916      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:46.480037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:39:47.285610 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4073" for this suite. @ 05/02/24 08:39:47.29
  STEP: Destroying namespace "webhook-markers-1999" for this suite. @ 05/02/24 08:39:47.297
• [8.570 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 05/02/24 08:39:47.305
  I0502 08:39:47.305494 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename gc @ 05/02/24 08:39:47.305
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:39:47.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:39:47.323
  STEP: create the rc @ 05/02/24 08:39:47.324
  W0502 08:39:47.328418      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0502 08:39:47.480706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:48.480899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:49.481127      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:50.481303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:51.481492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/02/24 08:39:52.333
  STEP: wait for all pods to be garbage collected @ 05/02/24 08:39:52.338
  E0502 08:39:52.481940      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:53.482119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:54.482346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:55.482502      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:56.482659      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/02/24 08:39:57.345
  I0502 08:39:57.407418 23 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0502 08:39:57.407523 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5835" for this suite. @ 05/02/24 08:39:57.412
• [10.115 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 05/02/24 08:39:57.42
  I0502 08:39:57.420147 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename subjectreview @ 05/02/24 08:39:57.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:39:57.437
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:39:57.442
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-3547" @ 05/02/24 08:39:57.444
  I0502 08:39:57.462935 23 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-3547:e2e"
  I0502 08:39:57.462949 23 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-3547"}
  I0502 08:39:57.462954 23 subjectreviews.go:71] saUID: "61dfbe51-92cc-4c46-98b5-64678295d391"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-3547:e2e" @ 05/02/24 08:39:57.462
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-3547:e2e" @ 05/02/24 08:39:57.463
  I0502 08:39:57.468189 23 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-3547:e2e" api 'list' configmaps in "subjectreview-3547" namespace @ 05/02/24 08:39:57.468
  I0502 08:39:57.469247 23 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-3547:e2e" @ 05/02/24 08:39:57.469
  I0502 08:39:57.470841 23 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0502 08:39:57.470856 23 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0502 08:39:57.470923 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-3547" for this suite. @ 05/02/24 08:39:57.473
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 05/02/24 08:39:57.479
  I0502 08:39:57.479376 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:39:57.479
  E0502 08:39:57.483214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:39:57.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:39:57.499
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 08:39:57.501
  E0502 08:39:58.483389      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:39:59.483985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:00.484369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:01.484516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:40:01.519
  I0502 08:40:01.521419 23 output.go:196] Trying to get logs from node mini-1 pod downwardapi-volume-4bd6734b-c521-47d9-8401-411824ff0b23 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 08:40:01.531
  I0502 08:40:01.547356 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1515" for this suite. @ 05/02/24 08:40:01.55
• [4.079 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:850
  STEP: Creating a kubernetes client @ 05/02/24 08:40:01.558
  I0502 08:40:01.558461 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 08:40:01.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:40:01.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:40:01.577
  STEP: creating service multi-endpoint-test in namespace services-2616 @ 05/02/24 08:40:01.579
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2616 to expose endpoints map[] @ 05/02/24 08:40:01.59
  I0502 08:40:01.604836 23 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2616 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2616 @ 05/02/24 08:40:01.604
  E0502 08:40:02.485018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:03.484788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2616 to expose endpoints map[pod1:[100]] @ 05/02/24 08:40:03.624
  I0502 08:40:03.630535 23 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2616 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-2616 @ 05/02/24 08:40:03.63
  E0502 08:40:04.484862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:05.485107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2616 to expose endpoints map[pod1:[100] pod2:[101]] @ 05/02/24 08:40:05.647
  I0502 08:40:05.656244 23 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2616 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 05/02/24 08:40:05.656
  I0502 08:40:05.656285 23 resource.go:361] Creating new exec pod
  E0502 08:40:06.485404      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:07.486434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:08.486531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:08.668943 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-2616 exec execpod55wq8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I0502 08:40:08.754406 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  I0502 08:40:08.754431 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 08:40:08.754473 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-2616 exec execpod55wq8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.97.205.61 80'
  I0502 08:40:08.825819 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.97.205.61 80\nConnection to 10.97.205.61 80 port [tcp/http] succeeded!\n"
  I0502 08:40:08.825843 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 08:40:08.825889 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-2616 exec execpod55wq8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0502 08:40:08.897419 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  I0502 08:40:08.897445 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 08:40:08.897484 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-2616 exec execpod55wq8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.97.205.61 81'
  I0502 08:40:08.971911 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.97.205.61 81\nConnection to 10.97.205.61 81 port [tcp/*] succeeded!\n"
  I0502 08:40:08.971939 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2616 @ 05/02/24 08:40:08.971
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2616 to expose endpoints map[pod2:[101]] @ 05/02/24 08:40:08.991
  I0502 08:40:09.031304 23 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2616 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-2616 @ 05/02/24 08:40:09.031
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2616 to expose endpoints map[] @ 05/02/24 08:40:09.049
  E0502 08:40:09.487562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:10.066026 23 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-2616 exposes endpoints map[]
  I0502 08:40:10.089774 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2616" for this suite. @ 05/02/24 08:40:10.093
• [8.541 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:833
  STEP: Creating a kubernetes client @ 05/02/24 08:40:10.099
  I0502 08:40:10.099392 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename job @ 05/02/24 08:40:10.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:40:10.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:40:10.116
  STEP: Creating a job @ 05/02/24 08:40:10.118
  STEP: Ensure pods equal to parallelism count is attached to the job @ 05/02/24 08:40:10.122
  E0502 08:40:10.487674      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:11.487854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:12.488428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:13.488555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 05/02/24 08:40:14.125
  STEP: updating /status @ 05/02/24 08:40:14.131
  STEP: get /status @ 05/02/24 08:40:14.137
  I0502 08:40:14.139627 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6448" for this suite. @ 05/02/24 08:40:14.142
• [4.049 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 05/02/24 08:40:14.148
  I0502 08:40:14.148126 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replicaset @ 05/02/24 08:40:14.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:40:14.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:40:14.167
  STEP: Create a Replicaset @ 05/02/24 08:40:14.176
  STEP: Verify that the required pods have come up. @ 05/02/24 08:40:14.18
  I0502 08:40:14.183573 23 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0502 08:40:14.489017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:15.489186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:16.489385      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:17.490087      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:18.490226      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:19.187170 23 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/02/24 08:40:19.187
  STEP: Getting /status @ 05/02/24 08:40:19.187
  I0502 08:40:19.189773 23 replica_set.go:643] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 05/02/24 08:40:19.189
  I0502 08:40:19.196976 23 replica_set.go:663] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 05/02/24 08:40:19.197
  I0502 08:40:19.198507 23 replica_set.go:689] Observed &ReplicaSet event: ADDED
  I0502 08:40:19.198597 23 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0502 08:40:19.198641 23 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0502 08:40:19.198699 23 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0502 08:40:19.198738 23 replica_set.go:682] Found replicaset test-rs in namespace replicaset-4272 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0502 08:40:19.198759 23 replica_set.go:693] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 05/02/24 08:40:19.198
  I0502 08:40:19.198780 23 replica_set.go:697] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0502 08:40:19.203684 23 replica_set.go:701] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 05/02/24 08:40:19.203
  I0502 08:40:19.204947 23 replica_set.go:725] Observed &ReplicaSet event: ADDED
  I0502 08:40:19.205021 23 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0502 08:40:19.205061 23 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0502 08:40:19.205097 23 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0502 08:40:19.205107 23 replica_set.go:721] Observed replicaset test-rs in namespace replicaset-4272 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0502 08:40:19.205145 23 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0502 08:40:19.205190 23 replica_set.go:718] Found replicaset test-rs in namespace replicaset-4272 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0502 08:40:19.205204 23 replica_set.go:729] Replicaset test-rs has a patched status
  I0502 08:40:19.205245 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4272" for this suite. @ 05/02/24 08:40:19.208
• [5.067 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 05/02/24 08:40:19.216
  I0502 08:40:19.216859 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename containers @ 05/02/24 08:40:19.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:40:19.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:40:19.239
  STEP: Creating a pod to test override command @ 05/02/24 08:40:19.241
  E0502 08:40:19.490614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:20.490739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:21.490965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:22.492034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:40:23.261
  I0502 08:40:23.263746 23 output.go:196] Trying to get logs from node mini-1 pod client-containers-8735facc-59bd-419a-a78a-4da38ef44aed container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:40:23.268
  I0502 08:40:23.281894 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-357" for this suite. @ 05/02/24 08:40:23.285
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 05/02/24 08:40:23.29
  I0502 08:40:23.290891 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:40:23.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:40:23.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:40:23.31
  STEP: Creating configMap with name projected-configmap-test-volume-map-0e6f6e24-79cd-4067-b7b0-92808b93b34f @ 05/02/24 08:40:23.312
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:40:23.316
  E0502 08:40:23.492622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:24.493032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:25.493432      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:26.493640      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:40:27.334
  I0502 08:40:27.337171 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-configmaps-25bbc04d-91fb-47f6-8f93-fbb1d935a8ed container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:40:27.34
  I0502 08:40:27.352658 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6082" for this suite. @ 05/02/24 08:40:27.355
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 05/02/24 08:40:27.361
  I0502 08:40:27.361452 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replicaset @ 05/02/24 08:40:27.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:40:27.381
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:40:27.383
  I0502 08:40:27.397455 23 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0502 08:40:27.493820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:28.493985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:29.494533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:30.494679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:31.494834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:32.400094 23 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/02/24 08:40:32.4
  STEP: Scaling up "test-rs" replicaset @ 05/02/24 08:40:32.4
  I0502 08:40:32.407645 23 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 05/02/24 08:40:32.407
  I0502 08:40:32.421060 23 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-3314 with ReadyReplicas 1, AvailableReplicas 1
  I0502 08:40:32.431722 23 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-3314 with ReadyReplicas 1, AvailableReplicas 1
  I0502 08:40:32.445977 23 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-3314 with ReadyReplicas 1, AvailableReplicas 1
  I0502 08:40:32.467517 23 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-3314 with ReadyReplicas 1, AvailableReplicas 1
  E0502 08:40:32.495745      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:33.495957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:33.903005 23 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-3314 with ReadyReplicas 2, AvailableReplicas 2
  I0502 08:40:34.109192 23 replica_set.go:545] observed Replicaset test-rs in namespace replicaset-3314 with ReadyReplicas 3 found true
  I0502 08:40:34.109296 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3314" for this suite. @ 05/02/24 08:40:34.112
• [6.757 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 05/02/24 08:40:34.118
  I0502 08:40:34.118870 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename daemonsets @ 05/02/24 08:40:34.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:40:34.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:40:34.138
  STEP: Creating simple DaemonSet "daemon-set" @ 05/02/24 08:40:34.158
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/02/24 08:40:34.162
  I0502 08:40:34.165108 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:34.165141 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:34.165167 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:34.167266 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:40:34.167277 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 08:40:34.496769      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:35.166672 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:35.166714 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:35.166727 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:35.169336 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:40:35.169348 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 08:40:35.497791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:36.167370 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:36.167411 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:36.167435 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:36.170285 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0502 08:40:36.170297 23 fixtures.go:130] Node mini-2 is running 0 daemon pod, expected 1
  E0502 08:40:36.498736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:37.166401 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:37.166437 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:37.166462 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:37.169299 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0502 08:40:37.169326 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 05/02/24 08:40:37.171
  I0502 08:40:37.183371 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:37.183415 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:37.183443 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:37.185985 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0502 08:40:37.185997 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 08:40:37.499226      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:38.184050 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:38.184087 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:38.184098 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:38.187006 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0502 08:40:38.187018 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 08:40:38.499318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:39.182788 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:39.182826 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:39.182852 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:39.185629 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0502 08:40:39.185643 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 08:40:39.500040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:40.183766 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:40.183792 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:40.183818 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:40:40.186567 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0502 08:40:40.186579 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/02/24 08:40:40.19
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4153, will wait for the garbage collector to delete the pods @ 05/02/24 08:40:40.19
  I0502 08:40:40.247601 23 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 4.938827ms
  I0502 08:40:40.348155 23 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.550259ms
  E0502 08:40:40.500074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:41.500923      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:42.501701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:43.151915 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:40:43.151947 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0502 08:40:43.154191 23 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19715"},"items":null}

  I0502 08:40:43.156506 23 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19715"},"items":null}

  I0502 08:40:43.167395 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4153" for this suite. @ 05/02/24 08:40:43.172
• [9.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 05/02/24 08:40:43.178
  I0502 08:40:43.178212 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename statefulset @ 05/02/24 08:40:43.178
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:40:43.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:40:43.195
  STEP: Creating service test in namespace statefulset-3479 @ 05/02/24 08:40:43.197
  I0502 08:40:43.238830 23 wait.go:40] Found 0 stateful pods, waiting for 1
  E0502 08:40:43.502285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:44.502675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:45.502827      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:46.503014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:47.503840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:48.504001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:49.504349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:50.504473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:51.504638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:52.505604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:40:53.232048 23 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 05/02/24 08:40:53.236
  W0502 08:40:53.244064      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  I0502 08:40:53.249024 23 wait.go:40] Found 1 stateful pods, waiting for 2
  E0502 08:40:53.506363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:54.506644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:55.507071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:56.508096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:57.508392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:58.508543      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:40:59.508835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:00.508975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:01.509148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:02.509360      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:41:03.250357 23 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0502 08:41:03.250375 23 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 05/02/24 08:41:03.255
  STEP: Delete all of the StatefulSets @ 05/02/24 08:41:03.257
  STEP: Verify that StatefulSets have been deleted @ 05/02/24 08:41:03.262
  I0502 08:41:03.264713 23 statefulset.go:135] Deleting all statefulset in ns statefulset-3479
  I0502 08:41:03.280740 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3479" for this suite. @ 05/02/24 08:41:03.287
• [20.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 05/02/24 08:41:03.295
  I0502 08:41:03.295954 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename field-validation @ 05/02/24 08:41:03.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:41:03.309
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:41:03.312
  I0502 08:41:03.314630 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:41:03.509490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:04.510087      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:05.510265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:41:06.398403 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6313" for this suite. @ 05/02/24 08:41:06.401
• [3.112 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1284
  STEP: Creating a kubernetes client @ 05/02/24 08:41:06.408
  I0502 08:41:06.408267 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 08:41:06.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:41:06.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:41:06.426
  STEP: creating service nodeport-test with type=NodePort in namespace services-1833 @ 05/02/24 08:41:06.431
  STEP: creating replication controller nodeport-test in namespace services-1833 @ 05/02/24 08:41:06.46
  I0502 08:41:06.473937      23 runners.go:198] Created replication controller with name: nodeport-test, namespace: services-1833, replica count: 2
  E0502 08:41:06.510524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:07.510711      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:08.511368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:09.511752      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:41:09.524970      23 runners.go:198] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0502 08:41:09.525009 23 resource.go:361] Creating new exec pod
  E0502 08:41:10.512254      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:11.512464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:12.513377      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:41:12.550658 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1833 exec execpod79t7x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0502 08:41:12.637925 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I0502 08:41:12.637949 23 builder.go:147] stdout: "nodeport-test-nz2gl"
  I0502 08:41:12.637993 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1833 exec execpod79t7x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.105.104.51 80'
  I0502 08:41:12.703047 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.105.104.51 80\nConnection to 10.105.104.51 80 port [tcp/http] succeeded!\n"
  I0502 08:41:12.703071 23 builder.go:147] stdout: "nodeport-test-nz2gl"
  I0502 08:41:12.703113 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1833 exec execpod79t7x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 32680'
  I0502 08:41:12.775070 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 32680\nConnection to 10.221.190.32 32680 port [tcp/*] succeeded!\n"
  I0502 08:41:12.775096 23 builder.go:147] stdout: ""
  E0502 08:41:13.513866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:41:13.703210 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1833 exec execpod79t7x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 32680'
  I0502 08:41:13.815194 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 32680\nConnection to 10.221.190.32 32680 port [tcp/*] succeeded!\n"
  I0502 08:41:13.815218 23 builder.go:147] stdout: ""
  E0502 08:41:14.514161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:41:14.703491 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1833 exec execpod79t7x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 32680'
  I0502 08:41:14.774358 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 32680\nConnection to 10.221.190.32 32680 port [tcp/*] succeeded!\n"
  I0502 08:41:14.774382 23 builder.go:147] stdout: ""
  E0502 08:41:15.514205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:41:15.703588 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1833 exec execpod79t7x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 32680'
  I0502 08:41:15.789671 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 32680\nConnection to 10.221.190.32 32680 port [tcp/*] succeeded!\n"
  I0502 08:41:15.789721 23 builder.go:147] stdout: "nodeport-test-nz2gl"
  I0502 08:41:15.789785 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1833 exec execpod79t7x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.31 32680'
  I0502 08:41:15.861600 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.31 32680\nConnection to 10.221.190.31 32680 port [tcp/*] succeeded!\n"
  I0502 08:41:15.861625 23 builder.go:147] stdout: "nodeport-test-nz2gl"
  I0502 08:41:15.861684 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1833" for this suite. @ 05/02/24 08:41:15.865
• [9.463 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 05/02/24 08:41:15.871
  I0502 08:41:15.871467 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/02/24 08:41:15.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:41:15.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:41:15.892
  STEP: fetching the /apis discovery document @ 05/02/24 08:41:15.893
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 05/02/24 08:41:15.894
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 05/02/24 08:41:15.894
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 05/02/24 08:41:15.894
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 05/02/24 08:41:15.895
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 05/02/24 08:41:15.895
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 05/02/24 08:41:15.896
  I0502 08:41:15.896046 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1556" for this suite. @ 05/02/24 08:41:15.899
• [0.033 seconds]
------------------------------
SSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 05/02/24 08:41:15.904
  I0502 08:41:15.904468 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename disruption @ 05/02/24 08:41:15.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:41:15.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:41:15.925
  STEP: Creating a kubernetes client @ 05/02/24 08:41:15.927
  I0502 08:41:15.927590 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename disruption-2 @ 05/02/24 08:41:15.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:41:15.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:41:15.947
  STEP: Waiting for the pdb to be processed @ 05/02/24 08:41:15.952
  E0502 08:41:16.515128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:17.515282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/02/24 08:41:17.96
  E0502 08:41:18.516198      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:19.516546      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/02/24 08:41:19.967
  E0502 08:41:20.517044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:21.518074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 05/02/24 08:41:21.971
  STEP: listing a collection of PDBs in namespace disruption-7482 @ 05/02/24 08:41:21.973
  STEP: deleting a collection of PDBs @ 05/02/24 08:41:21.976
  STEP: Waiting for the PDB collection to be deleted @ 05/02/24 08:41:21.985
  I0502 08:41:21.987796 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-4497" for this suite. @ 05/02/24 08:41:21.99
  I0502 08:41:21.997157 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7482" for this suite. @ 05/02/24 08:41:22.005
• [6.109 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:817
  STEP: Creating a kubernetes client @ 05/02/24 08:41:22.013
  I0502 08:41:22.013584 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:41:22.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:41:22.032
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:41:22.035
  STEP: Setting up server cert @ 05/02/24 08:41:22.062
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:41:22.491
  STEP: Deploying the webhook pod @ 05/02/24 08:41:22.501
  STEP: Wait for the deployment to be ready @ 05/02/24 08:41:22.511
  E0502 08:41:22.518399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:41:22.532917 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:41:23.518857      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:24.519106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:41:24.539
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:41:24.55
  E0502 08:41:25.519386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:41:25.550599 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 05/02/24 08:41:25.555
  I0502 08:41:25.601906 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8940" for this suite. @ 05/02/24 08:41:25.607
  STEP: Destroying namespace "webhook-markers-4983" for this suite. @ 05/02/24 08:41:25.618
• [3.613 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 05/02/24 08:41:25.626
  I0502 08:41:25.626244 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/02/24 08:41:25.626
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:41:25.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:41:25.644
  E0502 08:41:26.519637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:27.520101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 05/02/24 08:41:27.668
  STEP: Cleaning up the configmap @ 05/02/24 08:41:27.674
  STEP: Cleaning up the pod @ 05/02/24 08:41:27.678
  I0502 08:41:27.689521 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-4868" for this suite. @ 05/02/24 08:41:27.694
• [2.074 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 05/02/24 08:41:27.7
  I0502 08:41:27.700257 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:41:27.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:41:27.715
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:41:27.717
  STEP: Creating secret with name projected-secret-test-cb02e584-3001-467b-9e62-bab814eb2547 @ 05/02/24 08:41:27.72
  STEP: Creating a pod to test consume secrets @ 05/02/24 08:41:27.724
  E0502 08:41:28.521148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:29.521814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:30.522164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:31.522358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:41:31.74
  I0502 08:41:31.743416 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-secrets-efaee5ee-8f65-49d9-aacc-573882d62423 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 08:41:31.747
  I0502 08:41:31.759473 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8948" for this suite. @ 05/02/24 08:41:31.762
• [4.069 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 05/02/24 08:41:31.769
  I0502 08:41:31.769103 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename init-container @ 05/02/24 08:41:31.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:41:31.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:41:31.79
  STEP: creating the pod @ 05/02/24 08:41:31.793
  I0502 08:41:31.793747 23 init_container.go:374] PodSpec: initContainers in spec.initContainers
  E0502 08:41:32.522983      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:33.523859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:34.524005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:35.524794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:36.524982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:37.525153      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:38.525327      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:39.525882      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:40.526037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:41.526169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:42.526332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:43.526473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:44.526804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:45.526957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:46.527107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:47.527773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:48.527971      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:49.528535      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:50.528678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:51.528839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:52.529000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:53.529139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:54.529410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:55.529532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:56.529720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:57.530003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:58.531000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:41:59.531416      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:00.531584      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:01.531701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:02.532046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:03.532006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:04.532341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:05.532595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:06.532749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:07.532907      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:08.533050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:09.533639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:42:10.257343 23 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-97b4a625-5fe1-4c96-b5e1-407ca3e5352b", GenerateName:"", Namespace:"init-container-6604", SelfLink:"", UID:"e127cfe8-58d5-4572-b8f8-02c51142a787", ResourceVersion:"20494", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 8, 41, 31, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"793740661"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"14d120409fb7cd821972cb270ff3b185f21da9ae299669beeeb71548f75d7ffa", "cni.projectcalico.org/podIP":"192.168.125.252/32", "cni.projectcalico.org/podIPs":"192.168.125.252/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 8, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a360d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 8, 41, 32, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a36120), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 8, 42, 10, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a36150), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-zn52x", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0055b2720), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-zn52x", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-zn52x", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-zn52x", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0045b0308), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"mini-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc005348200), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0045b0390)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0045b03b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0045b03b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0045b03bc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000f5c670), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 2, 8, 41, 33, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 2, 8, 41, 31, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 2, 8, 41, 31, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 2, 8, 41, 31, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 2, 8, 41, 31, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.221.190.31", HostIPs:[]v1.HostIP{v1.HostIP{IP:"10.221.190.31"}}, PodIP:"192.168.125.252", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.125.252"}}, StartTime:time.Date(2024, time.May, 2, 8, 41, 31, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc004a36198), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc004b3a070)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://5789ef5fe2a76270919a1179adc8500f5d1e127322a8414ef22e8e5fa952176b", Started:(*bool)(0xc0045b045a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0055b2780), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0045b046f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0055b2760), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc0045b0434), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I0502 08:42:10.257449 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-6604" for this suite. @ 05/02/24 08:42:10.261
• [38.498 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 05/02/24 08:42:10.267
  I0502 08:42:10.267315 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 08:42:10.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:42:10.28
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:42:10.284
  E0502 08:42:10.534585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:11.534750      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:12.535152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:13.535278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:14.535867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:15.536007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:16.536957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:17.537137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:42:18.341
  I0502 08:42:18.344211 23 output.go:196] Trying to get logs from node mini-3 pod client-envvars-35d4e69b-44bc-4b1f-805c-2c576d0e5208 container env3cont: <nil>
  STEP: delete the pod @ 05/02/24 08:42:18.354
  I0502 08:42:18.366605 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5763" for this suite. @ 05/02/24 08:42:18.369
• [8.108 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 05/02/24 08:42:18.375
  I0502 08:42:18.375343 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pv @ 05/02/24 08:42:18.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:42:18.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:42:18.396
  STEP: Creating initial PV and PVC @ 05/02/24 08:42:18.398
  I0502 08:42:18.398760 23 pv.go:390] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-3818" @ 05/02/24 08:42:18.413
  STEP: Listing PVCs in namespace "pv-3818" @ 05/02/24 08:42:18.417
  STEP: Patching the PV "pv-3818-mz6b9" @ 05/02/24 08:42:18.421
  STEP: Patching the PVC "pvc-7529s" @ 05/02/24 08:42:18.431
  STEP: Getting PV "pv-3818-mz6b9" @ 05/02/24 08:42:18.438
  STEP: Getting PVC "pvc-7529s" @ 05/02/24 08:42:18.443
  STEP: Deleting PVC "pvc-7529s" @ 05/02/24 08:42:18.448
  STEP: Confirm deletion of PVC "pvc-7529s" @ 05/02/24 08:42:18.458
  E0502 08:42:18.538061      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:19.538380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-3818-mz6b9" @ 05/02/24 08:42:20.466
  STEP: Confirm deletion of PV "pv-3818-mz6b9" @ 05/02/24 08:42:20.471
  E0502 08:42:20.538759      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:21.538941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 05/02/24 08:42:22.478
  I0502 08:42:22.478981 23 pv.go:390] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-3818-hxb2p" @ 05/02/24 08:42:22.488
  STEP: Updating the PVC "pvc-t79cg" @ 05/02/24 08:42:22.516
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-t79cg=updated" @ 05/02/24 08:42:22.523
  STEP: Deleting PVC "pvc-t79cg" via DeleteCollection @ 05/02/24 08:42:22.525
  STEP: Confirm deletion of PVC "pvc-t79cg" @ 05/02/24 08:42:22.531
  E0502 08:42:22.539462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:23.539588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-3818-hxb2p" via DeleteCollection @ 05/02/24 08:42:24.537
  E0502 08:42:24.539622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Confirm deletion of PV "pv-3818-hxb2p" @ 05/02/24 08:42:24.543
  E0502 08:42:25.540476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:26.540631      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:42:26.555111 23 persistent_volumes.go:407] AfterEach: deleting 1 PVCs and 1 PVs...
  I0502 08:42:26.555126 23 pv.go:201] Deleting PersistentVolumeClaim "pvc-t79cg"
  I0502 08:42:26.557737 23 pv.go:189] Deleting PersistentVolume "pv-3818-hxb2p"
  I0502 08:42:26.559958 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-3818" for this suite. @ 05/02/24 08:42:26.563
• [8.194 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:443
  STEP: Creating a kubernetes client @ 05/02/24 08:42:26.569
  I0502 08:42:26.569680 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/02/24 08:42:26.57
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:42:26.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:42:26.588
  STEP: set up a multi version CRD @ 05/02/24 08:42:26.59
  I0502 08:42:26.590630 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:42:27.540932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:28.541781      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:29.542618      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:30.542801      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 05/02/24 08:42:31.311
  STEP: check the unserved version gets removed @ 05/02/24 08:42:31.325
  E0502 08:42:31.543395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:32.544303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 05/02/24 08:42:33.092
  E0502 08:42:33.544959      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:34.545454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:35.545715      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:36.546282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:42:36.618105 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4261" for this suite. @ 05/02/24 08:42:36.625
• [10.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1533
  STEP: Creating a kubernetes client @ 05/02/24 08:42:36.632
  I0502 08:42:36.632107 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:42:36.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:42:36.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:42:36.651
  STEP: creating Agnhost RC @ 05/02/24 08:42:36.653
  I0502 08:42:36.653679 23 kubectl.go:1540] namespace kubectl-2450
  I0502 08:42:36.653700 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-2450 create -f -'
  I0502 08:42:36.727354 23 builder.go:146] stderr: ""
  I0502 08:42:36.727376 23 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/02/24 08:42:36.727
  E0502 08:42:37.547094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:42:37.731437 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:42:37.731452 23 framework.go:733] Found 0 / 1
  E0502 08:42:38.547209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:42:38.730619 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:42:38.730637 23 framework.go:733] Found 1 / 1
  I0502 08:42:38.730645 23 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0502 08:42:38.733193 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:42:38.733219 23 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0502 08:42:38.733224 23 kubectl.go:1547] wait on agnhost-primary startup in kubectl-2450 
  I0502 08:42:38.733271 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-2450 logs agnhost-primary-hnm7w agnhost-primary'
  I0502 08:42:38.776159 23 builder.go:146] stderr: ""
  I0502 08:42:38.776197 23 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 05/02/24 08:42:38.776
  I0502 08:42:38.776271 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-2450 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I0502 08:42:38.832621 23 builder.go:146] stderr: ""
  I0502 08:42:38.832646 23 builder.go:147] stdout: "service/rm2 exposed\n"
  I0502 08:42:38.839660 23 utils.go:1179] Service rm2 in namespace kubectl-2450 found.
  E0502 08:42:39.547581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:40.547749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 05/02/24 08:42:40.845
  I0502 08:42:40.845438 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-2450 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I0502 08:42:40.897432 23 builder.go:146] stderr: ""
  I0502 08:42:40.897454 23 builder.go:147] stdout: "service/rm3 exposed\n"
  I0502 08:42:40.901433 23 utils.go:1179] Service rm3 in namespace kubectl-2450 found.
  E0502 08:42:41.548178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:42.548348      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:42:42.907188 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2450" for this suite. @ 05/02/24 08:42:42.91
• [6.284 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 05/02/24 08:42:42.916
  I0502 08:42:42.916614 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename runtimeclass @ 05/02/24 08:42:42.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:42:42.933
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:42:42.936
  E0502 08:42:43.548550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:44.548839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:42:44.958700 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8845" for this suite. @ 05/02/24 08:42:44.961
• [2.051 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 05/02/24 08:42:44.967
  I0502 08:42:44.967816 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename svcaccounts @ 05/02/24 08:42:44.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:42:44.983
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:42:44.984
  I0502 08:42:44.996571 23 service_accounts.go:618] created pod
  E0502 08:42:45.548912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:46.549066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:47.549954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:48.550273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:42:49.01
  E0502 08:42:49.551097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:50.551353      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:51.551509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:52.551849      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:53.551994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:54.552480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:55.552625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:56.552774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:57.552970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:58.553839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:42:59.554520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:00.555178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:01.556233      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:02.557081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:03.557247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:04.557576      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:05.558085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:06.558580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:07.559307      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:08.559486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:09.559970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:10.560151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:11.560313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:12.560471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:13.560666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:14.561008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:15.561166      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:16.561317      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:17.561483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:18.561626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:43:19.010503 23 service_accounts.go:624] polling logs
  I0502 08:43:19.023309 23 service_accounts.go:634] Pod logs: 
  I0502 08:42:46.083146       1 log.go:245] OK: Got token
  I0502 08:42:46.083200       1 log.go:245] validating with in-cluster discovery
  I0502 08:42:46.083357       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0502 08:42:46.083385       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-2387:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0004fb030), NotBefore:(*jwt.NumericDate)(0xc0004fb120), IssuedAt:(*jwt.NumericDate)(0xc0004fb040), ID:"03eb1691-e569-4276-a9f6-8ac66602a134"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-2387", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d473bfa5-781b-4e4a-a126-a9ecbf9b48de"}}}
  I0502 08:42:46.091102       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0502 08:42:46.095687       1 log.go:245] OK: Validated signature on JWT
  I0502 08:42:46.095749       1 log.go:245] OK: Got valid claims from token!
  I0502 08:42:46.095768       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-2387:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000012b40), NotBefore:(*jwt.NumericDate)(0xc000012b68), IssuedAt:(*jwt.NumericDate)(0xc000012b48), ID:"03eb1691-e569-4276-a9f6-8ac66602a134"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-2387", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d473bfa5-781b-4e4a-a126-a9ecbf9b48de"}}}

  I0502 08:43:19.023340 23 service_accounts.go:638] completed pod
  I0502 08:43:19.028364 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2387" for this suite. @ 05/02/24 08:43:19.031
• [34.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1627
  STEP: Creating a kubernetes client @ 05/02/24 08:43:19.038
  I0502 08:43:19.038097 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:43:19.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:43:19.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:43:19.061
  STEP: creating the pod @ 05/02/24 08:43:19.062
  I0502 08:43:19.062782 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-9323 create -f -'
  I0502 08:43:19.137301 23 builder.go:146] stderr: ""
  I0502 08:43:19.137324 23 builder.go:147] stdout: "pod/pause created\n"
  E0502 08:43:19.562451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:20.562647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 05/02/24 08:43:21.148
  I0502 08:43:21.148833 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-9323 label pods pause testing-label=testing-label-value'
  I0502 08:43:21.194224 23 builder.go:146] stderr: ""
  I0502 08:43:21.194274 23 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 05/02/24 08:43:21.194
  I0502 08:43:21.194341 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-9323 get pod pause -L testing-label'
  I0502 08:43:21.231483 23 builder.go:146] stderr: ""
  I0502 08:43:21.231506 23 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 05/02/24 08:43:21.231
  I0502 08:43:21.231550 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-9323 label pods pause testing-label-'
  I0502 08:43:21.276032 23 builder.go:146] stderr: ""
  I0502 08:43:21.276060 23 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 05/02/24 08:43:21.276
  I0502 08:43:21.276101 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-9323 get pod pause -L testing-label'
  I0502 08:43:21.312113 23 builder.go:146] stderr: ""
  I0502 08:43:21.312137 23 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 05/02/24 08:43:21.312
  I0502 08:43:21.312206 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-9323 delete --grace-period=0 --force -f -'
  I0502 08:43:21.359912 23 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0502 08:43:21.359933 23 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I0502 08:43:21.359957 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-9323 get rc,svc -l name=pause --no-headers'
  I0502 08:43:21.400686 23 builder.go:146] stderr: "No resources found in kubectl-9323 namespace.\n"
  I0502 08:43:21.400710 23 builder.go:147] stdout: ""
  I0502 08:43:21.400738 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-9323 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0502 08:43:21.437537 23 builder.go:146] stderr: ""
  I0502 08:43:21.437560 23 builder.go:147] stdout: ""
  I0502 08:43:21.437611 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9323" for this suite. @ 05/02/24 08:43:21.441
• [2.410 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 05/02/24 08:43:21.448
  I0502 08:43:21.448278 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename security-context @ 05/02/24 08:43:21.448
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:43:21.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:43:21.474
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/02/24 08:43:21.476
  E0502 08:43:21.563442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:22.563601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:23.563683      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:24.563906      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:43:25.497
  I0502 08:43:25.500212 23 output.go:196] Trying to get logs from node mini-1 pod security-context-6153cdbd-c55d-41fb-9a3c-e0dc9e67b0d0 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 08:43:25.504
  I0502 08:43:25.517555 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-1998" for this suite. @ 05/02/24 08:43:25.52
• [4.079 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 05/02/24 08:43:25.527
  I0502 08:43:25.527482 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 08:43:25.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:43:25.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:43:25.549
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/02/24 08:43:25.552
  E0502 08:43:25.564633      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:26.564821      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:27.565204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:28.565936      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:29.566206      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:43:29.569
  I0502 08:43:29.572319 23 output.go:196] Trying to get logs from node mini-2 pod pod-82f0ec09-79f2-4203-8d5a-a89f3553f470 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 08:43:29.576
  I0502 08:43:29.588477 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6710" for this suite. @ 05/02/24 08:43:29.591
• [4.071 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 05/02/24 08:43:29.598
  I0502 08:43:29.598216 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:43:29.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:43:29.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:43:29.62
  STEP: Creating configMap with name configmap-test-volume-1dfae668-4d17-42aa-ab00-a00d330c22e0 @ 05/02/24 08:43:29.622
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:43:29.625
  E0502 08:43:30.566505      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:31.566639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:32.566699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:33.566815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:43:33.643
  I0502 08:43:33.645558 23 output.go:196] Trying to get logs from node mini-2 pod pod-configmaps-a3e0ed04-bc68-4f30-be2b-a6bf3cfd8886 container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:43:33.649
  I0502 08:43:33.663881 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4855" for this suite. @ 05/02/24 08:43:33.667
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 05/02/24 08:43:33.673
  I0502 08:43:33.673507 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-pred @ 05/02/24 08:43:33.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:43:33.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:43:33.742
  I0502 08:43:33.744035 23 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0502 08:43:33.749304 23 util.go:400] Waiting for terminating namespaces to be deleted...
  I0502 08:43:33.751255 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-1 before test
  I0502 08:43:33.759445 23 predicates.go:887] calico-node-74plz from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.759456 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 08:43:33.759462 23 predicates.go:887] kube-proxy-m56bg from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.759467 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 08:43:33.759472 23 predicates.go:887] helm-charts-fluent-bit-kxv24 from logging started at 2024-05-02 08:03:28 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.759476 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 08:43:33.759480 23 predicates.go:887] kps-prometheus-node-exporter-85b92 from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.759484 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 08:43:33.759502 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-qq8kg from sonobuoy started at 2024-05-02 08:09:23 +0000 UTC (2 container statuses recorded)
  I0502 08:43:33.759506 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:43:33.759510 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0502 08:43:33.759514 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-2 before test
  I0502 08:43:33.787345 23 predicates.go:887] calico-node-r29fd from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.787357 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 08:43:33.787363 23 predicates.go:887] kube-proxy-hmtzq from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.787367 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 08:43:33.787371 23 predicates.go:887] helm-charts-fluent-bit-hx6df from logging started at 2024-05-02 08:03:27 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.787375 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 08:43:33.787379 23 predicates.go:887] kps-prometheus-node-exporter-r49xh from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.787383 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 08:43:33.787401 23 predicates.go:887] sonobuoy from sonobuoy started at 2024-05-02 08:09:14 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.787405 23 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0502 08:43:33.787410 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-zq7p5 from sonobuoy started at 2024-05-02 08:09:23 +0000 UTC (2 container statuses recorded)
  I0502 08:43:33.787414 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:43:33.787418 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0502 08:43:33.787422 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-3 before test
  I0502 08:43:33.815719 23 predicates.go:887] calico-node-2k27s from kube-system started at 2024-05-02 08:02:51 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.815730 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 08:43:33.815736 23 predicates.go:887] kube-proxy-jxzqw from kube-system started at 2024-05-02 08:02:51 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.815741 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 08:43:33.815745 23 predicates.go:887] helm-charts-fluent-bit-hsj7q from logging started at 2024-05-02 08:03:28 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.815749 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 08:43:33.815753 23 predicates.go:887] kps-prometheus-node-exporter-mrb8g from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 08:43:33.815757 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 08:43:33.815761 23 predicates.go:887] sonobuoy-e2e-job-746b2c2b96604533 from sonobuoy started at 2024-05-02 08:09:22 +0000 UTC (2 container statuses recorded)
  I0502 08:43:33.815779 23 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0502 08:43:33.815783 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:43:33.815788 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-5zkb9 from sonobuoy started at 2024-05-02 08:09:22 +0000 UTC (2 container statuses recorded)
  I0502 08:43:33.815792 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:43:33.815796 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/02/24 08:43:33.815
  E0502 08:43:34.567627      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:35.567753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/02/24 08:43:35.873
  STEP: Trying to apply a random label on the found node. @ 05/02/24 08:43:35.89
  STEP: verifying the node has the label kubernetes.io/e2e-dee5013e-281d-48fe-aef4-5940f02ac5df 95 @ 05/02/24 08:43:35.903
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 05/02/24 08:43:35.906
  E0502 08:43:36.567986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:37.568123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.221.190.32 on the node which pod4 resides and expect not scheduled @ 05/02/24 08:43:37.917
  E0502 08:43:38.568710      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:39.569020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:40.569105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:41.569260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:42.570188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:43.570327      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:44.571050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:45.571194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:46.571416      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:47.571597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:48.572065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:49.572409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:50.572656      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:51.572802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:52.573147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:53.573281      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:54.573611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:55.573747      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:56.574403      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:57.574586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:58.574873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:43:59.575132      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:00.575442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:01.575586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:02.576499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:03.576754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:04.577578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:05.577731      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:06.578459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:07.578627      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:08.579384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:09.579851      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:10.580727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:11.580867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:12.581330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:13.581475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:14.581933      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:15.582087      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:16.582463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:17.582632      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:18.582963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:19.583334      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:20.583873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:21.584051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:22.584855      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:23.584976      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:24.585034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:25.586031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:26.586169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:27.586547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:28.586701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:29.587078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:30.587115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:31.587260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:32.587653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:33.587806      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:34.588465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:35.588609      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:36.588889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:37.589167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:38.589218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:39.589762      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:40.590328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:41.590469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:42.590607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:43.590747      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:44.591171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:45.591297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:46.592063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:47.592228      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:48.592932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:49.593137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:50.593947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:51.594098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:52.594219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:53.594336      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:54.595030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:55.595151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:56.595488      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:57.595957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:58.596827      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:44:59.597076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:00.597831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:01.597997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:02.598118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:03.598267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:04.598430      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:05.598581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:06.598972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:07.599124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:08.599485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:09.599942      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:10.600771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:11.600937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:12.601047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:13.601189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:14.601804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:15.601966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:16.602901      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:17.603074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:18.603688      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:19.604326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:20.604816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:21.605057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:22.605504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:23.605718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:24.606527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:25.607050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:26.607178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:27.607341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:28.607444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:29.607972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:30.608258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:31.608406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:32.608812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:33.608978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:34.609663      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:35.609790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:36.610355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:37.610509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:38.611535      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:39.611970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:40.612605      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:41.612755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:42.613041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:43.613180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:44.613908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:45.614052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:46.614732      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:47.614839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:48.615859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:49.616192      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:50.616579      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:51.616726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:52.617783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:53.617972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:54.618199      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:55.618351      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:56.618587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:57.618745      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:58.618919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:45:59.619259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:00.619349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:01.619510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:02.619651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:03.619803      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:04.619904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:05.620023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:06.620134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:07.620292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:08.621219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:09.622002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:10.622113      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:11.622282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:12.622607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:13.623052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:14.623424      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:15.623550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:16.623672      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:17.623846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:18.624179      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:19.624684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:20.624983      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:21.626066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:22.627054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:23.627195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:24.627890      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:25.628161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:26.628615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:27.628789      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:28.629369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:29.630171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:30.630550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:31.630690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:32.630987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:33.631146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:34.631569      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:35.631694      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:36.632012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:37.632177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:38.633146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:39.633661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:40.634200      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:41.634352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:42.634600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:43.635491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:44.636564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:45.636689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:46.637029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:47.637195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:48.637293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:49.637804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:50.638554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:51.638725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:52.639241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:53.639342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:54.639639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:55.639770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:56.640314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:57.640497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:58.640602      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:46:59.641025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:00.641612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:01.641781      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:02.642011      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:03.642170      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:04.642623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:05.642756      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:06.642948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:07.643090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:08.644077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:09.644524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:10.645149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:11.645335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:12.646103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:13.646272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:14.647033      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:15.647162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:16.647473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:17.647638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:18.648052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:19.648443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:20.649126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:21.649265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:22.650097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:23.650236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:24.650353      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:25.650516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:26.650671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:27.650859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:28.650955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:29.651147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:30.651578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:31.651729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:32.652697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:33.652811      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:34.653019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:35.653145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:36.653205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:37.653371      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:38.653794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:39.654103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:40.654133      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:41.654308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:42.654837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:43.654963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:44.655079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:45.655225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:46.655405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:47.655555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:48.655704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:49.656106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:50.656528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:51.656628      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:52.656849      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:53.657001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:54.657963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:55.658084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:56.659121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:57.659286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:58.660052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:47:59.660511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:00.660962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:01.661124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:02.661573      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:03.661735      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:04.662076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:05.662210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:06.662925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:07.663093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:08.663773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:09.664045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:10.664109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:11.664264      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:12.664446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:13.664607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:14.664954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:15.665119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:16.665541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:17.665696      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:18.665812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:19.666821      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:20.667064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:21.667361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:22.667680      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:23.667843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:24.668316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:25.668570      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:26.668666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:27.668824      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:28.669437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:29.669974      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:30.670331      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:31.670472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:32.671442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:33.671576      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:34.672498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:35.672603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:36.673123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:37.672987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-dee5013e-281d-48fe-aef4-5940f02ac5df off the node mini-2 @ 05/02/24 08:48:37.923
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-dee5013e-281d-48fe-aef4-5940f02ac5df @ 05/02/24 08:48:37.935
  I0502 08:48:37.939815 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6765" for this suite. @ 05/02/24 08:48:37.945
• [304.286 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 05/02/24 08:48:37.959
  I0502 08:48:37.959783 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 08:48:37.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:48:37.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:48:37.993
  STEP: Creating Pod @ 05/02/24 08:48:37.996
  E0502 08:48:38.673629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:39.674002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 05/02/24 08:48:40.01
  I0502 08:48:40.010569 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6983 PodName:pod-sharedvolume-acf128af-f476-4f4c-b427-8d0e94498cf0 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:48:40.010580 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:48:40.010874 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:48:40.010929 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-6983/pods/pod-sharedvolume-acf128af-f476-4f4c-b427-8d0e94498cf0/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  I0502 08:48:40.048705 23 exec_util.go:106] Exec stderr: ""
  I0502 08:48:40.048775 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6983" for this suite. @ 05/02/24 08:48:40.053
• [2.102 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 05/02/24 08:48:40.061
  I0502 08:48:40.061659 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-runtime @ 05/02/24 08:48:40.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:48:40.08
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:48:40.083
  STEP: create the container @ 05/02/24 08:48:40.085
  W0502 08:48:40.092196      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/02/24 08:48:40.092
  E0502 08:48:40.674486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:41.674985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:42.675358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/02/24 08:48:43.11
  STEP: the container should be terminated @ 05/02/24 08:48:43.112
  STEP: the termination message should be set @ 05/02/24 08:48:43.112
  I0502 08:48:43.112448 23 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/02/24 08:48:43.112
  I0502 08:48:43.123851 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7784" for this suite. @ 05/02/24 08:48:43.126
• [3.074 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1394
  STEP: Creating a kubernetes client @ 05/02/24 08:48:43.135
  I0502 08:48:43.135488 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:48:43.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:48:43.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:48:43.16
  I0502 08:48:43.163164 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-602 create -f -'
  I0502 08:48:43.236488 23 builder.go:146] stderr: ""
  I0502 08:48:43.236511 23 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I0502 08:48:43.236540 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-602 create -f -'
  I0502 08:48:43.327000 23 builder.go:146] stderr: ""
  I0502 08:48:43.327025 23 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/02/24 08:48:43.327
  E0502 08:48:43.676395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:48:44.330058 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:48:44.330092 23 framework.go:733] Found 0 / 1
  E0502 08:48:44.676439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:48:45.329753 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:48:45.329774 23 framework.go:733] Found 1 / 1
  I0502 08:48:45.329797 23 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0502 08:48:45.331865 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:48:45.331895 23 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0502 08:48:45.331943 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-602 describe pod agnhost-primary-g8wkt'
  I0502 08:48:45.379751 23 builder.go:146] stderr: ""
  I0502 08:48:45.379793 23 builder.go:147] stdout: "Name:             agnhost-primary-g8wkt\nNamespace:        kubectl-602\nPriority:         0\nService Account:  default\nNode:             mini-1/10.221.190.31\nStart Time:       Thu, 02 May 2024 08:48:43 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 9196479cbbe9c6510758398d0a7828c7a5f3aaabc029c3879adc2e336807c26f\n                  cni.projectcalico.org/podIP: 192.168.125.195/32\n                  cni.projectcalico.org/podIPs: 192.168.125.195/32\nStatus:           Running\nIP:               192.168.125.195\nIPs:\n  IP:           192.168.125.195\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://c73816670026a192970aa9c4e105322663af9dda595cb3d295027a13ec755c53\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 02 May 2024 08:48:44 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nk2h7 (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-nk2h7:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-602/agnhost-primary-g8wkt to mini-1\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  I0502 08:48:45.379829 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-602 describe rc agnhost-primary'
  I0502 08:48:45.430321 23 builder.go:146] stderr: ""
  I0502 08:48:45.430353 23 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-602\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-g8wkt\n"
  I0502 08:48:45.430420 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-602 describe service agnhost-primary'
  I0502 08:48:45.478835 23 builder.go:146] stderr: ""
  I0502 08:48:45.478862 23 builder.go:147] stdout: "Name:              agnhost-primary\nNamespace:         kubectl-602\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.104.211.178\nIPs:               10.104.211.178\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.125.195:6379\nSession Affinity:  None\nEvents:            <none>\n"
  I0502 08:48:45.483035 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-602 describe node master-1'
  I0502 08:48:45.571431 23 builder.go:146] stderr: ""
  I0502 08:48:45.571533 23 builder.go:147] stdout: "Name:               master-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.221.190.5/23\n                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.39.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 02 May 2024 07:56:52 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  master-1\n  AcquireTime:     <unset>\n  RenewTime:       Thu, 02 May 2024 08:48:36 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 02 May 2024 07:57:52 +0000   Thu, 02 May 2024 07:57:52 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Thu, 02 May 2024 08:45:53 +0000   Thu, 02 May 2024 07:56:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Thu, 02 May 2024 08:45:53 +0000   Thu, 02 May 2024 07:56:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Thu, 02 May 2024 08:45:53 +0000   Thu, 02 May 2024 07:56:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Thu, 02 May 2024 08:45:53 +0000   Thu, 02 May 2024 08:06:04 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.221.190.5\n  Hostname:    master-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  104322028Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8144884Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  96143180846\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8042484Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 64dab925dc0f4991bee88bac418f5bbb\n  System UUID:                32642b42-741e-a822-2e85-3735e764229a\n  Boot ID:                    5c73c527-7dd4-4803-adc3-d71cee0f3ba9\n  Kernel Version:             5.6.14-300.fc32.x86_64\n  OS Image:                   Fedora CoreOS 32.20200601.3.0\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.30.0\n  Kube-Proxy Version:         v1.30.0\nPodCIDR:                      192.168.0.0/24\nPodCIDRs:                     192.168.0.0/24\nNon-terminated Pods:          (16 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                     orka-webhooks-f7c686b7f-c5q57                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         41m\n  kube-system                 calico-kube-controllers-5d8db5696b-7mldt                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         50m\n  kube-system                 calico-node-b2mth                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         50m\n  kube-system                 coredns-7db6d8ff4d-qwm58                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     51m\n  kube-system                 coredns-7db6d8ff4d-wlj7z                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     51m\n  kube-system                 etcd-master-1                                              100m (5%)     0 (0%)      100Mi (1%)       0 (0%)         51m\n  kube-system                 kube-apiserver-master-1                                    250m (12%)    0 (0%)      0 (0%)           0 (0%)         51m\n  kube-system                 kube-controller-manager-master-1                           200m (10%)    0 (0%)      0 (0%)           0 (0%)         51m\n  kube-system                 kube-proxy-4jkln                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         51m\n  kube-system                 kube-scheduler-master-1                                    100m (5%)     0 (0%)      0 (0%)           0 (0%)         51m\n  kube-system                 traefik-ingress-controller-869cc89694-ldhjt                0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  logging                     helm-charts-fluent-bit-brlkw                               200m (10%)    200m (10%)  512Mi (6%)       512Mi (6%)     45m\n  metallb-system              controller-99df4fb6d-7rdf2                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         50m\n  metallb-system              speaker-j85gn                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         50m\n  monitoring                  kps-prometheus-node-exporter-fx9ms                         100m (5%)     100m (5%)   100Mi (1%)       100Mi (1%)     44m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-da82723a9e834026-mz2m6    0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1400m (70%)  300m (15%)\n  memory             852Mi (10%)  952Mi (12%)\n  ephemeral-storage  0 (0%)       0 (0%)\n  hugepages-1Gi      0 (0%)       0 (0%)\n  hugepages-2Mi      0 (0%)       0 (0%)\nEvents:\n  Type     Reason                   Age                From             Message\n  ----     ------                   ----               ----             -------\n  Normal   Starting                 51m                kube-proxy       \n  Normal   NodeHasSufficientMemory  52m (x8 over 52m)  kubelet          Node master-1 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    52m (x8 over 52m)  kubelet          Node master-1 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     52m (x7 over 52m)  kubelet          Node master-1 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  52m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeNotReady             51m                kubelet          Node master-1 status is now: NodeNotReady\n  Warning  InvalidDiskCapacity      51m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  51m                kubelet          Node master-1 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    51m                kubelet          Node master-1 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     51m                kubelet          Node master-1 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  51m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                51m                kubelet          Node master-1 status is now: NodeReady\n  Normal   Starting                 51m                kubelet          Starting kubelet.\n  Normal   RegisteredNode           51m                node-controller  Node master-1 event: Registered Node master-1 in Controller\n  Normal   Starting                 42m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      42m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  42m                kubelet          Node master-1 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    42m                kubelet          Node master-1 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     42m                kubelet          Node master-1 status is now: NodeHasSufficientPID\n  Normal   NodeNotReady             42m                kubelet          Node master-1 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  42m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                42m                kubelet          Node master-1 status is now: NodeReady\n"
  I0502 08:48:45.571579 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-602 describe namespace kubectl-602'
  I0502 08:48:45.614567 23 builder.go:146] stderr: ""
  I0502 08:48:45.614602 23 builder.go:147] stdout: "Name:         kubectl-602\nLabels:       e2e-framework=kubectl\n              e2e-run=1e8eb09b-6877-4925-80e2-315df5ad7200\n              kubernetes.io/metadata.name=kubectl-602\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0502 08:48:45.614665 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-602" for this suite. @ 05/02/24 08:48:45.617
• [2.489 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 05/02/24 08:48:45.624
  I0502 08:48:45.624386 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename csistoragecapacity @ 05/02/24 08:48:45.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:48:45.64
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:48:45.642
  STEP: getting /apis @ 05/02/24 08:48:45.644
  STEP: getting /apis/storage.k8s.io @ 05/02/24 08:48:45.647
  STEP: getting /apis/storage.k8s.io/v1 @ 05/02/24 08:48:45.648
  STEP: creating @ 05/02/24 08:48:45.648
  STEP: watching @ 05/02/24 08:48:45.661
  I0502 08:48:45.661330 23 csistoragecapacity.go:143] starting watch
  STEP: getting @ 05/02/24 08:48:45.667
  STEP: listing in namespace @ 05/02/24 08:48:45.67
  STEP: listing across namespaces @ 05/02/24 08:48:45.672
  STEP: patching @ 05/02/24 08:48:45.674
  E0502 08:48:45.677184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating @ 05/02/24 08:48:45.677
  I0502 08:48:45.681673 23 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I0502 08:48:45.681701 23 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 05/02/24 08:48:45.681
  STEP: deleting a collection @ 05/02/24 08:48:45.69
  I0502 08:48:45.702375 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-7254" for this suite. @ 05/02/24 08:48:45.705
• [0.087 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 05/02/24 08:48:45.711
  I0502 08:48:45.711649 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 08:48:45.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:48:45.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:48:45.732
  E0502 08:48:46.677967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:47.678133      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:48.678184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:49.678718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:50.678989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:51.679936      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:52.680870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:53.680995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:54.681178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:55.681253      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:56.681444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:57.681494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:58.681594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:48:59.681826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:00.682068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:01.682162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:02.682339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/02/24 08:49:02.738
  E0502 08:49:03.682412      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:04.683354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:05.683508      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:06.683771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:07.683839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/02/24 08:49:07.741
  STEP: Ensuring resource quota status is calculated @ 05/02/24 08:49:07.746
  E0502 08:49:08.684257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:09.684757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 05/02/24 08:49:09.75
  STEP: Ensuring resource quota status captures configMap creation @ 05/02/24 08:49:09.759
  E0502 08:49:10.685023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:11.685170      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 05/02/24 08:49:11.763
  STEP: Ensuring resource quota status released usage @ 05/02/24 08:49:11.769
  E0502 08:49:12.685940      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:13.686422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:13.772634 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2036" for this suite. @ 05/02/24 08:49:13.776
• [28.071 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 05/02/24 08:49:13.782
  I0502 08:49:13.782810 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename discovery @ 05/02/24 08:49:13.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:13.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:13.803
  STEP: Setting up server cert @ 05/02/24 08:49:13.807
  I0502 08:49:14.073446 23 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0502 08:49:14.074384 23 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0502 08:49:14.074399 23 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0502 08:49:14.074425 23 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0502 08:49:14.074446 23 discovery.go:139] Checking APIGroup: apps
  I0502 08:49:14.075130 23 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0502 08:49:14.075142 23 discovery.go:148] Versions found [{apps/v1 v1}]
  I0502 08:49:14.075147 23 discovery.go:154] apps/v1 matches apps/v1
  I0502 08:49:14.075155 23 discovery.go:139] Checking APIGroup: events.k8s.io
  I0502 08:49:14.075825 23 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0502 08:49:14.075835 23 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0502 08:49:14.075840 23 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0502 08:49:14.075844 23 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0502 08:49:14.076582 23 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0502 08:49:14.076592 23 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0502 08:49:14.076615 23 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0502 08:49:14.076620 23 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0502 08:49:14.077206 23 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0502 08:49:14.077220 23 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0502 08:49:14.077248 23 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0502 08:49:14.077252 23 discovery.go:139] Checking APIGroup: autoscaling
  I0502 08:49:14.077974 23 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0502 08:49:14.077985 23 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0502 08:49:14.077989 23 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0502 08:49:14.078009 23 discovery.go:139] Checking APIGroup: batch
  I0502 08:49:14.078818 23 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0502 08:49:14.078830 23 discovery.go:148] Versions found [{batch/v1 v1}]
  I0502 08:49:14.078849 23 discovery.go:154] batch/v1 matches batch/v1
  I0502 08:49:14.078853 23 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0502 08:49:14.079441 23 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0502 08:49:14.079451 23 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0502 08:49:14.079474 23 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0502 08:49:14.079478 23 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0502 08:49:14.080136 23 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0502 08:49:14.080146 23 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0502 08:49:14.080151 23 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0502 08:49:14.080171 23 discovery.go:139] Checking APIGroup: policy
  I0502 08:49:14.080818 23 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0502 08:49:14.080827 23 discovery.go:148] Versions found [{policy/v1 v1}]
  I0502 08:49:14.080831 23 discovery.go:154] policy/v1 matches policy/v1
  I0502 08:49:14.080835 23 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0502 08:49:14.081455 23 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0502 08:49:14.081465 23 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0502 08:49:14.081492 23 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0502 08:49:14.081499 23 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0502 08:49:14.082177 23 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0502 08:49:14.082188 23 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0502 08:49:14.082212 23 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0502 08:49:14.082219 23 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0502 08:49:14.082893 23 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0502 08:49:14.082921 23 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0502 08:49:14.082925 23 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0502 08:49:14.082929 23 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0502 08:49:14.083533 23 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0502 08:49:14.083545 23 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0502 08:49:14.083549 23 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0502 08:49:14.083554 23 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0502 08:49:14.084127 23 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0502 08:49:14.084136 23 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0502 08:49:14.084140 23 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0502 08:49:14.084145 23 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0502 08:49:14.084676 23 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0502 08:49:14.084701 23 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0502 08:49:14.084706 23 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0502 08:49:14.084713 23 discovery.go:139] Checking APIGroup: node.k8s.io
  I0502 08:49:14.085351 23 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0502 08:49:14.085383 23 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0502 08:49:14.085387 23 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0502 08:49:14.085392 23 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0502 08:49:14.086023 23 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0502 08:49:14.086062 23 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0502 08:49:14.086066 23 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0502 08:49:14.086070 23 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0502 08:49:14.087152 23 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0502 08:49:14.087186 23 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  I0502 08:49:14.087191 23 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0502 08:49:14.087196 23 discovery.go:139] Checking APIGroup: acme.cert-manager.io
  I0502 08:49:14.087791 23 discovery.go:147] PreferredVersion.GroupVersion: acme.cert-manager.io/v1
  I0502 08:49:14.087822 23 discovery.go:148] Versions found [{acme.cert-manager.io/v1 v1}]
  I0502 08:49:14.087826 23 discovery.go:154] acme.cert-manager.io/v1 matches acme.cert-manager.io/v1
  I0502 08:49:14.087831 23 discovery.go:139] Checking APIGroup: cert-manager.io
  I0502 08:49:14.088433 23 discovery.go:147] PreferredVersion.GroupVersion: cert-manager.io/v1
  I0502 08:49:14.088447 23 discovery.go:148] Versions found [{cert-manager.io/v1 v1}]
  I0502 08:49:14.088465 23 discovery.go:154] cert-manager.io/v1 matches cert-manager.io/v1
  I0502 08:49:14.088470 23 discovery.go:139] Checking APIGroup: crd.projectcalico.org
  I0502 08:49:14.088959 23 discovery.go:147] PreferredVersion.GroupVersion: crd.projectcalico.org/v1
  I0502 08:49:14.088969 23 discovery.go:148] Versions found [{crd.projectcalico.org/v1 v1}]
  I0502 08:49:14.088987 23 discovery.go:154] crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
  I0502 08:49:14.088992 23 discovery.go:139] Checking APIGroup: monitoring.coreos.com
  I0502 08:49:14.089638 23 discovery.go:147] PreferredVersion.GroupVersion: monitoring.coreos.com/v1
  I0502 08:49:14.089650 23 discovery.go:148] Versions found [{monitoring.coreos.com/v1 v1} {monitoring.coreos.com/v1alpha1 v1alpha1}]
  I0502 08:49:14.089654 23 discovery.go:154] monitoring.coreos.com/v1 matches monitoring.coreos.com/v1
  I0502 08:49:14.089659 23 discovery.go:139] Checking APIGroup: orka.macstadium.com
  I0502 08:49:14.090142 23 discovery.go:147] PreferredVersion.GroupVersion: orka.macstadium.com/v1
  I0502 08:49:14.090165 23 discovery.go:148] Versions found [{orka.macstadium.com/v1 v1}]
  I0502 08:49:14.090172 23 discovery.go:154] orka.macstadium.com/v1 matches orka.macstadium.com/v1
  I0502 08:49:14.090176 23 discovery.go:139] Checking APIGroup: metallb.io
  I0502 08:49:14.090718 23 discovery.go:147] PreferredVersion.GroupVersion: metallb.io/v1beta2
  I0502 08:49:14.090751 23 discovery.go:148] Versions found [{metallb.io/v1beta2 v1beta2} {metallb.io/v1beta1 v1beta1} {metallb.io/v1alpha1 v1alpha1}]
  I0502 08:49:14.090756 23 discovery.go:154] metallb.io/v1beta2 matches metallb.io/v1beta2
  I0502 08:49:14.090760 23 discovery.go:139] Checking APIGroup: traefik.containo.us
  I0502 08:49:14.091473 23 discovery.go:147] PreferredVersion.GroupVersion: traefik.containo.us/v1alpha1
  I0502 08:49:14.091504 23 discovery.go:148] Versions found [{traefik.containo.us/v1alpha1 v1alpha1}]
  I0502 08:49:14.091509 23 discovery.go:154] traefik.containo.us/v1alpha1 matches traefik.containo.us/v1alpha1
  I0502 08:49:14.091513 23 discovery.go:139] Checking APIGroup: traefik.io
  I0502 08:49:14.092126 23 discovery.go:147] PreferredVersion.GroupVersion: traefik.io/v1alpha1
  I0502 08:49:14.092158 23 discovery.go:148] Versions found [{traefik.io/v1alpha1 v1alpha1}]
  I0502 08:49:14.092164 23 discovery.go:154] traefik.io/v1alpha1 matches traefik.io/v1alpha1
  I0502 08:49:14.092233 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-6647" for this suite. @ 05/02/24 08:49:14.095
• [0.320 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:350
  STEP: Creating a kubernetes client @ 05/02/24 08:49:14.102
  I0502 08:49:14.102751 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename security-context-test @ 05/02/24 08:49:14.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:14.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:14.12
  E0502 08:49:14.686961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:15.687179      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:16.687864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:17.688068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:18.141463 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5079" for this suite. @ 05/02/24 08:49:18.145
• [4.049 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 05/02/24 08:49:18.151
  I0502 08:49:18.151448 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename namespaces @ 05/02/24 08:49:18.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:18.17
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:18.173
  STEP: creating a Namespace @ 05/02/24 08:49:18.175
  STEP: patching the Namespace @ 05/02/24 08:49:18.191
  STEP: get the Namespace and ensuring it has the label @ 05/02/24 08:49:18.196
  I0502 08:49:18.199080 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2028" for this suite. @ 05/02/24 08:49:18.202
  STEP: Destroying namespace "nspatchtest-e88ac482-f45e-4174-9e15-fb34e5895794-4713" for this suite. @ 05/02/24 08:49:18.21
• [0.067 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 05/02/24 08:49:18.218
  I0502 08:49:18.218661 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:49:18.219
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:18.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:18.234
  STEP: Creating configMap with name configmap-test-volume-d35977ed-6571-4be2-ad8f-ff4b88c2a046 @ 05/02/24 08:49:18.237
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:49:18.241
  E0502 08:49:18.688242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:19.688657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:20.688794      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:21.688987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:49:22.259
  I0502 08:49:22.261728 23 output.go:196] Trying to get logs from node mini-1 pod pod-configmaps-124a3a52-dbfa-4190-b9b2-c01a77dc0427 container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:49:22.274
  I0502 08:49:22.286099 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-904" for this suite. @ 05/02/24 08:49:22.289
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1693
  STEP: Creating a kubernetes client @ 05/02/24 08:49:22.296
  I0502 08:49:22.296050 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:49:22.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:22.311
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:22.313
  STEP: creating Agnhost RC @ 05/02/24 08:49:22.315
  I0502 08:49:22.315268 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-7236 create -f -'
  I0502 08:49:22.385633 23 builder.go:146] stderr: ""
  I0502 08:49:22.385656 23 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/02/24 08:49:22.385
  E0502 08:49:22.689043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:23.390170 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:49:23.390186 23 framework.go:733] Found 0 / 1
  E0502 08:49:23.689474      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:24.389617 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:49:24.389637 23 framework.go:733] Found 1 / 1
  I0502 08:49:24.389661 23 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 05/02/24 08:49:24.389
  I0502 08:49:24.392319 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:49:24.392332 23 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0502 08:49:24.392366 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-7236 patch pod agnhost-primary-xzt5x -p {"metadata":{"annotations":{"x":"y"}}}'
  I0502 08:49:24.435963 23 builder.go:146] stderr: ""
  I0502 08:49:24.435991 23 builder.go:147] stdout: "pod/agnhost-primary-xzt5x patched\n"
  STEP: checking annotations @ 05/02/24 08:49:24.436
  I0502 08:49:24.438238 23 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0502 08:49:24.438253 23 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0502 08:49:24.438299 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7236" for this suite. @ 05/02/24 08:49:24.441
• [2.151 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 05/02/24 08:49:24.447
  I0502 08:49:24.447569 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:49:24.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:24.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:24.468
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 08:49:24.47
  E0502 08:49:24.689669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:25.690462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:26.690841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:27.690967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:49:28.49
  I0502 08:49:28.493309 23 output.go:196] Trying to get logs from node mini-3 pod downwardapi-volume-d76cadc1-6d9b-4737-8432-8e0cedf60a1f container client-container: <nil>
  STEP: delete the pod @ 05/02/24 08:49:28.505
  I0502 08:49:28.516951 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1980" for this suite. @ 05/02/24 08:49:28.52
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 05/02/24 08:49:28.526
  I0502 08:49:28.526946 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:49:28.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:28.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:28.544
  STEP: Setting up server cert @ 05/02/24 08:49:28.568
  E0502 08:49:28.691941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:49:29.253
  STEP: Deploying the webhook pod @ 05/02/24 08:49:29.26
  STEP: Wait for the deployment to be ready @ 05/02/24 08:49:29.271
  I0502 08:49:29.279361 23 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0502 08:49:29.692958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:30.693097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:49:31.288
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:49:31.3
  E0502 08:49:31.693227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:32.300998 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0502 08:49:32.306735 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:49:32.693293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7082-crds.webhook.example.com via the AdmissionRegistration API @ 05/02/24 08:49:32.817
  STEP: Creating a custom resource while v1 is storage version @ 05/02/24 08:49:32.827
  E0502 08:49:33.693954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:34.694222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 05/02/24 08:49:34.855
  STEP: Patching the custom resource while v2 is storage version @ 05/02/24 08:49:34.862
  I0502 08:49:35.472785 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8423" for this suite. @ 05/02/24 08:49:35.476
  STEP: Destroying namespace "webhook-markers-8949" for this suite. @ 05/02/24 08:49:35.481
• [6.961 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 05/02/24 08:49:35.487
  I0502 08:49:35.487768 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename containers @ 05/02/24 08:49:35.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:35.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:35.507
  STEP: Creating a pod to test override arguments @ 05/02/24 08:49:35.509
  E0502 08:49:35.695067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:36.695178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:37.695262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:38.695391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:49:39.526
  I0502 08:49:39.529088 23 output.go:196] Trying to get logs from node mini-1 pod client-containers-e290f407-541a-4273-9c4b-7e48122965e5 container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:49:39.533
  I0502 08:49:39.545133 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-7783" for this suite. @ 05/02/24 08:49:39.548
• [4.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 05/02/24 08:49:39.554
  I0502 08:49:39.554923 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename daemonsets @ 05/02/24 08:49:39.555
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:39.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:39.572
  STEP: Creating simple DaemonSet "daemon-set" @ 05/02/24 08:49:39.591
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/02/24 08:49:39.595
  I0502 08:49:39.600299 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:39.600335 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:39.600367 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:39.603450 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:49:39.603461 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 08:49:39.695721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:40.601317 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:40.601358 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:40.601372 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:40.604550 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:49:40.604562 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 08:49:40.696625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:41.599624 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:41.599668 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:41.599692 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:41.602081 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:49:41.602095 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 08:49:41.697223      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:42.600553 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:42.600594 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:42.600622 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:42.603618 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0502 08:49:42.603630 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 08:49:42.697727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:43.600937 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:43.600987 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:43.601025 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 08:49:43.603597 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0502 08:49:43.603610 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 05/02/24 08:49:43.605
  I0502 08:49:43.607858 23 daemon_set.go:912] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 05/02/24 08:49:43.607
  I0502 08:49:43.614863 23 daemon_set.go:932] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 05/02/24 08:49:43.614
  I0502 08:49:43.616058 23 daemon_set.go:957] Observed &DaemonSet event: ADDED
  I0502 08:49:43.616125 23 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.616190 23 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.616269 23 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.616365 23 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.616424 23 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.616440 23 daemon_set.go:950] Found daemon set daemon-set in namespace daemonsets-5156 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0502 08:49:43.616447 23 daemon_set.go:961] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 05/02/24 08:49:43.616
  STEP: watching for the daemon set status to be patched @ 05/02/24 08:49:43.621
  I0502 08:49:43.625307 23 daemon_set.go:1001] Observed &DaemonSet event: ADDED
  I0502 08:49:43.625370 23 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.625430 23 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.625532 23 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.625591 23 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.625641 23 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.625655 23 daemon_set.go:997] Observed daemon set daemon-set in namespace daemonsets-5156 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0502 08:49:43.625713 23 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0502 08:49:43.625728 23 daemon_set.go:994] Found daemon set daemon-set in namespace daemonsets-5156 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0502 08:49:43.625738 23 daemon_set.go:1005] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 05/02/24 08:49:43.628
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5156, will wait for the garbage collector to delete the pods @ 05/02/24 08:49:43.628
  I0502 08:49:43.686053 23 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 5.257447ms
  E0502 08:49:43.698250      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:43.786403 23 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.348716ms
  E0502 08:49:44.699236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:45.700045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:49:45.890136 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:49:45.890166 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0502 08:49:45.892519 23 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22739"},"items":null}

  I0502 08:49:45.894727 23 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22739"},"items":null}

  I0502 08:49:45.905612 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5156" for this suite. @ 05/02/24 08:49:45.908
• [6.362 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 05/02/24 08:49:45.916
  I0502 08:49:45.916697 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-runtime @ 05/02/24 08:49:45.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:45.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:45.937
  STEP: create the container @ 05/02/24 08:49:45.939
  W0502 08:49:45.947216      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/02/24 08:49:45.947
  E0502 08:49:46.700280      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:47.701049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:48.701237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:49.701826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/02/24 08:49:49.969
  STEP: the container should be terminated @ 05/02/24 08:49:49.971
  STEP: the termination message should be set @ 05/02/24 08:49:49.971
  I0502 08:49:49.971260 23 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 05/02/24 08:49:49.971
  I0502 08:49:49.983976 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-2813" for this suite. @ 05/02/24 08:49:49.987
• [4.076 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 05/02/24 08:49:49.992
  I0502 08:49:49.992788 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 08:49:49.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:49:50.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:49:50.011
  E0502 08:49:50.702787      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:51.703032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:52.703164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:53.703552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:54.703843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:55.704465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:56.705249      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:57.705599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:58.705725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:49:59.705973      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:00.706376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:01.706807      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:02.707373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:03.707819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:04.708210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:05.709074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:06.709580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:07.710036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:08.710475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:09.710863      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:10.711585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:11.711680      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:12.711724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:13.712156      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:14.712374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:15.712726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:16.712835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:17.713009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:18.713348      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:19.713476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:20.714235      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:21.714996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:22.715549      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:23.715962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:24.716091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:25.716261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:26.716484      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:27.716730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:28.717006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:29.718085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:30.718921      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:31.718964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:32.719019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:33.719482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:34.719950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:35.720078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:36.720244      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:37.720339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:38.720693      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:39.720902      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:40.720964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:41.721273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:42.721551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:43.721964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:44.722124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:45.722764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:46.722865      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:47.723032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:48.723257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:49.723336      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:50:50.024109 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-609" for this suite. @ 05/02/24 08:50:50.027
• [60.042 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 05/02/24 08:50:50.035
  I0502 08:50:50.035215 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename dns @ 05/02/24 08:50:50.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:50:50.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:50:50.069
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6195.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6195.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 05/02/24 08:50:50.071
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6195.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6195.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 05/02/24 08:50:50.071
  STEP: creating a pod to probe /etc/hosts @ 05/02/24 08:50:50.071
  STEP: submitting the pod to kubernetes @ 05/02/24 08:50:50.071
  E0502 08:50:50.724399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:51.725097      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:52.725367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:53.726100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/02/24 08:50:54.089
  STEP: looking for the results for each expected name from probers @ 05/02/24 08:50:54.092
  I0502 08:50:54.105179 23 dns_common.go:527] DNS probes using dns-6195/dns-test-44b373a9-a895-4c20-b5dd-ae827c789fce succeeded

  STEP: deleting the pod @ 05/02/24 08:50:54.105
  I0502 08:50:54.115789 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6195" for this suite. @ 05/02/24 08:50:54.119
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 05/02/24 08:50:54.125
  I0502 08:50:54.125912 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubelet-test @ 05/02/24 08:50:54.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:50:54.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:50:54.145
  STEP: Waiting for pod completion @ 05/02/24 08:50:54.152
  E0502 08:50:54.726149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:55.727042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:56.728059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:57.728229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:50:58.167057 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8189" for this suite. @ 05/02/24 08:50:58.17
• [4.049 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 05/02/24 08:50:58.175
  I0502 08:50:58.175376 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-watch @ 05/02/24 08:50:58.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:50:58.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:50:58.192
  I0502 08:50:58.194391 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:50:58.728772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:50:59.729151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 05/02/24 08:51:00.729
  E0502 08:51:00.729721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:51:00.733696 23 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-02T08:51:00Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-02T08:51:00Z]] name:name1 resourceVersion:23124 uid:b4f757e5-8bc4-4a0e-bd19-50dadfcbe7e7] num:map[num1:9223372036854775807 num2:1000000]]}
  E0502 08:51:01.729838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:02.730019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:03.730024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:04.731025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:05.731320      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:06.731476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:07.731620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:08.731831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:09.732174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:10.732322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 05/02/24 08:51:10.734
  I0502 08:51:10.739962 23 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-02T08:51:10Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-02T08:51:10Z]] name:name2 resourceVersion:23162 uid:fa1049c1-439c-4363-9cb2-b617beb731c2] num:map[num1:9223372036854775807 num2:1000000]]}
  E0502 08:51:11.732383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:12.732555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:13.732743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:14.733080      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:15.733220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:16.733338      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:17.733497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:18.733638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:19.734109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:20.735083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 05/02/24 08:51:20.74
  I0502 08:51:20.747206 23 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-02T08:51:00Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-02T08:51:20Z]] name:name1 resourceVersion:23190 uid:b4f757e5-8bc4-4a0e-bd19-50dadfcbe7e7] num:map[num1:9223372036854775807 num2:1000000]]}
  E0502 08:51:21.736045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:22.736334      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:23.736480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:24.736806      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:25.736932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:26.737106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:27.737253      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:28.737406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:29.737948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:30.738103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 05/02/24 08:51:30.747
  I0502 08:51:30.752517 23 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-02T08:51:10Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-02T08:51:30Z]] name:name2 resourceVersion:23219 uid:fa1049c1-439c-4363-9cb2-b617beb731c2] num:map[num1:9223372036854775807 num2:1000000]]}
  E0502 08:51:31.739019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:32.739212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:33.739342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:34.739650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:35.739786      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:36.739925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:37.740094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:38.740233      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:39.740732      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:40.740877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 05/02/24 08:51:40.753
  I0502 08:51:40.759203 23 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-02T08:51:00Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-02T08:51:20Z]] name:name1 resourceVersion:23247 uid:b4f757e5-8bc4-4a0e-bd19-50dadfcbe7e7] num:map[num1:9223372036854775807 num2:1000000]]}
  E0502 08:51:41.740960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:42.741103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:43.741229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:44.741653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:45.741791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:46.741921      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:47.742082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:48.742229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:49.742666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:50.742808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 05/02/24 08:51:50.76
  I0502 08:51:50.767004 23 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-02T08:51:10Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-02T08:51:30Z]] name:name2 resourceVersion:23278 uid:fa1049c1-439c-4363-9cb2-b617beb731c2] num:map[num1:9223372036854775807 num2:1000000]]}
  E0502 08:51:51.743017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:52.743230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:53.744056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:54.744344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:55.744503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:56.744669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:57.744830      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:58.744993      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:51:59.745476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:00.745612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:01.279556 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-7132" for this suite. @ 05/02/24 08:52:01.284
• [63.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 05/02/24 08:52:01.292
  I0502 08:52:01.292569 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename svcaccounts @ 05/02/24 08:52:01.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:52:01.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:52:01.31
  E0502 08:52:01.746028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:02.747067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 05/02/24 08:52:03.329
  I0502 08:52:03.329534 23 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5255 pod-service-account-968c045e-599a-41d2-950a-9836deb48aa3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 05/02/24 08:52:03.417
  I0502 08:52:03.417712 23 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5255 pod-service-account-968c045e-599a-41d2-950a-9836deb48aa3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 05/02/24 08:52:03.485
  I0502 08:52:03.485837 23 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5255 pod-service-account-968c045e-599a-41d2-950a-9836deb48aa3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I0502 08:52:03.556199 23 service_accounts.go:114] Got root ca configmap in namespace "svcaccounts-5255"
  I0502 08:52:03.558055 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5255" for this suite. @ 05/02/24 08:52:03.565
• [2.286 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 05/02/24 08:52:03.578
  I0502 08:52:03.578258 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replicaset @ 05/02/24 08:52:03.578
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:52:03.592
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:52:03.601
  I0502 08:52:03.602803 23 replica_set.go:191] Creating ReplicaSet my-hostname-basic-f5149b88-c902-44a9-9aab-9bb6d0f7ceed
  I0502 08:52:03.609196 23 resource.go:87] Pod name my-hostname-basic-f5149b88-c902-44a9-9aab-9bb6d0f7ceed: Found 0 pods out of 1
  E0502 08:52:03.747523      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:04.747820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:05.747936      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:06.748122      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:07.748278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:08.611590 23 resource.go:87] Pod name my-hostname-basic-f5149b88-c902-44a9-9aab-9bb6d0f7ceed: Found 1 pods out of 1
  I0502 08:52:08.611622 23 replica_set.go:204] Ensuring a pod for ReplicaSet "my-hostname-basic-f5149b88-c902-44a9-9aab-9bb6d0f7ceed" is running
  I0502 08:52:08.613994 23 replica_set.go:220] Pod "my-hostname-basic-f5149b88-c902-44a9-9aab-9bb6d0f7ceed-gz4ts" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 08:52:05 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 08:52:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 08:52:05 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 08:52:05 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 08:52:03 +0000 UTC Reason: Message:}])
  I0502 08:52:08.614022 23 replica_set.go:228] Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/02/24 08:52:08.614
  I0502 08:52:08.620873 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3099" for this suite. @ 05/02/24 08:52:08.623
• [5.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 05/02/24 08:52:08.629
  I0502 08:52:08.629398 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename subpath @ 05/02/24 08:52:08.629
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:52:08.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:52:08.649
  STEP: Setting up data @ 05/02/24 08:52:08.651
  STEP: Creating pod pod-subpath-test-downwardapi-tts6 @ 05/02/24 08:52:08.657
  STEP: Creating a pod to test atomic-volume-subpath @ 05/02/24 08:52:08.657
  E0502 08:52:08.748694      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:09.749109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:10.749566      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:11.750024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:12.750439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:13.750613      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:14.750897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:15.751028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:16.751650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:17.751829      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:18.752174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:19.752570      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:20.752773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:21.753024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:22.753610      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:23.753777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:24.754145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:25.754271      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:26.754726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:27.754911      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:28.755317      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:29.756390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:30.756679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:31.757021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:52:32.719
  I0502 08:52:32.721705 23 output.go:196] Trying to get logs from node mini-1 pod pod-subpath-test-downwardapi-tts6 container test-container-subpath-downwardapi-tts6: <nil>
  STEP: delete the pod @ 05/02/24 08:52:32.73
  STEP: Deleting pod pod-subpath-test-downwardapi-tts6 @ 05/02/24 08:52:32.743
  I0502 08:52:32.743666 23 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-tts6" in namespace "subpath-1100"
  I0502 08:52:32.745637 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1100" for this suite. @ 05/02/24 08:52:32.748
• [24.125 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1759
  STEP: Creating a kubernetes client @ 05/02/24 08:52:32.756
  I0502 08:52:32.756319 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 08:52:32.756
  E0502 08:52:32.757239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:52:32.776
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:52:32.778
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/02/24 08:52:32.78
  I0502 08:52:32.780403 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-2931 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I0502 08:52:32.822241 23 builder.go:146] stderr: ""
  I0502 08:52:32.822278 23 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/02/24 08:52:32.822
  I0502 08:52:32.824399 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-2931 delete pods e2e-test-httpd-pod'
  E0502 08:52:33.757494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:34.126868 23 builder.go:146] stderr: ""
  I0502 08:52:34.126898 23 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0502 08:52:34.126959 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2931" for this suite. @ 05/02/24 08:52:34.132
• [1.382 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 05/02/24 08:52:34.138
  I0502 08:52:34.138527 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:52:34.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:52:34.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:52:34.155
  STEP: Creating configMap that has name configmap-test-emptyKey-b0e7d8c7-d5cb-4b4a-ba44-5a0786b558f9 @ 05/02/24 08:52:34.158
  I0502 08:52:34.159840 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8827" for this suite. @ 05/02/24 08:52:34.163
• [0.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 05/02/24 08:52:34.169
  I0502 08:52:34.169857 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/02/24 08:52:34.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:52:34.191
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:52:34.193
  STEP: create the container to handle the HTTPGet hook request. @ 05/02/24 08:52:34.2
  E0502 08:52:34.757998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:35.758154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/02/24 08:52:36.216
  E0502 08:52:36.759018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:37.759124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/02/24 08:52:38.229
  STEP: delete the pod with lifecycle hook @ 05/02/24 08:52:38.237
  E0502 08:52:38.760093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:39.760528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:40.761363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:41.762018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:42.251467 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4643" for this suite. @ 05/02/24 08:52:42.255
• [8.092 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 05/02/24 08:52:42.261
  I0502 08:52:42.261664 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename deployment @ 05/02/24 08:52:42.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:52:42.279
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:52:42.282
  I0502 08:52:42.299125 23 resource.go:87] Pod name rollover-pod: Found 0 pods out of 1
  E0502 08:52:42.762674      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:43.762833      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:44.763298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:45.763465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:46.763621      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:47.302765 23 resource.go:87] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/02/24 08:52:47.302
  I0502 08:52:47.302818 23 deployment.go:911] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0502 08:52:47.764028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:48.764189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:49.306143 23 deployment.go:921] Creating deployment "test-rollover-deployment"
  I0502 08:52:49.312871 23 deployment.go:934] Make sure deployment "test-rollover-deployment" performs scaling operations
  E0502 08:52:49.765113      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:50.765263      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:51.320937 23 deployment.go:939] Check revision of new replica set for deployment "test-rollover-deployment"
  I0502 08:52:51.324897 23 deployment.go:943] Ensure that both replica sets have 1 created replica
  I0502 08:52:51.328174 23 deployment.go:952] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0502 08:52:51.334157 23 deployment.go:313] Updating deployment test-rollover-deployment
  I0502 08:52:51.334170 23 deployment.go:961] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0502 08:52:51.765842      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:52.766004      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:53.339569 23 deployment.go:966] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0502 08:52:53.344457 23 deployment.go:970] Make sure deployment "test-rollover-deployment" is complete
  I0502 08:52:53.348545 23 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0502 08:52:53.348588 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 53, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:52:53.766937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:54.767242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:55.355403 23 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0502 08:52:55.355448 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 53, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:52:55.767661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:56.767806      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:57.354645 23 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0502 08:52:57.354704 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 53, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:52:57.767988      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:52:58.768136      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:52:59.354968 23 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0502 08:52:59.355012 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 53, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:52:59.768306      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:00.768436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:01.354672 23 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0502 08:53:01.354715 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 52, 53, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 52, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:01.769065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:02.769196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:03.354700 23 deployment.go:94] 
  I0502 08:53:03.354737 23 deployment.go:974] Ensure that both old replica sets have no replicas
  I0502 08:53:03.360442 23 deployment.go:633] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8435",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0b015526-f616-4110-bfee-78d53e116dd7",
      ResourceVersion: (string) (len=5) "23771",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236769,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236771,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236783,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236769,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236769,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236783,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236769,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-679c966bdf\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0502 08:53:03.363728 23 deployment.go:39] New ReplicaSet "test-rollover-deployment-679c966bdf" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-679c966bdf",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8435",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ef068713-11c6-4ef7-be8b-9fe1a08418c8",
      ResourceVersion: (string) (len=5) "23761",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236771,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "0b015526-f616-4110-bfee-78d53e116dd7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236771,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 62 30 31 35 35  32 36 2d 66 36 31 36 2d  |\"0b015526-f616-|
              00000120  34 31 31 30 2d 62 66 65  65 2d 37 38 64 35 33 65  |4110-bfee-78d53e|
              00000130  31 31 36 64 64 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |116dd7\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236783,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf",
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:53:03.364564 23 deployment.go:44] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0502 08:53:03.364700 23 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8435",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c1de0c9a-75fa-4c12-af0d-d880b5dba552",
      ResourceVersion: (string) (len=5) "23770",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236762,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "0b015526-f616-4110-bfee-78d53e116dd7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236762,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236783,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  30 62 30 31 35 35 32 36  2d 66 36 31 36 2d 34 31  |0b015526-f616-41|
              000000c0  31 30 2d 62 66 65 65 2d  37 38 64 35 33 65 31 31  |10-bfee-78d53e11|
              000000d0  36 64 64 37 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |6dd7\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236783,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=5) "httpd",
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:53:03.365644 23 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-65bd487b4b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8435",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "24cd7ac0-3dfb-4328-8754-87950e856463",
      ResourceVersion: (string) (len=5) "23710",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236769,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "0b015526-f616-4110-bfee-78d53e116dd7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236771,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 62 30 31 35 35  32 36 2d 66 36 31 36 2d  |\"0b015526-f616-|
              00000120  34 31 31 30 2d 62 66 65  65 2d 37 38 64 35 33 65  |4110-bfee-78d53e|
              00000130  31 31 36 64 64 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |116dd7\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236771,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:53:03.369479 23 deployment.go:67] Pod "test-rollover-deployment-679c966bdf-5jw5c" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-679c966bdf-5jw5c",
      GenerateName: (string) (len=36) "test-rollover-deployment-679c966bdf-",
      Namespace: (string) (len=15) "deployment-8435",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "71ed463e-16be-498e-a467-27a90b61d0ad",
      ResourceVersion: (string) (len=5) "23729",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236771,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "67184e34d00db2e91e0fef8310aa650029a29cf9664a381b9701435caf599f08",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.158.184/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.158.184/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-679c966bdf",
          UID: (types.UID) (len=36) "ef068713-11c6-4ef7-be8b-9fe1a08418c8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236771,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236771,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 66  30 36 38 37 31 33 2d 31  |d\":\"ef068713-1|
              00000090  31 63 36 2d 34 65 66 37  2d 62 65 38 62 2d 39 66  |1c6-4ef7-be8b-9f|
              000000a0  65 31 61 30 38 34 31 38  63 38 5c 22 7d 22 3a 7b  |e1a08418c8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236773,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 35  38 2e 31 38 34 5c 22 7d  |2.168.158.184\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vq4rr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vq4rr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236773,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236771,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236773,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236773,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236771,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) (len=15) "192.168.158.184",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.158.184"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236771,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850236772,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://79f2e565c86ec8c0ef19a40696894df5691e48bafa3dec02fc1d227878a983a2",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:53:03.370725 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8435" for this suite. @ 05/02/24 08:53:03.374
• [21.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 05/02/24 08:53:03.38
  I0502 08:53:03.380894 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename runtimeclass @ 05/02/24 08:53:03.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:03.398
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:03.4
  I0502 08:53:03.406768 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7531" for this suite. @ 05/02/24 08:53:03.409
• [0.035 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 05/02/24 08:53:03.415
  I0502 08:53:03.415467 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename proxy @ 05/02/24 08:53:03.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:03.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:03.434
  I0502 08:53:03.438719 23 proxy.go:387] Creating pod...
  E0502 08:53:03.769724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:04.770026      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:05.453236 23 proxy.go:411] Creating service...
  I0502 08:53:05.494839 23 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/pods/agnhost/proxy?method=DELETE
  I0502 08:53:05.509241 23 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0502 08:53:05.509286 23 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/pods/agnhost/proxy?method=OPTIONS
  I0502 08:53:05.530133 23 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0502 08:53:05.530151 23 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/pods/agnhost/proxy?method=PATCH
  I0502 08:53:05.544075 23 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0502 08:53:05.544089 23 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/pods/agnhost/proxy?method=POST
  I0502 08:53:05.563912 23 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0502 08:53:05.563928 23 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/pods/agnhost/proxy?method=PUT
  I0502 08:53:05.568515 23 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0502 08:53:05.568528 23 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/services/e2e-proxy-test-service/proxy?method=DELETE
  I0502 08:53:05.585087 23 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0502 08:53:05.585102 23 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0502 08:53:05.608039 23 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0502 08:53:05.608053 23 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/services/e2e-proxy-test-service/proxy?method=PATCH
  I0502 08:53:05.633720 23 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0502 08:53:05.633732 23 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/services/e2e-proxy-test-service/proxy?method=POST
  I0502 08:53:05.656334 23 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0502 08:53:05.656347 23 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/services/e2e-proxy-test-service/proxy?method=PUT
  I0502 08:53:05.676383 23 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0502 08:53:05.676394 23 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/pods/agnhost/proxy?method=GET
  I0502 08:53:05.681545 23 proxy.go:487] http.Client request:GET StatusCode:301
  I0502 08:53:05.681559 23 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/services/e2e-proxy-test-service/proxy?method=GET
  I0502 08:53:05.688294 23 proxy.go:487] http.Client request:GET StatusCode:301
  I0502 08:53:05.688306 23 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/pods/agnhost/proxy?method=HEAD
  I0502 08:53:05.690412 23 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0502 08:53:05.690422 23 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4385/services/e2e-proxy-test-service/proxy?method=HEAD
  I0502 08:53:05.693237 23 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0502 08:53:05.693302 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-4385" for this suite. @ 05/02/24 08:53:05.696
• [2.287 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:70
  STEP: Creating a kubernetes client @ 05/02/24 08:53:05.702
  I0502 08:53:05.702950 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/02/24 08:53:05.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:05.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:05.729
  I0502 08:53:05.731332 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:53:05.770921      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:06.771742      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:07.772473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 05/02/24 08:53:08.113
  I0502 08:53:08.113310 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 --namespace=crd-publish-openapi-6207 create -f -'
  I0502 08:53:08.223305 23 builder.go:146] stderr: ""
  I0502 08:53:08.223329 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-3204-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0502 08:53:08.223354 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 --namespace=crd-publish-openapi-6207 delete e2e-test-crd-publish-openapi-3204-crds test-foo'
  I0502 08:53:08.309715 23 builder.go:146] stderr: ""
  I0502 08:53:08.309739 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-3204-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I0502 08:53:08.309765 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 --namespace=crd-publish-openapi-6207 apply -f -'
  I0502 08:53:08.359488 23 builder.go:146] stderr: ""
  I0502 08:53:08.359512 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-3204-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0502 08:53:08.359537 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 --namespace=crd-publish-openapi-6207 delete e2e-test-crd-publish-openapi-3204-crds test-foo'
  I0502 08:53:08.405320 23 builder.go:146] stderr: ""
  I0502 08:53:08.405345 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-3204-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 05/02/24 08:53:08.405
  I0502 08:53:08.405395 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 --namespace=crd-publish-openapi-6207 create -f -'
  I0502 08:53:08.453687 23 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 05/02/24 08:53:08.453
  I0502 08:53:08.453749 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 --namespace=crd-publish-openapi-6207 create -f -'
  I0502 08:53:08.490308 23 builder.go:135] rc: 1
  I0502 08:53:08.490354 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 --namespace=crd-publish-openapi-6207 apply -f -'
  I0502 08:53:08.533950 23 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 05/02/24 08:53:08.533
  I0502 08:53:08.534015 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 --namespace=crd-publish-openapi-6207 create -f -'
  I0502 08:53:08.570154 23 builder.go:135] rc: 1
  I0502 08:53:08.570198 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 --namespace=crd-publish-openapi-6207 apply -f -'
  I0502 08:53:08.618991 23 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 05/02/24 08:53:08.619
  I0502 08:53:08.619055 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 explain e2e-test-crd-publish-openapi-3204-crds'
  I0502 08:53:08.653895 23 builder.go:146] stderr: ""
  I0502 08:53:08.653930 23 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3204-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 05/02/24 08:53:08.654
  I0502 08:53:08.654098 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 explain e2e-test-crd-publish-openapi-3204-crds.metadata'
  I0502 08:53:08.689046 23 builder.go:146] stderr: ""
  I0502 08:53:08.689115 23 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3204-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0502 08:53:08.689232 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 explain e2e-test-crd-publish-openapi-3204-crds.spec'
  I0502 08:53:08.724346 23 builder.go:146] stderr: ""
  I0502 08:53:08.724371 23 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3204-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0502 08:53:08.724427 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 explain e2e-test-crd-publish-openapi-3204-crds.spec.bars'
  I0502 08:53:08.759189 23 builder.go:146] stderr: ""
  I0502 08:53:08.759217 23 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3204-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 05/02/24 08:53:08.759
  I0502 08:53:08.759332 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-6207 explain e2e-test-crd-publish-openapi-3204-crds.spec.bars2'
  E0502 08:53:08.772590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:08.794901 23 builder.go:135] rc: 1
  E0502 08:53:09.772700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:10.773720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:10.985756 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6207" for this suite. @ 05/02/24 08:53:11.011
• [5.349 seconds]
------------------------------
SS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 05/02/24 08:53:11.051
  I0502 08:53:11.051699 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename ingressclass @ 05/02/24 08:53:11.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:11.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:11.107
  STEP: getting /apis @ 05/02/24 08:53:11.11
  STEP: getting /apis/networking.k8s.io @ 05/02/24 08:53:11.113
  STEP: getting /apis/networking.k8s.iov1 @ 05/02/24 08:53:11.114
  STEP: creating @ 05/02/24 08:53:11.114
  STEP: getting @ 05/02/24 08:53:11.125
  STEP: listing @ 05/02/24 08:53:11.127
  STEP: watching @ 05/02/24 08:53:11.129
  I0502 08:53:11.129587 23 ingressclass.go:348] starting watch
  STEP: patching @ 05/02/24 08:53:11.13
  STEP: updating @ 05/02/24 08:53:11.136
  I0502 08:53:11.144671 23 ingressclass.go:364] waiting for watch events with expected annotations
  I0502 08:53:11.144688 23 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 05/02/24 08:53:11.144
  STEP: deleting a collection @ 05/02/24 08:53:11.159
  I0502 08:53:11.174865 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-9830" for this suite. @ 05/02/24 08:53:11.177
• [0.133 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 05/02/24 08:53:11.184
  I0502 08:53:11.184795 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename aggregator @ 05/02/24 08:53:11.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:11.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:11.206
  I0502 08:53:11.208354 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Registering the sample API server. @ 05/02/24 08:53:11.208
  I0502 08:53:11.587262 23 helpers.go:161] Found ClusterRoles; assuming RBAC is enabled.
  I0502 08:53:11.614305 23 deployment.go:222] deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0502 08:53:11.774523      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:12.774695      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:13.661941 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:13.775120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:14.775363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:15.665968 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:15.776075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:16.776258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:17.666058 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:17.777241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:18.777408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:19.666629 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:19.777831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:20.778001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:21.665583 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:21.778737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:22.778892      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:23.666381 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:23.779597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:24.779941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:25.666696 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:25.780829      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:26.780995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:27.668135 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:27.781305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:28.781445      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:29.666309 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:29.782484      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:30.782620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:31.666144 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:31.783358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:32.783516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:33.665815 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:33.783950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:34.784216      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:35.665774 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 08:53:35.784963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:36.785155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:37.785895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:37.786246 23 aggregator.go:749] Waited 111.732414ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 05/02/24 08:53:37.91
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 05/02/24 08:53:37.913
  STEP: List APIServices @ 05/02/24 08:53:37.919
  I0502 08:53:37.924763 23 aggregator.go:550] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 05/02/24 08:53:37.924
  I0502 08:53:37.935071 23 aggregator.go:575] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 05/02/24 08:53:37.935
  I0502 08:53:37.944005 23 aggregator.go:601] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.May, 2, 8, 53, 37, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 05/02/24 08:53:37.944
  I0502 08:53:37.946670 23 aggregator.go:619] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-05-02 08:53:37 +0000 UTC Passed all checks passed}
  I0502 08:53:37.946688 23 aggregator.go:615] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0502 08:53:37.946696 23 aggregator.go:625] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 05/02/24 08:53:37.946
  I0502 08:53:37.958446 23 aggregator.go:641] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-1329131059" @ 05/02/24 08:53:37.958
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 05/02/24 08:53:38.021
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 05/02/24 08:53:38.045
  STEP: Patch APIService Status @ 05/02/24 08:53:38.047
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 05/02/24 08:53:38.054
  I0502 08:53:38.056674 23 aggregator.go:719] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-05-02 08:53:37 +0000 UTC Passed all checks passed}
  I0502 08:53:38.056704 23 aggregator.go:719] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0502 08:53:38.056728 23 aggregator.go:715] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0502 08:53:38.056738 23 aggregator.go:725] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 05/02/24 08:53:38.056
  STEP: Confirm that the generated APIService has been deleted @ 05/02/24 08:53:38.065
  I0502 08:53:38.065644 23 aggregator.go:786] Requesting list of APIServices to confirm quantity
  I0502 08:53:38.072357 23 aggregator.go:796] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0502 08:53:38.072369 23 aggregator.go:738] APIService v1alpha1.wardle.example.com has been deleted.
  I0502 08:53:38.177896 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-6996" for this suite. @ 05/02/24 08:53:38.181
• [27.002 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 05/02/24 08:53:38.187
  I0502 08:53:38.187232 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 08:53:38.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:38.206
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:38.208
  STEP: Creating secret with name secret-test-553f7da9-c0a8-4df1-bf05-2ac3d0edd53b @ 05/02/24 08:53:38.243
  STEP: Creating a pod to test consume secrets @ 05/02/24 08:53:38.247
  E0502 08:53:38.786353      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:39.786849      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:40.787258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:41.788124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:53:42.267
  I0502 08:53:42.270363 23 output.go:196] Trying to get logs from node mini-2 pod pod-secrets-d0a41c07-b7c5-4971-939f-22985e8ca549 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 08:53:42.282
  I0502 08:53:42.295512 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9241" for this suite. @ 05/02/24 08:53:42.299
  STEP: Destroying namespace "secret-namespace-4411" for this suite. @ 05/02/24 08:53:42.309
• [4.131 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 05/02/24 08:53:42.318
  I0502 08:53:42.318630 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:53:42.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:42.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:42.337
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-895466fa-1e67-4261-a09b-a844e982fba8 @ 05/02/24 08:53:42.342
  STEP: Creating the pod @ 05/02/24 08:53:42.347
  E0502 08:53:42.789141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:43.789325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-895466fa-1e67-4261-a09b-a844e982fba8 @ 05/02/24 08:53:44.376
  STEP: waiting to observe update in volume @ 05/02/24 08:53:44.381
  E0502 08:53:44.789511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:45.789639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:46.392758 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5517" for this suite. @ 05/02/24 08:53:46.396
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 05/02/24 08:53:46.406
  I0502 08:53:46.406293 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:53:46.406
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:46.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:46.424
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 08:53:46.426
  E0502 08:53:46.790238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:47.790402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:48.790432      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:49.790790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:53:50.448
  I0502 08:53:50.451583 23 output.go:196] Trying to get logs from node mini-1 pod downwardapi-volume-ec6e3889-8f74-41ad-bdd2-441cdf76a03d container client-container: <nil>
  STEP: delete the pod @ 05/02/24 08:53:50.456
  I0502 08:53:50.482684 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6816" for this suite. @ 05/02/24 08:53:50.492
• [4.097 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 05/02/24 08:53:50.503
  I0502 08:53:50.503275 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename svcaccounts @ 05/02/24 08:53:50.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:50.524
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:50.527
  STEP: creating a ServiceAccount @ 05/02/24 08:53:50.529
  STEP: watching for the ServiceAccount to be added @ 05/02/24 08:53:50.537
  STEP: patching the ServiceAccount @ 05/02/24 08:53:50.539
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 05/02/24 08:53:50.546
  STEP: deleting the ServiceAccount @ 05/02/24 08:53:50.55
  I0502 08:53:50.563025 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6040" for this suite. @ 05/02/24 08:53:50.567
• [0.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 05/02/24 08:53:50.575
  I0502 08:53:50.575179 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 05/02/24 08:53:50.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:50.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:50.599
  STEP: Setting up the test @ 05/02/24 08:53:50.601
  STEP: Creating hostNetwork=false pod @ 05/02/24 08:53:50.601
  E0502 08:53:50.791346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:51.791479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:52.791806      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:53.791955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 05/02/24 08:53:54.628
  E0502 08:53:54.792619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:55.792753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 05/02/24 08:53:56.646
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 05/02/24 08:53:56.646
  I0502 08:53:56.646705 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.646719 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.647015 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.647062 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0502 08:53:56.695523 23 exec_util.go:106] Exec stderr: ""
  I0502 08:53:56.695543 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.695563 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.695924 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.695976 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0502 08:53:56.729795 23 exec_util.go:106] Exec stderr: ""
  I0502 08:53:56.729825 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.729834 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.730096 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.730134 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0502 08:53:56.754167 23 exec_util.go:106] Exec stderr: ""
  I0502 08:53:56.754199 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.754205 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.754435 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.754486 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0502 08:53:56.788533 23 exec_util.go:106] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 05/02/24 08:53:56.788
  I0502 08:53:56.788560 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.788568 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.788817 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.788840 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  E0502 08:53:56.793119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:53:56.825916 23 exec_util.go:106] Exec stderr: ""
  I0502 08:53:56.825932 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.825938 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.826228 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.826253 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0502 08:53:56.855519 23 exec_util.go:106] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 05/02/24 08:53:56.855
  I0502 08:53:56.855573 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.855583 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.855811 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.855834 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0502 08:53:56.893494 23 exec_util.go:106] Exec stderr: ""
  I0502 08:53:56.893535 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.893554 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.893824 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.893849 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0502 08:53:56.925261 23 exec_util.go:106] Exec stderr: ""
  I0502 08:53:56.925276 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.925282 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.925563 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.925600 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0502 08:53:56.956337 23 exec_util.go:106] Exec stderr: ""
  I0502 08:53:56.956371 23 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9590 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 08:53:56.956381 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:53:56.956668 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 08:53:56.956699 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9590/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0502 08:53:56.982691 23 exec_util.go:106] Exec stderr: ""
  I0502 08:53:56.982756 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-9590" for this suite. @ 05/02/24 08:53:56.989
• [6.424 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 05/02/24 08:53:56.999
  I0502 08:53:56.999122 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:53:56.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:53:57.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:53:57.023
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 08:53:57.025
  E0502 08:53:57.794030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:58.794176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:53:59.794723      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:00.794914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:54:01.044
  I0502 08:54:01.047628 23 output.go:196] Trying to get logs from node mini-3 pod downwardapi-volume-3ae06482-e279-4a64-a23d-da6ff8b5f37f container client-container: <nil>
  STEP: delete the pod @ 05/02/24 08:54:01.057
  I0502 08:54:01.078972 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5963" for this suite. @ 05/02/24 08:54:01.084
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 05/02/24 08:54:01.092
  I0502 08:54:01.092700 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/02/24 08:54:01.093
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:54:01.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:54:01.114
  I0502 08:54:01.116626 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 08:54:01.657800 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3771" for this suite. @ 05/02/24 08:54:01.665
• [0.585 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 05/02/24 08:54:01.678
  I0502 08:54:01.678270 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-pred @ 05/02/24 08:54:01.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:54:01.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:54:01.699
  I0502 08:54:01.704067 23 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0502 08:54:01.711694 23 util.go:400] Waiting for terminating namespaces to be deleted...
  I0502 08:54:01.714337 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-1 before test
  I0502 08:54:01.722832 23 predicates.go:887] test-host-network-pod from e2e-kubelet-etc-hosts-9590 started at 2024-05-02 08:53:54 +0000 UTC (2 container statuses recorded)
  I0502 08:54:01.722859 23 predicates.go:889] 	Container busybox-1 ready: true, restart count 0
  I0502 08:54:01.722865 23 predicates.go:889] 	Container busybox-2 ready: true, restart count 0
  I0502 08:54:01.722870 23 predicates.go:887] calico-node-74plz from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.722875 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 08:54:01.722879 23 predicates.go:887] kube-proxy-m56bg from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.722890 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 08:54:01.722899 23 predicates.go:887] helm-charts-fluent-bit-kxv24 from logging started at 2024-05-02 08:03:28 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.722903 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 08:54:01.722908 23 predicates.go:887] kps-prometheus-node-exporter-85b92 from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.722912 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 08:54:01.722916 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-qq8kg from sonobuoy started at 2024-05-02 08:09:23 +0000 UTC (2 container statuses recorded)
  I0502 08:54:01.722920 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:54:01.722924 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0502 08:54:01.722929 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-2 before test
  I0502 08:54:01.731144 23 predicates.go:887] test-pod from e2e-kubelet-etc-hosts-9590 started at 2024-05-02 08:53:50 +0000 UTC (3 container statuses recorded)
  I0502 08:54:01.731157 23 predicates.go:889] 	Container busybox-1 ready: true, restart count 0
  I0502 08:54:01.731161 23 predicates.go:889] 	Container busybox-2 ready: true, restart count 0
  I0502 08:54:01.731167 23 predicates.go:889] 	Container busybox-3 ready: true, restart count 0
  I0502 08:54:01.731175 23 predicates.go:887] calico-node-r29fd from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.731179 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 08:54:01.731185 23 predicates.go:887] kube-proxy-hmtzq from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.731188 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 08:54:01.731193 23 predicates.go:887] helm-charts-fluent-bit-hx6df from logging started at 2024-05-02 08:03:27 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.731197 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 08:54:01.731201 23 predicates.go:887] kps-prometheus-node-exporter-r49xh from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.731205 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 08:54:01.731210 23 predicates.go:887] sonobuoy from sonobuoy started at 2024-05-02 08:09:14 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.731213 23 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0502 08:54:01.731218 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-zq7p5 from sonobuoy started at 2024-05-02 08:09:23 +0000 UTC (2 container statuses recorded)
  I0502 08:54:01.731222 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:54:01.731226 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0502 08:54:01.731230 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-3 before test
  I0502 08:54:01.739365 23 predicates.go:887] calico-node-2k27s from kube-system started at 2024-05-02 08:02:51 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.739379 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 08:54:01.739385 23 predicates.go:887] kube-proxy-jxzqw from kube-system started at 2024-05-02 08:02:51 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.739390 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 08:54:01.739397 23 predicates.go:887] helm-charts-fluent-bit-hsj7q from logging started at 2024-05-02 08:03:28 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.739403 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 08:54:01.739408 23 predicates.go:887] kps-prometheus-node-exporter-mrb8g from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 08:54:01.739411 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 08:54:01.739416 23 predicates.go:887] sonobuoy-e2e-job-746b2c2b96604533 from sonobuoy started at 2024-05-02 08:09:22 +0000 UTC (2 container statuses recorded)
  I0502 08:54:01.739420 23 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0502 08:54:01.739424 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:54:01.739428 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-5zkb9 from sonobuoy started at 2024-05-02 08:09:22 +0000 UTC (2 container statuses recorded)
  I0502 08:54:01.739432 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 08:54:01.739436 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node mini-1 @ 05/02/24 08:54:01.77
  STEP: verifying the node has the label node mini-2 @ 05/02/24 08:54:01.784
  E0502 08:54:01.795616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the node has the label node mini-3 @ 05/02/24 08:54:01.797
  I0502 08:54:01.816329 23 predicates.go:374] Pod test-host-network-pod requesting resource cpu=0m on Node mini-1
  I0502 08:54:01.816354 23 predicates.go:374] Pod test-pod requesting resource cpu=0m on Node mini-2
  I0502 08:54:01.816361 23 predicates.go:374] Pod calico-node-2k27s requesting resource cpu=250m on Node mini-3
  I0502 08:54:01.816367 23 predicates.go:374] Pod calico-node-74plz requesting resource cpu=250m on Node mini-1
  I0502 08:54:01.816371 23 predicates.go:374] Pod calico-node-r29fd requesting resource cpu=250m on Node mini-2
  I0502 08:54:01.816377 23 predicates.go:374] Pod kube-proxy-hmtzq requesting resource cpu=0m on Node mini-2
  I0502 08:54:01.816382 23 predicates.go:374] Pod kube-proxy-jxzqw requesting resource cpu=0m on Node mini-3
  I0502 08:54:01.816386 23 predicates.go:374] Pod kube-proxy-m56bg requesting resource cpu=0m on Node mini-1
  I0502 08:54:01.816392 23 predicates.go:374] Pod helm-charts-fluent-bit-hsj7q requesting resource cpu=200m on Node mini-3
  I0502 08:54:01.816396 23 predicates.go:374] Pod helm-charts-fluent-bit-hx6df requesting resource cpu=200m on Node mini-2
  I0502 08:54:01.816403 23 predicates.go:374] Pod helm-charts-fluent-bit-kxv24 requesting resource cpu=200m on Node mini-1
  I0502 08:54:01.816408 23 predicates.go:374] Pod kps-prometheus-node-exporter-85b92 requesting resource cpu=100m on Node mini-1
  I0502 08:54:01.816413 23 predicates.go:374] Pod kps-prometheus-node-exporter-mrb8g requesting resource cpu=100m on Node mini-3
  I0502 08:54:01.816417 23 predicates.go:374] Pod kps-prometheus-node-exporter-r49xh requesting resource cpu=100m on Node mini-2
  I0502 08:54:01.816422 23 predicates.go:374] Pod sonobuoy requesting resource cpu=0m on Node mini-2
  I0502 08:54:01.816429 23 predicates.go:374] Pod sonobuoy-e2e-job-746b2c2b96604533 requesting resource cpu=0m on Node mini-3
  I0502 08:54:01.816434 23 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-da82723a9e834026-5zkb9 requesting resource cpu=0m on Node mini-3
  I0502 08:54:01.816439 23 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-da82723a9e834026-qq8kg requesting resource cpu=0m on Node mini-1
  I0502 08:54:01.816443 23 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-da82723a9e834026-zq7p5 requesting resource cpu=0m on Node mini-2
  STEP: Starting Pods to consume most of the cluster CPU. @ 05/02/24 08:54:01.816
  I0502 08:54:01.816467 23 predicates.go:384] Creating a pod which consumes cpu=8015m on Node mini-1
  I0502 08:54:01.827062 23 predicates.go:384] Creating a pod which consumes cpu=8015m on Node mini-2
  I0502 08:54:01.833631 23 predicates.go:384] Creating a pod which consumes cpu=8015m on Node mini-3
  E0502 08:54:02.796101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:03.797070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 05/02/24 08:54:03.858
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-14a51b0f-e81c-4bdc-8426-49090a48a2a8.17cba00893e832f4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8964/filler-pod-14a51b0f-e81c-4bdc-8426-49090a48a2a8 to mini-2] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-14a51b0f-e81c-4bdc-8426-49090a48a2a8.17cba008c2736ade], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-14a51b0f-e81c-4bdc-8426-49090a48a2a8.17cba008d349bda7], Reason = [Created], Message = [Created container filler-pod-14a51b0f-e81c-4bdc-8426-49090a48a2a8] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-14a51b0f-e81c-4bdc-8426-49090a48a2a8.17cba008d7aebe71], Reason = [Started], Message = [Started container filler-pod-14a51b0f-e81c-4bdc-8426-49090a48a2a8] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1890eee3-b79c-4b61-8956-8dffbc2d3dae.17cba0089428685d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8964/filler-pod-1890eee3-b79c-4b61-8956-8dffbc2d3dae to mini-3] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1890eee3-b79c-4b61-8956-8dffbc2d3dae.17cba008c152b9ca], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1890eee3-b79c-4b61-8956-8dffbc2d3dae.17cba008d21bd3f8], Reason = [Created], Message = [Created container filler-pod-1890eee3-b79c-4b61-8956-8dffbc2d3dae] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1890eee3-b79c-4b61-8956-8dffbc2d3dae.17cba008d6373a1e], Reason = [Started], Message = [Started container filler-pod-1890eee3-b79c-4b61-8956-8dffbc2d3dae] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d1d7b12f-70ca-4e6b-94e8-fbd532033e52.17cba008933900a7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8964/filler-pod-d1d7b12f-70ca-4e6b-94e8-fbd532033e52 to mini-1] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d1d7b12f-70ca-4e6b-94e8-fbd532033e52.17cba008bf8bdca0], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d1d7b12f-70ca-4e6b-94e8-fbd532033e52.17cba008d05b907c], Reason = [Created], Message = [Created container filler-pod-d1d7b12f-70ca-4e6b-94e8-fbd532033e52] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-d1d7b12f-70ca-4e6b-94e8-fbd532033e52.17cba008d487cb62], Reason = [Started], Message = [Started container filler-pod-d1d7b12f-70ca-4e6b-94e8-fbd532033e52] @ 05/02/24 08:54:03.861
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17cba0090c7cbd52], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }. preemption: 0/6 nodes are available: 3 No preemption victims found for incoming pod, 3 Preemption is not helpful for scheduling.] @ 05/02/24 08:54:03.878
  E0502 08:54:04.797371      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node mini-1 @ 05/02/24 08:54:04.873
  STEP: verifying the node doesn't have the label node @ 05/02/24 08:54:04.884
  STEP: removing the label node off the node mini-2 @ 05/02/24 08:54:04.889
  STEP: verifying the node doesn't have the label node @ 05/02/24 08:54:04.9
  STEP: removing the label node off the node mini-3 @ 05/02/24 08:54:04.904
  STEP: verifying the node doesn't have the label node @ 05/02/24 08:54:04.915
  I0502 08:54:04.919840 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8964" for this suite. @ 05/02/24 08:54:04.924
• [3.255 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 05/02/24 08:54:04.933
  I0502 08:54:04.933605 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:54:04.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:54:04.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:54:04.956
  STEP: Setting up server cert @ 05/02/24 08:54:04.985
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:54:05.43
  STEP: Deploying the webhook pod @ 05/02/24 08:54:05.438
  STEP: Wait for the deployment to be ready @ 05/02/24 08:54:05.451
  I0502 08:54:05.462734 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:54:05.798158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:06.798380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:54:07.473
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:54:07.488
  E0502 08:54:07.798409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:54:08.488177 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/02/24 08:54:08.496
  STEP: create a pod @ 05/02/24 08:54:08.517
  E0502 08:54:08.798437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:09.798802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 05/02/24 08:54:10.546
  I0502 08:54:10.546858 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=webhook-4044 attach --namespace=webhook-4044 to-be-attached-pod -i -c=container1'
  I0502 08:54:10.597391 23 builder.go:135] rc: 1
  I0502 08:54:10.694213 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4044" for this suite. @ 05/02/24 08:54:10.707
  STEP: Destroying namespace "webhook-markers-3490" for this suite. @ 05/02/24 08:54:10.728
• [5.808 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3161
  STEP: Creating a kubernetes client @ 05/02/24 08:54:10.742
  I0502 08:54:10.742051 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 08:54:10.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:54:10.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:54:10.765
  STEP: creating an Endpoint @ 05/02/24 08:54:10.77
  STEP: waiting for available Endpoint @ 05/02/24 08:54:10.775
  STEP: listing all Endpoints @ 05/02/24 08:54:10.776
  STEP: updating the Endpoint @ 05/02/24 08:54:10.779
  STEP: fetching the Endpoint @ 05/02/24 08:54:10.785
  STEP: patching the Endpoint @ 05/02/24 08:54:10.788
  STEP: fetching the Endpoint @ 05/02/24 08:54:10.795
  STEP: deleting the Endpoint by Collection @ 05/02/24 08:54:10.798
  E0502 08:54:10.799661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for Endpoint deletion @ 05/02/24 08:54:10.814
  STEP: fetching the Endpoint @ 05/02/24 08:54:10.816
  I0502 08:54:10.819824 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7424" for this suite. @ 05/02/24 08:54:10.823
• [0.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:310
  STEP: Creating a kubernetes client @ 05/02/24 08:54:10.831
  I0502 08:54:10.831400 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/02/24 08:54:10.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:54:10.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:54:10.854
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 05/02/24 08:54:10.857
  I0502 08:54:10.857867 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:54:11.800072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:12.801075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:13.801748      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:14.802050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:15.802525      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:16.803401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:17.803949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:18.804937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 05/02/24 08:54:18.967
  I0502 08:54:18.967430 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:54:19.805850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:20.806811      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:54:21.314042 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:54:21.806844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:22.807460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:23.808214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:24.808451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:25.809201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:26.809628      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:27.809905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:28.810568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:54:29.710850 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1727" for this suite. @ 05/02/24 08:54:29.717
• [18.894 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 05/02/24 08:54:29.725
  I0502 08:54:29.725166 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename deployment @ 05/02/24 08:54:29.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:54:29.742
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:54:29.745
  I0502 08:54:29.747019 23 deployment.go:1645] Creating simple deployment test-new-deployment
  I0502 08:54:29.766568 23 deployment.go:222] deployment "test-new-deployment" doesn't have the required revision set
  E0502 08:54:29.810729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:30.810944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 05/02/24 08:54:31.779
  STEP: updating a scale subresource @ 05/02/24 08:54:31.782
  STEP: verifying the deployment Spec.Replicas was modified @ 05/02/24 08:54:31.786
  STEP: Patch a scale subresource @ 05/02/24 08:54:31.788
  E0502 08:54:31.811598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:54:31.819829 23 deployment.go:633] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3918",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4d07ee9a-9ef0-43c5-a3dc-dbdec528dc18",
      ResourceVersion: (string) (len=5) "24740",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236869,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236869,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236869,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-77db57d8df\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0502 08:54:31.827185 23 deployment.go:39] New ReplicaSet "test-new-deployment-77db57d8df" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-77db57d8df",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3918",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9af63469-2db5-4368-8fed-1ea9946e1046",
      ResourceVersion: (string) (len=5) "24743",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236869,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "4d07ee9a-9ef0-43c5-a3dc-dbdec528dc18",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 64 30 37 65 65  39 61 2d 39 65 66 30 2d  |\"4d07ee9a-9ef0-|
              00000120  34 33 63 35 2d 61 33 64  63 2d 64 62 64 65 63 35  |43c5-a3dc-dbdec5|
              00000130  32 38 64 63 31 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |28dc18\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0502 08:54:31.834093 23 deployment.go:67] Pod "test-new-deployment-77db57d8df-8t9d6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-77db57d8df-8t9d6",
      GenerateName: (string) (len=31) "test-new-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-3918",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e818f634-4adf-4fda-a07d-2b13c05bcf13",
      ResourceVersion: (string) (len=5) "24732",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236869,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "44351f5628e1c433abcf4d98d8a7b41f11aa0da966dc997755b83e13873ea8da",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=18) "192.168.125.216/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=18) "192.168.125.216/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-77db57d8df",
          UID: (types.UID) (len=36) "9af63469-2db5-4368-8fed-1ea9946e1046",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236869,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 61  66 36 33 34 36 39 2d 32  |d\":\"9af63469-2|
              00000090  64 62 35 2d 34 33 36 38  2d 38 66 65 64 2d 31 65  |db5-4368-8fed-1e|
              000000a0  61 39 39 34 36 65 31 30  34 36 5c 22 7d 22 3a 7b  |a9946e1046\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236870,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  35 2e 32 31 36 5c 22 7d  |2.168.125.216\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tfgjg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tfgjg",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236869,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236869,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.31",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.31"
        }
      },
      PodIP: (string) (len=15) "192.168.125.216",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.125.216"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236869,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63850236870,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://e01a1ee0c57a9ddd3734852e88c85cb71f55ef792b19ba6f433f5a7dc6f670db",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:54:31.835406 23 deployment.go:67] Pod "test-new-deployment-77db57d8df-nwzsc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-77db57d8df-nwzsc",
      GenerateName: (string) (len=31) "test-new-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-3918",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9ad8a3fc-3c70-40cb-97f4-5c695e1bc63d",
      ResourceVersion: (string) (len=5) "24748",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236871,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-77db57d8df",
          UID: (types.UID) (len=36) "9af63469-2db5-4368-8fed-1ea9946e1046",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 61  66 36 33 34 36 39 2d 32  |d\":\"9af63469-2|
              00000090  64 62 35 2d 34 33 36 38  2d 38 66 65 64 2d 31 65  |db5-4368-8fed-1e|
              000000a0  61 39 39 34 36 65 31 30  34 36 5c 22 7d 22 3a 7b  |a9946e1046\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-n5fjp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-n5fjp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=6) "mini-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63850236871,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "10.221.190.32",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "10.221.190.32"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63850236871,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0502 08:54:31.836471 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3918" for this suite. @ 05/02/24 08:54:31.845
• [2.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 05/02/24 08:54:31.86
  I0502 08:54:31.860612 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename statefulset @ 05/02/24 08:54:31.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:54:31.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:54:31.901
  STEP: Creating service test in namespace statefulset-5972 @ 05/02/24 08:54:31.903
  STEP: Creating a new StatefulSet @ 05/02/24 08:54:31.907
  I0502 08:54:31.922340 23 wait.go:40] Found 0 stateful pods, waiting for 3
  E0502 08:54:32.812303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:33.812469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:34.812805      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:35.813031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:36.813171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:37.814099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:38.814376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:39.815424      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:40.815570      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:41.815707      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:54:41.923365 23 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0502 08:54:41.923380 23 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0502 08:54:41.923386 23 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0502 08:54:41.929247 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5972 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 08:54:42.019447 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 08:54:42.019497 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 08:54:42.019518 23 statefulset.go:2184] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0502 08:54:42.816080      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:43.816585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:44.817325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:45.817426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:46.817919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:47.818149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:48.818862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:49.819273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:50.819968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:51.820163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/02/24 08:54:52.025
  I0502 08:54:52.043377 23 statefulset.go:2241] Updating stateful set ss2
  STEP: Creating a new revision @ 05/02/24 08:54:52.043
  E0502 08:54:52.820463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:53.820979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:54.821561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:55.822117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:56.822540      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:57.823229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:58.823375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:54:59.824240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:00.824402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:01.824521      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 05/02/24 08:55:02.049
  I0502 08:55:02.051983 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5972 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0502 08:55:02.134121 23 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0502 08:55:02.134146 23 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0502 08:55:02.134154 23 statefulset.go:2208] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0502 08:55:02.825032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:03.826075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:04.826168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:05.826313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:06.827046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:07.828042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:08.828182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:09.828624      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:10.828760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:11.828900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:12.829541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:13.829689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:14.829976      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:15.830133      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:16.830290      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:17.830449      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:18.830587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:19.830841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:20.831061      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:21.831182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:55:22.144027 23 wait.go:158] Waiting for StatefulSet statefulset-5972/ss2 to complete update
  E0502 08:55:22.831709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:23.831865      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:24.832124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:25.832267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:26.832406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:27.832563      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:28.833313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:29.833601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:30.833761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:31.833891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 05/02/24 08:55:32.146
  I0502 08:55:32.146407 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5972 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 08:55:32.252500 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 08:55:32.252523 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 08:55:32.252532 23 statefulset.go:2184] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0502 08:55:32.834238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:33.834419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:34.834676      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:35.834837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:36.835009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:37.835172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:38.835194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:39.835460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:40.835611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:41.835751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:55:42.278937 23 statefulset.go:2241] Updating stateful set ss2
  E0502 08:55:42.836511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:43.837082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:44.837303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:45.837430      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:46.837581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:47.837732      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:48.838057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:49.838179      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:50.838315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:51.838441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 05/02/24 08:55:52.284
  I0502 08:55:52.286789 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5972 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0502 08:55:52.365961 23 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0502 08:55:52.365984 23 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0502 08:55:52.365992 23 statefulset.go:2208] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0502 08:55:52.839429      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:53.839601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:54.839875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:55.840025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:56.841057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:57.841227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:58.841655      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:55:59.841790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:00.841944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:01.842071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:56:02.376771 23 statefulset.go:135] Deleting all statefulset in ns statefulset-5972
  I0502 08:56:02.378551 23 rest.go:150] Scaling statefulset ss2 to 0
  E0502 08:56:02.843085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:03.844083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:04.844332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:05.844466      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:06.844619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:07.844808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:08.845241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:09.845473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:10.846376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:11.846501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:56:12.389986 23 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0502 08:56:12.391827 23 rest.go:88] Deleting statefulset ss2
  I0502 08:56:12.400798 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5972" for this suite. @ 05/02/24 08:56:12.404
• [100.555 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 05/02/24 08:56:12.416
  I0502 08:56:12.416151 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 08:56:12.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:12.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:12.436
  STEP: Discovering how many secrets are in namespace by default @ 05/02/24 08:56:12.437
  E0502 08:56:12.847109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:13.848025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:14.849058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:15.849150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:16.850202      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/02/24 08:56:17.44
  E0502 08:56:17.850891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:18.851240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:19.851302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:20.852266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:21.852387      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/02/24 08:56:22.443
  STEP: Ensuring resource quota status is calculated @ 05/02/24 08:56:22.447
  E0502 08:56:22.853439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:23.853598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 05/02/24 08:56:24.451
  STEP: Ensuring resource quota status captures secret creation @ 05/02/24 08:56:24.462
  E0502 08:56:24.854279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:25.854386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 05/02/24 08:56:26.468
  STEP: Ensuring resource quota status released usage @ 05/02/24 08:56:26.473
  E0502 08:56:26.855068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:27.855235      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:56:28.476688 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7836" for this suite. @ 05/02/24 08:56:28.479
• [16.070 seconds]
------------------------------
SS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 05/02/24 08:56:28.486
  I0502 08:56:28.486231 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename prestop @ 05/02/24 08:56:28.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:28.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:28.501
  STEP: Creating server pod server in namespace prestop-8442 @ 05/02/24 08:56:28.503
  STEP: Waiting for pods to come up. @ 05/02/24 08:56:28.51
  E0502 08:56:28.855469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:29.855740      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:30.856735      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:31.857056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-8442 @ 05/02/24 08:56:32.522
  E0502 08:56:32.857769      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:33.857972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 05/02/24 08:56:34.534
  E0502 08:56:34.858428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:35.858568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:36.858719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:37.858827      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:38.859263      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:56:39.544834 23 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 05/02/24 08:56:39.544
  I0502 08:56:39.554014 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-8442" for this suite. @ 05/02/24 08:56:39.559
• [11.079 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 05/02/24 08:56:39.565
  I0502 08:56:39.565019 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:56:39.565
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:39.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:39.581
  STEP: Creating configMap with name projected-configmap-test-volume-map-d9d530e4-9f31-4f59-bc87-05907462d600 @ 05/02/24 08:56:39.583
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:56:39.586
  E0502 08:56:39.859342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:40.859596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:41.859795      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:42.859986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:56:43.605
  I0502 08:56:43.607297 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-configmaps-abdd9141-c87d-4509-ac38-4eed3ecd2dda container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:56:43.617
  I0502 08:56:43.630824 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1244" for this suite. @ 05/02/24 08:56:43.634
• [4.076 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:779
  STEP: Creating a kubernetes client @ 05/02/24 08:56:43.64
  I0502 08:56:43.640680 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 08:56:43.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:43.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:43.658
  I0502 08:56:43.662127 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6674" for this suite. @ 05/02/24 08:56:43.664
• [0.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:57
  STEP: Creating a kubernetes client @ 05/02/24 08:56:43.67
  I0502 08:56:43.670799 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename volumeattachment @ 05/02/24 08:56:43.671
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:43.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:43.691
  STEP: Create VolumeAttachment "va-e2e-wlxqb" on node "master-2" @ 05/02/24 08:56:43.696
  STEP: Get VolumeAttachment "va-e2e-wlxqb" on node "master-2" @ 05/02/24 08:56:43.699
  STEP: Patch VolumeAttachment "va-e2e-wlxqb" on node "master-2" @ 05/02/24 08:56:43.701
  STEP: List VolumeAttachments with "va-e2e-wlxqb=patched" label @ 05/02/24 08:56:43.705
  STEP: Delete VolumeAttachment "va-e2e-wlxqb" on node "master-2" @ 05/02/24 08:56:43.707
  STEP: Confirm deletion of VolumeAttachment "va-e2e-wlxqb" on node "master-2" @ 05/02/24 08:56:43.711
  STEP: Create VolumeAttachment "va-e2e-p9nh9" on node "master-2" @ 05/02/24 08:56:43.715
  STEP: Update the VolumeAttachment "va-e2e-p9nh9" on node "master-2" with label "va-e2e=updated" @ 05/02/24 08:56:43.718
  STEP: Create VolumeAttachment "va-e2e-qzts9" on node "mini-3" @ 05/02/24 08:56:43.725
  STEP: Update the VolumeAttachment "va-e2e-qzts9" on node "mini-3" with label "va-e2e=updated" @ 05/02/24 08:56:43.728
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 05/02/24 08:56:43.733
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 05/02/24 08:56:43.74
  I0502 08:56:43.742319 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-2555" for this suite. @ 05/02/24 08:56:43.744
• [0.081 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 05/02/24 08:56:43.751
  I0502 08:56:43.751471 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 08:56:43.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:43.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:43.769
  STEP: Creating a pod to test downward api env vars @ 05/02/24 08:56:43.771
  E0502 08:56:43.860100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:44.860321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:45.860749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:46.860877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:56:47.793
  I0502 08:56:47.795781 23 output.go:196] Trying to get logs from node mini-1 pod downward-api-153547b8-16b4-4585-aea6-ce8bef09289d container dapi-container: <nil>
  STEP: delete the pod @ 05/02/24 08:56:47.8
  I0502 08:56:47.811864 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8910" for this suite. @ 05/02/24 08:56:47.814
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 05/02/24 08:56:47.821
  I0502 08:56:47.821129 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename events @ 05/02/24 08:56:47.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:47.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:47.838
  STEP: creating a test event @ 05/02/24 08:56:47.841
  STEP: listing events in all namespaces @ 05/02/24 08:56:47.853
  E0502 08:56:47.861399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing events in test namespace @ 05/02/24 08:56:47.863
  STEP: listing events with field selection filtering on source @ 05/02/24 08:56:47.865
  STEP: listing events with field selection filtering on reportingController @ 05/02/24 08:56:47.867
  STEP: getting the test event @ 05/02/24 08:56:47.869
  STEP: patching the test event @ 05/02/24 08:56:47.87
  STEP: getting the test event @ 05/02/24 08:56:47.878
  STEP: updating the test event @ 05/02/24 08:56:47.88
  STEP: getting the test event @ 05/02/24 08:56:47.885
  STEP: deleting the test event @ 05/02/24 08:56:47.887
  STEP: listing events in all namespaces @ 05/02/24 08:56:47.892
  STEP: listing events in test namespace @ 05/02/24 08:56:47.904
  I0502 08:56:47.906721 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2701" for this suite. @ 05/02/24 08:56:47.91
• [0.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 05/02/24 08:56:47.921
  I0502 08:56:47.921602 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/02/24 08:56:47.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:47.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:47.94
  STEP: creating the policy @ 05/02/24 08:56:47.946
  STEP: waiting until the marker is denied @ 05/02/24 08:56:47.965
  E0502 08:56:48.862067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 05/02/24 08:56:49.018
  STEP: testing a non-replicated ReplicaSet not to be denied @ 05/02/24 08:56:49.087
  I0502 08:56:49.214555 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-796" for this suite. @ 05/02/24 08:56:49.244
• [1.356 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2240
  STEP: Creating a kubernetes client @ 05/02/24 08:56:49.277
  I0502 08:56:49.277383 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 08:56:49.277
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:49.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:49.326
  STEP: creating service in namespace services-1675 @ 05/02/24 08:56:49.329
  STEP: creating service affinity-nodeport-transition in namespace services-1675 @ 05/02/24 08:56:49.329
  STEP: creating replication controller affinity-nodeport-transition in namespace services-1675 @ 05/02/24 08:56:49.372
  I0502 08:56:49.385561      23 runners.go:198] Created replication controller with name: affinity-nodeport-transition, namespace: services-1675, replica count: 3
  E0502 08:56:49.862354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:50.862558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:51.862623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:56:52.436992      23 runners.go:198] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0502 08:56:52.482850 23 resource.go:361] Creating new exec pod
  E0502 08:56:52.863344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:53.863491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:54.863637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:56:55.505460 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1675 exec execpod-affinityh7hdl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I0502 08:56:55.596477 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  I0502 08:56:55.596504 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 08:56:55.596546 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1675 exec execpod-affinityh7hdl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.109.97.229 80'
  I0502 08:56:55.667118 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.109.97.229 80\nConnection to 10.109.97.229 80 port [tcp/http] succeeded!\n"
  I0502 08:56:55.667145 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 08:56:55.667189 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1675 exec execpod-affinityh7hdl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.31 30898'
  I0502 08:56:55.738794 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.31 30898\nConnection to 10.221.190.31 30898 port [tcp/*] succeeded!\n"
  I0502 08:56:55.738822 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 08:56:55.738869 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1675 exec execpod-affinityh7hdl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 30898'
  I0502 08:56:55.821112 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 30898\nConnection to 10.221.190.32 30898 port [tcp/*] succeeded!\n"
  I0502 08:56:55.821139 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 08:56:55.831104 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1675 exec execpod-affinityh7hdl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.221.190.31:30898/ ; done'
  E0502 08:56:55.864382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:56:55.937960 23 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n"
  I0502 08:56:55.937989 23 builder.go:147] stdout: "\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-9c4dx\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-9c4dx\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-9c4dx\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-twbdb\naffinity-nodeport-transition-9c4dx"
  I0502 08:56:55.938001 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938007 23 service.go:242] Received response from host: affinity-nodeport-transition-9c4dx
  I0502 08:56:55.938013 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938018 23 service.go:242] Received response from host: affinity-nodeport-transition-9c4dx
  I0502 08:56:55.938023 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938028 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938032 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938037 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:55.938042 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938050 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:55.938058 23 service.go:242] Received response from host: affinity-nodeport-transition-9c4dx
  I0502 08:56:55.938069 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938078 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938087 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938095 23 service.go:242] Received response from host: affinity-nodeport-transition-twbdb
  I0502 08:56:55.938107 23 service.go:242] Received response from host: affinity-nodeport-transition-9c4dx
  I0502 08:56:55.949527 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1675 exec execpod-affinityh7hdl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.221.190.31:30898/ ; done'
  I0502 08:56:56.055579 23 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30898/\n"
  I0502 08:56:56.055607 23 builder.go:147] stdout: "\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt\naffinity-nodeport-transition-md5nt"
  I0502 08:56:56.055617 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055623 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055630 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055634 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055643 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055647 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055652 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055656 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055662 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055670 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055680 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055690 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055699 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055710 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055719 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055731 23 service.go:242] Received response from host: affinity-nodeport-transition-md5nt
  I0502 08:56:56.055767 23 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-1675, will wait for the garbage collector to delete the pods @ 05/02/24 08:56:56.067
  I0502 08:56:56.125675 23 resources.go:139] Deleting ReplicationController affinity-nodeport-transition took: 4.904667ms
  I0502 08:56:56.226136 23 resources.go:163] Terminating ReplicationController affinity-nodeport-transition pods took: 100.455931ms
  E0502 08:56:56.865210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:57.865993      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:56:58.866035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:56:59.255506 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1675" for this suite. @ 05/02/24 08:56:59.258
• [9.989 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 05/02/24 08:56:59.265
  I0502 08:56:59.265924 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 08:56:59.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:56:59.28
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:56:59.282
  STEP: Creating a pod to test emptydir volume type on node default medium @ 05/02/24 08:56:59.284
  E0502 08:56:59.866608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:00.866736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:01.867059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:02.867181      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:57:03.302
  I0502 08:57:03.305177 23 output.go:196] Trying to get logs from node mini-1 pod pod-abdbe8e0-f292-4618-8e80-0ed1e8faa745 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 08:57:03.31
  I0502 08:57:03.324466 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9656" for this suite. @ 05/02/24 08:57:03.329
• [4.069 seconds]
------------------------------
S
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 05/02/24 08:57:03.335
  I0502 08:57:03.335045 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename runtimeclass @ 05/02/24 08:57:03.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:03.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:03.353
  STEP: Deleting RuntimeClass runtimeclass-3360-delete-me @ 05/02/24 08:57:03.358
  STEP: Waiting for the RuntimeClass to disappear @ 05/02/24 08:57:03.363
  I0502 08:57:03.369832 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3360" for this suite. @ 05/02/24 08:57:03.372
• [0.043 seconds]
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 05/02/24 08:57:03.377
  I0502 08:57:03.377919 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename watch @ 05/02/24 08:57:03.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:03.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:03.396
  STEP: creating a new configmap @ 05/02/24 08:57:03.399
  STEP: modifying the configmap once @ 05/02/24 08:57:03.402
  STEP: modifying the configmap a second time @ 05/02/24 08:57:03.409
  STEP: deleting the configmap @ 05/02/24 08:57:03.415
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 05/02/24 08:57:03.419
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 05/02/24 08:57:03.42
  I0502 08:57:03.420958 23 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5764  411bc11c-a2ff-4683-bd28-679f1c801420 26266 0 2024-05-02 08:57:03 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-02 08:57:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 08:57:03.421025 23 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5764  411bc11c-a2ff-4683-bd28-679f1c801420 26267 0 2024-05-02 08:57:03 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-02 08:57:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 08:57:03.421054 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5764" for this suite. @ 05/02/24 08:57:03.424
• [0.052 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 05/02/24 08:57:03.429
  I0502 08:57:03.429978 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename init-container @ 05/02/24 08:57:03.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:03.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:03.451
  STEP: creating the pod @ 05/02/24 08:57:03.453
  I0502 08:57:03.453559 23 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E0502 08:57:03.867467      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:04.868076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:05.868989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:06.869008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:07.781965 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5" for this suite. @ 05/02/24 08:57:07.785
• [4.361 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 05/02/24 08:57:07.791
  I0502 08:57:07.791130 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename daemonsets @ 05/02/24 08:57:07.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:07.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:07.804
  I0502 08:57:07.819985 23 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 05/02/24 08:57:07.824
  I0502 08:57:07.826475 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:57:07.826488 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 05/02/24 08:57:07.826
  I0502 08:57:07.852128 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:57:07.852150 23 fixtures.go:130] Node mini-3 is running 0 daemon pod, expected 1
  E0502 08:57:07.869342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:08.844743 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:57:08.844764 23 fixtures.go:130] Node mini-3 is running 0 daemon pod, expected 1
  E0502 08:57:08.869842      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:09.846179 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0502 08:57:09.846221 23 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 05/02/24 08:57:09.848
  I0502 08:57:09.861474 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0502 08:57:09.861491 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0502 08:57:09.870614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:10.860619 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:57:10.860640 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 05/02/24 08:57:10.86
  E0502 08:57:10.871465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:10.874985 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:57:10.874997 23 fixtures.go:130] Node mini-3 is running 0 daemon pod, expected 1
  E0502 08:57:11.872032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:11.874808 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:57:11.874825 23 fixtures.go:130] Node mini-3 is running 0 daemon pod, expected 1
  E0502 08:57:12.872116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:12.874197 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:57:12.874215 23 fixtures.go:130] Node mini-3 is running 0 daemon pod, expected 1
  E0502 08:57:13.872512      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:13.874511 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0502 08:57:13.874528 23 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/02/24 08:57:13.878
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3170, will wait for the garbage collector to delete the pods @ 05/02/24 08:57:13.878
  I0502 08:57:13.936089 23 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 4.489443ms
  I0502 08:57:14.036150 23 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.058079ms
  E0502 08:57:14.873498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:15.874116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:16.339226 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 08:57:16.339259 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0502 08:57:16.341359 23 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26466"},"items":null}

  I0502 08:57:16.343166 23 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26466"},"items":null}

  I0502 08:57:16.359870 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3170" for this suite. @ 05/02/24 08:57:16.363
• [8.580 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 05/02/24 08:57:16.371
  I0502 08:57:16.371395 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:57:16.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:16.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:16.39
  STEP: Creating configMap configmap-9518/configmap-test-cebad63a-9080-49d5-a493-c1893bd60a09 @ 05/02/24 08:57:16.392
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:57:16.396
  E0502 08:57:16.875173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:17.876060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:18.876842      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:19.877205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:57:20.415
  I0502 08:57:20.417950 23 output.go:196] Trying to get logs from node mini-1 pod pod-configmaps-a0a00b44-68ec-4d40-ba04-3617c62e01cf container env-test: <nil>
  STEP: delete the pod @ 05/02/24 08:57:20.422
  I0502 08:57:20.432863 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9518" for this suite. @ 05/02/24 08:57:20.435
• [4.070 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:841
  STEP: Creating a kubernetes client @ 05/02/24 08:57:20.441
  I0502 08:57:20.441576 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:57:20.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:20.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:20.458
  STEP: Setting up server cert @ 05/02/24 08:57:20.485
  E0502 08:57:20.878123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:57:20.945
  STEP: Deploying the webhook pod @ 05/02/24 08:57:20.951
  STEP: Wait for the deployment to be ready @ 05/02/24 08:57:20.961
  I0502 08:57:20.974901 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:57:21.878937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:22.879128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:57:22.987
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:57:23.003
  E0502 08:57:23.879514      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:24.003813 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 05/02/24 08:57:24.009
  I0502 08:57:24.057326 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9200" for this suite. @ 05/02/24 08:57:24.062
  STEP: Destroying namespace "webhook-markers-7037" for this suite. @ 05/02/24 08:57:24.071
• [3.641 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 05/02/24 08:57:24.082
  I0502 08:57:24.082614 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename containers @ 05/02/24 08:57:24.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:24.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:24.123
  STEP: Creating a pod to test override all @ 05/02/24 08:57:24.125
  E0502 08:57:24.880531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:25.880662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:26.880828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:27.880949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:57:28.145
  I0502 08:57:28.148010 23 output.go:196] Trying to get logs from node mini-2 pod client-containers-ba93b826-508d-4150-a177-4f25ef502520 container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:57:28.156
  I0502 08:57:28.169107 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9543" for this suite. @ 05/02/24 08:57:28.172
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 05/02/24 08:57:28.178
  I0502 08:57:28.178975 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/02/24 08:57:28.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:28.195
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:28.197
  I0502 08:57:28.199070 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 08:57:28.881034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:29.881325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:30.881694      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:57:31.245185 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-7283" for this suite. @ 05/02/24 08:57:31.248
• [3.076 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 05/02/24 08:57:31.254
  I0502 08:57:31.254966 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 08:57:31.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:31.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:31.272
  STEP: Creating configMap with name configmap-test-volume-map-25e5706b-2fdb-4be2-9269-5a03039eb4b7 @ 05/02/24 08:57:31.274
  STEP: Creating a pod to test consume configMaps @ 05/02/24 08:57:31.277
  E0502 08:57:31.882015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:32.882189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:33.883057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:34.883460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 08:57:35.296
  I0502 08:57:35.299102 23 output.go:196] Trying to get logs from node mini-1 pod pod-configmaps-aaef0e71-f18a-49c2-a7ab-ed318f6647ac container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 08:57:35.303
  I0502 08:57:35.320185 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5412" for this suite. @ 05/02/24 08:57:35.323
• [4.075 seconds]
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 05/02/24 08:57:35.33
  I0502 08:57:35.330161 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 08:57:35.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:57:35.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:57:35.348
  STEP: Creating secret with name s-test-opt-del-e99bfd7a-f52d-4dbd-8b3f-1b1c51616822 @ 05/02/24 08:57:35.353
  STEP: Creating secret with name s-test-opt-upd-f4ff8f43-8831-4aba-8a5a-227c88ce0438 @ 05/02/24 08:57:35.357
  STEP: Creating the pod @ 05/02/24 08:57:35.361
  E0502 08:57:35.884128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:36.885114      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:37.885889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:38.886243      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-e99bfd7a-f52d-4dbd-8b3f-1b1c51616822 @ 05/02/24 08:57:39.403
  STEP: Updating secret s-test-opt-upd-f4ff8f43-8831-4aba-8a5a-227c88ce0438 @ 05/02/24 08:57:39.408
  STEP: Creating secret with name s-test-opt-create-963a4af5-560f-4419-964a-01f387170497 @ 05/02/24 08:57:39.413
  STEP: waiting to observe update in volume @ 05/02/24 08:57:39.417
  E0502 08:57:39.886355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:40.887066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:41.887341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:42.887441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:43.887656      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:44.887975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:45.888878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:46.889046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:47.889271      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:48.889550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:49.889968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:50.890106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:51.890367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:52.890501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:53.891532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:54.891814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:55.892589      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:56.892720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:57.893456      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:58.893880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:57:59.894845      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:00.895036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:01.895824      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:02.895938      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:03.896089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:04.897072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:05.898044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:06.898191      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:07.898510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:08.898797      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:09.899085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:10.899214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:11.899741      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:12.899903      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:13.900590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:14.900853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:15.900958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:16.901090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:17.901156      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:18.901441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:19.902070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:20.902211      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:21.902427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:22.902575      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:23.902869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:24.903178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:25.903950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:26.904084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:27.904846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:28.905152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:29.905219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:30.905486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:31.905639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:32.905836      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:33.906737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:34.907132      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:35.907996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:36.908136      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:37.908928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:38.909201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:39.909821      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:40.909968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:41.909987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:42.910234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:43.911315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:44.911638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:45.911838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:46.912035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:47.912222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:48.912482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:58:49.627504 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7448" for this suite. @ 05/02/24 08:58:49.63
• [74.306 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 05/02/24 08:58:49.636
  I0502 08:58:49.636186 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 08:58:49.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:58:49.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:58:49.657
  STEP: Setting up server cert @ 05/02/24 08:58:49.684
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 08:58:49.893
  STEP: Deploying the webhook pod @ 05/02/24 08:58:49.9
  STEP: Wait for the deployment to be ready @ 05/02/24 08:58:49.911
  E0502 08:58:49.913218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:58:49.916422 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 08:58:50.913477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:51.913629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 08:58:51.924
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 08:58:51.935
  E0502 08:58:52.914367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 08:58:52.935597 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 05/02/24 08:58:52.94
  STEP: create a pod that should be updated by the webhook @ 05/02/24 08:58:52.951
  I0502 08:58:53.049781 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7190" for this suite. @ 05/02/24 08:58:53.055
  STEP: Destroying namespace "webhook-markers-4090" for this suite. @ 05/02/24 08:58:53.065
• [3.438 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3136
  STEP: Creating a kubernetes client @ 05/02/24 08:58:53.074
  I0502 08:58:53.074297 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 08:58:53.074
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:58:53.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:58:53.09
  STEP: fetching services @ 05/02/24 08:58:53.092
  I0502 08:58:53.097317 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9644" for this suite. @ 05/02/24 08:58:53.1
• [0.032 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 05/02/24 08:58:53.106
  I0502 08:58:53.106381 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename var-expansion @ 05/02/24 08:58:53.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 08:58:53.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 08:58:53.123
  STEP: creating the pod with failed condition @ 05/02/24 08:58:53.125
  E0502 08:58:53.914995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:54.915406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:55.916472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:56.917102      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:57.918002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:58.918395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:58:59.919104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:00.919276      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:01.919846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:02.920015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:03.920715      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:04.921004      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:05.921306      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:06.921450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:07.921850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:08.922376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:09.922863      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:10.922963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:11.924049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:12.924197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:13.924329      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:14.924623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:15.925661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:16.926100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:17.927068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:18.927317      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:19.928017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:20.929073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:21.930016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:22.930173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:23.930990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:24.931304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:25.932031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:26.932171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:27.932604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:28.932972      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:29.933031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:30.933176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:31.933216      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:32.933388      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:33.933503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:34.933799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:35.933962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:36.934103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:37.934352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:38.934405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:39.934776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:40.934918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:41.935234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:42.935396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:43.935792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:44.935982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:45.936955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:46.937133      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:47.937411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:48.938345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:49.939019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:50.939208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:51.939472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:52.939629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:53.939952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:54.940251      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:55.940395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:56.941144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:57.941842      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:58.942016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 08:59:59.942989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:00.943174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:01.944011      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:02.944175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:03.944920      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:04.945273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:05.945843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:06.945994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:07.946497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:08.946776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:09.946969      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:10.947144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:11.947343      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:12.947500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:13.947706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:14.948047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:15.948704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:16.948835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:17.949883      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:18.950168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:19.951137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:20.951323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:21.951839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:22.952006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:23.952152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:24.952434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:25.953042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:26.953204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:27.953602      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:28.953949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:29.954130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:30.954431      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:31.955327      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:32.955503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:33.956073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:34.956370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:35.956992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:36.957172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:37.957503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:38.957700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:39.958258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:40.958405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:41.958611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:42.958778      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:43.958985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:44.959411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:45.959905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:46.960071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:47.960542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:48.960814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:49.961556      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:50.961721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:51.962469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:52.962614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 05/02/24 09:00:53.133
  I0502 09:00:53.644316 23 pod_client.go:141] Successfully updated pod "var-expansion-20f1280d-9341-407a-b747-56af1610b83c"
  STEP: waiting for pod running @ 05/02/24 09:00:53.644
  E0502 09:00:53.963675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:54.964137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/02/24 09:00:55.652
  I0502 09:00:55.652951 23 delete.go:62] Deleting pod "var-expansion-20f1280d-9341-407a-b747-56af1610b83c" in namespace "var-expansion-3474"
  I0502 09:00:55.679541 23 delete.go:70] Wait up to 5m0s for pod "var-expansion-20f1280d-9341-407a-b747-56af1610b83c" to be fully deleted
  E0502 09:00:55.964279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:56.965043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:57.965992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:58.966350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:00:59.966952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:00.967049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:01.967522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:02.967697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:03.967904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:04.968212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:05.968735      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:06.968912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:07.969511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:08.969657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:09.970292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:10.970442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:11.970623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:12.970772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:13.971004      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:14.971313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:15.971536      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:16.971679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:17.971820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:18.972057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:19.972305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:20.972473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:21.972598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:22.972757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:23.973015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:24.973340      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:25.973851      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:26.974047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:27.741717 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3474" for this suite. @ 05/02/24 09:01:27.744
• [154.648 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 05/02/24 09:01:27.754
  I0502 09:01:27.754798 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sysctl @ 05/02/24 09:01:27.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:01:27.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:01:27.779
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 05/02/24 09:01:27.782
  STEP: Watching for error events or started pod @ 05/02/24 09:01:27.787
  E0502 09:01:27.974220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:28.974529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 05/02/24 09:01:29.792
  E0502 09:01:29.975427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:30.975533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 05/02/24 09:01:31.8
  STEP: Getting logs from the pod @ 05/02/24 09:01:31.8
  STEP: Checking that the sysctl is actually updated @ 05/02/24 09:01:31.811
  I0502 09:01:31.811683 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-184" for this suite. @ 05/02/24 09:01:31.814
• [4.066 seconds]
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 05/02/24 09:01:31.82
  I0502 09:01:31.820913 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/02/24 09:01:31.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:01:31.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:01:31.839
  STEP: creating a target pod @ 05/02/24 09:01:31.84
  E0502 09:01:31.976074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:32.976504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 05/02/24 09:01:33.858
  E0502 09:01:33.977065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:34.977362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:35.977870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:36.978007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 05/02/24 09:01:37.878
  I0502 09:01:37.878362 23 exec_util.go:55] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3885 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 09:01:37.878386 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 09:01:37.878687 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 09:01:37.878728 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-3885/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0502 09:01:37.926335 23 exec_util.go:106] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 05/02/24 09:01:37.931
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 05/02/24 09:01:37.934
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 05/02/24 09:01:37.943
  I0502 09:01:37.947448 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-3885" for this suite. @ 05/02/24 09:01:37.955
• [6.141 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 05/02/24 09:01:37.962
  I0502 09:01:37.962241 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename watch @ 05/02/24 09:01:37.962
  E0502 09:01:37.979010      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:01:37.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:01:37.981
  STEP: creating a watch on configmaps @ 05/02/24 09:01:37.983
  STEP: creating a new configmap @ 05/02/24 09:01:37.984
  STEP: modifying the configmap once @ 05/02/24 09:01:37.988
  STEP: closing the watch once it receives two notifications @ 05/02/24 09:01:37.993
  I0502 09:01:37.994008 23 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6424  d0811e48-c54c-4683-8c92-06aef249ee37 27705 0 2024-05-02 09:01:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-02 09:01:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 09:01:37.994078 23 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6424  d0811e48-c54c-4683-8c92-06aef249ee37 27706 0 2024-05-02 09:01:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-02 09:01:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 05/02/24 09:01:37.994
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 05/02/24 09:01:38
  STEP: deleting the configmap @ 05/02/24 09:01:38.001
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 05/02/24 09:01:38.005
  I0502 09:01:38.005865 23 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6424  d0811e48-c54c-4683-8c92-06aef249ee37 27707 0 2024-05-02 09:01:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-02 09:01:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 09:01:38.005933 23 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6424  d0811e48-c54c-4683-8c92-06aef249ee37 27708 0 2024-05-02 09:01:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-02 09:01:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 09:01:38.005963 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6424" for this suite. @ 05/02/24 09:01:38.008
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 05/02/24 09:01:38.015
  I0502 09:01:38.015236 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 09:01:38.015
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:01:38.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:01:38.031
  STEP: Creating pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511 @ 05/02/24 09:01:38.033
  E0502 09:01:38.979776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:39.980856      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/02/24 09:01:40.047
  I0502 09:01:40.049223 23 container_probe.go:1749] Initial restart count of pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 is 0
  I0502 09:01:40.051329 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:40.981296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:41.981421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:42.054605 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:42.981562      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:43.981861      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:44.058700 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:44.981957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:45.982145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:46.062739 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:46.982641      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:47.983026      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:48.066585 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:48.983719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:49.984028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:50.070185 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:50.984137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:51.984291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:52.073739 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:52.984637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:53.985448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:54.077764 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:54.985830      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:55.985952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:56.081384 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:56.985957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:57.986091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:01:58.085756 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:01:58.986864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:01:59.987304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:00.089893 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:00.987774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:01.987939      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:02.093283 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:02.987986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:03.988169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:04.096623 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:04.989022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:05.989150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:06.100720 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:06.989538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:07.989907      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:08.104104 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:08.990345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:09.990702      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:10.108599 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:10.991480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:11.991603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:12.112556 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:12.992470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:13.992588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:14.115876 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:14.992922      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:15.993105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:16.119546 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:16.993500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:17.993629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:18.123659 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:18.993685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:19.993962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:20.127480 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:20.994429      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:21.994619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:22.131196 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:22.995028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:23.995462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:24.135805 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:24.995963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:25.995975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:26.139148 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:26.996089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:27.996270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:28.142534 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:28.996638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:29.996954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:30.146510 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:30.997393      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:31.997685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:32.150216 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:32.998022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:33.998300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:34.153526 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:34.998437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:35.998650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:36.157164 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:36.999018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:37.999156      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:38.160878 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:38.999969      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:40.000341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:40.164963 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:41.000784      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:42.000934      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:42.168325 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:43.001177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:44.001287      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:44.172012 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:45.001863      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:46.002027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:46.175504 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:47.002311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:48.002454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:48.179082 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:49.003260      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:50.003903      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:50.182387 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:51.004121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:52.004305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:52.185715 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  E0502 09:02:53.004600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:54.004977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:02:54.189361 23 container_probe.go:1759] Get pod test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 in namespace container-probe-7511
  I0502 09:02:54.189394 23 container_probe.go:1763] Restart count of pod container-probe-7511/test-grpc-ebb9dd1b-c5f7-40e6-8759-308d26224b32 is now 1 (1m14.140141271s elapsed)
  STEP: deleting the pod @ 05/02/24 09:02:54.189
  I0502 09:02:54.201927 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7511" for this suite. @ 05/02/24 09:02:54.208
• [76.201 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 05/02/24 09:02:54.215
  I0502 09:02:54.215985 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:02:54.216
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:02:54.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:02:54.241
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 09:02:54.244
  E0502 09:02:55.005300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:56.006074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:57.006194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:02:58.006314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:02:58.262
  I0502 09:02:58.265432 23 output.go:196] Trying to get logs from node mini-1 pod downwardapi-volume-82da27b9-35ed-4a86-a6b7-06a1ee5c18ba container client-container: <nil>
  STEP: delete the pod @ 05/02/24 09:02:58.276
  I0502 09:02:58.289874 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4673" for this suite. @ 05/02/24 09:02:58.293
• [4.083 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 05/02/24 09:02:58.301
  I0502 09:02:58.301510 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 09:02:58.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:02:58.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:02:58.321
  STEP: Creating a ResourceQuota with terminating scope @ 05/02/24 09:02:58.323
  STEP: Ensuring ResourceQuota status is calculated @ 05/02/24 09:02:58.326
  E0502 09:02:59.006475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:00.006994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 05/02/24 09:03:00.33
  STEP: Ensuring ResourceQuota status is calculated @ 05/02/24 09:03:00.335
  E0502 09:03:01.007947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:02.008023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 05/02/24 09:03:02.338
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 05/02/24 09:03:02.35
  E0502 09:03:03.008605      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:04.008764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 05/02/24 09:03:04.354
  E0502 09:03:05.009062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:06.009213      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/02/24 09:03:06.357
  STEP: Ensuring resource quota status released the pod usage @ 05/02/24 09:03:06.368
  E0502 09:03:07.010046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:08.011111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 05/02/24 09:03:08.372
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 05/02/24 09:03:08.381
  E0502 09:03:09.011156      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:10.011392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 05/02/24 09:03:10.385
  E0502 09:03:11.011619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:12.011754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/02/24 09:03:12.387
  STEP: Ensuring resource quota status released the pod usage @ 05/02/24 09:03:12.399
  E0502 09:03:13.011812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:14.011952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:14.402591 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6569" for this suite. @ 05/02/24 09:03:14.405
• [16.111 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 05/02/24 09:03:14.412
  I0502 09:03:14.412625 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename field-validation @ 05/02/24 09:03:14.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:03:14.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:03:14.433
  I0502 09:03:14.435184 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 09:03:15.012220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:16.012387      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0502 09:03:16.974276      23 warnings.go:70] unknown field "alpha"
  W0502 09:03:16.974300      23 warnings.go:70] unknown field "beta"
  W0502 09:03:16.974303      23 warnings.go:70] unknown field "delta"
  W0502 09:03:16.974305      23 warnings.go:70] unknown field "epsilon"
  W0502 09:03:16.974321      23 warnings.go:70] unknown field "gamma"
  E0502 09:03:17.013339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:17.507746 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9475" for this suite. @ 05/02/24 09:03:17.511
• [3.104 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 05/02/24 09:03:17.516
  I0502 09:03:17.516877 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 09:03:17.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:03:17.531
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:03:17.533
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 09:03:17.535
  E0502 09:03:18.013598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:19.014118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:20.014891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:21.015059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:03:21.551
  I0502 09:03:21.554216 23 output.go:196] Trying to get logs from node mini-1 pod downwardapi-volume-d95021b5-c354-4ac2-a2e9-bee09eb54992 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 09:03:21.558
  I0502 09:03:21.569723 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8577" for this suite. @ 05/02/24 09:03:21.572
• [4.062 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 05/02/24 09:03:21.579
  I0502 09:03:21.579186 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename controllerrevisions @ 05/02/24 09:03:21.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:03:21.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:03:21.597
  STEP: Creating DaemonSet "e2e-72vkd-daemon-set" @ 05/02/24 09:03:21.612
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/02/24 09:03:21.617
  I0502 09:03:21.620134 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:21.620154 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:21.620192 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:21.621840 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-72vkd-daemon-set: 0
  I0502 09:03:21.621852 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:03:22.015164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:22.621682 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:22.621720 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:22.621732 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:22.624339 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-72vkd-daemon-set: 0
  I0502 09:03:22.624352 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:03:23.015791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:23.621473 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:23.621512 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:23.621524 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:23.624247 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-72vkd-daemon-set: 2
  I0502 09:03:23.624259 23 fixtures.go:130] Node mini-3 is running 0 daemon pod, expected 1
  E0502 09:03:24.016676      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:24.621690 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:24.621729 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:24.621754 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:03:24.624200 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-72vkd-daemon-set: 3
  I0502 09:03:24.624211 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset e2e-72vkd-daemon-set
  STEP: Confirm DaemonSet "e2e-72vkd-daemon-set" successfully created with "daemonset-name=e2e-72vkd-daemon-set" label @ 05/02/24 09:03:24.626
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-72vkd-daemon-set" @ 05/02/24 09:03:24.63
  I0502 09:03:24.632700 23 controller_revision.go:162] Located ControllerRevision: "e2e-72vkd-daemon-set-84b467dd5"
  STEP: Patching ControllerRevision "e2e-72vkd-daemon-set-84b467dd5" @ 05/02/24 09:03:24.634
  I0502 09:03:24.639854 23 controller_revision.go:173] e2e-72vkd-daemon-set-84b467dd5 has been patched
  STEP: Create a new ControllerRevision @ 05/02/24 09:03:24.639
  I0502 09:03:24.644877 23 controller_revision.go:191] Created ControllerRevision: e2e-72vkd-daemon-set-679cff7c59
  STEP: Confirm that there are two ControllerRevisions @ 05/02/24 09:03:24.644
  I0502 09:03:24.644935 23 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0502 09:03:24.647179 23 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-72vkd-daemon-set-84b467dd5" @ 05/02/24 09:03:24.647
  STEP: Confirm that there is only one ControllerRevision @ 05/02/24 09:03:24.654
  I0502 09:03:24.654179 23 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0502 09:03:24.656637 23 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-72vkd-daemon-set-679cff7c59" @ 05/02/24 09:03:24.658
  I0502 09:03:24.665811 23 controller_revision.go:220] e2e-72vkd-daemon-set-679cff7c59 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 05/02/24 09:03:24.665
  W0502 09:03:24.677362      23 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 05/02/24 09:03:24.677
  I0502 09:03:24.677430 23 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  E0502 09:03:25.016881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:25.677732 23 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0502 09:03:25.684604 23 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-72vkd-daemon-set-679cff7c59=updated" @ 05/02/24 09:03:25.684
  STEP: Confirm that there is only one ControllerRevision @ 05/02/24 09:03:25.696
  I0502 09:03:25.696057 23 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0502 09:03:25.700855 23 controller_revision.go:265] Found 1 ControllerRevisions
  I0502 09:03:25.704080 23 controller_revision.go:246] ControllerRevision "e2e-72vkd-daemon-set-6658777c8b" has revision 3
  STEP: Deleting DaemonSet "e2e-72vkd-daemon-set" @ 05/02/24 09:03:25.706
  STEP: deleting DaemonSet.extensions e2e-72vkd-daemon-set in namespace controllerrevisions-7909, will wait for the garbage collector to delete the pods @ 05/02/24 09:03:25.706
  I0502 09:03:25.766269 23 resources.go:139] Deleting DaemonSet.extensions e2e-72vkd-daemon-set took: 6.002836ms
  I0502 09:03:25.866720 23 resources.go:163] Terminating DaemonSet.extensions e2e-72vkd-daemon-set pods took: 100.447007ms
  E0502 09:03:26.017302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:27.017737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:28.018767      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:28.070154 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-72vkd-daemon-set: 0
  I0502 09:03:28.070196 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-72vkd-daemon-set
  I0502 09:03:28.072378 23 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28317"},"items":null}

  I0502 09:03:28.074460 23 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28317"},"items":null}

  I0502 09:03:28.083365 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-7909" for this suite. @ 05/02/24 09:03:28.085
• [6.512 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 05/02/24 09:03:28.091
  I0502 09:03:28.091629 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:03:28.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:03:28.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:03:28.113
  STEP: Creating secret with name secret-test-926cdf63-0530-4061-94b6-4dd12ba2ee6a @ 05/02/24 09:03:28.114
  STEP: Creating a pod to test consume secrets @ 05/02/24 09:03:28.118
  E0502 09:03:29.018802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:30.019080      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:31.019218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:32.019368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:03:32.135
  I0502 09:03:32.137869 23 output.go:196] Trying to get logs from node mini-1 pod pod-secrets-80fd6725-22c3-425a-8b87-d918f5f48138 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:03:32.141
  I0502 09:03:32.154241 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4065" for this suite. @ 05/02/24 09:03:32.158
• [4.073 seconds]
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 05/02/24 09:03:32.165
  I0502 09:03:32.165045 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-pred @ 05/02/24 09:03:32.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:03:32.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:03:32.183
  I0502 09:03:32.185287 23 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0502 09:03:32.192478 23 util.go:400] Waiting for terminating namespaces to be deleted...
  I0502 09:03:32.194770 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-1 before test
  I0502 09:03:32.202548 23 predicates.go:887] calico-node-74plz from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.202560 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 09:03:32.202579 23 predicates.go:887] kube-proxy-m56bg from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.202583 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 09:03:32.202602 23 predicates.go:887] helm-charts-fluent-bit-kxv24 from logging started at 2024-05-02 08:03:28 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.202606 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 09:03:32.202610 23 predicates.go:887] kps-prometheus-node-exporter-85b92 from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.202614 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 09:03:32.202619 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-qq8kg from sonobuoy started at 2024-05-02 08:09:23 +0000 UTC (2 container statuses recorded)
  I0502 09:03:32.202622 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 09:03:32.202626 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0502 09:03:32.202630 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-2 before test
  I0502 09:03:32.210490 23 predicates.go:887] calico-node-r29fd from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.210503 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 09:03:32.210523 23 predicates.go:887] kube-proxy-hmtzq from kube-system started at 2024-05-02 08:02:50 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.210528 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 09:03:32.210533 23 predicates.go:887] helm-charts-fluent-bit-hx6df from logging started at 2024-05-02 08:03:27 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.210539 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 09:03:32.210548 23 predicates.go:887] kps-prometheus-node-exporter-r49xh from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.210553 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 09:03:32.210558 23 predicates.go:887] sonobuoy from sonobuoy started at 2024-05-02 08:09:14 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.210562 23 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0502 09:03:32.210567 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-zq7p5 from sonobuoy started at 2024-05-02 08:09:23 +0000 UTC (2 container statuses recorded)
  I0502 09:03:32.210571 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 09:03:32.210575 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0502 09:03:32.210579 23 predicates.go:121] 
  Logging pods the apiserver thinks is on node mini-3 before test
  I0502 09:03:32.220677 23 predicates.go:887] calico-node-2k27s from kube-system started at 2024-05-02 08:02:51 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.220689 23 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0502 09:03:32.220708 23 predicates.go:887] kube-proxy-jxzqw from kube-system started at 2024-05-02 08:02:51 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.220712 23 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0502 09:03:32.220731 23 predicates.go:887] helm-charts-fluent-bit-hsj7q from logging started at 2024-05-02 08:03:28 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.220735 23 predicates.go:889] 	Container fluent-bit ready: true, restart count 0
  I0502 09:03:32.220739 23 predicates.go:887] kps-prometheus-node-exporter-mrb8g from monitoring started at 2024-05-02 08:04:31 +0000 UTC (1 container statuses recorded)
  I0502 09:03:32.220743 23 predicates.go:889] 	Container node-exporter ready: true, restart count 0
  I0502 09:03:32.220748 23 predicates.go:887] sonobuoy-e2e-job-746b2c2b96604533 from sonobuoy started at 2024-05-02 08:09:22 +0000 UTC (2 container statuses recorded)
  I0502 09:03:32.220752 23 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0502 09:03:32.220756 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 09:03:32.220760 23 predicates.go:887] sonobuoy-systemd-logs-daemon-set-da82723a9e834026-5zkb9 from sonobuoy started at 2024-05-02 08:09:22 +0000 UTC (2 container statuses recorded)
  I0502 09:03:32.220764 23 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0502 09:03:32.220768 23 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 05/02/24 09:03:32.22
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17cba08d624b8c2a], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 node(s) didn't match Pod's node affinity/selector, 3 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }. preemption: 0/6 nodes are available: 6 Preemption is not helpful for scheduling.] @ 05/02/24 09:03:32.249
  E0502 09:03:33.019597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:33.246421 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7098" for this suite. @ 05/02/24 09:03:33.249
• [1.093 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 05/02/24 09:03:33.258
  I0502 09:03:33.258452 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename dns @ 05/02/24 09:03:33.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:03:33.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:03:33.28
  STEP: Creating a test headless service @ 05/02/24 09:03:33.282
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3616.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3616.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 05/02/24 09:03:33.287
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3616.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3616.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 05/02/24 09:03:33.287
  STEP: creating a pod to probe DNS @ 05/02/24 09:03:33.287
  STEP: submitting the pod to kubernetes @ 05/02/24 09:03:33.287
  E0502 09:03:34.019939      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:35.020285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:36.021158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:37.021324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/02/24 09:03:37.313
  STEP: looking for the results for each expected name from probers @ 05/02/24 09:03:37.315
  I0502 09:03:37.325838 23 dns_common.go:527] DNS probes using dns-3616/dns-test-bd0dab5b-dbcf-4dc9-a2c0-9958a9d433d9 succeeded

  STEP: deleting the pod @ 05/02/24 09:03:37.325
  STEP: deleting the test headless service @ 05/02/24 09:03:37.339
  I0502 09:03:37.381552 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3616" for this suite. @ 05/02/24 09:03:37.397
• [4.163 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2203
  STEP: Creating a kubernetes client @ 05/02/24 09:03:37.421
  I0502 09:03:37.421737 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 09:03:37.422
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:03:37.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:03:37.474
  STEP: creating service in namespace services-5361 @ 05/02/24 09:03:37.479
  STEP: creating service affinity-clusterip-transition in namespace services-5361 @ 05/02/24 09:03:37.479
  STEP: creating replication controller affinity-clusterip-transition in namespace services-5361 @ 05/02/24 09:03:37.532
  I0502 09:03:37.569927      23 runners.go:198] Created replication controller with name: affinity-clusterip-transition, namespace: services-5361, replica count: 3
  E0502 09:03:38.021757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:39.021853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:40.022323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:40.620998      23 runners.go:198] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0502 09:03:40.626314 23 resource.go:361] Creating new exec pod
  E0502 09:03:41.022841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:42.023455      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:43.023813      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:43.641533 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-5361 exec execpod-affinitym6z7c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I0502 09:03:43.728388 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  I0502 09:03:43.728440 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:03:43.728523 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-5361 exec execpod-affinitym6z7c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.109.25.70 80'
  I0502 09:03:43.806811 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.109.25.70 80\nConnection to 10.109.25.70 80 port [tcp/http] succeeded!\n"
  I0502 09:03:43.806837 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:03:43.815024 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-5361 exec execpod-affinitym6z7c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.109.25.70:80/ ; done'
  I0502 09:03:43.919415 23 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n"
  I0502 09:03:43.919445 23 builder.go:147] stdout: "\naffinity-clusterip-transition-482ts\naffinity-clusterip-transition-cc6v8\naffinity-clusterip-transition-482ts\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-482ts\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cc6v8\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-482ts\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cc6v8\naffinity-clusterip-transition-cc6v8\naffinity-clusterip-transition-cc6v8\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t"
  I0502 09:03:43.919455 23 service.go:242] Received response from host: affinity-clusterip-transition-482ts
  I0502 09:03:43.919461 23 service.go:242] Received response from host: affinity-clusterip-transition-cc6v8
  I0502 09:03:43.919468 23 service.go:242] Received response from host: affinity-clusterip-transition-482ts
  I0502 09:03:43.919473 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:43.919478 23 service.go:242] Received response from host: affinity-clusterip-transition-482ts
  I0502 09:03:43.919483 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:43.919487 23 service.go:242] Received response from host: affinity-clusterip-transition-cc6v8
  I0502 09:03:43.919492 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:43.919498 23 service.go:242] Received response from host: affinity-clusterip-transition-482ts
  I0502 09:03:43.919503 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:43.919508 23 service.go:242] Received response from host: affinity-clusterip-transition-cc6v8
  I0502 09:03:43.919513 23 service.go:242] Received response from host: affinity-clusterip-transition-cc6v8
  I0502 09:03:43.919519 23 service.go:242] Received response from host: affinity-clusterip-transition-cc6v8
  I0502 09:03:43.919527 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:43.919533 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:43.919538 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:43.926952 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-5361 exec execpod-affinitym6z7c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.109.25.70:80/ ; done'
  E0502 09:03:44.023878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:44.034990 23 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.109.25.70:80/\n"
  I0502 09:03:44.035018 23 builder.go:147] stdout: "\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t\naffinity-clusterip-transition-cg29t"
  I0502 09:03:44.035028 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035035 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035043 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035048 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035053 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035058 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035063 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035068 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035073 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035078 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035083 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035087 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035092 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035097 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035102 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035107 23 service.go:242] Received response from host: affinity-clusterip-transition-cg29t
  I0502 09:03:44.035145 23 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-5361, will wait for the garbage collector to delete the pods @ 05/02/24 09:03:44.048
  I0502 09:03:44.106149 23 resources.go:139] Deleting ReplicationController affinity-clusterip-transition took: 4.740898ms
  I0502 09:03:44.207027 23 resources.go:163] Terminating ReplicationController affinity-clusterip-transition pods took: 100.874291ms
  E0502 09:03:45.024242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:46.024990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:47.025322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:47.239722 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5361" for this suite. @ 05/02/24 09:03:47.244
• [9.829 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 05/02/24 09:03:47.251
  I0502 09:03:47.251145 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/02/24 09:03:47.251
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:03:47.268
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:03:47.27
  I0502 09:03:47.272311 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 09:03:48.025697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:49.025864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:50.026017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:50.321623 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-3803" for this suite. @ 05/02/24 09:03:50.325
• [3.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 05/02/24 09:03:50.333
  I0502 09:03:50.333050 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 09:03:50.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:03:50.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:03:50.354
  STEP: Creating resourceQuota "e2e-rq-status-sqxcg" @ 05/02/24 09:03:50.359
  I0502 09:03:50.367361 23 resource_quota.go:1051] Resource quota "e2e-rq-status-sqxcg" reports spec: hard cpu limit of 500m
  I0502 09:03:50.367376 23 resource_quota.go:1053] Resource quota "e2e-rq-status-sqxcg" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-sqxcg" /status @ 05/02/24 09:03:50.367
  STEP: Confirm /status for "e2e-rq-status-sqxcg" resourceQuota via watch @ 05/02/24 09:03:50.372
  I0502 09:03:50.374010 23 resource_quota.go:1080] observed resourceQuota "e2e-rq-status-sqxcg" in namespace "resourcequota-2897" with hard status: v1.ResourceList(nil)
  I0502 09:03:50.374052 23 resource_quota.go:1083] Found resourceQuota "e2e-rq-status-sqxcg" in namespace "resourcequota-2897" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0502 09:03:50.374081 23 resource_quota.go:1090] ResourceQuota "e2e-rq-status-sqxcg" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 05/02/24 09:03:50.375
  I0502 09:03:50.381302 23 resource_quota.go:1101] Resource quota "e2e-rq-status-sqxcg" reports spec: hard cpu limit of 1
  I0502 09:03:50.381319 23 resource_quota.go:1102] Resource quota "e2e-rq-status-sqxcg" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-sqxcg" /status @ 05/02/24 09:03:50.381
  STEP: Confirm /status for "e2e-rq-status-sqxcg" resourceQuota via watch @ 05/02/24 09:03:50.386
  I0502 09:03:50.387963 23 resource_quota.go:1124] observed resourceQuota "e2e-rq-status-sqxcg" in namespace "resourcequota-2897" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0502 09:03:50.387983 23 resource_quota.go:1127] Found resourceQuota "e2e-rq-status-sqxcg" in namespace "resourcequota-2897" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0502 09:03:50.387993 23 resource_quota.go:1134] ResourceQuota "e2e-rq-status-sqxcg" /status was patched
  STEP: Get "e2e-rq-status-sqxcg" /status @ 05/02/24 09:03:50.388
  I0502 09:03:50.390170 23 resource_quota.go:1145] Resourcequota "e2e-rq-status-sqxcg" reports status: hard cpu of 1
  I0502 09:03:50.390187 23 resource_quota.go:1147] Resourcequota "e2e-rq-status-sqxcg" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-sqxcg" /status before checking Spec is unchanged @ 05/02/24 09:03:50.391
  I0502 09:03:50.396003 23 resource_quota.go:1167] Resourcequota "e2e-rq-status-sqxcg" reports status: hard cpu of 2
  I0502 09:03:50.396020 23 resource_quota.go:1169] Resourcequota "e2e-rq-status-sqxcg" reports status: hard memory of 2Gi
  I0502 09:03:50.396979 23 resource_quota.go:1181] Found resourceQuota "e2e-rq-status-sqxcg" in namespace "resourcequota-2897" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0502 09:03:50.398922 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb668), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb6b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb6e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:03:51.026541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:52.026877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:53.027005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:54.028118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:55.029077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:03:55.400507 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9f4a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9f4d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9f500), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:03:56.029137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:57.029286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:58.029437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:03:59.029772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:00.030016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:00.400910 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9f680), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9f6b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9f6e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:01.030565      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:02.030718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:03.030852      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:04.030945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:05.031256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:05.401383 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc7818), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc7890), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc7938), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:06.032078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:07.032194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:08.032360      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:09.032526      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:10.032750      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:10.400415 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddba10), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddba58), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddbaa0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:11.033278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:12.033439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:13.033553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:14.033672      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:15.033940      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:15.400395 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9f950), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9f980), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9f9b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:16.034022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:17.034147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:18.034347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:19.034504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:20.035368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:20.401388 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9fae8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9fb18), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004d9fb48), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:21.035945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:22.036030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:23.036190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:24.036342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:25.036639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:25.400235 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddbd88), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddbdd0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddbe30), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:26.036831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:27.037001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:28.037146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:29.037326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:30.037751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:30.400402 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510048), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510078), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045100a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:31.038042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:32.038171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:33.038322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:34.038433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:35.038766      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:35.400321 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972120), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972150), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039721c8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:36.038878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:37.039049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:38.039205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:39.039592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:40.040060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:40.400854 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000dda180), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000dda1e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000dda2d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:41.040502      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:42.040663      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:43.040786      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:44.040958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:45.041345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:45.400794 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000dda4e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000dda528), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000dda588), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:46.041437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:47.041574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:48.041738      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:49.042065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:50.042399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:50.401223 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045102b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045102e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510318), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:51.042814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:52.042942      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:53.043107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:54.043257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:55.043541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:04:55.401496 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510540), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510570), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045105b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:04:56.044087      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:57.044265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:58.044385      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:04:59.044607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:00.044930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:00.400620 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510768), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510798), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045107c8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:01.045272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:02.045392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:03.045545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:04.045654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:05.045957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:05.400360 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045109a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045109f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510a80), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:06.045996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:07.046978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:08.047086      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:09.047458      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:10.047763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:10.400242 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000dda978), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000dda9d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddaa20), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:11.047912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:12.048035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:13.048195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:14.048314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:15.048641      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:15.400240 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972660), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039726c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972720), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:16.048870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:17.048993      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:18.049147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:19.049463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:20.049779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:20.400201 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039728d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972918), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972960), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:21.049845      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:22.050006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:23.050141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:24.050295      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:25.050566      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:25.401977 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddad80), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddadb0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddae10), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:26.050583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:27.050736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:28.050895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:29.051082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:30.051466      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:30.401052 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb068), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb0b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb0e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:31.051700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:32.051881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:33.052039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:34.052195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:35.052477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:35.401050 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb2d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb320), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb368), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:36.052625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:37.052752      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:38.053070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:39.053529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:40.054066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:40.400817 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb5a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb5f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb668), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:41.054446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:42.054619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:43.055095      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:44.055291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:45.055554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:45.401283 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb8f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb950), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddb998), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:46.055882      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:47.056067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:48.056252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:49.056624      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:50.056963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:50.400429 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510ed0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510f00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510f48), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:51.057038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:52.057196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:53.057341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:54.057470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:55.058084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:05:55.401155 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972d68), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972db0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972df8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:05:56.058984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:57.059104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:58.059269      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:05:59.059350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:00.059713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:00.400015 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004511170), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045111a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045111d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:01.059722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:02.059853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:03.060013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:04.060168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:05.060472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:05.401359 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004511338), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004511368), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045113c8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:06.061019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:07.061166      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:08.061324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:09.061559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:10.061887      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:10.400383 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004511578), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045115a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004511620), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:11.062005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:12.062145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:13.063064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:14.063179      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:15.063455      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:15.400719 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045117d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004511800), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004511830), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:16.064427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:17.065297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:18.065407      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:19.065798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:20.066100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:20.400866 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddbd70), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddbdb8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ddbde8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:21.066519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:22.066614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:23.066767      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:24.066943      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:25.067005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:25.400592 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003973218), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003973290), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039732c0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:26.067255      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:27.068049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:28.068182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:29.068412      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:30.068749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:30.400195 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0039720a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972120), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003972150), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:31.069736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:32.070390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:33.070554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:34.070730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:35.071046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:35.400992 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045100d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510108), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510138), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:36.071613      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:37.071949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:38.072090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:39.072516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:40.072806      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:40.401060 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045102b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045102e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004510318), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:41.073812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:42.073928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:43.074032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:44.074188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:45.074529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:45.401264 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc61f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc6258), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc6288), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:46.074906      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:47.075055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:48.075245      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:49.075612      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:50.075860      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:50.400481 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc6558), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc65e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc6618), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:51.076151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:52.076262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:53.076371      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:54.076500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:55.076822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:06:55.400255 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc6930), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc69a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc69d8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:06:56.077625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:57.077725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:58.077853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:06:59.078122      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:00.078426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:00.401327 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc6c90), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc6d08), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc6d50), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:07:01.078939      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:02.079029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:03.079151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:04.079310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:05.079693      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:05.400350 23 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sqxcg" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sqxcg", GenerateName:"", Namespace:"resourcequota-2897", SelfLink:"", UID:"b276c6ea-14f2-400a-b3f0-7294fd81c051", ResourceVersion:"28651", Generation:0, CreationTimestamp:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sqxcg"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc7020), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc7068), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 2, 9, 3, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fc70e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0502 09:07:06.080029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:07.080974      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:08.081105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:09.081506      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:10.081822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:10.400038 23 resource_quota.go:1209] ResourceQuota "e2e-rq-status-sqxcg" Spec was unchanged and /status reset
  I0502 09:07:10.400139 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2897" for this suite. @ 05/02/24 09:07:10.403
• [200.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 05/02/24 09:07:10.413
  I0502 09:07:10.413462 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 09:07:10.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:07:10.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:07:10.434
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/02/24 09:07:10.435
  E0502 09:07:11.082627      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:12.082900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:13.083734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:14.083912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:07:14.452
  I0502 09:07:14.454732 23 output.go:196] Trying to get logs from node mini-2 pod pod-4654938e-c83b-4e96-82f3-04dc700baa77 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 09:07:14.465
  I0502 09:07:14.478686 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6800" for this suite. @ 05/02/24 09:07:14.481
• [4.073 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 05/02/24 09:07:14.486
  I0502 09:07:14.486855 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 09:07:14.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:07:14.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:07:14.502
  STEP: Creating configMap with name configmap-test-upd-2c38a1c6-c24b-482c-9395-6b2e451a8f90 @ 05/02/24 09:07:14.507
  STEP: Creating the pod @ 05/02/24 09:07:14.51
  E0502 09:07:15.084917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:16.085164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 05/02/24 09:07:16.529
  STEP: Waiting for pod with binary data @ 05/02/24 09:07:16.538
  I0502 09:07:16.542396 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1264" for this suite. @ 05/02/24 09:07:16.545
• [2.065 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 05/02/24 09:07:16.551
  I0502 09:07:16.551990 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 09:07:16.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:07:16.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:07:16.57
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/02/24 09:07:16.572
  E0502 09:07:17.086103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:18.086349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:19.087265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:20.087440      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:07:20.592
  I0502 09:07:20.595097 23 output.go:196] Trying to get logs from node mini-2 pod pod-51ac5bf4-2330-4e6f-b061-8f2ab81b772c container test-container: <nil>
  STEP: delete the pod @ 05/02/24 09:07:20.6
  I0502 09:07:20.613506 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7719" for this suite. @ 05/02/24 09:07:20.616
• [4.070 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:355
  STEP: Creating a kubernetes client @ 05/02/24 09:07:20.622
  I0502 09:07:20.622143 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 09:07:20.622
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:07:20.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:07:20.639
  STEP: creating a replication controller @ 05/02/24 09:07:20.64
  I0502 09:07:20.640976 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 create -f -'
  I0502 09:07:20.716744 23 builder.go:146] stderr: ""
  I0502 09:07:20.716766 23 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/02/24 09:07:20.716
  I0502 09:07:20.716813 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:07:20.756481 23 builder.go:146] stderr: ""
  I0502 09:07:20.756504 23 builder.go:147] stdout: "update-demo-nautilus-2x4r2 update-demo-nautilus-n28sm "
  I0502 09:07:20.756530 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-2x4r2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:07:20.793328 23 builder.go:146] stderr: ""
  I0502 09:07:20.793350 23 builder.go:147] stdout: ""
  I0502 09:07:20.793359 23 kubectl.go:2501] update-demo-nautilus-2x4r2 is created but not running
  E0502 09:07:21.087686      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:22.087801      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:23.087866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:24.088023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:25.089052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:25.793845 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:07:25.831627 23 builder.go:146] stderr: ""
  I0502 09:07:25.831651 23 builder.go:147] stdout: "update-demo-nautilus-2x4r2 update-demo-nautilus-n28sm "
  I0502 09:07:25.831679 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-2x4r2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:07:25.868325 23 builder.go:146] stderr: ""
  I0502 09:07:25.868347 23 builder.go:147] stdout: ""
  I0502 09:07:25.868354 23 kubectl.go:2501] update-demo-nautilus-2x4r2 is created but not running
  E0502 09:07:26.089726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:27.090094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:28.090219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:29.090450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:30.090688      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:30.868581 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:07:30.907621 23 builder.go:146] stderr: ""
  I0502 09:07:30.907669 23 builder.go:147] stdout: "update-demo-nautilus-2x4r2 update-demo-nautilus-n28sm "
  I0502 09:07:30.907706 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-2x4r2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:07:30.946678 23 builder.go:146] stderr: ""
  I0502 09:07:30.946701 23 builder.go:147] stdout: "true"
  I0502 09:07:30.946759 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-2x4r2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0502 09:07:30.982759 23 builder.go:146] stderr: ""
  I0502 09:07:30.982783 23 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0502 09:07:30.982791 23 kubectl.go:2392] validating pod update-demo-nautilus-2x4r2
  I0502 09:07:30.987144 23 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0502 09:07:30.987179 23 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0502 09:07:30.987188 23 kubectl.go:2519] update-demo-nautilus-2x4r2 is verified up and running
  I0502 09:07:30.987208 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-n28sm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:07:31.022537 23 builder.go:146] stderr: ""
  I0502 09:07:31.022561 23 builder.go:147] stdout: "true"
  I0502 09:07:31.022585 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-n28sm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0502 09:07:31.058252 23 builder.go:146] stderr: ""
  I0502 09:07:31.058282 23 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0502 09:07:31.058290 23 kubectl.go:2392] validating pod update-demo-nautilus-n28sm
  I0502 09:07:31.061915 23 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0502 09:07:31.061939 23 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0502 09:07:31.061947 23 kubectl.go:2519] update-demo-nautilus-n28sm is verified up and running
  STEP: scaling down the replication controller @ 05/02/24 09:07:31.061
  I0502 09:07:31.062773 23 kubectl.go:324] scanned /root for discovery docs: <nil>
  I0502 09:07:31.062795 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0502 09:07:31.091017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:32.091160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:32.110797 23 builder.go:146] stderr: ""
  I0502 09:07:32.110818 23 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/02/24 09:07:32.11
  I0502 09:07:32.110870 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:07:32.148486 23 builder.go:146] stderr: ""
  I0502 09:07:32.148536 23 builder.go:147] stdout: "update-demo-nautilus-2x4r2 update-demo-nautilus-n28sm "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 05/02/24 09:07:32.148
  E0502 09:07:33.091515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:34.091651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:35.091876      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:36.092040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:37.092160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:37.149362 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:07:37.189114 23 builder.go:146] stderr: ""
  I0502 09:07:37.189150 23 builder.go:147] stdout: "update-demo-nautilus-n28sm "
  I0502 09:07:37.189205 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-n28sm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:07:37.225325 23 builder.go:146] stderr: ""
  I0502 09:07:37.225352 23 builder.go:147] stdout: "true"
  I0502 09:07:37.225421 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-n28sm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0502 09:07:37.261924 23 builder.go:146] stderr: ""
  I0502 09:07:37.261946 23 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0502 09:07:37.261955 23 kubectl.go:2392] validating pod update-demo-nautilus-n28sm
  I0502 09:07:37.265279 23 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0502 09:07:37.265304 23 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0502 09:07:37.265314 23 kubectl.go:2519] update-demo-nautilus-n28sm is verified up and running
  STEP: scaling up the replication controller @ 05/02/24 09:07:37.265
  I0502 09:07:37.266080 23 kubectl.go:324] scanned /root for discovery docs: <nil>
  I0502 09:07:37.266101 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0502 09:07:38.093177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:38.320498 23 builder.go:146] stderr: ""
  I0502 09:07:38.320548 23 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/02/24 09:07:38.32
  I0502 09:07:38.320622 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:07:38.359983 23 builder.go:146] stderr: ""
  I0502 09:07:38.360005 23 builder.go:147] stdout: "update-demo-nautilus-mqgcs update-demo-nautilus-n28sm "
  I0502 09:07:38.360029 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-mqgcs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:07:38.395924 23 builder.go:146] stderr: ""
  I0502 09:07:38.395945 23 builder.go:147] stdout: ""
  I0502 09:07:38.395957 23 kubectl.go:2501] update-demo-nautilus-mqgcs is created but not running
  E0502 09:07:39.093805      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:40.094012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:41.094131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:42.094244      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:43.094373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:43.396843 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:07:43.436052 23 builder.go:146] stderr: ""
  I0502 09:07:43.436089 23 builder.go:147] stdout: "update-demo-nautilus-mqgcs update-demo-nautilus-n28sm "
  I0502 09:07:43.436129 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-mqgcs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:07:43.473921 23 builder.go:146] stderr: ""
  I0502 09:07:43.473945 23 builder.go:147] stdout: ""
  I0502 09:07:43.473953 23 kubectl.go:2501] update-demo-nautilus-mqgcs is created but not running
  E0502 09:07:44.094616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:45.094957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:46.095095      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:47.095246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:48.095393      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:48.474989 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:07:48.513319 23 builder.go:146] stderr: ""
  I0502 09:07:48.513343 23 builder.go:147] stdout: "update-demo-nautilus-mqgcs update-demo-nautilus-n28sm "
  I0502 09:07:48.513368 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-mqgcs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:07:48.549910 23 builder.go:146] stderr: ""
  I0502 09:07:48.549935 23 builder.go:147] stdout: "true"
  I0502 09:07:48.549959 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-mqgcs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0502 09:07:48.585905 23 builder.go:146] stderr: ""
  I0502 09:07:48.585927 23 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0502 09:07:48.585936 23 kubectl.go:2392] validating pod update-demo-nautilus-mqgcs
  I0502 09:07:48.589706 23 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0502 09:07:48.589731 23 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0502 09:07:48.589739 23 kubectl.go:2519] update-demo-nautilus-mqgcs is verified up and running
  I0502 09:07:48.589761 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-n28sm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:07:48.625385 23 builder.go:146] stderr: ""
  I0502 09:07:48.625410 23 builder.go:147] stdout: "true"
  I0502 09:07:48.625434 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods update-demo-nautilus-n28sm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0502 09:07:48.661650 23 builder.go:146] stderr: ""
  I0502 09:07:48.661673 23 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0502 09:07:48.661681 23 kubectl.go:2392] validating pod update-demo-nautilus-n28sm
  I0502 09:07:48.664752 23 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0502 09:07:48.664777 23 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0502 09:07:48.664784 23 kubectl.go:2519] update-demo-nautilus-n28sm is verified up and running
  STEP: using delete to clean up resources @ 05/02/24 09:07:48.664
  I0502 09:07:48.664822 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 delete --grace-period=0 --force -f -'
  I0502 09:07:48.708747 23 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0502 09:07:48.708772 23 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0502 09:07:48.708796 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get rc,svc -l name=update-demo --no-headers'
  I0502 09:07:48.750022 23 builder.go:146] stderr: "No resources found in kubectl-8525 namespace.\n"
  I0502 09:07:48.750055 23 builder.go:147] stdout: ""
  I0502 09:07:48.750094 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8525 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0502 09:07:48.790376 23 builder.go:146] stderr: ""
  I0502 09:07:48.790401 23 builder.go:147] stdout: ""
  I0502 09:07:48.790469 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8525" for this suite. @ 05/02/24 09:07:48.794
• [28.182 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:766
  STEP: Creating a kubernetes client @ 05/02/24 09:07:48.804
  I0502 09:07:48.804318 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 09:07:48.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:07:48.822
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:07:48.825
  STEP: Setting up server cert @ 05/02/24 09:07:48.844
  E0502 09:07:49.095816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 09:07:49.252
  STEP: Deploying the webhook pod @ 05/02/24 09:07:49.259
  STEP: Wait for the deployment to be ready @ 05/02/24 09:07:49.27
  I0502 09:07:49.284853 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 09:07:50.096719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:51.096869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 09:07:51.292
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 09:07:51.306
  E0502 09:07:52.097938      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:52.307322 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 05/02/24 09:07:52.312
  STEP: verifying the mutating webhook match conditions @ 05/02/24 09:07:52.317
  STEP: updating the mutating webhook match conditions @ 05/02/24 09:07:52.319
  STEP: verifying the mutating webhook match conditions @ 05/02/24 09:07:52.325
  I0502 09:07:52.371847 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1945" for this suite. @ 05/02/24 09:07:52.386
  STEP: Destroying namespace "webhook-markers-8574" for this suite. @ 05/02/24 09:07:52.402
• [3.610 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 05/02/24 09:07:52.414
  I0502 09:07:52.414546 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename namespaces @ 05/02/24 09:07:52.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:07:52.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:07:52.429
  STEP: Updating Namespace "namespaces-2774" @ 05/02/24 09:07:52.431
  I0502 09:07:52.437296 23 namespace.go:389] Namespace "namespaces-2774" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"1e8eb09b-6877-4925-80e2-315df5ad7200", "kubernetes.io/metadata.name":"namespaces-2774", "namespaces-2774":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0502 09:07:52.437333 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2774" for this suite. @ 05/02/24 09:07:52.44
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 05/02/24 09:07:52.447
  I0502 09:07:52.447253 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 09:07:52.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:07:52.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:07:52.478
  STEP: Setting up server cert @ 05/02/24 09:07:52.505
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 09:07:52.635
  STEP: Deploying the webhook pod @ 05/02/24 09:07:52.64
  STEP: Wait for the deployment to be ready @ 05/02/24 09:07:52.65
  I0502 09:07:52.662008 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 09:07:53.098437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:54.098598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 09:07:54.674
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 09:07:54.689
  E0502 09:07:55.099194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:07:55.689854 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/02/24 09:07:55.695
  E0502 09:07:56.099964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/02/24 09:07:56.734
  STEP: Creating a dummy validating-webhook-configuration object @ 05/02/24 09:07:56.744
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 05/02/24 09:07:56.751
  STEP: Creating a dummy mutating-webhook-configuration object @ 05/02/24 09:07:56.756
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 05/02/24 09:07:56.764
  I0502 09:07:56.836859 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9291" for this suite. @ 05/02/24 09:07:56.842
  STEP: Destroying namespace "webhook-markers-5620" for this suite. @ 05/02/24 09:07:56.849
• [4.409 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 05/02/24 09:07:56.856
  I0502 09:07:56.856024 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename taint-single-pod @ 05/02/24 09:07:56.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:07:56.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:07:56.872
  I0502 09:07:56.875234 23 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0502 09:07:57.100799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:58.100966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:07:59.101640      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:00.102028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:01.103029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:02.103185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:03.103563      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:04.103697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:05.104444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:06.105067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:07.105793      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:08.105933      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:09.106024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:10.106075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:11.106136      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:12.106292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:13.106952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:14.107109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:15.107839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:16.108298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:17.108315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:18.108617      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:19.109173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:20.109496      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:21.110302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:22.110458      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:23.111240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:24.111398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:25.111507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:26.111658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:27.112076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:28.112220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:29.113020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:30.114014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:31.114112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:32.115022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:33.115765      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:34.115900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:35.115961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:36.116503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:37.117423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:38.117557      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:39.118378      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:40.118657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:41.119566      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:42.119743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:43.120584      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:44.120760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:45.121608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:46.121779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:47.121880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:48.122057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:49.122597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:50.122826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:51.123022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:52.124094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:53.124232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:54.124390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:55.125050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:56.125644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:08:56.875571 23 util.go:400] Waiting for terminating namespaces to be deleted...
  I0502 09:08:56.878833 23 taints.go:150] Starting informer...
  STEP: Starting pod... @ 05/02/24 09:08:56.878
  I0502 09:08:57.093859 23 taints.go:300] Pod is running on mini-1. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/02/24 09:08:57.093
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/02/24 09:08:57.103
  STEP: Waiting short time to make sure Pod is queued for deletion @ 05/02/24 09:08:57.113
  I0502 09:08:57.113522 23 taints.go:319] Pod wasn't evicted. Proceeding
  I0502 09:08:57.113529 23 taints.go:326] Removing taint from Node
  E0502 09:08:57.126062      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/02/24 09:08:57.141
  STEP: Waiting some time to make sure that toleration time passed. @ 05/02/24 09:08:57.16
  E0502 09:08:58.126505      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:08:59.127397      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:00.127754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:01.127939      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:02.128128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:03.128318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:04.128484      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:05.128912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:06.129064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:07.130027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:08.130212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:09.130558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:10.130786      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:11.131057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:12.131248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:13.131974      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:14.132130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:15.132570      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:16.132764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:17.132939      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:18.133091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:19.133405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:20.133788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:21.133911      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:22.134043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:23.134193      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:24.134324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:25.134749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:26.134893      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:27.135935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:28.136092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:29.136973      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:30.137335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:31.137490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:32.137649      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:33.137803      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:34.137960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:35.138373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:36.138504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:37.138675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:38.138835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:39.139571      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:40.139919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:41.140053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:42.140220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:43.140371      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:44.140520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:45.140952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:46.141108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:47.141252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:48.141400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:49.141641      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:50.141977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:51.142120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:52.142308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:53.142469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:54.142595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:55.142959      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:56.143118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:57.143220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:58.143380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:09:59.143599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:00.143823      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:01.143995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:02.144152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:03.144299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:04.144483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:05.144652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:06.145697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:07.145802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:08.145955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:09.146348      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:10.146470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:11.146608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:12.146770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:10:12.160984 23 taints.go:335] Pod wasn't evicted. Test successful
  I0502 09:10:12.161100 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-402" for this suite. @ 05/02/24 09:10:12.165
• [135.319 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 05/02/24 09:10:12.175
  I0502 09:10:12.175587 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename endpointslice @ 05/02/24 09:10:12.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:10:12.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:10:12.201
  STEP: getting /apis @ 05/02/24 09:10:12.203
  STEP: getting /apis/discovery.k8s.io @ 05/02/24 09:10:12.205
  STEP: getting /apis/discovery.k8s.iov1 @ 05/02/24 09:10:12.206
  STEP: creating @ 05/02/24 09:10:12.207
  STEP: getting @ 05/02/24 09:10:12.222
  STEP: listing @ 05/02/24 09:10:12.224
  STEP: watching @ 05/02/24 09:10:12.226
  I0502 09:10:12.226343 23 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 05/02/24 09:10:12.227
  STEP: cluster-wide watching @ 05/02/24 09:10:12.23
  I0502 09:10:12.230245 23 endpointslice.go:459] starting watch
  STEP: patching @ 05/02/24 09:10:12.231
  STEP: updating @ 05/02/24 09:10:12.235
  I0502 09:10:12.242076 23 endpointslice.go:482] waiting for watch events with expected annotations
  I0502 09:10:12.242093 23 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 05/02/24 09:10:12.242
  STEP: deleting a collection @ 05/02/24 09:10:12.252
  I0502 09:10:12.264102 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9829" for this suite. @ 05/02/24 09:10:12.266
• [0.097 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 05/02/24 09:10:12.272
  I0502 09:10:12.272457 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replicaset @ 05/02/24 09:10:12.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:10:12.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:10:12.291
  STEP: Create a ReplicaSet @ 05/02/24 09:10:12.292
  STEP: Verify that the required pods have come up @ 05/02/24 09:10:12.297
  I0502 09:10:12.301255 23 resource.go:87] Pod name sample-pod: Found 0 pods out of 3
  E0502 09:10:13.147185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:14.147734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:15.148019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:16.148204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:17.148378      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:10:17.304508 23 resource.go:87] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 05/02/24 09:10:17.304
  I0502 09:10:17.306676 23 replica_set.go:583] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 05/02/24 09:10:17.306
  STEP: DeleteCollection of the ReplicaSets @ 05/02/24 09:10:17.31
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 05/02/24 09:10:17.316
  I0502 09:10:17.327366 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7088" for this suite. @ 05/02/24 09:10:17.332
• [5.088 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1497
  STEP: Creating a kubernetes client @ 05/02/24 09:10:17.36
  I0502 09:10:17.360224 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 09:10:17.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:10:17.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:10:17.392
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7743 @ 05/02/24 09:10:17.396
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/02/24 09:10:17.411
  STEP: creating service externalsvc in namespace services-7743 @ 05/02/24 09:10:17.411
  STEP: creating replication controller externalsvc in namespace services-7743 @ 05/02/24 09:10:17.433
  I0502 09:10:17.439714      23 runners.go:198] Created replication controller with name: externalsvc, namespace: services-7743, replica count: 2
  E0502 09:10:18.148713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:19.149499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:20.150261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:10:20.490834      23 runners.go:198] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 05/02/24 09:10:20.493
  I0502 09:10:20.523245 23 resource.go:361] Creating new exec pod
  E0502 09:10:21.151015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:22.151180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:23.151691      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:24.152023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:10:24.545915 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-7743 exec execpodr8l8c -- /bin/sh -x -c nslookup clusterip-service.services-7743.svc.cluster.local'
  I0502 09:10:24.646696 23 builder.go:146] stderr: "+ nslookup clusterip-service.services-7743.svc.cluster.local\n"
  I0502 09:10:24.646735 23 builder.go:147] stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-7743.svc.cluster.local\tcanonical name = externalsvc.services-7743.svc.cluster.local.\nName:\texternalsvc.services-7743.svc.cluster.local\nAddress: 10.107.32.29\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-7743, will wait for the garbage collector to delete the pods @ 05/02/24 09:10:24.646
  I0502 09:10:24.705172 23 resources.go:139] Deleting ReplicationController externalsvc took: 5.219446ms
  I0502 09:10:24.805220 23 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.046451ms
  E0502 09:10:25.152181      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:26.152839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:27.153860      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:10:27.732424 23 service.go:1506] Cleaning up the ClusterIP to ExternalName test service
  I0502 09:10:27.743473 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7743" for this suite. @ 05/02/24 09:10:27.75
• [10.395 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 05/02/24 09:10:27.755
  I0502 09:10:27.755826 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:10:27.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:10:27.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:10:27.783
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 09:10:27.785
  E0502 09:10:28.154573      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:29.155268      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:30.155755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:31.155931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:10:31.804
  I0502 09:10:31.806523 23 output.go:196] Trying to get logs from node mini-2 pod downwardapi-volume-16af6455-41c7-4d3d-aa86-7ba7aa31bad1 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 09:10:31.814
  I0502 09:10:31.825833 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1276" for this suite. @ 05/02/24 09:10:31.829
• [4.080 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 05/02/24 09:10:31.835
  I0502 09:10:31.835490 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 09:10:31.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:10:31.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:10:31.854
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/02/24 09:10:31.856
  E0502 09:10:32.156400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:33.156724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:34.156766      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:35.156916      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:10:35.88
  I0502 09:10:35.883005 23 output.go:196] Trying to get logs from node mini-1 pod pod-0dc50df1-a9d8-4b08-87c7-0008bbfd0d82 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 09:10:35.893
  I0502 09:10:35.906984 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9104" for this suite. @ 05/02/24 09:10:35.91
• [4.082 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 05/02/24 09:10:35.917
  I0502 09:10:35.917403 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename dns @ 05/02/24 09:10:35.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:10:35.931
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:10:35.934
  STEP: Creating a test headless service @ 05/02/24 09:10:35.936
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8946 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8946;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8946 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8946;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8946.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8946.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8946.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8946.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8946.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8946.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8946.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8946.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8946.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8946.svc;check="$$(dig +notcp +noall +answer +search 55.137.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.137.55_udp@PTR;check="$$(dig +tcp +noall +answer +search 55.137.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.137.55_tcp@PTR;sleep 1; done
   @ 05/02/24 09:10:35.958
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8946 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8946;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8946 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8946;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8946.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8946.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8946.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8946.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8946.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8946.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8946.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8946.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8946.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8946.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8946.svc;check="$$(dig +notcp +noall +answer +search 55.137.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.137.55_udp@PTR;check="$$(dig +tcp +noall +answer +search 55.137.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.137.55_tcp@PTR;sleep 1; done
   @ 05/02/24 09:10:35.958
  STEP: creating a pod to probe DNS @ 05/02/24 09:10:35.958
  STEP: submitting the pod to kubernetes @ 05/02/24 09:10:35.959
  E0502 09:10:36.156980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:37.157178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:38.157558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:39.158035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/02/24 09:10:39.986
  STEP: looking for the results for each expected name from probers @ 05/02/24 09:10:39.988
  I0502 09:10:39.992464 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:39.994678 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:39.996721 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:39.998811 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.000994 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.003025 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.005027 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.006944 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.016457 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.018373 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.020082 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.022010 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.023925 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.025952 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.028113 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.030004 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:40.037935 23 dns_common.go:489] Lookups using dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8946 wheezy_tcp@dns-test-service.dns-8946 wheezy_udp@dns-test-service.dns-8946.svc wheezy_tcp@dns-test-service.dns-8946.svc wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8946 jessie_tcp@dns-test-service.dns-8946 jessie_udp@dns-test-service.dns-8946.svc jessie_tcp@dns-test-service.dns-8946.svc jessie_udp@_http._tcp.dns-test-service.dns-8946.svc jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc]

  I0502 09:10:40.041527 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:10:40.044842 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:10:40.048113 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:10:40.158374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:41.158514      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:42.158685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:43.158978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:44.159288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:10:44.993008 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:44.995901 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:44.998559 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.001158 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.003518 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.006013 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.008589 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.011453 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.024266 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.026631 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.028842 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.031090 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.033402 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.035515 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.037912 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.040462 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:45.048761 23 dns_common.go:489] Lookups using dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8946 wheezy_tcp@dns-test-service.dns-8946 wheezy_udp@dns-test-service.dns-8946.svc wheezy_tcp@dns-test-service.dns-8946.svc wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8946 jessie_tcp@dns-test-service.dns-8946 jessie_udp@dns-test-service.dns-8946.svc jessie_tcp@dns-test-service.dns-8946.svc jessie_udp@_http._tcp.dns-test-service.dns-8946.svc jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc]

  I0502 09:10:45.052649 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:10:45.056466 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:10:45.060261 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:10:45.159594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:46.159748      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:47.159930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:48.160067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:49.160596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:10:49.993110 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:49.995567 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:49.997880 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.000054 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.002208 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.005565 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.008033 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.010413 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.020432 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.023135 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.025118 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.027241 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.029420 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.031417 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.033521 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.035425 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:50.043385 23 dns_common.go:489] Lookups using dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8946 wheezy_tcp@dns-test-service.dns-8946 wheezy_udp@dns-test-service.dns-8946.svc wheezy_tcp@dns-test-service.dns-8946.svc wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8946 jessie_tcp@dns-test-service.dns-8946 jessie_udp@dns-test-service.dns-8946.svc jessie_tcp@dns-test-service.dns-8946.svc jessie_udp@_http._tcp.dns-test-service.dns-8946.svc jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc]

  I0502 09:10:50.046821 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:10:50.049921 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:10:50.053153 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:10:50.161430      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:51.161561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:52.161706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:53.162201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:54.162783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:10:54.991781 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:54.994363 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:54.996683 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:54.998855 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.000989 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.003184 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.005219 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.007310 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.016935 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.018922 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.020787 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.022551 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.024273 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.026116 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.027893 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.029750 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:55.037201 23 dns_common.go:489] Lookups using dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8946 wheezy_tcp@dns-test-service.dns-8946 wheezy_udp@dns-test-service.dns-8946.svc wheezy_tcp@dns-test-service.dns-8946.svc wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8946 jessie_tcp@dns-test-service.dns-8946 jessie_udp@dns-test-service.dns-8946.svc jessie_tcp@dns-test-service.dns-8946.svc jessie_udp@_http._tcp.dns-test-service.dns-8946.svc jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc]

  I0502 09:10:55.040347 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:10:55.043324 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:10:55.046196 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:10:55.163427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:56.163605      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:57.163771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:58.163958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:10:59.164390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:10:59.992661 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:59.995118 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:59.997318 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:10:59.999408 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.001516 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.003811 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.005742 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.008076 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.020642 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.022925 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.025066 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.027078 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.029110 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.031051 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.032947 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.034827 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:00.043113 23 dns_common.go:489] Lookups using dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8946 wheezy_tcp@dns-test-service.dns-8946 wheezy_udp@dns-test-service.dns-8946.svc wheezy_tcp@dns-test-service.dns-8946.svc wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8946 jessie_tcp@dns-test-service.dns-8946 jessie_udp@dns-test-service.dns-8946.svc jessie_tcp@dns-test-service.dns-8946.svc jessie_udp@_http._tcp.dns-test-service.dns-8946.svc jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc]

  I0502 09:11:00.046517 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:11:00.050152 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:11:00.053438 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:11:00.164690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:01.165650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:02.165847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:03.165965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:04.166303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:04.992741 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:04.995242 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:04.997418 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:04.999419 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.001562 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.004056 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.006065 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.008267 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.019032 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.020831 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.022992 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.025136 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946 from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.027145 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.029332 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.031616 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.033676 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc from pod dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5: the server could not find the requested resource (get pods dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5)
  I0502 09:11:05.041095 23 dns_common.go:489] Lookups using dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8946 wheezy_tcp@dns-test-service.dns-8946 wheezy_udp@dns-test-service.dns-8946.svc wheezy_tcp@dns-test-service.dns-8946.svc wheezy_udp@_http._tcp.dns-test-service.dns-8946.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8946.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8946 jessie_tcp@dns-test-service.dns-8946 jessie_udp@dns-test-service.dns-8946.svc jessie_tcp@dns-test-service.dns-8946.svc jessie_udp@_http._tcp.dns-test-service.dns-8946.svc jessie_tcp@_http._tcp.dns-test-service.dns-8946.svc]

  I0502 09:11:05.044391 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:11:05.047829 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:11:05.050920 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:11:05.167170      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:06.167277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:07.167452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:08.167581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:09.168081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:10.043611 23 dns_common.go:527] DNS probes using dns-8946/dns-test-c8f4a7ed-19e8-4c07-b8a1-158e49d2ced5 succeeded

  STEP: deleting the pod @ 05/02/24 09:11:10.043
  STEP: deleting the test service @ 05/02/24 09:11:10.057
  STEP: deleting the test headless service @ 05/02/24 09:11:10.091
  I0502 09:11:10.106571 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8946" for this suite. @ 05/02/24 09:11:10.113
• [34.208 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 05/02/24 09:11:10.125
  I0502 09:11:10.125808 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename svcaccounts @ 05/02/24 09:11:10.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:11:10.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:11:10.149
  I0502 09:11:10.153617 23 service_accounts.go:754] Got root ca configmap in namespace "svcaccounts-7879"
  I0502 09:11:10.157338 23 service_accounts.go:757] Deleted root ca configmap in namespace "svcaccounts-7879"
  E0502 09:11:10.168489      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 05/02/24 09:11:10.658
  I0502 09:11:10.661117 23 service_accounts.go:771] Recreated root ca configmap in namespace "svcaccounts-7879"
  I0502 09:11:10.665736 23 service_accounts.go:782] Updated root ca configmap in namespace "svcaccounts-7879"
  STEP: waiting for the root ca configmap reconciled @ 05/02/24 09:11:11.166
  E0502 09:11:11.168727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:11.169388 23 service_accounts.go:800] Reconciled root ca configmap in namespace "svcaccounts-7879"
  I0502 09:11:11.169455 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7879" for this suite. @ 05/02/24 09:11:11.172
• [1.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 05/02/24 09:11:11.179
  I0502 09:11:11.179648 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename dns @ 05/02/24 09:11:11.18
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:11:11.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:11:11.2
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/02/24 09:11:11.202
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/02/24 09:11:11.202
  STEP: creating a pod to probe DNS @ 05/02/24 09:11:11.202
  STEP: submitting the pod to kubernetes @ 05/02/24 09:11:11.202
  E0502 09:11:12.169021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:13.169263      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:14.169800      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:15.169986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/02/24 09:11:15.22
  STEP: looking for the results for each expected name from probers @ 05/02/24 09:11:15.224
  I0502 09:11:15.237328 23 dns_common.go:527] DNS probes using dns-6018/dns-test-61c87906-971e-4dd6-8109-689e4c1d4034 succeeded

  STEP: deleting the pod @ 05/02/24 09:11:15.237
  I0502 09:11:15.257022 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6018" for this suite. @ 05/02/24 09:11:15.263
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 05/02/24 09:11:15.269
  I0502 09:11:15.269609 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 09:11:15.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:11:15.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:11:15.289
  STEP: Creating pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050 @ 05/02/24 09:11:15.291
  E0502 09:11:16.169994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:17.170477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/02/24 09:11:17.308
  I0502 09:11:17.310450 23 container_probe.go:1749] Initial restart count of pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 is 0
  I0502 09:11:17.313105 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:18.171019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:19.171685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:19.317052 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:20.171880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:21.172023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:21.320096 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:22.173036      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:23.173125      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:23.323356 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:24.173457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:25.173621      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:25.327253 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:26.174071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:27.174227      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:27.330458 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:28.174326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:29.174740      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:29.334714 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:30.175547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:31.175681      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:31.337956 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:32.175833      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:33.175982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:33.341456 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:34.176590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:35.176753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:35.345282 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  E0502 09:11:36.177100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:37.177277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:37.348168 23 container_probe.go:1759] Get pod liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 in namespace container-probe-8050
  I0502 09:11:37.348200 23 container_probe.go:1763] Restart count of pod container-probe-8050/liveness-7be4d9b1-f4c8-411a-a1b2-71a63f4a0563 is now 1 (20.037734068s elapsed)
  STEP: deleting the pod @ 05/02/24 09:11:37.348
  I0502 09:11:37.359677 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8050" for this suite. @ 05/02/24 09:11:37.363
• [22.101 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 05/02/24 09:11:37.37
  I0502 09:11:37.370878 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename gc @ 05/02/24 09:11:37.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:11:37.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:11:37.388
  STEP: create the rc @ 05/02/24 09:11:37.393
  W0502 09:11:37.397515      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0502 09:11:38.177356      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:39.177610      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:40.177985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:41.179028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/02/24 09:11:41.403
  STEP: wait for the rc to be deleted @ 05/02/24 09:11:41.413
  E0502 09:11:42.179736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:42.426578 23 garbage_collector.go:670] 80 pods remaining
  I0502 09:11:42.426598 23 garbage_collector.go:677] 80 pods has nil DeletionTimestamp
  I0502 09:11:42.426604 23 garbage_collector.go:678] 
  E0502 09:11:43.180672      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:43.425011 23 garbage_collector.go:670] 71 pods remaining
  I0502 09:11:43.425033 23 garbage_collector.go:677] 71 pods has nil DeletionTimestamp
  I0502 09:11:43.425038 23 garbage_collector.go:678] 
  E0502 09:11:44.181094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:44.423578 23 garbage_collector.go:670] 60 pods remaining
  I0502 09:11:44.423599 23 garbage_collector.go:677] 60 pods has nil DeletionTimestamp
  I0502 09:11:44.423604 23 garbage_collector.go:678] 
  E0502 09:11:45.181766      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:45.423419 23 garbage_collector.go:670] 40 pods remaining
  I0502 09:11:45.423440 23 garbage_collector.go:677] 40 pods has nil DeletionTimestamp
  I0502 09:11:45.423446 23 garbage_collector.go:678] 
  E0502 09:11:46.181839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:46.422126 23 garbage_collector.go:670] 31 pods remaining
  I0502 09:11:46.422145 23 garbage_collector.go:677] 31 pods has nil DeletionTimestamp
  I0502 09:11:46.422151 23 garbage_collector.go:678] 
  E0502 09:11:47.182561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:47.424182 23 garbage_collector.go:670] 20 pods remaining
  I0502 09:11:47.424202 23 garbage_collector.go:677] 20 pods has nil DeletionTimestamp
  I0502 09:11:47.424208 23 garbage_collector.go:678] 
  E0502 09:11:48.182783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/02/24 09:11:48.419
  I0502 09:11:48.497431 23 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0502 09:11:48.497521 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5711" for this suite. @ 05/02/24 09:11:48.501
• [11.136 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 05/02/24 09:11:48.507
  I0502 09:11:48.507427 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-webhook @ 05/02/24 09:11:48.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:11:48.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:11:48.531
  STEP: Setting up server cert @ 05/02/24 09:11:48.533
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/02/24 09:11:48.752
  STEP: Deploying the custom resource conversion webhook pod @ 05/02/24 09:11:48.762
  STEP: Wait for the deployment to be ready @ 05/02/24 09:11:48.784
  I0502 09:11:48.797253 23 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0502 09:11:49.182838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:50.182957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:50.806460 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-6c44f5d846\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 09:11:51.183950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:52.184078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:53.129433 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-6c44f5d846\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 09:11:53.184491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:54.185161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:54.822151 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-6c44f5d846\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 09:11:55.185480      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:56.186072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:56.966686 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 11, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-6c44f5d846\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 09:11:57.186966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:11:58.187116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 09:11:58.809
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 09:11:58.82
  E0502 09:11:59.187991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:11:59.820720 23 util.go:427] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0502 09:11:59.825775 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 09:12:00.188311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:01.188894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:02.188960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/02/24 09:12:02.373
  STEP: Create a v2 custom resource @ 05/02/24 09:12:02.394
  STEP: List CRs in v1 @ 05/02/24 09:12:02.421
  STEP: List CRs in v2 @ 05/02/24 09:12:02.424
  I0502 09:12:03.001807 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-4624" for this suite. @ 05/02/24 09:12:03.008
• [14.514 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 05/02/24 09:12:03.021
  I0502 09:12:03.021566 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-runtime @ 05/02/24 09:12:03.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:03.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:03.044
  STEP: create the container @ 05/02/24 09:12:03.045
  W0502 09:12:03.053176      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 05/02/24 09:12:03.053
  E0502 09:12:03.189065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:04.189568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:05.190175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:06.190935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/02/24 09:12:07.073
  STEP: the container should be terminated @ 05/02/24 09:12:07.076
  STEP: the termination message should be set @ 05/02/24 09:12:07.076
  I0502 09:12:07.076799 23 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/02/24 09:12:07.076
  I0502 09:12:07.091207 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7431" for this suite. @ 05/02/24 09:12:07.093
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:489
  STEP: Creating a kubernetes client @ 05/02/24 09:12:07.102
  I0502 09:12:07.102223 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename security-context-test @ 05/02/24 09:12:07.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:07.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:07.12
  E0502 09:12:07.191517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:08.191654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:09.191981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:10.192164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:12:11.139293 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4622" for this suite. @ 05/02/24 09:12:11.142
• [4.046 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 05/02/24 09:12:11.148
  I0502 09:12:11.148737 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/02/24 09:12:11.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:11.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:11.166
  STEP: Creating two CSIDrivers @ 05/02/24 09:12:11.168
  STEP: Getting "inline-driver-167cae71-ab71-4d22-af10-10aea05a237c" & "inline-driver-1d1b4deb-d255-49c6-9aae-b48172a47ea3" @ 05/02/24 09:12:11.18
  STEP: Patching the CSIDriver "inline-driver-1d1b4deb-d255-49c6-9aae-b48172a47ea3" @ 05/02/24 09:12:11.183
  STEP: Updating the CSIDriver "inline-driver-1d1b4deb-d255-49c6-9aae-b48172a47ea3" @ 05/02/24 09:12:11.191
  E0502 09:12:11.192595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-5131" @ 05/02/24 09:12:11.197
  STEP: Deleting CSIDriver "inline-driver-167cae71-ab71-4d22-af10-10aea05a237c" @ 05/02/24 09:12:11.2
  STEP: Confirm deletion of CSIDriver "inline-driver-167cae71-ab71-4d22-af10-10aea05a237c" @ 05/02/24 09:12:11.203
  STEP: Deleting CSIDriver "inline-driver-1d1b4deb-d255-49c6-9aae-b48172a47ea3" via DeleteCollection @ 05/02/24 09:12:11.205
  STEP: Confirm deletion of CSIDriver "inline-driver-1d1b4deb-d255-49c6-9aae-b48172a47ea3" @ 05/02/24 09:12:11.21
  I0502 09:12:11.212883 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5131" for this suite. @ 05/02/24 09:12:11.215
• [0.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 05/02/24 09:12:11.22
  I0502 09:12:11.220983 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename apf @ 05/02/24 09:12:11.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:11.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:11.24
  STEP: getting /apis @ 05/02/24 09:12:11.241
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/02/24 09:12:11.244
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/02/24 09:12:11.244
  STEP: creating @ 05/02/24 09:12:11.245
  STEP: getting @ 05/02/24 09:12:11.26
  STEP: listing @ 05/02/24 09:12:11.264
  STEP: watching @ 05/02/24 09:12:11.269
  I0502 09:12:11.270000 23 flowcontrol.go:394] starting watch
  STEP: patching @ 05/02/24 09:12:11.27
  STEP: updating @ 05/02/24 09:12:11.275
  I0502 09:12:11.280175 23 flowcontrol.go:422] waiting for watch events with expected annotations
  STEP: getting /status @ 05/02/24 09:12:11.28
  STEP: patching /status @ 05/02/24 09:12:11.282
  STEP: updating /status @ 05/02/24 09:12:11.286
  STEP: deleting @ 05/02/24 09:12:11.314
  STEP: deleting a collection @ 05/02/24 09:12:11.323
  I0502 09:12:11.341614 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-4951" for this suite. @ 05/02/24 09:12:11.344
• [0.132 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 05/02/24 09:12:11.353
  I0502 09:12:11.353132 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename field-validation @ 05/02/24 09:12:11.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:11.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:11.372
  STEP: apply creating a deployment @ 05/02/24 09:12:11.374
  I0502 09:12:11.383063 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8145" for this suite. @ 05/02/24 09:12:11.385
• [0.039 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 05/02/24 09:12:11.391
  I0502 09:12:11.391775 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/02/24 09:12:11.392
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:11.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:11.411
  I0502 09:12:11.412954 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 09:12:12.193577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:13.193833      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:14.194027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:12:14.594937 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7435" for this suite. @ 05/02/24 09:12:14.598
• [3.213 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 05/02/24 09:12:14.605
  I0502 09:12:14.605096 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename runtimeclass @ 05/02/24 09:12:14.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:14.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:14.622
  E0502 09:12:15.194083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:16.195057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:12:16.647431 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-228" for this suite. @ 05/02/24 09:12:16.651
• [2.058 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 05/02/24 09:12:16.663
  I0502 09:12:16.663581 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename svcaccounts @ 05/02/24 09:12:16.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:16.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:16.694
  STEP: Creating ServiceAccount "e2e-sa-zb6v6"  @ 05/02/24 09:12:16.696
  I0502 09:12:16.702626 23 service_accounts.go:825] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-zb6v6"  @ 05/02/24 09:12:16.702
  I0502 09:12:16.712947 23 service_accounts.go:839] AutomountServiceAccountToken: true
  I0502 09:12:16.712996 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8404" for this suite. @ 05/02/24 09:12:16.719
• [0.064 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 05/02/24 09:12:16.727
  I0502 09:12:16.727845 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename disruption @ 05/02/24 09:12:16.728
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:16.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:16.759
  STEP: Waiting for the pdb to be processed @ 05/02/24 09:12:16.769
  E0502 09:12:17.196019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:18.197039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 05/02/24 09:12:18.798
  I0502 09:12:18.811779 23 disruption.go:578] running pods: 0 < 3
  E0502 09:12:19.197478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:20.197602      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:12:20.802039 23 disruption.go:578] running pods: 1 < 3
  E0502 09:12:21.198507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:22.199059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:12:22.804851 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-457" for this suite. @ 05/02/24 09:12:22.807
• [6.086 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 05/02/24 09:12:22.814
  I0502 09:12:22.814397 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 09:12:22.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:22.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:22.832
  STEP: Creating configMap with name configmap-test-volume-cbada7ed-0af6-478a-bdb4-8a4828e51f18 @ 05/02/24 09:12:22.834
  STEP: Creating a pod to test consume configMaps @ 05/02/24 09:12:22.838
  E0502 09:12:23.199855      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:24.200238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:25.201130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:26.201294      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:12:26.856
  I0502 09:12:26.859234 23 output.go:196] Trying to get logs from node mini-1 pod pod-configmaps-77eeacf0-37df-4d34-aefd-a7cf9687e380 container configmap-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:12:26.863
  I0502 09:12:26.875667 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1406" for this suite. @ 05/02/24 09:12:26.879
• [4.071 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 05/02/24 09:12:26.885
  I0502 09:12:26.885262 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:12:26.885
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:26.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:26.905
  STEP: Creating configMap with name projected-configmap-test-volume-5d4117a6-a060-4c6f-9743-42806f6898ab @ 05/02/24 09:12:26.908
  STEP: Creating a pod to test consume configMaps @ 05/02/24 09:12:26.911
  E0502 09:12:27.201370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:28.201549      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:29.202527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:30.202685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:12:30.93
  I0502 09:12:30.932651 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-configmaps-e3107261-c317-443d-87da-fdf260d7c21d container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 09:12:30.936
  I0502 09:12:30.947807 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4009" for this suite. @ 05/02/24 09:12:30.951
• [4.073 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 05/02/24 09:12:30.958
  I0502 09:12:30.958220 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename field-validation @ 05/02/24 09:12:30.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:30.974
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:30.976
  I0502 09:12:30.978718 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  W0502 09:12:30.979096      23 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc004dd2070 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0502 09:12:31.203527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:32.203760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:33.203909      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0502 09:12:33.514364      23 warnings.go:70] unknown field "alpha"
  W0502 09:12:33.514386      23 warnings.go:70] unknown field "beta"
  W0502 09:12:33.514389      23 warnings.go:70] unknown field "delta"
  W0502 09:12:33.514405      23 warnings.go:70] unknown field "epsilon"
  W0502 09:12:33.514408      23 warnings.go:70] unknown field "gamma"
  I0502 09:12:34.046040 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-227" for this suite. @ 05/02/24 09:12:34.049
• [3.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 05/02/24 09:12:34.056
  I0502 09:12:34.056055 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename cronjob @ 05/02/24 09:12:34.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:12:34.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:12:34.077
  STEP: Creating a ReplaceConcurrent cronjob @ 05/02/24 09:12:34.08
  STEP: Ensuring a job is scheduled @ 05/02/24 09:12:34.083
  E0502 09:12:34.204235      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:35.204589      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:36.205008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:37.205160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:38.205405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:39.206053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:40.206347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:41.206463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:42.206582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:43.206756      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:44.207369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:45.207529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:46.208499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:47.208606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:48.208964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:49.209050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:50.210034      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:51.210215      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:52.210550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:53.210866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:54.211371      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:55.211522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:56.212475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:57.212603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:58.213006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:12:59.213616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:00.213713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:01.213874      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 05/02/24 09:13:02.088
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/02/24 09:13:02.091
  STEP: Ensuring the job is replaced with a new one @ 05/02/24 09:13:02.093
  E0502 09:13:02.214611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:03.214757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:04.215761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:05.215904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:06.215994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:07.216147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:08.216512      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:09.216669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:10.216728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:11.216898      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:12.217411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:13.217548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:14.217627      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:15.217774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:16.218738      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:17.218896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:18.218989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:19.219243      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:20.219513      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:21.219654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:22.219753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:23.219905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:24.219950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:25.220086      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:26.220462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:27.220613      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:28.220887      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:29.221288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:30.221667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:31.221837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:32.222244      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:33.222389      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:34.222943      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:35.223143      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:36.223663      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:37.223829      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:38.224345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:39.224797      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:40.225509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:41.225660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:42.225926      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:43.226078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:44.226531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:45.226665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:46.226947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:47.227049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:48.227376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:49.227835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:50.228256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:51.228427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:52.228533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:53.228693      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:54.229055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:55.229235      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:56.229802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:57.229975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:58.230545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:13:59.230657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:00.230958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:01.231100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 05/02/24 09:14:02.097
  I0502 09:14:02.102040 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3408" for this suite. @ 05/02/24 09:14:02.106
• [88.064 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:406
  STEP: Creating a kubernetes client @ 05/02/24 09:14:02.119
  I0502 09:14:02.119998 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/02/24 09:14:02.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:02.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:02.15
  STEP: getting /apis @ 05/02/24 09:14:02.156
  STEP: getting /apis/admissionregistration.k8s.io @ 05/02/24 09:14:02.16
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 05/02/24 09:14:02.161
  STEP: creating @ 05/02/24 09:14:02.161
  STEP: getting @ 05/02/24 09:14:02.184
  STEP: listing @ 05/02/24 09:14:02.193
  STEP: watching @ 05/02/24 09:14:02.198
  I0502 09:14:02.198855 23 validatingadmissionpolicy.go:523] starting watch
  STEP: patching @ 05/02/24 09:14:02.2
  STEP: updating @ 05/02/24 09:14:02.206
  I0502 09:14:02.212690 23 validatingadmissionpolicy.go:552] waiting for watch events with expected annotations
  I0502 09:14:02.212708 23 validatingadmissionpolicy.go:568] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 05/02/24 09:14:02.212
  STEP: patching /status @ 05/02/24 09:14:02.214
  STEP: updating /status @ 05/02/24 09:14:02.219
  STEP: deleting @ 05/02/24 09:14:02.228
  E0502 09:14:02.231528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting a collection @ 05/02/24 09:14:02.235
  I0502 09:14:02.246851 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-1800" for this suite. @ 05/02/24 09:14:02.253
• [0.187 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 05/02/24 09:14:02.307
  I0502 09:14:02.307048 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:14:02.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:02.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:02.354
  STEP: Creating the pod @ 05/02/24 09:14:02.356
  E0502 09:14:03.232065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:04.232621      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:14:04.910162 23 pod_client.go:141] Successfully updated pod "labelsupdate1dda70c8-11d6-41a6-b4cd-2889b206f160"
  E0502 09:14:05.233600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:06.233737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:14:06.920480 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6871" for this suite. @ 05/02/24 09:14:06.923
• [4.626 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 05/02/24 09:14:06.933
  I0502 09:14:06.933059 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 09:14:06.933
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:06.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:06.952
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/02/24 09:14:06.953
  E0502 09:14:07.234399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:08.234520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:09.235024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:10.235228      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:14:10.972
  I0502 09:14:10.974400 23 output.go:196] Trying to get logs from node mini-3 pod pod-2f47c9f7-71f3-4584-9e6f-422209ed03ac container test-container: <nil>
  STEP: delete the pod @ 05/02/24 09:14:10.985
  I0502 09:14:10.995640 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8583" for this suite. @ 05/02/24 09:14:10.998
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:420
  STEP: Creating a kubernetes client @ 05/02/24 09:14:11.004
  I0502 09:14:11.004650 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename job @ 05/02/24 09:14:11.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:11.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:11.021
  STEP: Creating Indexed job @ 05/02/24 09:14:11.022
  STEP: Ensuring job reaches completions @ 05/02/24 09:14:11.027
  E0502 09:14:11.235291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:12.235428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:13.236469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:14.236817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:15.237063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:16.237229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:17.237933      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:18.238026      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:19.238521      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:20.238688      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 05/02/24 09:14:21.03
  I0502 09:14:21.034289 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-828" for this suite. @ 05/02/24 09:14:21.037
• [10.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 05/02/24 09:14:21.043
  I0502 09:14:21.043883 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename proxy @ 05/02/24 09:14:21.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:21.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:21.069
  STEP: starting an echo server on multiple ports @ 05/02/24 09:14:21.084
  STEP: creating replication controller proxy-service-n4gbf in namespace proxy-2629 @ 05/02/24 09:14:21.084
  I0502 09:14:21.096110      23 runners.go:198] Created replication controller with name: proxy-service-n4gbf, namespace: proxy-2629, replica count: 1
  E0502 09:14:21.239053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:14:22.147006      23 runners.go:198] proxy-service-n4gbf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0502 09:14:22.239199      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:14:23.147907      23 runners.go:198] proxy-service-n4gbf Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0502 09:14:23.166893 23 proxy.go:230] setup took 2.09539133s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 05/02/24 09:14:23.166
  I0502 09:14:23.177318 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 10.366633ms)
  I0502 09:14:23.177622 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 10.547457ms)
  I0502 09:14:23.177629 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 10.612339ms)
  I0502 09:14:23.177633 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 10.572269ms)
  I0502 09:14:23.177641 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 10.615272ms)
  I0502 09:14:23.177846 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 10.794705ms)
  I0502 09:14:23.177871 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 10.847506ms)
  I0502 09:14:23.178677 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 11.725711ms)
  I0502 09:14:23.179699 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 12.691805ms)
  I0502 09:14:23.179757 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 12.758035ms)
  I0502 09:14:23.181146 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 14.116972ms)
  I0502 09:14:23.182377 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 15.309678ms)
  I0502 09:14:23.182395 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 15.4164ms)
  I0502 09:14:23.182587 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 15.54573ms)
  I0502 09:14:23.182615 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 15.540233ms)
  I0502 09:14:23.182625 23 proxy.go:558] (0) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 15.568654ms)
  I0502 09:14:23.188862 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 6.210018ms)
  I0502 09:14:23.193503 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 10.773295ms)
  I0502 09:14:23.193585 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 10.891478ms)
  I0502 09:14:23.193599 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 10.90017ms)
  I0502 09:14:23.193726 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 10.983291ms)
  I0502 09:14:23.193852 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 11.117555ms)
  I0502 09:14:23.193882 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 11.141164ms)
  I0502 09:14:23.193893 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 11.184231ms)
  I0502 09:14:23.193907 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 11.182688ms)
  I0502 09:14:23.193935 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 11.225404ms)
  I0502 09:14:23.195303 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 12.622091ms)
  I0502 09:14:23.195925 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 13.237144ms)
  I0502 09:14:23.196592 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 13.872654ms)
  I0502 09:14:23.196775 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 14.031568ms)
  I0502 09:14:23.196824 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 14.105069ms)
  I0502 09:14:23.197005 23 proxy.go:558] (1) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 14.289295ms)
  I0502 09:14:23.201182 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 4.109618ms)
  I0502 09:14:23.201383 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 4.32794ms)
  I0502 09:14:23.202168 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 5.08412ms)
  I0502 09:14:23.203405 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 6.302838ms)
  I0502 09:14:23.203528 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 6.429792ms)
  I0502 09:14:23.203529 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 6.431739ms)
  I0502 09:14:23.203561 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 6.464303ms)
  I0502 09:14:23.203564 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 6.483331ms)
  I0502 09:14:23.204067 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 7.006628ms)
  I0502 09:14:23.204088 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 7.05302ms)
  I0502 09:14:23.204327 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 7.207838ms)
  I0502 09:14:23.204566 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 7.499548ms)
  I0502 09:14:23.204575 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 7.466163ms)
  I0502 09:14:23.205147 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 8.04165ms)
  I0502 09:14:23.206321 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 9.199353ms)
  I0502 09:14:23.206779 23 proxy.go:558] (2) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 9.666436ms)
  I0502 09:14:23.212548 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 5.632738ms)
  I0502 09:14:23.212843 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 5.939312ms)
  I0502 09:14:23.212889 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 5.974337ms)
  I0502 09:14:23.213066 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 6.193497ms)
  I0502 09:14:23.213176 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 6.370663ms)
  I0502 09:14:23.213193 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 6.363924ms)
  I0502 09:14:23.213197 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 6.337888ms)
  I0502 09:14:23.213201 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 6.294168ms)
  I0502 09:14:23.213209 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 6.41459ms)
  I0502 09:14:23.213252 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 6.368095ms)
  I0502 09:14:23.214439 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 7.595772ms)
  I0502 09:14:23.214851 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 7.959707ms)
  I0502 09:14:23.215561 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 8.705637ms)
  I0502 09:14:23.215575 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 8.714373ms)
  I0502 09:14:23.215588 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 8.693585ms)
  I0502 09:14:23.215600 23 proxy.go:558] (3) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 8.726147ms)
  I0502 09:14:23.221745 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 6.117734ms)
  I0502 09:14:23.221833 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 6.18153ms)
  I0502 09:14:23.221839 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 6.205336ms)
  I0502 09:14:23.224797 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 9.126586ms)
  I0502 09:14:23.224891 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 9.265326ms)
  I0502 09:14:23.224900 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 9.280176ms)
  I0502 09:14:23.224896 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 9.239636ms)
  I0502 09:14:23.225113 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 9.445653ms)
  I0502 09:14:23.225142 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 9.480005ms)
  I0502 09:14:23.225158 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 9.500192ms)
  I0502 09:14:23.225370 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 9.731325ms)
  I0502 09:14:23.225383 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 9.736183ms)
  I0502 09:14:23.225386 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 9.734491ms)
  I0502 09:14:23.225855 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 10.205851ms)
  I0502 09:14:23.226624 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.948203ms)
  I0502 09:14:23.227126 23 proxy.go:558] (4) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 11.457439ms)
  I0502 09:14:23.231464 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 4.320378ms)
  I0502 09:14:23.232516 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 5.369621ms)
  I0502 09:14:23.234467 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 7.230687ms)
  I0502 09:14:23.235508 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.320194ms)
  I0502 09:14:23.235522 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 8.299135ms)
  I0502 09:14:23.235531 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 8.288278ms)
  I0502 09:14:23.235577 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 8.360533ms)
  I0502 09:14:23.235773 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.576248ms)
  I0502 09:14:23.235989 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 8.795272ms)
  I0502 09:14:23.236025 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 8.816459ms)
  I0502 09:14:23.236760 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 9.534088ms)
  I0502 09:14:23.237220 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 9.987751ms)
  I0502 09:14:23.237778 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 10.561866ms)
  I0502 09:14:23.237891 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.739216ms)
  I0502 09:14:23.238097 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 10.881838ms)
  I0502 09:14:23.238102 23 proxy.go:558] (5) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 10.868244ms)
  E0502 09:14:23.239201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:14:23.243181 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 5.053527ms)
  I0502 09:14:23.243298 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 5.173414ms)
  I0502 09:14:23.244843 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 6.700465ms)
  I0502 09:14:23.247377 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 9.216009ms)
  I0502 09:14:23.247549 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 9.376607ms)
  I0502 09:14:23.247666 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 9.515357ms)
  I0502 09:14:23.247667 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 9.543501ms)
  I0502 09:14:23.247670 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 9.492922ms)
  I0502 09:14:23.248013 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 9.859035ms)
  I0502 09:14:23.248045 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 9.882656ms)
  I0502 09:14:23.248202 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 10.030767ms)
  I0502 09:14:23.248751 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 10.602196ms)
  I0502 09:14:23.249057 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 10.893274ms)
  I0502 09:14:23.249058 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.884869ms)
  I0502 09:14:23.249221 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 11.066766ms)
  I0502 09:14:23.249247 23 proxy.go:558] (6) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 11.109483ms)
  I0502 09:14:23.254169 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 4.895973ms)
  I0502 09:14:23.254209 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 4.903265ms)
  I0502 09:14:23.254624 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 5.274777ms)
  I0502 09:14:23.254756 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 5.439366ms)
  I0502 09:14:23.254833 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 5.493262ms)
  I0502 09:14:23.254949 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 5.608799ms)
  I0502 09:14:23.255179 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 5.88653ms)
  I0502 09:14:23.255828 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 6.502605ms)
  I0502 09:14:23.255962 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 6.693026ms)
  I0502 09:14:23.256075 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 6.73832ms)
  I0502 09:14:23.256088 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 6.752379ms)
  I0502 09:14:23.257340 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 8.020155ms)
  I0502 09:14:23.258224 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 8.872402ms)
  I0502 09:14:23.258511 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 9.196554ms)
  I0502 09:14:23.258528 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 9.182644ms)
  I0502 09:14:23.258542 23 proxy.go:558] (7) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 9.211858ms)
  I0502 09:14:23.266611 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 7.996854ms)
  I0502 09:14:23.266658 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.020876ms)
  I0502 09:14:23.266674 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 8.119537ms)
  I0502 09:14:23.266684 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 8.112202ms)
  I0502 09:14:23.266764 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 8.13242ms)
  I0502 09:14:23.266804 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.158718ms)
  I0502 09:14:23.266808 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 8.18894ms)
  I0502 09:14:23.266925 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 8.299956ms)
  I0502 09:14:23.267036 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 8.392554ms)
  I0502 09:14:23.267041 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 8.44058ms)
  I0502 09:14:23.267064 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 8.478371ms)
  I0502 09:14:23.268967 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 10.341351ms)
  I0502 09:14:23.269475 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 10.863373ms)
  I0502 09:14:23.269607 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 11.053453ms)
  I0502 09:14:23.269625 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 11.001034ms)
  I0502 09:14:23.269643 23 proxy.go:558] (8) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 11.054894ms)
  I0502 09:14:23.275079 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 5.414974ms)
  I0502 09:14:23.276019 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 6.319726ms)
  I0502 09:14:23.276068 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 6.353746ms)
  I0502 09:14:23.276175 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 6.469696ms)
  I0502 09:14:23.276202 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 6.508771ms)
  I0502 09:14:23.276255 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 6.579775ms)
  I0502 09:14:23.276283 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 6.572994ms)
  I0502 09:14:23.276283 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 6.571367ms)
  I0502 09:14:23.276298 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 6.606481ms)
  I0502 09:14:23.276376 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 6.683034ms)
  I0502 09:14:23.278524 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 8.837456ms)
  I0502 09:14:23.279200 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 9.531286ms)
  I0502 09:14:23.279214 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 9.552832ms)
  I0502 09:14:23.279238 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 9.539617ms)
  I0502 09:14:23.279259 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 9.578325ms)
  I0502 09:14:23.279313 23 proxy.go:558] (9) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 9.605524ms)
  I0502 09:14:23.283675 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 4.336289ms)
  I0502 09:14:23.283691 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 4.333668ms)
  I0502 09:14:23.285875 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 6.525361ms)
  I0502 09:14:23.286358 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 6.95519ms)
  I0502 09:14:23.286359 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 6.969404ms)
  I0502 09:14:23.286432 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 7.097925ms)
  I0502 09:14:23.286459 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 7.052429ms)
  I0502 09:14:23.286523 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 7.143033ms)
  I0502 09:14:23.286571 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 7.188479ms)
  I0502 09:14:23.286572 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 7.200567ms)
  I0502 09:14:23.286661 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 7.294372ms)
  I0502 09:14:23.288513 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 9.10318ms)
  I0502 09:14:23.289528 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 10.134028ms)
  I0502 09:14:23.289543 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 10.14651ms)
  I0502 09:14:23.289550 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 10.138689ms)
  I0502 09:14:23.289661 23 proxy.go:558] (10) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 10.253908ms)
  I0502 09:14:23.298628 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 8.91616ms)
  I0502 09:14:23.298628 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 8.952541ms)
  I0502 09:14:23.298637 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 8.904712ms)
  I0502 09:14:23.298642 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 8.891054ms)
  I0502 09:14:23.298641 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 8.957641ms)
  I0502 09:14:23.298652 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 8.89362ms)
  I0502 09:14:23.298656 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 8.918004ms)
  I0502 09:14:23.298655 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.966215ms)
  I0502 09:14:23.298663 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.944095ms)
  I0502 09:14:23.298648 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 8.910344ms)
  I0502 09:14:23.301287 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 11.592571ms)
  I0502 09:14:23.301919 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 12.192455ms)
  I0502 09:14:23.302037 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 12.325779ms)
  I0502 09:14:23.302078 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 12.326977ms)
  I0502 09:14:23.302238 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 12.495756ms)
  I0502 09:14:23.302271 23 proxy.go:558] (11) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 12.526765ms)
  I0502 09:14:23.309555 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 7.205482ms)
  I0502 09:14:23.309569 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 7.23035ms)
  I0502 09:14:23.309568 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 7.222097ms)
  I0502 09:14:23.309580 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 7.252801ms)
  I0502 09:14:23.309623 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 7.264103ms)
  I0502 09:14:23.309634 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 7.328651ms)
  I0502 09:14:23.309639 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 7.279702ms)
  I0502 09:14:23.309646 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 7.294707ms)
  I0502 09:14:23.309684 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 7.399398ms)
  I0502 09:14:23.309758 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 7.418185ms)
  I0502 09:14:23.309933 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 7.635606ms)
  I0502 09:14:23.311520 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 9.170574ms)
  I0502 09:14:23.312334 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.000349ms)
  I0502 09:14:23.312348 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 10.018481ms)
  I0502 09:14:23.312521 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 10.158823ms)
  I0502 09:14:23.312543 23 proxy.go:558] (12) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 10.226506ms)
  I0502 09:14:23.320027 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 7.39295ms)
  I0502 09:14:23.320130 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 7.536902ms)
  I0502 09:14:23.320229 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 7.670386ms)
  I0502 09:14:23.320244 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 7.613534ms)
  I0502 09:14:23.320244 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 7.67542ms)
  I0502 09:14:23.320267 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 7.644671ms)
  I0502 09:14:23.320576 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 8.014752ms)
  I0502 09:14:23.320688 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 8.063805ms)
  I0502 09:14:23.321171 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 8.57149ms)
  I0502 09:14:23.321355 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 8.744109ms)
  I0502 09:14:23.321366 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.758427ms)
  I0502 09:14:23.321758 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 9.133147ms)
  I0502 09:14:23.322565 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 9.972989ms)
  I0502 09:14:23.322646 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 10.048921ms)
  I0502 09:14:23.322718 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.101108ms)
  I0502 09:14:23.322828 23 proxy.go:558] (13) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 10.245184ms)
  I0502 09:14:23.327955 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 5.083761ms)
  I0502 09:14:23.328078 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 5.227593ms)
  I0502 09:14:23.328094 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 5.218016ms)
  I0502 09:14:23.331778 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.883424ms)
  I0502 09:14:23.331867 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 8.945941ms)
  I0502 09:14:23.331897 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 9.002523ms)
  I0502 09:14:23.332015 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 9.105188ms)
  I0502 09:14:23.332038 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 9.142504ms)
  I0502 09:14:23.332038 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 9.127381ms)
  I0502 09:14:23.332365 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 9.440278ms)
  I0502 09:14:23.332610 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 9.693614ms)
  I0502 09:14:23.333210 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.329384ms)
  I0502 09:14:23.333388 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 10.466716ms)
  I0502 09:14:23.333505 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 10.596329ms)
  I0502 09:14:23.333620 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 10.70786ms)
  I0502 09:14:23.333638 23 proxy.go:558] (14) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 10.73587ms)
  I0502 09:14:23.339071 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 5.40804ms)
  I0502 09:14:23.341971 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 8.303758ms)
  I0502 09:14:23.342702 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.989763ms)
  I0502 09:14:23.342705 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 9.01375ms)
  I0502 09:14:23.342718 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 9.025236ms)
  I0502 09:14:23.342719 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 9.022193ms)
  I0502 09:14:23.342734 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 9.024956ms)
  I0502 09:14:23.342808 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 9.094945ms)
  I0502 09:14:23.342966 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 9.258652ms)
  I0502 09:14:23.343139 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 9.486498ms)
  I0502 09:14:23.344162 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 10.451762ms)
  I0502 09:14:23.344239 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 10.565335ms)
  I0502 09:14:23.344351 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 10.662987ms)
  I0502 09:14:23.344436 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.757315ms)
  I0502 09:14:23.345439 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 11.75219ms)
  I0502 09:14:23.345540 23 proxy.go:558] (15) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 11.840613ms)
  I0502 09:14:23.351165 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 5.598195ms)
  I0502 09:14:23.352741 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 7.110527ms)
  I0502 09:14:23.355612 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 9.989535ms)
  I0502 09:14:23.355618 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 9.99537ms)
  I0502 09:14:23.355630 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 9.998978ms)
  I0502 09:14:23.355634 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 10.019252ms)
  I0502 09:14:23.355639 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 10.004989ms)
  I0502 09:14:23.355645 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 10.041012ms)
  I0502 09:14:23.355649 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 10.03487ms)
  I0502 09:14:23.355658 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 10.021364ms)
  I0502 09:14:23.356427 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 10.835332ms)
  I0502 09:14:23.356522 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.924625ms)
  I0502 09:14:23.356649 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 11.095171ms)
  I0502 09:14:23.356662 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 11.047714ms)
  I0502 09:14:23.356697 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 11.109731ms)
  I0502 09:14:23.356906 23 proxy.go:558] (16) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 11.296427ms)
  I0502 09:14:23.365206 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.217122ms)
  I0502 09:14:23.365222 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 8.237166ms)
  I0502 09:14:23.365231 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 8.242551ms)
  I0502 09:14:23.365251 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 8.312784ms)
  I0502 09:14:23.365255 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 8.281421ms)
  I0502 09:14:23.365270 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 8.34547ms)
  I0502 09:14:23.365374 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 8.44353ms)
  I0502 09:14:23.365378 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 8.401151ms)
  I0502 09:14:23.365400 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 8.429926ms)
  I0502 09:14:23.365412 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 8.46539ms)
  I0502 09:14:23.366042 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 9.115818ms)
  I0502 09:14:23.367450 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.487561ms)
  I0502 09:14:23.368267 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 11.312146ms)
  I0502 09:14:23.368273 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 11.290926ms)
  I0502 09:14:23.368464 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 11.504313ms)
  I0502 09:14:23.368486 23 proxy.go:558] (17) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 11.512866ms)
  I0502 09:14:23.373920 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 5.419798ms)
  I0502 09:14:23.376475 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 7.935084ms)
  I0502 09:14:23.378483 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 9.887139ms)
  I0502 09:14:23.378515 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 9.944492ms)
  I0502 09:14:23.378671 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 10.0954ms)
  I0502 09:14:23.378686 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 10.109387ms)
  I0502 09:14:23.378686 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 10.102018ms)
  I0502 09:14:23.378703 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 10.112955ms)
  I0502 09:14:23.379586 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 10.997545ms)
  I0502 09:14:23.379600 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 11.017791ms)
  I0502 09:14:23.381372 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 12.813298ms)
  I0502 09:14:23.381722 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 13.183813ms)
  I0502 09:14:23.381737 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 13.174151ms)
  I0502 09:14:23.381744 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 13.213581ms)
  I0502 09:14:23.381856 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 13.256843ms)
  I0502 09:14:23.381974 23 proxy.go:558] (18) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 13.379282ms)
  I0502 09:14:23.389058 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 7.021157ms)
  I0502 09:14:23.389073 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">test<... (200; 7.046316ms)
  I0502 09:14:23.389081 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:1080/proxy/rewriteme">... (200; 7.059838ms)
  I0502 09:14:23.389158 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 7.125501ms)
  I0502 09:14:23.389204 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:443/proxy/tlsrewritem... (200; 7.143794ms)
  I0502 09:14:23.389315 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/: <a href="/api/v1/namespaces/proxy-2629/pods/proxy-service-n4gbf-vclz4/proxy/rewriteme">test</a> (200; 7.255643ms)
  I0502 09:14:23.389458 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:162/proxy/: bar (200; 7.410719ms)
  I0502 09:14:23.389503 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/http:proxy-service-n4gbf-vclz4:160/proxy/: foo (200; 7.46681ms)
  I0502 09:14:23.389523 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:460/proxy/: tls baz (200; 7.459044ms)
  I0502 09:14:23.389630 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/pods/https:proxy-service-n4gbf-vclz4:462/proxy/: tls qux (200; 7.571138ms)
  I0502 09:14:23.391381 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname1/proxy/: foo (200; 9.313114ms)
  I0502 09:14:23.392291 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname1/proxy/: foo (200; 10.291408ms)
  I0502 09:14:23.392303 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/services/proxy-service-n4gbf:portname2/proxy/: bar (200; 10.31269ms)
  I0502 09:14:23.392327 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/services/http:proxy-service-n4gbf:portname2/proxy/: bar (200; 10.322191ms)
  I0502 09:14:23.392465 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname2/proxy/: tls qux (200; 10.42022ms)
  I0502 09:14:23.392478 23 proxy.go:558] (19) /api/v1/namespaces/proxy-2629/services/https:proxy-service-n4gbf:tlsportname1/proxy/: tls baz (200; 10.417974ms)
  STEP: deleting ReplicationController proxy-service-n4gbf in namespace proxy-2629, will wait for the garbage collector to delete the pods @ 05/02/24 09:14:23.392
  I0502 09:14:23.451523 23 resources.go:139] Deleting ReplicationController proxy-service-n4gbf took: 6.522937ms
  I0502 09:14:23.552120 23 resources.go:163] Terminating ReplicationController proxy-service-n4gbf pods took: 100.597582ms
  E0502 09:14:24.240226      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:25.241006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:14:26.153079 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2629" for this suite. @ 05/02/24 09:14:26.157
• [5.129 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 05/02/24 09:14:26.172
  I0502 09:14:26.172707 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 09:14:26.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:26.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:26.204
  STEP: Creating configMap with name configmap-test-upd-91b67aae-9006-40fb-a27a-db9d75eeecb8 @ 05/02/24 09:14:26.209
  STEP: Creating the pod @ 05/02/24 09:14:26.213
  E0502 09:14:26.241948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:27.242077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-91b67aae-9006-40fb-a27a-db9d75eeecb8 @ 05/02/24 09:14:28.236
  STEP: waiting to observe update in volume @ 05/02/24 09:14:28.24
  E0502 09:14:28.242702      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:29.243144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:30.243338      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:14:30.249489 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5643" for this suite. @ 05/02/24 09:14:30.253
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 05/02/24 09:14:30.26
  I0502 09:14:30.260306 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 09:14:30.26
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:30.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:30.28
  STEP: Creating a ResourceQuota with best effort scope @ 05/02/24 09:14:30.281
  STEP: Ensuring ResourceQuota status is calculated @ 05/02/24 09:14:30.284
  E0502 09:14:31.244916      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:32.245268      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 05/02/24 09:14:32.288
  STEP: Ensuring ResourceQuota status is calculated @ 05/02/24 09:14:32.292
  E0502 09:14:33.245286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:34.245704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 05/02/24 09:14:34.296
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 05/02/24 09:14:34.308
  E0502 09:14:35.246282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:36.246450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 05/02/24 09:14:36.311
  E0502 09:14:37.247309      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:38.247450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/02/24 09:14:38.314
  STEP: Ensuring resource quota status released the pod usage @ 05/02/24 09:14:38.336
  E0502 09:14:39.248363      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:40.248530      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 05/02/24 09:14:40.339
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 05/02/24 09:14:40.349
  E0502 09:14:41.249014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:42.249176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 05/02/24 09:14:42.353
  E0502 09:14:43.249979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:44.250324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/02/24 09:14:44.356
  STEP: Ensuring resource quota status released the pod usage @ 05/02/24 09:14:44.371
  E0502 09:14:45.250427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:46.250592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:14:46.375213 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1763" for this suite. @ 05/02/24 09:14:46.379
• [16.125 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 05/02/24 09:14:46.385
  I0502 09:14:46.385624 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replication-controller @ 05/02/24 09:14:46.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:46.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:46.409
  STEP: Creating replication controller my-hostname-basic-0e0f5db8-5e5f-4893-9cf3-b28b2a473519 @ 05/02/24 09:14:46.411
  I0502 09:14:46.423953 23 resource.go:87] Pod name my-hostname-basic-0e0f5db8-5e5f-4893-9cf3-b28b2a473519: Found 0 pods out of 1
  E0502 09:14:47.250866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:48.251030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:49.251615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:50.251757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:51.251941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:14:51.428353 23 resource.go:87] Pod name my-hostname-basic-0e0f5db8-5e5f-4893-9cf3-b28b2a473519: Found 1 pods out of 1
  I0502 09:14:51.428369 23 rc.go:507] Ensuring all pods for ReplicationController "my-hostname-basic-0e0f5db8-5e5f-4893-9cf3-b28b2a473519" are running
  I0502 09:14:51.431230 23 rc.go:523] Pod "my-hostname-basic-0e0f5db8-5e5f-4893-9cf3-b28b2a473519-gs2dh" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 09:14:48 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 09:14:46 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 09:14:48 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 09:14:48 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-02 09:14:46 +0000 UTC Reason: Message:}])
  I0502 09:14:51.431257 23 rc.go:531] Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/02/24 09:14:51.431
  I0502 09:14:51.441152 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8713" for this suite. @ 05/02/24 09:14:51.444
• [5.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 05/02/24 09:14:51.452
  I0502 09:14:51.452963 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 09:14:51.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:51.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:51.478
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/02/24 09:14:51.48
  E0502 09:14:52.252656      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:53.253064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:54.253284      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:55.253434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:14:55.502
  I0502 09:14:55.506132 23 output.go:196] Trying to get logs from node mini-1 pod pod-68a906fe-3f12-49dd-aa7b-e25ce545233e container test-container: <nil>
  STEP: delete the pod @ 05/02/24 09:14:55.51
  I0502 09:14:55.522779 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8341" for this suite. @ 05/02/24 09:14:55.525
• [4.078 seconds]
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 05/02/24 09:14:55.531
  I0502 09:14:55.531353 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pod-network-test @ 05/02/24 09:14:55.531
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:14:55.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:14:55.548
  STEP: Performing setup for networking test in namespace pod-network-test-41 @ 05/02/24 09:14:55.55
  STEP: creating a selector @ 05/02/24 09:14:55.55
  STEP: Creating the service pods in kubernetes @ 05/02/24 09:14:55.55
  I0502 09:14:55.550820 23 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0502 09:14:56.253453      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:57.253586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:58.253752      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:14:59.254200      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:00.254711      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:01.254882      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:02.255096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:03.255314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:04.256129      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:05.256262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:06.257081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:07.257212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:08.257538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:09.257792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:10.258010      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:11.258119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:12.258369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:13.258521      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:14.258625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:15.258726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:16.259120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:17.259256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/02/24 09:15:17.637
  E0502 09:15:18.259506      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:19.259844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:15:19.667221 23 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0502 09:15:19.667252 23 utils.go:472] Going to poll 192.168.125.228 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0502 09:15:19.669161 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.125.228:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-41 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 09:15:19.669175 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 09:15:19.669489 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 09:15:19.669551 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-41/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.125.228%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0502 09:15:19.719224 23 utils.go:489] Found all 1 expected endpoints: [netserver-0]
  I0502 09:15:19.719241 23 utils.go:472] Going to poll 192.168.158.189 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0502 09:15:19.722501 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.158.189:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-41 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 09:15:19.722526 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 09:15:19.722803 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 09:15:19.722862 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-41/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.158.189%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0502 09:15:19.767005 23 utils.go:489] Found all 1 expected endpoints: [netserver-1]
  I0502 09:15:19.767023 23 utils.go:472] Going to poll 192.168.32.51 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0502 09:15:19.771051 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.32.51:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-41 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 09:15:19.771064 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 09:15:19.771342 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 09:15:19.771376 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-41/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.32.51%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0502 09:15:19.815753 23 utils.go:489] Found all 1 expected endpoints: [netserver-2]
  I0502 09:15:19.815828 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-41" for this suite. @ 05/02/24 09:15:19.82
• [24.296 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 05/02/24 09:15:19.827
  I0502 09:15:19.827524 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:15:19.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:15:19.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:15:19.851
  STEP: Creating projection with secret that has name projected-secret-test-map-4ffde7c2-82dc-4e40-b399-a704a4c8bb4a @ 05/02/24 09:15:19.853
  STEP: Creating a pod to test consume secrets @ 05/02/24 09:15:19.856
  E0502 09:15:20.260379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:21.260620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:22.261164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:23.261333      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:15:23.877
  I0502 09:15:23.879718 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-secrets-366c4c61-38b2-4d82-91aa-cb0c4615d5c9 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:15:23.883
  I0502 09:15:23.893517 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-60" for this suite. @ 05/02/24 09:15:23.896
• [4.075 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 05/02/24 09:15:23.902
  I0502 09:15:23.902568 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename field-validation @ 05/02/24 09:15:23.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:15:23.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:15:23.922
  I0502 09:15:23.923682 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 09:15:24.261841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:25.262023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:26.262146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0502 09:15:26.459018      23 warnings.go:70] unknown field "alpha"
  W0502 09:15:26.459029      23 warnings.go:70] unknown field "beta"
  W0502 09:15:26.459032      23 warnings.go:70] unknown field "delta"
  W0502 09:15:26.459035      23 warnings.go:70] unknown field "epsilon"
  W0502 09:15:26.459038      23 warnings.go:70] unknown field "gamma"
  I0502 09:15:26.992630 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1773" for this suite. @ 05/02/24 09:15:26.995
• [3.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 05/02/24 09:15:27.002
  I0502 09:15:27.002563 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 09:15:27.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:15:27.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:15:27.022
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/02/24 09:15:27.023
  E0502 09:15:27.262496      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:28.262678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:29.263087      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:30.263264      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:15:31.038
  I0502 09:15:31.040936 23 output.go:196] Trying to get logs from node mini-2 pod pod-39bbed20-0ac9-4f94-9864-b20ef3947cd2 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 09:15:31.051
  I0502 09:15:31.064105 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4410" for this suite. @ 05/02/24 09:15:31.067
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 05/02/24 09:15:31.073
  I0502 09:15:31.073534 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename chunking @ 05/02/24 09:15:31.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:15:31.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:15:31.095
  STEP: creating a large number of resources @ 05/02/24 09:15:31.097
  E0502 09:15:31.263579      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:32.264444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:33.265464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:34.265943      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:35.266556      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:36.266658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:37.266899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:38.267675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:39.268196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:40.268568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:41.269021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:42.269494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:43.270455      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:44.271451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:45.271677      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:46.272152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:47.272954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:48.273595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 05/02/24 09:15:48.779
  I0502 09:15:48.828183 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0502 09:15:48.878016 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0502 09:15:48.927806 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0502 09:15:48.978358 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0502 09:15:49.027691 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0502 09:15:49.078136 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0502 09:15:49.127322 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0502 09:15:49.179407 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0502 09:15:49.228441 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  E0502 09:15:49.274623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:15:49.278036 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0502 09:15:49.328421 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0502 09:15:49.378404 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0502 09:15:49.431717 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0502 09:15:49.478549 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0502 09:15:49.528665 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0502 09:15:49.578593 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0502 09:15:49.628547 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0502 09:15:49.678098 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0502 09:15:49.727618 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0502 09:15:49.778446 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0502 09:15:49.828200 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0502 09:15:49.878031 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0502 09:15:49.927466 23 chunking.go:98] Retrieved 17/17 results with rv 34810 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTAsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0502 09:15:49.977825 23 chunking.go:98] Retrieved 9/17 results with rv 34810 and continue 
  I0502 09:15:50.028680 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0502 09:15:50.078592 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0502 09:15:50.128587 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0502 09:15:50.178205 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0502 09:15:50.228003 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  E0502 09:15:50.275405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:15:50.277779 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0502 09:15:50.328796 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0502 09:15:50.378504 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0502 09:15:50.428043 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0502 09:15:50.477868 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0502 09:15:50.527418 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0502 09:15:50.578296 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0502 09:15:50.628295 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0502 09:15:50.677998 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0502 09:15:50.727445 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0502 09:15:50.778176 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0502 09:15:50.827823 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0502 09:15:50.877101 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0502 09:15:50.929618 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0502 09:15:50.978097 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0502 09:15:51.027775 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0502 09:15:51.078064 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0502 09:15:51.127792 23 chunking.go:98] Retrieved 17/17 results with rv 34815 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTUsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0502 09:15:51.178414 23 chunking.go:98] Retrieved 9/17 results with rv 34815 and continue 
  I0502 09:15:51.227934 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  E0502 09:15:51.276300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:15:51.277503 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0502 09:15:51.328302 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0502 09:15:51.377732 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0502 09:15:51.428513 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0502 09:15:51.477812 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0502 09:15:51.528481 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0502 09:15:51.578059 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0502 09:15:51.627685 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0502 09:15:51.678236 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0502 09:15:51.727845 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0502 09:15:51.778133 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0502 09:15:51.827153 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0502 09:15:51.877773 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0502 09:15:51.928565 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0502 09:15:51.978257 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0502 09:15:52.027476 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0502 09:15:52.077988 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0502 09:15:52.128100 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0502 09:15:52.177586 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0502 09:15:52.228317 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  E0502 09:15:52.276756      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:15:52.277814 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0502 09:15:52.328548 23 chunking.go:98] Retrieved 17/17 results with rv 34819 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ4MTksInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0502 09:15:52.377673 23 chunking.go:98] Retrieved 9/17 results with rv 34819 and continue 
  STEP: retrieving those results all at once @ 05/02/24 09:15:52.377
  I0502 09:15:52.436146 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-2411" for this suite. @ 05/02/24 09:15:52.478
• [21.459 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 05/02/24 09:15:52.532
  I0502 09:15:52.532672 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:15:52.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:15:52.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:15:52.558
  STEP: Creating secret with name secret-test-27f05c56-2d91-4146-bf0e-d50c577a4da6 @ 05/02/24 09:15:52.56
  STEP: Creating a pod to test consume secrets @ 05/02/24 09:15:52.564
  E0502 09:15:53.276903      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:54.277208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:55.277550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:56.277715      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:15:56.585
  I0502 09:15:56.588015 23 output.go:196] Trying to get logs from node mini-1 pod pod-secrets-1b815d60-d67b-4067-b083-cb943d6e1199 container secret-env-test: <nil>
  STEP: delete the pod @ 05/02/24 09:15:56.594
  I0502 09:15:56.607075 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7966" for this suite. @ 05/02/24 09:15:56.61
• [4.085 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:358
  STEP: Creating a kubernetes client @ 05/02/24 09:15:56.617
  I0502 09:15:56.617416 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/02/24 09:15:56.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:15:56.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:15:56.644
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 05/02/24 09:15:56.646
  I0502 09:15:56.646551 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 09:15:57.278290      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:58.278925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:15:59.279960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:15:59.483403 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 09:16:00.280110      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:01.280872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:02.281028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:03.281669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:04.281798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:05.282814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:06.283063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:07.283906      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:07.922445 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2379" for this suite. @ 05/02/24 09:16:07.93
• [11.323 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 05/02/24 09:16:07.941
  I0502 09:16:07.941044 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 09:16:07.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:16:07.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:16:07.968
  STEP: Creating pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456 @ 05/02/24 09:16:07.97
  E0502 09:16:08.284021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:09.284439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/02/24 09:16:09.996
  I0502 09:16:09.999201 23 container_probe.go:1749] Initial restart count of pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 is 0
  I0502 09:16:10.002009 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:10.285352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:11.285492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:12.005964 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:12.286305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:13.287088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:14.015939 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:14.287325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:15.287490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:16.020156 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:16.288450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:17.288614      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:18.023873 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:18.289226      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:19.289751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:20.027745 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:20.289974      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:21.290120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:22.031947 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:22.291059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:23.291208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:24.035080 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:24.291627      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:25.291769      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:26.038703 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:26.291987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:27.292141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:28.042332 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:28.292779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:29.292876      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:30.046526 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  I0502 09:16:30.046560 23 container_probe.go:1763] Restart count of pod container-probe-9456/liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 is now 1 (20.047331597s elapsed)
  E0502 09:16:30.293900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:31.294354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:32.050681 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:32.295403      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:33.295568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:34.054290 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:34.295684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:35.296004      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:36.059006 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:36.296221      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:37.296476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:38.062839 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:38.297545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:39.297897      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:40.068179 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:40.298576      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:41.298708      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:42.072318 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:42.299748      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:43.299844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:44.076013 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:44.300454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:45.300606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:46.079975 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:46.301259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:47.301418      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:48.084162 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:48.302482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:49.303010      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:50.088692 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  I0502 09:16:50.088725 23 container_probe.go:1763] Restart count of pod container-probe-9456/liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 is now 2 (40.089484319s elapsed)
  E0502 09:16:50.303996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:51.304144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:52.092744 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:52.305103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:53.305262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:54.097009 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:54.306306      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:55.306460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:56.101141 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:56.307458      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:57.307583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:16:58.104676 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:16:58.307977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:16:59.308408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:00.109712 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:00.308981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:01.309142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:02.113367 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:02.309610      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:03.309812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:04.117360 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:04.310837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:05.310977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:06.121992 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:06.311212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:07.311527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:08.126387 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:08.311567      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:09.311699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:10.131203 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  I0502 09:17:10.131224 23 container_probe.go:1763] Restart count of pod container-probe-9456/liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 is now 3 (1m0.131995349s elapsed)
  E0502 09:17:10.312538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:11.312783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:12.135027 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:12.313232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:13.314041      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:14.139072 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:14.314619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:15.314721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:16.143033 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:16.315328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:17.315501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:18.146801 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:18.316051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:19.316610      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:20.151363 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:20.317642      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:21.317800      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:22.156738 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:22.317981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:23.318214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:24.160795 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:24.319052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:25.319183      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:26.164932 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:26.320232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:27.320411      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:28.170082 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:28.321330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:29.321770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:30.173979 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  I0502 09:17:30.174012 23 container_probe.go:1763] Restart count of pod container-probe-9456/liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 is now 4 (1m20.174771192s elapsed)
  E0502 09:17:30.322310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:31.322461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:32.177787 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:32.323063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:33.323190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:34.182161 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:34.323325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:35.323463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:36.185883 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:36.324063      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:37.324212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:38.189929 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:38.325196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:39.325802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:40.195002 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:40.326241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:41.327111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:42.198780 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:42.327966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:43.328112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:44.203021 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:44.328214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:45.328354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:46.207077 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:46.329336      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:47.329508      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:48.210783 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:48.330017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:49.330628      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:50.215266 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:50.331510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:51.331648      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:52.218959 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:52.332145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:53.332257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:54.223065 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:54.333242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:55.333391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:56.226998 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:56.334273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:57.334454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:17:58.230958 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:17:58.335234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:17:59.335765      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:00.235458 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:00.336669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:01.336834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:02.239328 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:02.337609      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:03.337734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:04.243139 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:04.338362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:05.338487      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:06.246691 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:06.338904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:07.339059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:08.250478 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:08.339583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:09.339980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:10.254498 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:10.340779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:11.340905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:12.259196 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:12.341327      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:13.341998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:14.263746 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:14.342930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:15.343044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:16.267838 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:16.343992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:17.344148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:18.272099 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:18.344163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:19.344812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:20.277146 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:20.345239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:21.345397      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:22.281452 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:22.345616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:23.345771      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:24.285680 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:24.346834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:25.346994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:26.290086 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:26.347262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:27.347414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:28.294473 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  E0502 09:18:28.347608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:29.347981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:30.298824 23 container_probe.go:1759] Get pod liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 in namespace container-probe-9456
  I0502 09:18:30.298872 23 container_probe.go:1763] Restart count of pod container-probe-9456/liveness-ce39a11b-baf4-4c0a-b082-c59593b6c493 is now 5 (2m20.299630268s elapsed)
  STEP: deleting the pod @ 05/02/24 09:18:30.298
  I0502 09:18:30.310147 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9456" for this suite. @ 05/02/24 09:18:30.314
• [142.382 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 05/02/24 09:18:30.323
  I0502 09:18:30.323644 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename statefulset @ 05/02/24 09:18:30.324
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:18:30.345
  E0502 09:18:30.348162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:18:30.348
  STEP: Creating service test in namespace statefulset-6984 @ 05/02/24 09:18:30.35
  STEP: Creating a new StatefulSet @ 05/02/24 09:18:30.354
  I0502 09:18:30.369265 23 wait.go:40] Found 0 stateful pods, waiting for 3
  E0502 09:18:31.348414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:32.348584      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:33.348871      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:34.349193      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:35.349358      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:36.349535      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:37.349658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:38.349795      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:39.350416      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:40.350582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:18:40.369917 23 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0502 09:18:40.369932 23 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0502 09:18:40.369952 23 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/02/24 09:18:40.378
  I0502 09:18:40.397359 23 statefulset.go:2241] Updating stateful set ss2
  STEP: Creating a new revision @ 05/02/24 09:18:40.397
  E0502 09:18:41.350899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:42.351040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:43.351201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:44.351507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:45.351623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:46.351762      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:47.351958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:48.352081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:49.352611      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:50.352780      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 05/02/24 09:18:50.404
  STEP: Performing a canary update @ 05/02/24 09:18:50.404
  I0502 09:18:50.424267 23 statefulset.go:2241] Updating stateful set ss2
  I0502 09:18:50.433777 23 wait.go:74] Waiting for Pod statefulset-6984/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0502 09:18:51.353693      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:52.353841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:53.353985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:54.354301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:55.354464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:56.354630      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:57.354829      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:58.354950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:18:59.355342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:00.355521      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 05/02/24 09:19:00.432
  I0502 09:19:00.471477 23 wait.go:40] Found 1 stateful pods, waiting for 3
  E0502 09:19:01.356380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:02.357049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:03.357293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:04.357774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:05.357928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:06.358075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:07.358300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:08.358444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:09.358814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:10.358988      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:19:10.472621 23 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0502 09:19:10.472636 23 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0502 09:19:10.472655 23 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 05/02/24 09:19:10.478
  I0502 09:19:10.497281 23 statefulset.go:2241] Updating stateful set ss2
  I0502 09:19:10.512728 23 wait.go:74] Waiting for Pod statefulset-6984/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0502 09:19:11.359632      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:12.359788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:13.359901      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:14.360223      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:15.360373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:16.360553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:17.360715      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:18.360869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:19.361322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:20.361472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:19:20.524287 23 statefulset.go:2241] Updating stateful set ss2
  I0502 09:19:20.534333 23 wait.go:56] Waiting for StatefulSet statefulset-6984/ss2 to complete update
  I0502 09:19:20.534376 23 wait.go:63] Waiting for Pod statefulset-6984/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0502 09:19:21.362225      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:22.363015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:23.363151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:24.363304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:25.363469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:26.363875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:27.364046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:28.364124      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:29.364790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:30.364962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:19:30.532089 23 statefulset.go:135] Deleting all statefulset in ns statefulset-6984
  I0502 09:19:30.534522 23 rest.go:150] Scaling statefulset ss2 to 0
  E0502 09:19:31.365748      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:32.365931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:33.366091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:34.366408      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:35.366538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:36.366703      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:37.366845      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:38.366968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:39.367444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:40.367594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:19:40.546388 23 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0502 09:19:40.549262 23 rest.go:88] Deleting statefulset ss2
  I0502 09:19:40.563488 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6984" for this suite. @ 05/02/24 09:19:40.569
• [70.253 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 05/02/24 09:19:40.577
  I0502 09:19:40.577107 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename endpointslice @ 05/02/24 09:19:40.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:19:40.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:19:40.597
  E0502 09:19:41.367692      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:42.367900      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:19:42.664171 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1468" for this suite. @ 05/02/24 09:19:42.667
• [2.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 05/02/24 09:19:42.676
  I0502 09:19:42.676323 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename endpointslice @ 05/02/24 09:19:42.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:19:42.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:19:42.696
  E0502 09:19:43.368762      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:44.369011      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 05/02/24 09:19:44.784
  STEP: referencing matching pods with named port @ 05/02/24 09:19:44.79
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 05/02/24 09:19:44.795
  STEP: recreating EndpointSlices after they've been deleted @ 05/02/24 09:19:44.8
  I0502 09:19:44.816985 23 endpointslice.go:938] EndpointSlice for Service endpointslice-7659/example-named-port not found
  E0502 09:19:45.369684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:46.369871      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:19:46.821131 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7659" for this suite. @ 05/02/24 09:19:46.826
• [4.157 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1079
  STEP: Creating a kubernetes client @ 05/02/24 09:19:46.833
  I0502 09:19:46.833999 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 09:19:46.834
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:19:46.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:19:46.855
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/02/24 09:19:46.857
  I0502 09:19:46.857467 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8807 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0502 09:19:46.902746 23 builder.go:146] stderr: ""
  I0502 09:19:46.902769 23 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 05/02/24 09:19:46.902
  I0502 09:19:46.902813 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8807 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I0502 09:19:46.942377 23 builder.go:146] stderr: ""
  I0502 09:19:46.942400 23 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/02/24 09:19:46.942
  I0502 09:19:46.945829 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-8807 delete pods e2e-test-httpd-pod'
  E0502 09:19:47.370205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:48.370364      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:19:48.642139 23 builder.go:146] stderr: ""
  I0502 09:19:48.642160 23 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0502 09:19:48.642208 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8807" for this suite. @ 05/02/24 09:19:48.645
• [1.820 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 05/02/24 09:19:48.653
  I0502 09:19:48.653625 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 09:19:48.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:19:48.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:19:48.674
  E0502 09:19:49.371396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:50.371565      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:51.371854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:52.372176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:53.372238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:54.372452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:55.372783      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:56.373040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:57.373921      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:58.374096      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:19:59.374932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:00.375114      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:01.376128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:02.376264      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:03.376395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:04.376770      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:05.377261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:06.377429      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:07.377739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:08.377977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:09.378596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:10.378756      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:10.735407 23 container_probe.go:92] Container started at 2024-05-02 09:19:49 +0000 UTC, pod became ready at 2024-05-02 09:20:09 +0000 UTC
  I0502 09:20:10.735500 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-339" for this suite. @ 05/02/24 09:20:10.738
• [22.093 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 05/02/24 09:20:10.746
  I0502 09:20:10.746661 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename namespaces @ 05/02/24 09:20:10.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:20:10.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:20:10.771
  STEP: Creating namespace "e2e-ns-vn9x4" @ 05/02/24 09:20:10.773
  I0502 09:20:10.789536 23 namespace.go:411] Namespace "e2e-ns-vn9x4-6717" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-vn9x4-6717" @ 05/02/24 09:20:10.789
  I0502 09:20:10.795955 23 namespace.go:434] Namespace "e2e-ns-vn9x4-6717" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-vn9x4-6717" @ 05/02/24 09:20:10.795
  I0502 09:20:10.803102 23 namespace.go:463] Namespace "e2e-ns-vn9x4-6717" has []v1.FinalizerName{"kubernetes"}
  I0502 09:20:10.803171 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6744" for this suite. @ 05/02/24 09:20:10.806
  STEP: Destroying namespace "e2e-ns-vn9x4-6717" for this suite. @ 05/02/24 09:20:10.813
• [0.073 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 05/02/24 09:20:10.819
  I0502 09:20:10.819526 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 09:20:10.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:20:10.838
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:20:10.841
  STEP: Creating pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952 @ 05/02/24 09:20:10.843
  E0502 09:20:11.378814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:12.378987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/02/24 09:20:12.856
  I0502 09:20:12.859519 23 container_probe.go:1749] Initial restart count of pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 is 0
  I0502 09:20:12.862241 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:13.379854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:14.380061      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:14.866502 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:15.381138      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:16.381316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:16.870414 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:17.381989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:18.382539      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:18.875205 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:19.382922      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:20.383168      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:20.879979 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:21.383504      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:22.383667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:22.883572 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:23.384126      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:24.384472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:24.887600 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:25.385141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:26.385315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:26.891738 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:27.385431      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:28.386154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:28.895661 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:29.386231      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:30.386405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:30.899701 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:31.387375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:32.387603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:32.903379 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:33.387898      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:34.388133      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:34.907127 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:35.388573      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:36.388721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:36.911317 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:37.388818      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:38.389000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:38.915063 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:39.389774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:40.390229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:40.919599 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:41.391132      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:42.391314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:42.925365 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:43.391904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:44.392076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:44.929416 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:45.393005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:46.393165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:46.932794 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:47.393248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:48.393407      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:48.936343 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:49.393847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:50.393997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:50.940113 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:51.394559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:52.394755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:52.943963 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:53.395503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:54.395777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:54.947394 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:55.395909      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:56.396268      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:56.951450 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:57.396978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:20:58.397138      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:20:58.955384 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:20:59.398021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:00.398197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:00.959854 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:01.398270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:02.398476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:02.963851 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:03.399381      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:04.399791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:04.968706 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:05.400082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:06.400234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:06.972856 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:07.400349      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:08.400528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:08.976903 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:09.401542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:10.401698      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:10.980863 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:11.402014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:12.402178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:12.985957 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:13.402301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:14.402522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:14.990462 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:15.402790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:16.402929      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:16.994173 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:17.403678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:18.403829      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:18.998102 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:19.404709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:20.404844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:21.003622 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:21.405068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:22.405236      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:23.007202 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:23.405234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:24.405374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:25.011808 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:25.406242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:26.406413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:27.015487 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:27.406979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:28.407128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:29.018697 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:29.407252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:30.407417      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:31.022828 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:31.408300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:32.408478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:33.027524 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:33.409020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:34.409266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:35.032139 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:35.409506      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:36.409669      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:37.035561 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:37.409955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:38.410066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:39.039345 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:39.410947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:40.411121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:41.044309 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:41.411742      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:42.411859      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:43.047988 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:43.412400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:44.412830      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:45.051901 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:45.413350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:46.413474      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:47.055680 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:47.414123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:48.414297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:49.059496 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:49.415094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:50.415266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:51.063947 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:51.415341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:52.415492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:53.068124 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:53.416413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:54.416807      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:55.074052 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:55.417028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:56.417157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:57.079668 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:57.418075      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:21:58.418217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:21:59.083794 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:21:59.418348      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:00.418502      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:01.087903 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:01.419288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:02.419429      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:03.091832 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:03.420203      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:04.420319      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:05.095684 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:05.421125      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:06.421289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:07.099370 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:07.421547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:08.421786      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:09.103567 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:09.422016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:10.422176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:11.107794 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:11.422166      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:12.422299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:13.111880 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:13.423276      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:14.423409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:15.115993 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:15.424415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:16.424548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:17.119932 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:17.425396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:18.425500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:19.124747 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:19.426376      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:20.426537      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:21.128785 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:21.427220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:22.427351      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:23.131908 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:23.428314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:24.428613      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:25.135435 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:25.428752      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:26.428868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:27.139375 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:27.429729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:28.429882      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:29.144216 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:29.430581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:30.430711      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:31.148054 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:31.431462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:32.431625      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:33.152018 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:33.432439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:34.432743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:35.156611 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:35.432889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:36.433003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:37.161436 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:37.433793      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:38.433989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:39.166103 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:39.434546      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:40.434730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:41.171091 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:41.435479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:42.435601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:43.174969 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:43.436364      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:44.436713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:45.179497 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:45.436764      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:46.436919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:47.183496 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:47.437913      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:48.438017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:49.188072 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:49.438330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:50.438467      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:51.192841 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:51.439128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:52.439285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:53.196956 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:53.440341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:54.440722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:55.200926 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:55.441285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:56.441436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:57.204807 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:57.442089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:22:58.442233      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:22:59.209130 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:22:59.442368      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:00.442486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:01.213128 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:01.443472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:02.443598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:03.217306 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:03.444666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:04.444944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:05.221213 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:05.445571      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:06.445712      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:07.225479 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:07.446749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:08.446888      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:09.229718 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:09.446960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:10.447086      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:11.233896 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:11.447148      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:12.448046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:13.237172 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:13.448465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:14.448782      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:15.241079 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:15.449382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:16.449538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:17.244831 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:17.450135      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:18.450281      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:19.249053 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:19.450289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:20.450432      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:21.253265 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:21.450530      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:22.450708      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:23.257008 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:23.451247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:24.451553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:25.260844 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:25.452098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:26.452256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:27.265065 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:27.452292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:28.452458      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:29.269305 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:29.452481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:30.452651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:31.273498 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:31.452738      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:32.452895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:33.277077 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:33.453335      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:34.453647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:35.281500 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:35.453718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:36.453872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:37.285060 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:37.454304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:38.454451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:39.289259 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:39.455448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:40.455649      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:41.295159 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:41.456398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:42.456642      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:43.299134 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:43.457441      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:44.457777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:45.303789 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:45.457912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:46.458070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:47.307210 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:47.458437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:48.458581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:49.311171 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:49.459403      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:50.459565      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:51.315048 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:51.460321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:52.460484      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:53.318741 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:53.460986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:54.461248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:55.322573 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:55.461774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:56.461937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:57.326791 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:57.462961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:23:58.463111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:23:59.331231 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:23:59.463469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:00.463644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:01.335160 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:24:01.464369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:02.464532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:03.338896 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:24:03.464990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:04.465313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:05.343439 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:24:05.465667      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:06.465816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:07.347840 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:24:07.466141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:08.466116      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:09.352252 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:24:09.466352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:10.466532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:11.356716 23 container_probe.go:1759] Get pod test-grpc-f523243e-3e9a-4fd6-b9fc-80ff9c4caf53 in namespace container-probe-8952
  E0502 09:24:11.466944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:12.467115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/02/24 09:24:13.357
  I0502 09:24:13.370902 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8952" for this suite. @ 05/02/24 09:24:13.377
• [242.572 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 05/02/24 09:24:13.391
  I0502 09:24:13.391245 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 09:24:13.391
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:24:13.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:24:13.42
  STEP: Create set of pods @ 05/02/24 09:24:13.423
  I0502 09:24:13.433635 23 pods.go:871] created test-pod-1
  I0502 09:24:13.439656 23 pods.go:871] created test-pod-2
  I0502 09:24:13.448174 23 pods.go:871] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 05/02/24 09:24:13.448
  E0502 09:24:13.467224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:14.467740      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:15.467862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 05/02/24 09:24:15.499
  I0502 09:24:15.502416 23 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  E0502 09:24:16.468400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:16.504374 23 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  E0502 09:24:17.469305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:17.504231 23 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  E0502 09:24:18.470162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:18.504313 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9629" for this suite. @ 05/02/24 09:24:18.507
• [5.124 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 05/02/24 09:24:18.514
  I0502 09:24:18.514870 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename statefulset @ 05/02/24 09:24:18.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:24:18.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:24:18.543
  STEP: Creating service test in namespace statefulset-5683 @ 05/02/24 09:24:18.544
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 05/02/24 09:24:18.549
  STEP: Creating stateful set ss in namespace statefulset-5683 @ 05/02/24 09:24:18.551
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5683 @ 05/02/24 09:24:18.557
  I0502 09:24:18.560520 23 wait.go:40] Found 0 stateful pods, waiting for 1
  E0502 09:24:19.470800      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:20.471706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:21.471905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:22.472067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:23.472208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:24.472383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:25.472535      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:26.472701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:27.472864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:28.472963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:28.563082 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 05/02/24 09:24:28.563
  I0502 09:24:28.568184 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5683 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 09:24:28.651660 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 09:24:28.651697 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 09:24:28.651723 23 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0502 09:24:28.656086 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0502 09:24:29.473536      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:30.473668      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:31.473779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:32.473866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:33.473968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:34.474100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:35.474238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:36.474396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:37.474551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:38.474685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:38.656302 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0502 09:24:38.656336 23 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0502 09:24:38.675411 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 9.9999999s
  E0502 09:24:39.475481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:39.680383 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 8.993289783s
  E0502 09:24:40.476207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:40.684565 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 7.988481645s
  E0502 09:24:41.476346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:41.688932 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 6.98428805s
  E0502 09:24:42.476749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:42.693971 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 5.979926372s
  E0502 09:24:43.477774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:43.698668 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 4.974867099s
  E0502 09:24:44.478626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:44.711639 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 3.970077209s
  E0502 09:24:45.479403      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:45.716610 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 2.957222398s
  E0502 09:24:46.479472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:46.721437 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 1.95222382s
  E0502 09:24:47.480141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:47.726070 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 947.508893ms
  E0502 09:24:48.480829      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5683 @ 05/02/24 09:24:48.726
  I0502 09:24:48.730550 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5683 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0502 09:24:48.813049 23 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0502 09:24:48.813072 23 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0502 09:24:48.813080 23 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0502 09:24:48.816310 23 wait.go:40] Found 1 stateful pods, waiting for 3
  E0502 09:24:49.481318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:50.481477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:51.481561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:52.481713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:53.481865      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:54.482081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:55.482213      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:56.482398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:57.482551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:24:58.482705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:24:58.817117 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0502 09:24:58.817132 23 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0502 09:24:58.817151 23 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 05/02/24 09:24:58.817
  STEP: Scale down will halt with unhealthy stateful pod @ 05/02/24 09:24:58.817
  I0502 09:24:58.824523 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5683 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 09:24:58.907255 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 09:24:58.907281 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 09:24:58.907289 23 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0502 09:24:58.907318 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5683 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 09:24:59.016240 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 09:24:59.016263 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 09:24:59.016271 23 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0502 09:24:59.016298 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5683 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0502 09:24:59.092765 23 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0502 09:24:59.092793 23 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0502 09:24:59.092801 23 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0502 09:24:59.092807 23 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0502 09:24:59.096372 23 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0502 09:24:59.482949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:00.483984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:01.484163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:02.484342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:03.484498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:04.484812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:05.484992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:06.485159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:07.485289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:08.485461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:09.099515 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0502 09:25:09.099537 23 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0502 09:25:09.099556 23 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0502 09:25:09.114042 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 9.999999894s
  E0502 09:25:09.485554      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:10.118364 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 8.99325948s
  E0502 09:25:10.485737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:11.121969 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 7.989016325s
  E0502 09:25:11.486367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:12.126880 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 6.985387755s
  E0502 09:25:12.487332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:13.132008 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 5.980435652s
  E0502 09:25:13.487426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:14.136270 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 4.975360788s
  E0502 09:25:14.487757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:15.141014 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 3.971029188s
  E0502 09:25:15.488420      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:16.145227 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 2.9663499s
  E0502 09:25:16.488542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:17.150210 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 1.962254516s
  E0502 09:25:17.488586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:18.157510 23 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 957.153879ms
  E0502 09:25:18.488866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5683 @ 05/02/24 09:25:19.158
  I0502 09:25:19.162894 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5683 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0502 09:25:19.249516 23 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0502 09:25:19.249540 23 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0502 09:25:19.249547 23 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0502 09:25:19.249571 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5683 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0502 09:25:19.330790 23 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0502 09:25:19.330816 23 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0502 09:25:19.330825 23 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0502 09:25:19.330851 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=statefulset-5683 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0502 09:25:19.410167 23 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0502 09:25:19.410190 23 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0502 09:25:19.410198 23 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0502 09:25:19.410206 23 rest.go:150] Scaling statefulset ss to 0
  E0502 09:25:19.489115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:20.489821      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:21.490825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:22.491544      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:23.491678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:24.491892      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:25.492038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:26.492177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:27.492350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:28.492493      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 05/02/24 09:25:29.425
  I0502 09:25:29.425383 23 statefulset.go:135] Deleting all statefulset in ns statefulset-5683
  I0502 09:25:29.428931 23 rest.go:150] Scaling statefulset ss to 0
  I0502 09:25:29.440521 23 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0502 09:25:29.443667 23 rest.go:88] Deleting statefulset ss
  I0502 09:25:29.458800 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5683" for this suite. @ 05/02/24 09:25:29.463
• [70.958 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 05/02/24 09:25:29.472
  I0502 09:25:29.472685 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 09:25:29.473
  E0502 09:25:29.493171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:25:29.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:25:29.502
  STEP: creating the pod @ 05/02/24 09:25:29.503
  STEP: submitting the pod to kubernetes @ 05/02/24 09:25:29.504
  W0502 09:25:29.512513      23 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0502 09:25:30.493595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:31.493870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/02/24 09:25:31.526
  STEP: updating the pod @ 05/02/24 09:25:31.53
  I0502 09:25:32.044899 23 pod_client.go:141] Successfully updated pod "pod-update-activedeadlineseconds-c83fa2ad-8ca7-4820-988f-0cd60270b7ec"
  E0502 09:25:32.493968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:33.494123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:34.494716      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:35.494915      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:25:36.057599 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5040" for this suite. @ 05/02/24 09:25:36.061
• [6.599 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 05/02/24 09:25:36.071
  I0502 09:25:36.071583 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-preemption @ 05/02/24 09:25:36.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:25:36.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:25:36.101
  I0502 09:25:36.116117 23 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0502 09:25:36.495634      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:37.495844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:38.496886      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:39.497152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:40.497757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:41.497928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:42.498661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:43.498792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:44.499638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:45.499795      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:46.500450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:47.500583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:48.501481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:49.502008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:50.502892      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:51.503025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:52.503201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:53.503298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:54.504238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:55.504337      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:56.505156      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:57.506105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:58.506957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:25:59.507320      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:00.508308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:01.508442      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:02.508675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:03.508825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:04.508957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:05.509092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:06.509889      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:07.510069      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:08.510934      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:09.511285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:10.511629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:11.511801      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:12.512717      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:13.512877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:14.513891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:15.514050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:16.514204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:17.515051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:18.515477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:19.515822      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:20.516733      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:21.516865      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:22.517607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:23.517754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:24.518032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:25.518155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:26.518289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:27.518391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:28.519163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:29.519590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:30.520616      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:31.520747      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:32.521095      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:33.521256      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:34.522100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:35.522255      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:26:36.121898 23 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/02/24 09:26:36.125
  I0502 09:26:36.125164 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/02/24 09:26:36.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:26:36.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:26:36.145
  I0502 09:26:36.161350 23 preemption.go:818] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0502 09:26:36.164350 23 preemption.go:824] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  I0502 09:26:36.230662 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2816" for this suite. @ 05/02/24 09:26:36.233
  I0502 09:26:36.239957 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-610" for this suite. @ 05/02/24 09:26:36.243
• [60.179 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 05/02/24 09:26:36.25
  I0502 09:26:36.250759 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename gc @ 05/02/24 09:26:36.251
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:26:36.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:26:36.283
  I0502 09:26:36.326810 23 garbage_collector.go:840] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3b32d1be-4f84-446b-87a1-ed2bb9bb7caa", Controller:(*bool)(0xc003781c7e), BlockOwnerDeletion:(*bool)(0xc003781c7f)}}
  I0502 09:26:36.336781 23 garbage_collector.go:844] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"7c521d4a-0e65-4079-b859-d0d22e27a5d4", Controller:(*bool)(0xc003308e86), BlockOwnerDeletion:(*bool)(0xc003308e87)}}
  I0502 09:26:36.343064 23 garbage_collector.go:848] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f859c87b-45e2-4faf-97d8-a79303dd06da", Controller:(*bool)(0xc00330912e), BlockOwnerDeletion:(*bool)(0xc00330912f)}}
  E0502 09:26:36.523149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:37.523303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:38.523416      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:39.523782      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:40.523955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:26:41.356754 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2522" for this suite. @ 05/02/24 09:26:41.361
• [5.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 05/02/24 09:26:41.375
  I0502 09:26:41.375049 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename sched-preemption @ 05/02/24 09:26:41.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:26:41.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:26:41.401
  I0502 09:26:41.416982 23 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0502 09:26:41.524332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:42.524552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:43.524627      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:44.525607      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:45.526490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:46.526684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:47.527387      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:48.527525      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:49.528339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:50.528506      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:51.528719      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:52.528881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:53.529470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:54.529744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:55.530078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:56.530228      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:57.530218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:58.530373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:26:59.531332      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:00.532082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:01.532272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:02.532433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:03.533267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:04.533421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:05.534187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:06.534339      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:07.535131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:08.535270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:09.535877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:10.536045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:11.536194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:12.536557      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:13.537188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:14.537291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:15.537552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:16.537717      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:17.538199      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:18.538324      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:19.538405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:20.538550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:21.538773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:22.538984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:23.539944      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:24.540181      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:25.540202      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:26.540352      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:27.540925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:28.541103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:29.541930      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:30.542064      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:31.542160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:32.542396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:33.543392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:34.543744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:35.544540      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:36.544687      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:37.545242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:38.545395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:39.545646      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:40.545811      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:27:41.423365 23 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/02/24 09:27:41.426
  I0502 09:27:41.448946 23 preemption.go:269] Created pod: pod0-0-sched-preemption-low-priority
  I0502 09:27:41.468065 23 preemption.go:269] Created pod: pod0-1-sched-preemption-medium-priority
  I0502 09:27:41.492348 23 preemption.go:269] Created pod: pod1-0-sched-preemption-medium-priority
  I0502 09:27:41.500543 23 preemption.go:269] Created pod: pod1-1-sched-preemption-medium-priority
  I0502 09:27:41.519912 23 preemption.go:269] Created pod: pod2-0-sched-preemption-medium-priority
  I0502 09:27:41.528143 23 preemption.go:269] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/02/24 09:27:41.528
  E0502 09:27:41.546315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:42.546427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:43.546898      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:44.547932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:45.548076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 05/02/24 09:27:45.56
  E0502 09:27:46.548135      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:47.548275      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:48.548785      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:49.549074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:27:49.676003 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6523" for this suite. @ 05/02/24 09:27:49.69
• [68.385 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1420
  STEP: Creating a kubernetes client @ 05/02/24 09:27:49.759
  I0502 09:27:49.759937 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 09:27:49.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:27:49.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:27:49.846
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1636 @ 05/02/24 09:27:49.849
  STEP: changing the ExternalName service to type=ClusterIP @ 05/02/24 09:27:49.853
  STEP: creating replication controller externalname-service in namespace services-1636 @ 05/02/24 09:27:49.871
  I0502 09:27:49.886047      23 runners.go:198] Created replication controller with name: externalname-service, namespace: services-1636, replica count: 2
  E0502 09:27:50.549825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:51.550760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:52.550844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:27:52.937421      23 runners.go:198] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0502 09:27:52.937435 23 resource.go:361] Creating new exec pod
  E0502 09:27:53.551741      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:54.552182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:27:55.553214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:27:55.952813 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1636 exec execpodkqqt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0502 09:27:56.025794 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0502 09:27:56.025821 23 builder.go:147] stdout: ""
  E0502 09:27:56.553386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:27:56.952944 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1636 exec execpodkqqt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0502 09:27:57.037663 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0502 09:27:57.037686 23 builder.go:147] stdout: ""
  E0502 09:27:57.553434      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:27:57.952946 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1636 exec execpodkqqt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0502 09:27:58.025549 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0502 09:27:58.025573 23 builder.go:147] stdout: "externalname-service-lb82b"
  I0502 09:27:58.025617 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1636 exec execpodkqqt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.109.123.47 80'
  I0502 09:27:58.090648 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.109.123.47 80\nConnection to 10.109.123.47 80 port [tcp/http] succeeded!\n"
  I0502 09:27:58.090674 23 builder.go:147] stdout: ""
  E0502 09:27:58.554263      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:27:59.025994 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1636 exec execpodkqqt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.109.123.47 80'
  I0502 09:27:59.112344 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.109.123.47 80\nConnection to 10.109.123.47 80 port [tcp/http] succeeded!\n"
  I0502 09:27:59.112369 23 builder.go:147] stdout: ""
  E0502 09:27:59.555081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:28:00.025709 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-1636 exec execpodkqqt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.109.123.47 80'
  I0502 09:28:00.110990 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.109.123.47 80\nConnection to 10.109.123.47 80 port [tcp/http] succeeded!\n"
  I0502 09:28:00.111014 23 builder.go:147] stdout: "externalname-service-lb82b"
  I0502 09:28:00.111057 23 service.go:1429] Cleaning up the ExternalName to ClusterIP test service
  I0502 09:28:00.137779 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1636" for this suite. @ 05/02/24 09:28:00.142
• [10.393 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 05/02/24 09:28:00.152
  I0502 09:28:00.152580 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename namespaces @ 05/02/24 09:28:00.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:28:00.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:28:00.179
  STEP: Read namespace status @ 05/02/24 09:28:00.18
  I0502 09:28:00.183188 23 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 05/02/24 09:28:00.183
  I0502 09:28:00.189571 23 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 05/02/24 09:28:00.189
  I0502 09:28:00.197096 23 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0502 09:28:00.197133 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1900" for this suite. @ 05/02/24 09:28:00.2
• [0.058 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 05/02/24 09:28:00.211
  I0502 09:28:00.211124 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename apf @ 05/02/24 09:28:00.211
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:28:00.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:28:00.228
  STEP: getting /apis @ 05/02/24 09:28:00.23
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/02/24 09:28:00.233
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/02/24 09:28:00.234
  STEP: creating @ 05/02/24 09:28:00.234
  STEP: getting @ 05/02/24 09:28:00.246
  STEP: listing @ 05/02/24 09:28:00.249
  STEP: watching @ 05/02/24 09:28:00.251
  I0502 09:28:00.251700 23 flowcontrol.go:620] starting watch
  STEP: patching @ 05/02/24 09:28:00.252
  STEP: updating @ 05/02/24 09:28:00.258
  I0502 09:28:00.267307 23 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 05/02/24 09:28:00.267
  STEP: patching /status @ 05/02/24 09:28:00.27
  STEP: updating /status @ 05/02/24 09:28:00.275
  STEP: deleting @ 05/02/24 09:28:00.283
  STEP: deleting a collection @ 05/02/24 09:28:00.296
  I0502 09:28:00.314664 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-3657" for this suite. @ 05/02/24 09:28:00.318
• [0.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 05/02/24 09:28:00.325
  I0502 09:28:00.325458 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename subpath @ 05/02/24 09:28:00.325
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:28:00.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:28:00.351
  STEP: Setting up data @ 05/02/24 09:28:00.353
  STEP: Creating pod pod-subpath-test-projected-8b2f @ 05/02/24 09:28:00.363
  STEP: Creating a pod to test atomic-volume-subpath @ 05/02/24 09:28:00.363
  E0502 09:28:00.555519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:01.555689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:02.556725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:03.556890      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:04.557692      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:05.557871      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:06.557917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:07.558070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:08.558373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:09.558757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:10.559188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:11.559374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:12.559869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:13.559957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:14.560520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:15.560652      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:16.561452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:17.561608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:18.562306      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:19.562721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:20.563039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:21.563197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:22.563517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:23.563637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:28:24.425
  I0502 09:28:24.428195 23 output.go:196] Trying to get logs from node mini-2 pod pod-subpath-test-projected-8b2f container test-container-subpath-projected-8b2f: <nil>
  STEP: delete the pod @ 05/02/24 09:28:24.439
  STEP: Deleting pod pod-subpath-test-projected-8b2f @ 05/02/24 09:28:24.451
  I0502 09:28:24.451963 23 delete.go:62] Deleting pod "pod-subpath-test-projected-8b2f" in namespace "subpath-83"
  I0502 09:28:24.454631 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-83" for this suite. @ 05/02/24 09:28:24.458
• [24.141 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:154
  STEP: Creating a kubernetes client @ 05/02/24 09:28:24.466
  I0502 09:28:24.466789 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/02/24 09:28:24.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:28:24.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:28:24.49
  I0502 09:28:24.492508 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 09:28:24.564154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:25.565085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:26.566136      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/02/24 09:28:27.197
  I0502 09:28:27.197973 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-9929 --namespace=crd-publish-openapi-9929 create -f -'
  I0502 09:28:27.257272 23 builder.go:146] stderr: ""
  I0502 09:28:27.257308 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-4528-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0502 09:28:27.257345 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-9929 --namespace=crd-publish-openapi-9929 delete e2e-test-crd-publish-openapi-4528-crds test-cr'
  I0502 09:28:27.324917 23 builder.go:146] stderr: ""
  I0502 09:28:27.324940 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-4528-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I0502 09:28:27.324965 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-9929 --namespace=crd-publish-openapi-9929 apply -f -'
  I0502 09:28:27.374029 23 builder.go:146] stderr: ""
  I0502 09:28:27.374053 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-4528-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0502 09:28:27.374076 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-9929 --namespace=crd-publish-openapi-9929 delete e2e-test-crd-publish-openapi-4528-crds test-cr'
  I0502 09:28:27.416250 23 builder.go:146] stderr: ""
  I0502 09:28:27.416278 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-4528-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 05/02/24 09:28:27.416
  I0502 09:28:27.416332 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-9929 explain e2e-test-crd-publish-openapi-4528-crds'
  I0502 09:28:27.450682 23 builder.go:146] stderr: ""
  I0502 09:28:27.450715 23 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-4528-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0502 09:28:27.567022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:28.567820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:29.567970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:28:29.681818 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9929" for this suite. @ 05/02/24 09:28:29.688
• [5.228 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:601
  STEP: Creating a kubernetes client @ 05/02/24 09:28:29.695
  I0502 09:28:29.695258 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename job @ 05/02/24 09:28:29.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:28:29.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:28:29.719
  STEP: Creating a job @ 05/02/24 09:28:29.722
  STEP: Ensuring job reaches completions @ 05/02/24 09:28:29.727
  E0502 09:28:30.568699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:31.568850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:32.569089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:33.569239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:34.569532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:35.569696      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:36.570447      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:37.570621      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:38.571228      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:39.571754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:28:39.732476 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2337" for this suite. @ 05/02/24 09:28:39.736
• [10.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 05/02/24 09:28:39.745
  I0502 09:28:39.745130 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename field-validation @ 05/02/24 09:28:39.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:28:39.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:28:39.765
  STEP: apply creating a deployment @ 05/02/24 09:28:39.767
  I0502 09:28:39.783575 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3829" for this suite. @ 05/02/24 09:28:39.786
• [0.048 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 05/02/24 09:28:39.792
  I0502 09:28:39.792926 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 09:28:39.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:28:39.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:28:39.816
  STEP: Counting existing ResourceQuota @ 05/02/24 09:28:39.818
  E0502 09:28:40.572051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:41.572248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:42.573160      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:43.573541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:44.573984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/02/24 09:28:44.824
  STEP: Ensuring resource quota status is calculated @ 05/02/24 09:28:44.83
  E0502 09:28:45.574022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:46.574178      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 05/02/24 09:28:46.834
  STEP: Ensuring resource quota status captures replicaset creation @ 05/02/24 09:28:46.845
  E0502 09:28:47.574555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:48.574698      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 05/02/24 09:28:48.849
  STEP: Ensuring resource quota status released usage @ 05/02/24 09:28:48.854
  E0502 09:28:49.575586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:50.575752      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:28:50.859206 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7762" for this suite. @ 05/02/24 09:28:50.863
• [11.078 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3572
  STEP: Creating a kubernetes client @ 05/02/24 09:28:50.87
  I0502 09:28:50.870936 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 09:28:50.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:28:50.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:28:50.893
  STEP: creating a collection of services @ 05/02/24 09:28:50.895
  I0502 09:28:50.895592 23 service.go:3608] Creating e2e-svc-a-fphrw
  I0502 09:28:50.909611 23 service.go:3608] Creating e2e-svc-b-qcmb9
  I0502 09:28:50.932584 23 service.go:3608] Creating e2e-svc-c-6qffk
  STEP: deleting service collection @ 05/02/24 09:28:50.959
  I0502 09:28:51.000394 23 service.go:3643] Collection of services has been deleted
  I0502 09:28:51.000444 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-605" for this suite. @ 05/02/24 09:28:51.004
• [0.140 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 05/02/24 09:28:51.011
  I0502 09:28:51.011289 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/02/24 09:28:51.011
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:28:51.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:28:51.03
  STEP: create the container to handle the HTTPGet hook request. @ 05/02/24 09:28:51.038
  E0502 09:28:51.576588      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:52.576785      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:53.576840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:54.577122      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/02/24 09:28:55.068
  E0502 09:28:55.577131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:56.577552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/02/24 09:28:57.088
  STEP: delete the pod with lifecycle hook @ 05/02/24 09:28:57.093
  E0502 09:28:57.578456      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:58.578604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:28:59.578957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:00.579158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:01.112324 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6304" for this suite. @ 05/02/24 09:29:01.116
• [10.112 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 05/02/24 09:29:01.123
  I0502 09:29:01.123822 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 09:29:01.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:01.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:01.145
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 09:29:01.147
  E0502 09:29:01.579974      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:02.580281      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:03.580869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:04.581098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:29:05.17
  I0502 09:29:05.173898 23 output.go:196] Trying to get logs from node mini-1 pod downwardapi-volume-60a8e63e-284a-435b-94f1-60e63bdf6e64 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 09:29:05.185
  I0502 09:29:05.198507 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-523" for this suite. @ 05/02/24 09:29:05.201
• [4.085 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 05/02/24 09:29:05.208
  I0502 09:29:05.208506 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename svcaccounts @ 05/02/24 09:29:05.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:05.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:05.227
  STEP: Creating a pod to test service account token:  @ 05/02/24 09:29:05.229
  E0502 09:29:05.582082      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:06.582222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:07.583157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:08.583316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:29:09.247
  I0502 09:29:09.250645 23 output.go:196] Trying to get logs from node mini-1 pod test-pod-014a6f15-7272-4745-8a20-4b30723ab74c container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 09:29:09.255
  I0502 09:29:09.269293 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9563" for this suite. @ 05/02/24 09:29:09.272
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 05/02/24 09:29:09.278
  I0502 09:29:09.278729 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir @ 05/02/24 09:29:09.279
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:09.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:09.3
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/02/24 09:29:09.302
  E0502 09:29:09.583401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:10.583585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:11.584519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:12.584660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:29:13.324
  I0502 09:29:13.327828 23 output.go:196] Trying to get logs from node mini-1 pod pod-216e3fc3-b033-4f12-9e82-f29c94397ed4 container test-container: <nil>
  STEP: delete the pod @ 05/02/24 09:29:13.332
  I0502 09:29:13.345277 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7067" for this suite. @ 05/02/24 09:29:13.348
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 05/02/24 09:29:13.356
  I0502 09:29:13.356781 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 09:29:13.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:13.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:13.376
  STEP: Setting up server cert @ 05/02/24 09:29:13.402
  E0502 09:29:13.584823      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 09:29:13.701
  STEP: Deploying the webhook pod @ 05/02/24 09:29:13.709
  STEP: Wait for the deployment to be ready @ 05/02/24 09:29:13.72
  I0502 09:29:13.732925 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 09:29:14.584978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:15.585098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 09:29:15.742
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 09:29:15.757
  E0502 09:29:16.585916      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:16.757355 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 05/02/24 09:29:16.768
  STEP: Creating a custom resource definition that should be denied by the webhook @ 05/02/24 09:29:16.78
  I0502 09:29:16.780706 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 09:29:16.855916 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1708" for this suite. @ 05/02/24 09:29:16.86
  STEP: Destroying namespace "webhook-markers-3569" for this suite. @ 05/02/24 09:29:16.868
• [3.521 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3345
  STEP: Creating a kubernetes client @ 05/02/24 09:29:16.877
  I0502 09:29:16.877703 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 09:29:16.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:16.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:16.902
  STEP: creating a Service @ 05/02/24 09:29:16.907
  STEP: watching for the Service to be added @ 05/02/24 09:29:16.924
  I0502 09:29:16.926661 23 service.go:3397] Found Service test-service-hlrf7 in namespace services-5820 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 30467}]
  I0502 09:29:16.926677 23 service.go:3404] Service test-service-hlrf7 created
  STEP: Getting /status @ 05/02/24 09:29:16.926
  I0502 09:29:16.929589 23 service.go:3415] Service test-service-hlrf7 has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 05/02/24 09:29:16.929
  STEP: watching for the Service to be patched @ 05/02/24 09:29:16.935
  I0502 09:29:16.936564 23 service.go:3438] observed Service test-service-hlrf7 in namespace services-5820 with annotations: map[] & LoadBalancer: {[]}
  I0502 09:29:16.936580 23 service.go:3441] Found Service test-service-hlrf7 in namespace services-5820 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc0047ee1c0 []}]}
  I0502 09:29:16.936587 23 service.go:3448] Service test-service-hlrf7 has service status patched
  STEP: updating the ServiceStatus @ 05/02/24 09:29:16.936
  I0502 09:29:16.944453 23 service.go:3468] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 05/02/24 09:29:16.944
  I0502 09:29:16.945793 23 service.go:3479] Observed Service test-service-hlrf7 in namespace services-5820 with annotations: map[] & Conditions: {[]}
  I0502 09:29:16.945892 23 service.go:3494] Observed event: &Service{ObjectMeta:{test-service-hlrf7  services-5820  31cfaf7a-954b-43a9-9b90-7121d33139c7 39407 0 2024-05-02 09:29:16 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-05-02 09:29:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-05-02 09:29:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:30467,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.106.22.167,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.106.22.167],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,TrafficDistribution:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:*VIP,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  I0502 09:29:16.945915 23 service.go:3486] Found Service test-service-hlrf7 in namespace services-5820 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0502 09:29:16.945921 23 service.go:3498] Service test-service-hlrf7 has service status updated
  STEP: patching the service @ 05/02/24 09:29:16.945
  STEP: watching for the Service to be patched @ 05/02/24 09:29:16.958
  I0502 09:29:16.959775 23 service.go:3521] observed Service test-service-hlrf7 in namespace services-5820 with labels: map[test-service-static:true]
  I0502 09:29:16.959838 23 service.go:3521] observed Service test-service-hlrf7 in namespace services-5820 with labels: map[test-service-static:true]
  I0502 09:29:16.959847 23 service.go:3521] observed Service test-service-hlrf7 in namespace services-5820 with labels: map[test-service-static:true]
  I0502 09:29:16.959857 23 service.go:3524] Found Service test-service-hlrf7 in namespace services-5820 with labels: map[test-service:patched test-service-static:true]
  I0502 09:29:16.959866 23 service.go:3531] Service test-service-hlrf7 patched
  STEP: deleting the service @ 05/02/24 09:29:16.959
  STEP: watching for the Service to be deleted @ 05/02/24 09:29:16.986
  I0502 09:29:16.987314 23 service.go:3555] Observed event: ADDED
  I0502 09:29:16.987326 23 service.go:3555] Observed event: MODIFIED
  I0502 09:29:16.987333 23 service.go:3555] Observed event: MODIFIED
  I0502 09:29:16.987358 23 service.go:3555] Observed event: MODIFIED
  I0502 09:29:16.987379 23 service.go:3551] Found Service test-service-hlrf7 in namespace services-5820 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0502 09:29:16.987392 23 service.go:3560] Service test-service-hlrf7 deleted
  I0502 09:29:16.987430 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5820" for this suite. @ 05/02/24 09:29:16.99
• [0.120 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 05/02/24 09:29:16.997
  I0502 09:29:16.997372 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/02/24 09:29:16.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:17.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:17.015
  STEP: create the container to handle the HTTPGet hook request. @ 05/02/24 09:29:17.02
  E0502 09:29:17.586007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:18.586238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/02/24 09:29:19.037
  E0502 09:29:19.587029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:20.587184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/02/24 09:29:21.055
  E0502 09:29:21.588230      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:22.588384      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:23.588447      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:24.588751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/02/24 09:29:25.075
  I0502 09:29:25.088331 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5097" for this suite. @ 05/02/24 09:29:25.092
• [8.102 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 05/02/24 09:29:25.099
  I0502 09:29:25.099613 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:29:25.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:25.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:25.12
  I0502 09:29:25.161117 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1135" for this suite. @ 05/02/24 09:29:25.167
• [0.077 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:195
  STEP: Creating a kubernetes client @ 05/02/24 09:29:25.176
  I0502 09:29:25.176728 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/02/24 09:29:25.177
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:25.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:25.2
  I0502 09:29:25.202388 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  E0502 09:29:25.589819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:26.590685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:27.591603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/02/24 09:29:27.84
  I0502 09:29:27.840295 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-1245 --namespace=crd-publish-openapi-1245 create -f -'
  I0502 09:29:27.919875 23 builder.go:146] stderr: ""
  I0502 09:29:27.919906 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6238-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0502 09:29:27.919940 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-1245 --namespace=crd-publish-openapi-1245 delete e2e-test-crd-publish-openapi-6238-crds test-cr'
  I0502 09:29:27.969808 23 builder.go:146] stderr: ""
  I0502 09:29:27.969833 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6238-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I0502 09:29:27.969864 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-1245 --namespace=crd-publish-openapi-1245 apply -f -'
  I0502 09:29:28.014906 23 builder.go:146] stderr: ""
  I0502 09:29:28.014929 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6238-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0502 09:29:28.014960 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-1245 --namespace=crd-publish-openapi-1245 delete e2e-test-crd-publish-openapi-6238-crds test-cr'
  I0502 09:29:28.055133 23 builder.go:146] stderr: ""
  I0502 09:29:28.055160 23 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6238-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/02/24 09:29:28.055
  I0502 09:29:28.055223 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=crd-publish-openapi-1245 explain e2e-test-crd-publish-openapi-6238-crds'
  I0502 09:29:28.089459 23 builder.go:146] stderr: ""
  I0502 09:29:28.089497 23 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-6238-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0502 09:29:28.591981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:29.592234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:30.253100 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1245" for this suite. @ 05/02/24 09:29:30.264
• [5.100 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 05/02/24 09:29:30.276
  I0502 09:29:30.276699 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:29:30.277
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:30.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:30.305
  STEP: Creating secret with name secret-test-72bfa991-2e9e-4fe6-9704-fd1fbcbe55de @ 05/02/24 09:29:30.308
  STEP: Creating a pod to test consume secrets @ 05/02/24 09:29:30.313
  E0502 09:29:30.593250      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:31.593564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:32.594383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:33.594527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:29:34.337
  I0502 09:29:34.339904 23 output.go:196] Trying to get logs from node mini-1 pod pod-secrets-8b9bb745-cab7-4e11-968f-80cfa6a3e93e container secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:29:34.348
  I0502 09:29:34.361046 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6536" for this suite. @ 05/02/24 09:29:34.364
• [4.094 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 05/02/24 09:29:34.37
  I0502 09:29:34.370792 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename svc-latency @ 05/02/24 09:29:34.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:34.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:34.392
  I0502 09:29:34.393947 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-269 @ 05/02/24 09:29:34.394
  I0502 09:29:34.398495      23 runners.go:198] Created replication controller with name: svc-latency-rc, namespace: svc-latency-269, replica count: 1
  E0502 09:29:34.595022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:35.450317      23 runners.go:198] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0502 09:29:35.595643      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:36.450448      23 runners.go:198] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0502 09:29:36.568254 23 service_latency.go:356] Created: latency-svc-t45vx
  I0502 09:29:36.570317 23 service_latency.go:363] Got endpoints: latency-svc-t45vx [19.286ms]
  I0502 09:29:36.589004 23 service_latency.go:356] Created: latency-svc-ttdn6
  E0502 09:29:36.596040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:36.600052 23 service_latency.go:363] Got endpoints: latency-svc-ttdn6 [29.658798ms]
  I0502 09:29:36.608206 23 service_latency.go:356] Created: latency-svc-mzzqx
  I0502 09:29:36.621533 23 service_latency.go:363] Got endpoints: latency-svc-mzzqx [51.148502ms]
  I0502 09:29:36.629916 23 service_latency.go:356] Created: latency-svc-p899z
  I0502 09:29:36.637154 23 service_latency.go:363] Got endpoints: latency-svc-p899z [66.739979ms]
  I0502 09:29:36.639089 23 service_latency.go:356] Created: latency-svc-lnfbk
  I0502 09:29:36.654047 23 service_latency.go:356] Created: latency-svc-8f84p
  I0502 09:29:36.655484 23 service_latency.go:363] Got endpoints: latency-svc-lnfbk [85.070776ms]
  I0502 09:29:36.661006 23 service_latency.go:363] Got endpoints: latency-svc-8f84p [90.603087ms]
  I0502 09:29:36.671218 23 service_latency.go:356] Created: latency-svc-2kvcx
  I0502 09:29:36.676248 23 service_latency.go:363] Got endpoints: latency-svc-2kvcx [105.797688ms]
  I0502 09:29:36.687501 23 service_latency.go:356] Created: latency-svc-mxj8z
  I0502 09:29:36.697072 23 service_latency.go:363] Got endpoints: latency-svc-mxj8z [126.610342ms]
  I0502 09:29:36.699902 23 service_latency.go:356] Created: latency-svc-bsgt5
  I0502 09:29:36.709712 23 service_latency.go:363] Got endpoints: latency-svc-bsgt5 [139.230386ms]
  I0502 09:29:36.717195 23 service_latency.go:356] Created: latency-svc-8rjpg
  I0502 09:29:36.726301 23 service_latency.go:363] Got endpoints: latency-svc-8rjpg [155.812443ms]
  I0502 09:29:36.728415 23 service_latency.go:356] Created: latency-svc-9dxbq
  I0502 09:29:36.739743 23 service_latency.go:363] Got endpoints: latency-svc-9dxbq [169.25024ms]
  I0502 09:29:36.742286 23 service_latency.go:356] Created: latency-svc-jznpp
  I0502 09:29:36.751523 23 service_latency.go:363] Got endpoints: latency-svc-jznpp [181.026378ms]
  I0502 09:29:36.756429 23 service_latency.go:356] Created: latency-svc-lbp4k
  I0502 09:29:36.766936 23 service_latency.go:363] Got endpoints: latency-svc-lbp4k [196.560621ms]
  I0502 09:29:36.771214 23 service_latency.go:356] Created: latency-svc-99c2s
  I0502 09:29:36.785247 23 service_latency.go:363] Got endpoints: latency-svc-99c2s [214.78207ms]
  I0502 09:29:36.793252 23 service_latency.go:356] Created: latency-svc-4xvx2
  I0502 09:29:36.798232 23 service_latency.go:363] Got endpoints: latency-svc-4xvx2 [227.777068ms]
  I0502 09:29:36.801514 23 service_latency.go:356] Created: latency-svc-l2snx
  I0502 09:29:36.811280 23 service_latency.go:363] Got endpoints: latency-svc-l2snx [240.818902ms]
  I0502 09:29:36.815136 23 service_latency.go:356] Created: latency-svc-8gn4s
  I0502 09:29:36.821116 23 service_latency.go:363] Got endpoints: latency-svc-8gn4s [221.046971ms]
  I0502 09:29:36.832062 23 service_latency.go:356] Created: latency-svc-hpgxl
  I0502 09:29:36.840681 23 service_latency.go:363] Got endpoints: latency-svc-hpgxl [219.133518ms]
  I0502 09:29:36.848391 23 service_latency.go:356] Created: latency-svc-fpk7z
  I0502 09:29:36.853928 23 service_latency.go:363] Got endpoints: latency-svc-fpk7z [216.758846ms]
  I0502 09:29:36.863331 23 service_latency.go:356] Created: latency-svc-wdfj6
  I0502 09:29:36.871156 23 service_latency.go:363] Got endpoints: latency-svc-wdfj6 [215.657937ms]
  I0502 09:29:36.874914 23 service_latency.go:356] Created: latency-svc-s5s4d
  I0502 09:29:36.915314 23 service_latency.go:363] Got endpoints: latency-svc-s5s4d [254.29213ms]
  I0502 09:29:36.916931 23 service_latency.go:356] Created: latency-svc-jct2f
  I0502 09:29:36.925121 23 service_latency.go:363] Got endpoints: latency-svc-jct2f [248.858382ms]
  I0502 09:29:36.933196 23 service_latency.go:356] Created: latency-svc-2ggt7
  I0502 09:29:36.938050 23 service_latency.go:363] Got endpoints: latency-svc-2ggt7 [240.963665ms]
  I0502 09:29:36.942880 23 service_latency.go:356] Created: latency-svc-rw7rp
  I0502 09:29:36.948008 23 service_latency.go:363] Got endpoints: latency-svc-rw7rp [238.279434ms]
  I0502 09:29:36.955711 23 service_latency.go:356] Created: latency-svc-lbq6d
  I0502 09:29:36.963486 23 service_latency.go:363] Got endpoints: latency-svc-lbq6d [237.171248ms]
  I0502 09:29:36.966805 23 service_latency.go:356] Created: latency-svc-b9jss
  I0502 09:29:36.975198 23 service_latency.go:363] Got endpoints: latency-svc-b9jss [235.441559ms]
  I0502 09:29:36.978766 23 service_latency.go:356] Created: latency-svc-hqcnz
  I0502 09:29:36.986420 23 service_latency.go:363] Got endpoints: latency-svc-hqcnz [234.880021ms]
  I0502 09:29:36.991188 23 service_latency.go:356] Created: latency-svc-4fxvg
  I0502 09:29:36.999503 23 service_latency.go:363] Got endpoints: latency-svc-4fxvg [232.553816ms]
  I0502 09:29:37.010631 23 service_latency.go:356] Created: latency-svc-7frjp
  I0502 09:29:37.019373 23 service_latency.go:363] Got endpoints: latency-svc-7frjp [234.112099ms]
  I0502 09:29:37.024624 23 service_latency.go:356] Created: latency-svc-ppssr
  I0502 09:29:37.032904 23 service_latency.go:363] Got endpoints: latency-svc-ppssr [234.658049ms]
  I0502 09:29:37.037214 23 service_latency.go:356] Created: latency-svc-2w6mc
  I0502 09:29:37.042385 23 service_latency.go:363] Got endpoints: latency-svc-2w6mc [231.08953ms]
  I0502 09:29:37.045828 23 service_latency.go:356] Created: latency-svc-x9mv2
  I0502 09:29:37.054038 23 service_latency.go:363] Got endpoints: latency-svc-x9mv2 [232.908593ms]
  I0502 09:29:37.062291 23 service_latency.go:356] Created: latency-svc-j2dj5
  I0502 09:29:37.066341 23 service_latency.go:363] Got endpoints: latency-svc-j2dj5 [225.644655ms]
  I0502 09:29:37.069735 23 service_latency.go:356] Created: latency-svc-4xrfg
  I0502 09:29:37.080533 23 service_latency.go:363] Got endpoints: latency-svc-4xrfg [226.588797ms]
  I0502 09:29:37.085354 23 service_latency.go:356] Created: latency-svc-b4m4g
  I0502 09:29:37.095479 23 service_latency.go:363] Got endpoints: latency-svc-b4m4g [224.309087ms]
  I0502 09:29:37.098803 23 service_latency.go:356] Created: latency-svc-sg7ct
  I0502 09:29:37.104805 23 service_latency.go:363] Got endpoints: latency-svc-sg7ct [189.477029ms]
  I0502 09:29:37.113845 23 service_latency.go:356] Created: latency-svc-kb8g9
  I0502 09:29:37.130435 23 service_latency.go:363] Got endpoints: latency-svc-kb8g9 [205.299944ms]
  I0502 09:29:37.138978 23 service_latency.go:356] Created: latency-svc-zn967
  I0502 09:29:37.143881 23 service_latency.go:363] Got endpoints: latency-svc-zn967 [205.815181ms]
  I0502 09:29:37.151514 23 service_latency.go:356] Created: latency-svc-fmn2t
  I0502 09:29:37.158960 23 service_latency.go:363] Got endpoints: latency-svc-fmn2t [210.93921ms]
  I0502 09:29:37.167346 23 service_latency.go:356] Created: latency-svc-gbgdg
  I0502 09:29:37.173972 23 service_latency.go:363] Got endpoints: latency-svc-gbgdg [210.471175ms]
  I0502 09:29:37.177031 23 service_latency.go:356] Created: latency-svc-h4b5f
  I0502 09:29:37.184958 23 service_latency.go:363] Got endpoints: latency-svc-h4b5f [209.743227ms]
  I0502 09:29:37.193058 23 service_latency.go:356] Created: latency-svc-2hpv9
  I0502 09:29:37.197005 23 service_latency.go:363] Got endpoints: latency-svc-2hpv9 [210.567273ms]
  I0502 09:29:37.203169 23 service_latency.go:356] Created: latency-svc-d2mrt
  I0502 09:29:37.218581 23 service_latency.go:356] Created: latency-svc-ddwnk
  I0502 09:29:37.221762 23 service_latency.go:363] Got endpoints: latency-svc-d2mrt [222.244613ms]
  I0502 09:29:37.225946 23 service_latency.go:356] Created: latency-svc-2f2qd
  I0502 09:29:37.243860 23 service_latency.go:356] Created: latency-svc-xbldk
  I0502 09:29:37.254415 23 service_latency.go:356] Created: latency-svc-2blwl
  I0502 09:29:37.264430 23 service_latency.go:356] Created: latency-svc-cdtdj
  I0502 09:29:37.285051 23 service_latency.go:363] Got endpoints: latency-svc-ddwnk [265.662609ms]
  I0502 09:29:37.288921 23 service_latency.go:356] Created: latency-svc-rnmq2
  I0502 09:29:37.303070 23 service_latency.go:356] Created: latency-svc-h54dw
  I0502 09:29:37.313378 23 service_latency.go:356] Created: latency-svc-6xtg5
  I0502 09:29:37.319965 23 service_latency.go:363] Got endpoints: latency-svc-2f2qd [287.044117ms]
  I0502 09:29:37.328160 23 service_latency.go:356] Created: latency-svc-cvczt
  I0502 09:29:37.339529 23 service_latency.go:356] Created: latency-svc-42l2d
  I0502 09:29:37.370808 23 service_latency.go:363] Got endpoints: latency-svc-xbldk [328.410007ms]
  I0502 09:29:37.377575 23 service_latency.go:356] Created: latency-svc-hjtnf
  I0502 09:29:37.397239 23 service_latency.go:356] Created: latency-svc-6v55z
  I0502 09:29:37.406939 23 service_latency.go:356] Created: latency-svc-mgg8l
  I0502 09:29:37.420084 23 service_latency.go:356] Created: latency-svc-78p75
  I0502 09:29:37.433201 23 service_latency.go:363] Got endpoints: latency-svc-2blwl [379.149937ms]
  I0502 09:29:37.441146 23 service_latency.go:356] Created: latency-svc-nzrb8
  I0502 09:29:37.457099 23 service_latency.go:356] Created: latency-svc-dxxp2
  I0502 09:29:37.472307 23 service_latency.go:363] Got endpoints: latency-svc-cdtdj [405.948655ms]
  I0502 09:29:37.480893 23 service_latency.go:356] Created: latency-svc-6s9br
  I0502 09:29:37.488904 23 service_latency.go:356] Created: latency-svc-28b8b
  I0502 09:29:37.496682 23 service_latency.go:356] Created: latency-svc-dhkk9
  I0502 09:29:37.513097 23 service_latency.go:356] Created: latency-svc-v9578
  I0502 09:29:37.523148 23 service_latency.go:363] Got endpoints: latency-svc-rnmq2 [442.601471ms]
  I0502 09:29:37.535436 23 service_latency.go:356] Created: latency-svc-f9rbj
  I0502 09:29:37.570787 23 service_latency.go:363] Got endpoints: latency-svc-h54dw [475.292859ms]
  I0502 09:29:37.587438 23 service_latency.go:356] Created: latency-svc-cwxrq
  E0502 09:29:37.596532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:37.620929 23 service_latency.go:363] Got endpoints: latency-svc-6xtg5 [516.108356ms]
  I0502 09:29:37.642317 23 service_latency.go:356] Created: latency-svc-9r84f
  I0502 09:29:37.670507 23 service_latency.go:363] Got endpoints: latency-svc-cvczt [540.058542ms]
  I0502 09:29:37.682457 23 service_latency.go:356] Created: latency-svc-7wcf2
  I0502 09:29:37.719313 23 service_latency.go:363] Got endpoints: latency-svc-42l2d [575.41331ms]
  I0502 09:29:37.745377 23 service_latency.go:356] Created: latency-svc-mxzsw
  I0502 09:29:37.770261 23 service_latency.go:363] Got endpoints: latency-svc-hjtnf [611.285797ms]
  I0502 09:29:37.801562 23 service_latency.go:356] Created: latency-svc-tn5lp
  I0502 09:29:37.819020 23 service_latency.go:363] Got endpoints: latency-svc-6v55z [645.028288ms]
  I0502 09:29:37.842443 23 service_latency.go:356] Created: latency-svc-x8jf7
  I0502 09:29:37.875910 23 service_latency.go:363] Got endpoints: latency-svc-mgg8l [690.937335ms]
  I0502 09:29:37.890272 23 service_latency.go:356] Created: latency-svc-przmm
  I0502 09:29:37.920957 23 service_latency.go:363] Got endpoints: latency-svc-78p75 [723.937787ms]
  I0502 09:29:37.943426 23 service_latency.go:356] Created: latency-svc-jzqzs
  I0502 09:29:37.970512 23 service_latency.go:363] Got endpoints: latency-svc-nzrb8 [748.736251ms]
  I0502 09:29:38.002817 23 service_latency.go:356] Created: latency-svc-jlhwd
  I0502 09:29:38.018183 23 service_latency.go:363] Got endpoints: latency-svc-dxxp2 [733.118744ms]
  I0502 09:29:38.032252 23 service_latency.go:356] Created: latency-svc-9frnz
  I0502 09:29:38.069980 23 service_latency.go:363] Got endpoints: latency-svc-6s9br [749.996676ms]
  I0502 09:29:38.105270 23 service_latency.go:356] Created: latency-svc-hwmkt
  I0502 09:29:38.118437 23 service_latency.go:363] Got endpoints: latency-svc-28b8b [747.615705ms]
  I0502 09:29:38.129969 23 service_latency.go:356] Created: latency-svc-mmhlp
  I0502 09:29:38.169031 23 service_latency.go:363] Got endpoints: latency-svc-dhkk9 [735.81534ms]
  I0502 09:29:38.197494 23 service_latency.go:356] Created: latency-svc-6mvzx
  I0502 09:29:38.220277 23 service_latency.go:363] Got endpoints: latency-svc-v9578 [747.957043ms]
  I0502 09:29:38.232603 23 service_latency.go:356] Created: latency-svc-s6x58
  I0502 09:29:38.270243 23 service_latency.go:363] Got endpoints: latency-svc-f9rbj [747.080278ms]
  I0502 09:29:38.282263 23 service_latency.go:356] Created: latency-svc-8cxcn
  I0502 09:29:38.318552 23 service_latency.go:363] Got endpoints: latency-svc-cwxrq [747.745561ms]
  I0502 09:29:38.342202 23 service_latency.go:356] Created: latency-svc-cwlfd
  I0502 09:29:38.369248 23 service_latency.go:363] Got endpoints: latency-svc-9r84f [748.303757ms]
  I0502 09:29:38.387142 23 service_latency.go:356] Created: latency-svc-pjjks
  I0502 09:29:38.437758 23 service_latency.go:363] Got endpoints: latency-svc-7wcf2 [767.235832ms]
  I0502 09:29:38.486026 23 service_latency.go:356] Created: latency-svc-4mfbv
  I0502 09:29:38.486295 23 service_latency.go:363] Got endpoints: latency-svc-mxzsw [766.96683ms]
  I0502 09:29:38.532797 23 service_latency.go:356] Created: latency-svc-vhjxb
  I0502 09:29:38.538662 23 service_latency.go:363] Got endpoints: latency-svc-tn5lp [768.384713ms]
  I0502 09:29:38.581017 23 service_latency.go:356] Created: latency-svc-7n26r
  E0502 09:29:38.597135      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:38.600361 23 service_latency.go:363] Got endpoints: latency-svc-x8jf7 [781.309975ms]
  I0502 09:29:38.657124 23 service_latency.go:363] Got endpoints: latency-svc-przmm [781.20072ms]
  I0502 09:29:38.657443 23 service_latency.go:356] Created: latency-svc-z64z4
  I0502 09:29:38.673701 23 service_latency.go:363] Got endpoints: latency-svc-jzqzs [752.730703ms]
  I0502 09:29:38.681512 23 service_latency.go:356] Created: latency-svc-fpz6x
  I0502 09:29:38.698017 23 service_latency.go:356] Created: latency-svc-th7qb
  I0502 09:29:38.719540 23 service_latency.go:363] Got endpoints: latency-svc-jlhwd [749.013953ms]
  I0502 09:29:38.730336 23 service_latency.go:356] Created: latency-svc-tfbbb
  I0502 09:29:38.772076 23 service_latency.go:363] Got endpoints: latency-svc-9frnz [753.878941ms]
  I0502 09:29:38.785302 23 service_latency.go:356] Created: latency-svc-4f8pn
  I0502 09:29:38.820299 23 service_latency.go:363] Got endpoints: latency-svc-hwmkt [750.305769ms]
  I0502 09:29:38.840283 23 service_latency.go:356] Created: latency-svc-76xq4
  I0502 09:29:38.868557 23 service_latency.go:363] Got endpoints: latency-svc-mmhlp [750.106141ms]
  I0502 09:29:38.883494 23 service_latency.go:356] Created: latency-svc-mhcj4
  I0502 09:29:38.919435 23 service_latency.go:363] Got endpoints: latency-svc-6mvzx [750.385562ms]
  I0502 09:29:38.942498 23 service_latency.go:356] Created: latency-svc-nscjr
  I0502 09:29:38.967814 23 service_latency.go:363] Got endpoints: latency-svc-s6x58 [747.522177ms]
  I0502 09:29:39.001923 23 service_latency.go:356] Created: latency-svc-hjnb2
  I0502 09:29:39.018944 23 service_latency.go:363] Got endpoints: latency-svc-8cxcn [748.687045ms]
  I0502 09:29:39.032075 23 service_latency.go:356] Created: latency-svc-64xj5
  I0502 09:29:39.071928 23 service_latency.go:363] Got endpoints: latency-svc-cwlfd [753.34906ms]
  I0502 09:29:39.085234 23 service_latency.go:356] Created: latency-svc-l5ntg
  I0502 09:29:39.118443 23 service_latency.go:363] Got endpoints: latency-svc-pjjks [749.181763ms]
  I0502 09:29:39.142170 23 service_latency.go:356] Created: latency-svc-srkkl
  I0502 09:29:39.169484 23 service_latency.go:363] Got endpoints: latency-svc-4mfbv [731.696373ms]
  I0502 09:29:39.183726 23 service_latency.go:356] Created: latency-svc-shj5t
  I0502 09:29:39.219329 23 service_latency.go:363] Got endpoints: latency-svc-vhjxb [733.017667ms]
  I0502 09:29:39.231857 23 service_latency.go:356] Created: latency-svc-fgndd
  I0502 09:29:39.268414 23 service_latency.go:363] Got endpoints: latency-svc-7n26r [729.723461ms]
  I0502 09:29:39.281806 23 service_latency.go:356] Created: latency-svc-smwdb
  I0502 09:29:39.319386 23 service_latency.go:363] Got endpoints: latency-svc-z64z4 [719.010014ms]
  I0502 09:29:39.336536 23 service_latency.go:356] Created: latency-svc-8kll7
  I0502 09:29:39.369365 23 service_latency.go:363] Got endpoints: latency-svc-fpz6x [712.226247ms]
  I0502 09:29:39.399041 23 service_latency.go:356] Created: latency-svc-6wxzx
  I0502 09:29:39.421086 23 service_latency.go:363] Got endpoints: latency-svc-th7qb [747.369348ms]
  I0502 09:29:39.443618 23 service_latency.go:356] Created: latency-svc-lkpq8
  I0502 09:29:39.472577 23 service_latency.go:363] Got endpoints: latency-svc-tfbbb [753.022608ms]
  I0502 09:29:39.496527 23 service_latency.go:356] Created: latency-svc-gdd9z
  I0502 09:29:39.518472 23 service_latency.go:363] Got endpoints: latency-svc-4f8pn [746.381801ms]
  I0502 09:29:39.536873 23 service_latency.go:356] Created: latency-svc-28vw4
  I0502 09:29:39.569941 23 service_latency.go:363] Got endpoints: latency-svc-76xq4 [749.629576ms]
  E0502 09:29:39.597370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:39.597420 23 service_latency.go:356] Created: latency-svc-w8zkp
  I0502 09:29:39.618238 23 service_latency.go:363] Got endpoints: latency-svc-mhcj4 [749.666379ms]
  I0502 09:29:39.634427 23 service_latency.go:356] Created: latency-svc-4786w
  I0502 09:29:39.680280 23 service_latency.go:363] Got endpoints: latency-svc-nscjr [760.823082ms]
  I0502 09:29:39.702348 23 service_latency.go:356] Created: latency-svc-gvvrc
  I0502 09:29:39.757395 23 service_latency.go:363] Got endpoints: latency-svc-hjnb2 [789.555123ms]
  I0502 09:29:39.799132 23 service_latency.go:363] Got endpoints: latency-svc-64xj5 [780.172103ms]
  I0502 09:29:39.807658 23 service_latency.go:356] Created: latency-svc-5jtd9
  I0502 09:29:39.822360 23 service_latency.go:363] Got endpoints: latency-svc-l5ntg [750.418146ms]
  I0502 09:29:39.822398 23 service_latency.go:356] Created: latency-svc-7zfwd
  I0502 09:29:39.930354 23 service_latency.go:363] Got endpoints: latency-svc-srkkl [811.895302ms]
  I0502 09:29:39.930389 23 service_latency.go:363] Got endpoints: latency-svc-shj5t [760.888578ms]
  I0502 09:29:39.992848 23 service_latency.go:356] Created: latency-svc-jx78t
  I0502 09:29:39.997407 23 service_latency.go:363] Got endpoints: latency-svc-fgndd [778.063187ms]
  I0502 09:29:40.043646 23 service_latency.go:363] Got endpoints: latency-svc-smwdb [775.214905ms]
  I0502 09:29:40.053169 23 service_latency.go:356] Created: latency-svc-pqqq7
  I0502 09:29:40.082939 23 service_latency.go:363] Got endpoints: latency-svc-8kll7 [763.524978ms]
  I0502 09:29:40.153405 23 service_latency.go:363] Got endpoints: latency-svc-6wxzx [784.024945ms]
  I0502 09:29:40.196867 23 service_latency.go:356] Created: latency-svc-4vsqs
  I0502 09:29:40.196915 23 service_latency.go:356] Created: latency-svc-d9tl7
  I0502 09:29:40.198968 23 service_latency.go:363] Got endpoints: latency-svc-lkpq8 [777.867747ms]
  I0502 09:29:40.206862 23 service_latency.go:356] Created: latency-svc-f5b75
  I0502 09:29:40.206924 23 service_latency.go:356] Created: latency-svc-9sw8n
  I0502 09:29:40.223211 23 service_latency.go:363] Got endpoints: latency-svc-gdd9z [750.620176ms]
  I0502 09:29:40.229621 23 service_latency.go:356] Created: latency-svc-4n8v6
  I0502 09:29:40.341586 23 service_latency.go:356] Created: latency-svc-4knhn
  I0502 09:29:40.346731 23 service_latency.go:363] Got endpoints: latency-svc-w8zkp [776.773042ms]
  I0502 09:29:40.346737 23 service_latency.go:363] Got endpoints: latency-svc-28vw4 [828.252321ms]
  I0502 09:29:40.416562 23 service_latency.go:356] Created: latency-svc-px5cp
  I0502 09:29:40.419803 23 service_latency.go:363] Got endpoints: latency-svc-4786w [801.55086ms]
  I0502 09:29:40.461048 23 service_latency.go:363] Got endpoints: latency-svc-gvvrc [780.750443ms]
  I0502 09:29:40.476996 23 service_latency.go:356] Created: latency-svc-4zmrs
  I0502 09:29:40.482652 23 service_latency.go:363] Got endpoints: latency-svc-5jtd9 [725.243898ms]
  I0502 09:29:40.544996 23 service_latency.go:356] Created: latency-svc-jnjjp
  I0502 09:29:40.552940 23 service_latency.go:363] Got endpoints: latency-svc-7zfwd [753.793769ms]
  I0502 09:29:40.556743 23 service_latency.go:356] Created: latency-svc-nz8pg
  E0502 09:29:40.597906      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:40.631713 23 service_latency.go:363] Got endpoints: latency-svc-pqqq7 [701.328935ms]
  I0502 09:29:40.631757 23 service_latency.go:363] Got endpoints: latency-svc-jx78t [809.377946ms]
  I0502 09:29:40.637520 23 service_latency.go:356] Created: latency-svc-jbjz7
  I0502 09:29:40.650309 23 service_latency.go:356] Created: latency-svc-k2fnz
  I0502 09:29:40.660989 23 service_latency.go:356] Created: latency-svc-blvn9
  I0502 09:29:40.802501 23 service_latency.go:363] Got endpoints: latency-svc-4vsqs [719.546068ms]
  I0502 09:29:40.802518 23 service_latency.go:363] Got endpoints: latency-svc-d9tl7 [872.115377ms]
  I0502 09:29:40.802560 23 service_latency.go:363] Got endpoints: latency-svc-9sw8n [805.135033ms]
  I0502 09:29:40.811959 23 service_latency.go:356] Created: latency-svc-ltfcp
  I0502 09:29:40.822610 23 service_latency.go:363] Got endpoints: latency-svc-f5b75 [778.949708ms]
  I0502 09:29:40.989696 23 service_latency.go:363] Got endpoints: latency-svc-4knhn [790.714318ms]
  I0502 09:29:40.989701 23 service_latency.go:363] Got endpoints: latency-svc-px5cp [766.471366ms]
  I0502 09:29:40.989752 23 service_latency.go:363] Got endpoints: latency-svc-4n8v6 [836.329574ms]
  I0502 09:29:40.996506 23 service_latency.go:356] Created: latency-svc-llmxn
  I0502 09:29:41.069719 23 service_latency.go:363] Got endpoints: latency-svc-4zmrs [722.970385ms]
  I0502 09:29:41.073324 23 service_latency.go:363] Got endpoints: latency-svc-jnjjp [726.573346ms]
  I0502 09:29:41.075284 23 service_latency.go:356] Created: latency-svc-kvwbh
  I0502 09:29:41.155087 23 service_latency.go:363] Got endpoints: latency-svc-nz8pg [735.253774ms]
  I0502 09:29:41.161712 23 service_latency.go:356] Created: latency-svc-4cgnb
  I0502 09:29:41.171679 23 service_latency.go:363] Got endpoints: latency-svc-jbjz7 [710.615455ms]
  I0502 09:29:41.177095 23 service_latency.go:356] Created: latency-svc-dw5tj
  I0502 09:29:41.273056 23 service_latency.go:356] Created: latency-svc-7vbn6
  I0502 09:29:41.341496 23 service_latency.go:363] Got endpoints: latency-svc-blvn9 [788.52467ms]
  I0502 09:29:41.349282 23 service_latency.go:363] Got endpoints: latency-svc-ltfcp [717.509066ms]
  I0502 09:29:41.349294 23 service_latency.go:363] Got endpoints: latency-svc-k2fnz [866.627237ms]
  I0502 09:29:41.357966 23 service_latency.go:356] Created: latency-svc-dphtl
  I0502 09:29:41.367462 23 service_latency.go:356] Created: latency-svc-7qpnh
  I0502 09:29:41.471032 23 service_latency.go:363] Got endpoints: latency-svc-llmxn [839.302309ms]
  I0502 09:29:41.481769 23 service_latency.go:363] Got endpoints: latency-svc-4cgnb [679.240082ms]
  I0502 09:29:41.481823 23 service_latency.go:363] Got endpoints: latency-svc-kvwbh [679.306509ms]
  E0502 09:29:41.598976      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:41.614382 23 service_latency.go:363] Got endpoints: latency-svc-7vbn6 [791.756845ms]
  I0502 09:29:41.614393 23 service_latency.go:363] Got endpoints: latency-svc-dw5tj [811.815282ms]
  I0502 09:29:41.621710 23 service_latency.go:356] Created: latency-svc-dz4tx
  I0502 09:29:41.632676 23 service_latency.go:363] Got endpoints: latency-svc-dphtl [642.958892ms]
  I0502 09:29:41.690469 23 service_latency.go:356] Created: latency-svc-8cmk9
  I0502 09:29:41.720679 23 service_latency.go:363] Got endpoints: latency-svc-7qpnh [730.963412ms]
  I0502 09:29:41.725764 23 service_latency.go:363] Got endpoints: latency-svc-dz4tx [735.994821ms]
  I0502 09:29:41.731282 23 service_latency.go:356] Created: latency-svc-46vm4
  I0502 09:29:41.813718 23 service_latency.go:363] Got endpoints: latency-svc-8cmk9 [743.979061ms]
  I0502 09:29:41.819758 23 service_latency.go:356] Created: latency-svc-sjxnk
  I0502 09:29:41.867848 23 service_latency.go:363] Got endpoints: latency-svc-46vm4 [794.5066ms]
  I0502 09:29:41.873467 23 service_latency.go:356] Created: latency-svc-b9h9q
  I0502 09:29:41.875882 23 service_latency.go:363] Got endpoints: latency-svc-sjxnk [720.756113ms]
  I0502 09:29:41.898358 23 service_latency.go:356] Created: latency-svc-ppfd5
  I0502 09:29:41.952509 23 service_latency.go:363] Got endpoints: latency-svc-b9h9q [780.816734ms]
  I0502 09:29:41.960991 23 service_latency.go:356] Created: latency-svc-kdzkc
  I0502 09:29:41.970231 23 service_latency.go:363] Got endpoints: latency-svc-ppfd5 [628.718722ms]
  I0502 09:29:41.973158 23 service_latency.go:356] Created: latency-svc-5w6mh
  I0502 09:29:42.085275 23 service_latency.go:356] Created: latency-svc-ddl5c
  I0502 09:29:42.093297 23 service_latency.go:363] Got endpoints: latency-svc-5w6mh [743.988788ms]
  I0502 09:29:42.093331 23 service_latency.go:363] Got endpoints: latency-svc-kdzkc [744.034664ms]
  I0502 09:29:42.154600 23 service_latency.go:363] Got endpoints: latency-svc-ddl5c [683.553898ms]
  I0502 09:29:42.156477 23 service_latency.go:356] Created: latency-svc-6m8lw
  I0502 09:29:42.212463 23 service_latency.go:356] Created: latency-svc-jlrrq
  I0502 09:29:42.220408 23 service_latency.go:363] Got endpoints: latency-svc-6m8lw [738.62382ms]
  I0502 09:29:42.230793 23 service_latency.go:363] Got endpoints: latency-svc-jlrrq [748.953828ms]
  I0502 09:29:42.241995 23 service_latency.go:356] Created: latency-svc-tbxh8
  I0502 09:29:42.251978 23 service_latency.go:356] Created: latency-svc-fkxfn
  I0502 09:29:42.364142 23 service_latency.go:363] Got endpoints: latency-svc-fkxfn [749.729876ms]
  I0502 09:29:42.364182 23 service_latency.go:363] Got endpoints: latency-svc-tbxh8 [749.761449ms]
  I0502 09:29:42.368954 23 service_latency.go:356] Created: latency-svc-n8lzm
  I0502 09:29:42.408682 23 service_latency.go:363] Got endpoints: latency-svc-n8lzm [775.977594ms]
  I0502 09:29:42.426210 23 service_latency.go:356] Created: latency-svc-7948r
  I0502 09:29:42.459478 23 service_latency.go:363] Got endpoints: latency-svc-7948r [738.776048ms]
  I0502 09:29:42.468879 23 service_latency.go:356] Created: latency-svc-mcgxs
  I0502 09:29:42.484617 23 service_latency.go:363] Got endpoints: latency-svc-mcgxs [758.837948ms]
  I0502 09:29:42.490666 23 service_latency.go:356] Created: latency-svc-l7jvs
  E0502 09:29:42.599832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:42.606643 23 service_latency.go:363] Got endpoints: latency-svc-l7jvs [792.895975ms]
  I0502 09:29:42.612868 23 service_latency.go:356] Created: latency-svc-svl24
  I0502 09:29:42.623671 23 service_latency.go:363] Got endpoints: latency-svc-svl24 [755.808891ms]
  I0502 09:29:42.635424 23 service_latency.go:356] Created: latency-svc-jsgb7
  I0502 09:29:42.647194 23 service_latency.go:363] Got endpoints: latency-svc-jsgb7 [771.290527ms]
  I0502 09:29:42.776845 23 service_latency.go:356] Created: latency-svc-449zh
  I0502 09:29:42.787166 23 service_latency.go:363] Got endpoints: latency-svc-449zh [834.642607ms]
  I0502 09:29:42.889715 23 service_latency.go:356] Created: latency-svc-k94z8
  I0502 09:29:42.904252 23 service_latency.go:363] Got endpoints: latency-svc-k94z8 [934.006164ms]
  I0502 09:29:42.910302 23 service_latency.go:356] Created: latency-svc-5k9vg
  I0502 09:29:42.983812 23 service_latency.go:363] Got endpoints: latency-svc-5k9vg [890.487838ms]
  I0502 09:29:42.988026 23 service_latency.go:356] Created: latency-svc-khws5
  I0502 09:29:43.058246 23 service_latency.go:363] Got endpoints: latency-svc-khws5 [964.890156ms]
  I0502 09:29:43.064923 23 service_latency.go:356] Created: latency-svc-56cvs
  I0502 09:29:43.076954 23 service_latency.go:363] Got endpoints: latency-svc-56cvs [922.338355ms]
  I0502 09:29:43.110314 23 service_latency.go:356] Created: latency-svc-8gthp
  I0502 09:29:43.152966 23 service_latency.go:363] Got endpoints: latency-svc-8gthp [932.545239ms]
  I0502 09:29:43.185845 23 service_latency.go:356] Created: latency-svc-mn6p2
  I0502 09:29:43.196112 23 service_latency.go:363] Got endpoints: latency-svc-mn6p2 [965.305862ms]
  I0502 09:29:43.205033 23 service_latency.go:356] Created: latency-svc-jq5dv
  I0502 09:29:43.214290 23 service_latency.go:363] Got endpoints: latency-svc-jq5dv [850.093082ms]
  I0502 09:29:43.221236 23 service_latency.go:356] Created: latency-svc-fdtgh
  I0502 09:29:43.354678 23 service_latency.go:363] Got endpoints: latency-svc-fdtgh [990.508879ms]
  I0502 09:29:43.364433 23 service_latency.go:356] Created: latency-svc-rvg78
  I0502 09:29:43.383347 23 service_latency.go:356] Created: latency-svc-xfvkv
  I0502 09:29:43.384072 23 service_latency.go:363] Got endpoints: latency-svc-rvg78 [975.375845ms]
  I0502 09:29:43.431378 23 service_latency.go:363] Got endpoints: latency-svc-xfvkv [971.883338ms]
  I0502 09:29:43.437265 23 service_latency.go:356] Created: latency-svc-dhx9j
  I0502 09:29:43.507504 23 service_latency.go:363] Got endpoints: latency-svc-dhx9j [1.022850051s]
  I0502 09:29:43.514530 23 service_latency.go:356] Created: latency-svc-8q6fq
  I0502 09:29:43.561105 23 service_latency.go:363] Got endpoints: latency-svc-8q6fq [954.43985ms]
  I0502 09:29:43.565397 23 service_latency.go:356] Created: latency-svc-b95vl
  E0502 09:29:43.600173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:43.600183 23 service_latency.go:356] Created: latency-svc-7jrxq
  I0502 09:29:43.600692 23 service_latency.go:363] Got endpoints: latency-svc-b95vl [976.990334ms]
  I0502 09:29:43.651732 23 service_latency.go:363] Got endpoints: latency-svc-7jrxq [1.004523056s]
  I0502 09:29:43.686027 23 service_latency.go:356] Created: latency-svc-r2hx2
  I0502 09:29:43.693581 23 service_latency.go:356] Created: latency-svc-7mljv
  I0502 09:29:43.697949 23 service_latency.go:363] Got endpoints: latency-svc-r2hx2 [910.766704ms]
  I0502 09:29:43.703982 23 service_latency.go:363] Got endpoints: latency-svc-7mljv [799.71494ms]
  I0502 09:29:43.709971 23 service_latency.go:356] Created: latency-svc-md2fw
  I0502 09:29:43.720053 23 service_latency.go:363] Got endpoints: latency-svc-md2fw [736.22646ms]
  I0502 09:29:43.722683 23 service_latency.go:356] Created: latency-svc-dtsfs
  I0502 09:29:43.850532 23 service_latency.go:363] Got endpoints: latency-svc-dtsfs [792.271089ms]
  I0502 09:29:43.857356 23 service_latency.go:356] Created: latency-svc-fnvbj
  I0502 09:29:43.865776 23 service_latency.go:363] Got endpoints: latency-svc-fnvbj [788.806323ms]
  I0502 09:29:43.887110 23 service_latency.go:356] Created: latency-svc-hz28j
  I0502 09:29:43.924740 23 service_latency.go:363] Got endpoints: latency-svc-hz28j [771.759288ms]
  I0502 09:29:43.924871 23 service_latency.go:356] Created: latency-svc-2558k
  I0502 09:29:44.169756 23 service_latency.go:356] Created: latency-svc-jqvbv
  I0502 09:29:44.169818 23 service_latency.go:363] Got endpoints: latency-svc-2558k [973.691513ms]
  I0502 09:29:44.198026 23 service_latency.go:363] Got endpoints: latency-svc-jqvbv [983.722665ms]
  I0502 09:29:44.217713 23 service_latency.go:356] Created: latency-svc-wh87w
  I0502 09:29:44.236743 23 service_latency.go:363] Got endpoints: latency-svc-wh87w [882.048589ms]
  I0502 09:29:44.247311 23 service_latency.go:356] Created: latency-svc-v95hv
  I0502 09:29:44.268908 23 service_latency.go:363] Got endpoints: latency-svc-v95hv [884.82377ms]
  I0502 09:29:44.279523 23 service_latency.go:356] Created: latency-svc-4cjvk
  I0502 09:29:44.307086 23 service_latency.go:363] Got endpoints: latency-svc-4cjvk [875.692534ms]
  I0502 09:29:44.326191 23 service_latency.go:356] Created: latency-svc-t9kf4
  E0502 09:29:44.600597      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:44.738835 23 service_latency.go:363] Got endpoints: latency-svc-t9kf4 [1.231313964s]
  I0502 09:29:44.756068 23 service_latency.go:356] Created: latency-svc-8glzr
  I0502 09:29:44.789830 23 service_latency.go:363] Got endpoints: latency-svc-8glzr [1.228696447s]
  I0502 09:29:45.024766 23 service_latency.go:356] Created: latency-svc-4s9rn
  I0502 09:29:45.034953 23 service_latency.go:363] Got endpoints: latency-svc-4s9rn [1.434245654s]
  I0502 09:29:45.043743 23 service_latency.go:356] Created: latency-svc-gwj2f
  I0502 09:29:45.171626 23 service_latency.go:363] Got endpoints: latency-svc-gwj2f [1.519875775s]
  I0502 09:29:45.184185 23 service_latency.go:356] Created: latency-svc-x2dl2
  I0502 09:29:45.321059 23 service_latency.go:363] Got endpoints: latency-svc-x2dl2 [1.623094519s]
  I0502 09:29:45.336762 23 service_latency.go:356] Created: latency-svc-dxx8t
  I0502 09:29:45.342819 23 service_latency.go:363] Got endpoints: latency-svc-dxx8t [1.638809217s]
  I0502 09:29:45.415252 23 service_latency.go:356] Created: latency-svc-75m7k
  I0502 09:29:45.448282 23 service_latency.go:363] Got endpoints: latency-svc-75m7k [1.728215077s]
  I0502 09:29:45.455427 23 service_latency.go:356] Created: latency-svc-qqjfr
  I0502 09:29:45.513629 23 service_latency.go:363] Got endpoints: latency-svc-qqjfr [1.663082548s]
  I0502 09:29:45.518524 23 service_latency.go:356] Created: latency-svc-stztr
  I0502 09:29:45.568497 23 service_latency.go:363] Got endpoints: latency-svc-stztr [1.702705919s]
  I0502 09:29:45.575056 23 service_latency.go:356] Created: latency-svc-q65qd
  E0502 09:29:45.601139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:45.611013 23 service_latency.go:356] Created: latency-svc-bdv64
  I0502 09:29:45.616320 23 service_latency.go:363] Got endpoints: latency-svc-q65qd [1.691564283s]
  I0502 09:29:45.663771 23 service_latency.go:356] Created: latency-svc-f6lk8
  I0502 09:29:45.664758 23 service_latency.go:363] Got endpoints: latency-svc-bdv64 [1.494925431s]
  I0502 09:29:45.765971 23 service_latency.go:363] Got endpoints: latency-svc-f6lk8 [1.567930237s]
  I0502 09:29:45.769755 23 service_latency.go:356] Created: latency-svc-zpxx6
  I0502 09:29:45.776840 23 service_latency.go:363] Got endpoints: latency-svc-zpxx6 [1.540082s]
  I0502 09:29:45.778098 23 service_latency.go:356] Created: latency-svc-k7624
  I0502 09:29:45.787981 23 service_latency.go:363] Got endpoints: latency-svc-k7624 [1.519058687s]
  I0502 09:29:45.796308 23 service_latency.go:356] Created: latency-svc-98vbr
  I0502 09:29:45.878701 23 service_latency.go:363] Got endpoints: latency-svc-98vbr [1.571585534s]
  I0502 09:29:45.889853 23 service_latency.go:356] Created: latency-svc-lwkcm
  I0502 09:29:45.893894 23 service_latency.go:363] Got endpoints: latency-svc-lwkcm [1.155030478s]
  I0502 09:29:45.898101 23 service_latency.go:356] Created: latency-svc-x6zd2
  I0502 09:29:45.949312 23 service_latency.go:363] Got endpoints: latency-svc-x6zd2 [1.159452511s]
  I0502 09:29:45.954539 23 service_latency.go:356] Created: latency-svc-ct57m
  I0502 09:29:45.964495 23 service_latency.go:363] Got endpoints: latency-svc-ct57m [929.511851ms]
  I0502 09:29:46.060433 23 service_latency.go:356] Created: latency-svc-hctjt
  I0502 09:29:46.078670 23 service_latency.go:363] Got endpoints: latency-svc-hctjt [907.029002ms]
  I0502 09:29:46.082894 23 service_latency.go:356] Created: latency-svc-mh4s6
  I0502 09:29:46.093688 23 service_latency.go:363] Got endpoints: latency-svc-mh4s6 [772.600595ms]
  I0502 09:29:46.099338 23 service_latency.go:356] Created: latency-svc-sgsmd
  I0502 09:29:46.183991 23 service_latency.go:363] Got endpoints: latency-svc-sgsmd [841.144179ms]
  I0502 09:29:46.211498 23 service_latency.go:356] Created: latency-svc-qvn9q
  I0502 09:29:46.220853 23 service_latency.go:363] Got endpoints: latency-svc-qvn9q [772.556411ms]
  I0502 09:29:46.292906 23 service_latency.go:356] Created: latency-svc-wfdv4
  I0502 09:29:46.304048 23 service_latency.go:363] Got endpoints: latency-svc-wfdv4 [790.405864ms]
  I0502 09:29:46.307279 23 service_latency.go:356] Created: latency-svc-qb4bj
  I0502 09:29:46.314337 23 service_latency.go:363] Got endpoints: latency-svc-qb4bj [745.807557ms]
  I0502 09:29:46.314433 23 service_latency.go:114] Latencies: [29.658798ms 51.148502ms 66.739979ms 85.070776ms 90.603087ms 105.797688ms 126.610342ms 139.230386ms 155.812443ms 169.25024ms 181.026378ms 189.477029ms 196.560621ms 205.299944ms 205.815181ms 209.743227ms 210.471175ms 210.567273ms 210.93921ms 214.78207ms 215.657937ms 216.758846ms 219.133518ms 221.046971ms 222.244613ms 224.309087ms 225.644655ms 226.588797ms 227.777068ms 231.08953ms 232.553816ms 232.908593ms 234.112099ms 234.658049ms 234.880021ms 235.441559ms 237.171248ms 238.279434ms 240.818902ms 240.963665ms 248.858382ms 254.29213ms 265.662609ms 287.044117ms 328.410007ms 379.149937ms 405.948655ms 442.601471ms 475.292859ms 516.108356ms 540.058542ms 575.41331ms 611.285797ms 628.718722ms 642.958892ms 645.028288ms 679.240082ms 679.306509ms 683.553898ms 690.937335ms 701.328935ms 710.615455ms 712.226247ms 717.509066ms 719.010014ms 719.546068ms 720.756113ms 722.970385ms 723.937787ms 725.243898ms 726.573346ms 729.723461ms 730.963412ms 731.696373ms 733.017667ms 733.118744ms 735.253774ms 735.81534ms 735.994821ms 736.22646ms 738.62382ms 738.776048ms 743.979061ms 743.988788ms 744.034664ms 745.807557ms 746.381801ms 747.080278ms 747.369348ms 747.522177ms 747.615705ms 747.745561ms 747.957043ms 748.303757ms 748.687045ms 748.736251ms 748.953828ms 749.013953ms 749.181763ms 749.629576ms 749.666379ms 749.729876ms 749.761449ms 749.996676ms 750.106141ms 750.305769ms 750.385562ms 750.418146ms 750.620176ms 752.730703ms 753.022608ms 753.34906ms 753.793769ms 753.878941ms 755.808891ms 758.837948ms 760.823082ms 760.888578ms 763.524978ms 766.471366ms 766.96683ms 767.235832ms 768.384713ms 771.290527ms 771.759288ms 772.556411ms 772.600595ms 775.214905ms 775.977594ms 776.773042ms 777.867747ms 778.063187ms 778.949708ms 780.172103ms 780.750443ms 780.816734ms 781.20072ms 781.309975ms 784.024945ms 788.52467ms 788.806323ms 789.555123ms 790.405864ms 790.714318ms 791.756845ms 792.271089ms 792.895975ms 794.5066ms 799.71494ms 801.55086ms 805.135033ms 809.377946ms 811.815282ms 811.895302ms 828.252321ms 834.642607ms 836.329574ms 839.302309ms 841.144179ms 850.093082ms 866.627237ms 872.115377ms 875.692534ms 882.048589ms 884.82377ms 890.487838ms 907.029002ms 910.766704ms 922.338355ms 929.511851ms 932.545239ms 934.006164ms 954.43985ms 964.890156ms 965.305862ms 971.883338ms 973.691513ms 975.375845ms 976.990334ms 983.722665ms 990.508879ms 1.004523056s 1.022850051s 1.155030478s 1.159452511s 1.228696447s 1.231313964s 1.434245654s 1.494925431s 1.519058687s 1.519875775s 1.540082s 1.567930237s 1.571585534s 1.623094519s 1.638809217s 1.663082548s 1.691564283s 1.702705919s 1.728215077s]
  I0502 09:29:46.314449 23 service_latency.go:118] 50 %ile: 749.666379ms
  I0502 09:29:46.314459 23 service_latency.go:119] 90 %ile: 990.508879ms
  I0502 09:29:46.314466 23 service_latency.go:120] 99 %ile: 1.702705919s
  I0502 09:29:46.314474 23 service_latency.go:121] Total sample count: 200
  I0502 09:29:46.314516 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-269" for this suite. @ 05/02/24 09:29:46.32
• [12.005 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 05/02/24 09:29:46.376
  I0502 09:29:46.376208 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename init-container @ 05/02/24 09:29:46.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:46.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:46.414
  STEP: creating the pod @ 05/02/24 09:29:46.417
  I0502 09:29:46.417153 23 init_container.go:294] PodSpec: initContainers in spec.initContainers
  E0502 09:29:46.601601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:47.602215      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:48.602793      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:49.603261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:29:50.441545 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-6334" for this suite. @ 05/02/24 09:29:50.446
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 05/02/24 09:29:50.46
  I0502 09:29:50.460383 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/02/24 09:29:50.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:50.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:50.482
  STEP: creating a policy with variables @ 05/02/24 09:29:50.489
  STEP: waiting until the marker is denied @ 05/02/24 09:29:50.506
  E0502 09:29:50.604242      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 05/02/24 09:29:51.212
  STEP: testing a non-replicated ReplicaSet not to be denied @ 05/02/24 09:29:51.246
  I0502 09:29:51.304542 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-9220" for this suite. @ 05/02/24 09:29:51.309
• [0.855 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 05/02/24 09:29:51.315
  I0502 09:29:51.315829 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename dns @ 05/02/24 09:29:51.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:29:51.332
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:29:51.334
  STEP: Creating a test externalName service @ 05/02/24 09:29:51.336
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2862.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local; sleep 1; done
   @ 05/02/24 09:29:51.34
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2862.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local; sleep 1; done
   @ 05/02/24 09:29:51.34
  STEP: creating a pod to probe DNS @ 05/02/24 09:29:51.34
  STEP: submitting the pod to kubernetes @ 05/02/24 09:29:51.34
  E0502 09:29:51.604736      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:52.604923      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:53.605813      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:54.606002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/02/24 09:29:55.429
  STEP: looking for the results for each expected name from probers @ 05/02/24 09:29:55.434
  I0502 09:29:55.443538 23 dns_common.go:552] DNS probes using dns-test-d038e2ed-420f-4587-9fd0-6ce9f8608059 succeeded

  STEP: changing the externalName to bar.example.com @ 05/02/24 09:29:55.443
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2862.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local; sleep 1; done
   @ 05/02/24 09:29:55.455
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2862.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local; sleep 1; done
   @ 05/02/24 09:29:55.455
  STEP: creating a second pod to probe DNS @ 05/02/24 09:29:55.455
  STEP: submitting the pod to kubernetes @ 05/02/24 09:29:55.455
  E0502 09:29:55.606686      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:56.606855      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:57.607491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:58.607615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:29:59.608277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/02/24 09:29:59.656
  STEP: looking for the results for each expected name from probers @ 05/02/24 09:29:59.662
  I0502 09:29:59.754275 23 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:29:59.802145 23 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:29:59.802173 23 dns_common.go:489] Lookups using dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad failed for: [wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local]

  I0502 09:29:59.812833 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:29:59.819654 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:29:59.853663 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:30:00.608325      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:01.608494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:02.608654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:03.608775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:04.609088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:30:04.742611 23 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:30:04.760501 23 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:30:04.760532 23 dns_common.go:489] Lookups using dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad failed for: [wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local]

  I0502 09:30:04.830548 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:30:04.847118 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:30:04.950234 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:30:05.610117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:06.610277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:07.610437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:08.610656      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:09.611049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:30:09.668003 23 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:30:09.673390 23 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:30:09.673418 23 dns_common.go:489] Lookups using dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad failed for: [wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local]

  I0502 09:30:09.681617 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:30:09.738845 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:30:09.756228 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:30:10.611132      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:11.611307      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:12.611477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:13.611595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:14.611966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:30:14.667516 23 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:30:14.671156 23 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:30:14.671185 23 dns_common.go:489] Lookups using dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad failed for: [wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local]

  I0502 09:30:14.675608 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:30:14.679873 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:30:14.684242 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:30:15.612305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:16.612482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:17.612596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:18.612729      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:19.612910      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:30:19.666867 23 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:30:19.670090 23 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local from pod  dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0502 09:30:19.670117 23 dns_common.go:489] Lookups using dns-2862/dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad failed for: [wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local]

  I0502 09:30:19.673752 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:30:19.676805 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:30:19.680108 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:30:20.613134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:21.613275      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:22.613416      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:23.613552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:24.613898      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:30:24.672936 23 dns_common.go:552] DNS probes using dns-test-41ab85ae-3968-4ae4-ada7-de97312b90ad succeeded

  STEP: changing the service to type=ClusterIP @ 05/02/24 09:30:24.672
  W0502 09:30:24.690930      23 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2862.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2862.svc.cluster.local; sleep 1; done
   @ 05/02/24 09:30:24.69
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2862.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2862.svc.cluster.local; sleep 1; done
   @ 05/02/24 09:30:24.69
  STEP: creating a third pod to probe DNS @ 05/02/24 09:30:24.69
  STEP: submitting the pod to kubernetes @ 05/02/24 09:30:24.693
  E0502 09:30:25.613952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:26.614119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:27.614519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:28.614721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:29.615146      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:30.615330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:31.615779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:32.616007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/02/24 09:30:32.723
  STEP: looking for the results for each expected name from probers @ 05/02/24 09:30:32.726
  I0502 09:30:32.731701 23 dns_common.go:552] DNS probes using dns-test-7dda620b-30a8-4445-9e0f-b746770c6d9f succeeded

  STEP: deleting the pod @ 05/02/24 09:30:32.731
  STEP: deleting the pod @ 05/02/24 09:30:32.741
  STEP: deleting the pod @ 05/02/24 09:30:32.752
  STEP: deleting the test externalName service @ 05/02/24 09:30:32.767
  I0502 09:30:32.792680 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2862" for this suite. @ 05/02/24 09:30:32.796
• [41.486 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 05/02/24 09:30:32.801
  I0502 09:30:32.801680 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-runtime @ 05/02/24 09:30:32.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:30:32.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:30:32.818
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 05/02/24 09:30:32.827
  E0502 09:30:33.616996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:34.617018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:35.618013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:36.618388      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:37.618728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:38.619505      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:39.619777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:40.620006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:41.620364      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:42.621016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:43.621567      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:44.621763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:45.622301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:46.622767      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:47.623134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:48.623258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:49.624102      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:50.624433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 05/02/24 09:30:50.891
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 05/02/24 09:30:50.894
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 05/02/24 09:30:50.898
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 05/02/24 09:30:50.898
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 05/02/24 09:30:50.913
  E0502 09:30:51.625410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:52.625730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:53.625914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 05/02/24 09:30:53.928
  E0502 09:30:54.625987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 05/02/24 09:30:54.934
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 05/02/24 09:30:54.939
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 05/02/24 09:30:54.939
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 05/02/24 09:30:54.957
  E0502 09:30:55.626008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 05/02/24 09:30:55.967
  E0502 09:30:56.627088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:57.628014      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 05/02/24 09:30:57.978
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 05/02/24 09:30:57.983
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 05/02/24 09:30:57.983
  I0502 09:30:58.002760 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7221" for this suite. @ 05/02/24 09:30:58.006
• [25.212 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 05/02/24 09:30:58.014
  I0502 09:30:58.014122 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename var-expansion @ 05/02/24 09:30:58.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:30:58.03
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:30:58.032
  E0502 09:30:58.628826      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:30:59.629154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:00.046954 23 delete.go:62] Deleting pod "var-expansion-a7ffb104-52a8-4e9c-9ddb-ae64fcecdb6f" in namespace "var-expansion-9895"
  I0502 09:31:00.052813 23 delete.go:70] Wait up to 5m0s for pod "var-expansion-a7ffb104-52a8-4e9c-9ddb-ae64fcecdb6f" to be fully deleted
  E0502 09:31:00.629374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:01.629530      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:02.629894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:03.630007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:04.062851 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9895" for this suite. @ 05/02/24 09:31:04.067
• [6.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 05/02/24 09:31:04.075
  I0502 09:31:04.075842 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename daemonsets @ 05/02/24 09:31:04.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:31:04.095
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:31:04.097
  I0502 09:31:04.122171 23 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I0502 09:31:04.125561 23 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I0502 09:31:04.130751 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:04.130769 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:04.130781 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:04.133397 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:31:04.133409 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:31:04.630100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:05.130754 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:05.130781 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:05.130793 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:05.133772 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:31:05.133787 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:31:05.630966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:06.130424 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:06.130451 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:06.130465 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:06.132955 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0502 09:31:06.132968 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  I0502 09:31:06.132976 23 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I0502 09:31:06.138611 23 daemon_set.go:102] Updating DaemonSet daemon-set
  E0502 09:31:06.631038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:07.631353      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:08.148235 23 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I0502 09:31:08.154560 23 daemon_set.go:102] Updating DaemonSet daemon-set
  I0502 09:31:08.154588 23 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I0502 09:31:08.158944 23 daemon_set.go:1178] Wrong image for pod: daemon-set-cw6md. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I0502 09:31:08.158969 23 daemon_set.go:1183] Pod daemon-set-cw6md is not available
  I0502 09:31:08.161651 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:08.161683 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:08.161709 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0502 09:31:08.632079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:09.160814 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:09.160843 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:09.160895 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0502 09:31:09.632228      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:10.160682 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:10.160710 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:10.160723 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0502 09:31:10.633154      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:11.158202 23 daemon_set.go:1183] Pod daemon-set-npk84 is not available
  I0502 09:31:11.161562 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:11.161582 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:31:11.161597 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 05/02/24 09:31:11.166
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4424, will wait for the garbage collector to delete the pods @ 05/02/24 09:31:11.166
  I0502 09:31:11.224283 23 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 5.111523ms
  I0502 09:31:11.325105 23 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.817151ms
  E0502 09:31:11.633929      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:12.634413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:13.629287 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:31:13.629331 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0502 09:31:13.631722 23 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"42297"},"items":null}

  I0502 09:31:13.633555 23 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"42297"},"items":null}

  E0502 09:31:13.634618      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:13.641967 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4424" for this suite. @ 05/02/24 09:31:13.644
• [9.574 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 05/02/24 09:31:13.65
  I0502 09:31:13.650341 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:31:13.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:31:13.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:31:13.666
  STEP: creating secret secrets-1104/secret-test-7a00855a-80bf-4f22-9663-d12b3f41ebdf @ 05/02/24 09:31:13.668
  STEP: Creating a pod to test consume secrets @ 05/02/24 09:31:13.672
  E0502 09:31:14.635323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:15.635492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:16.636011      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:17.636159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:31:17.69
  I0502 09:31:17.693348 23 output.go:196] Trying to get logs from node mini-2 pod pod-configmaps-78024431-8994-4d2e-911b-3c82b3ec5887 container env-test: <nil>
  STEP: delete the pod @ 05/02/24 09:31:17.702
  I0502 09:31:17.715873 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1104" for this suite. @ 05/02/24 09:31:17.72
• [4.079 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 05/02/24 09:31:17.729
  I0502 09:31:17.729804 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename subpath @ 05/02/24 09:31:17.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:31:17.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:31:17.753
  STEP: Setting up data @ 05/02/24 09:31:17.755
  STEP: Creating pod pod-subpath-test-secret-47wf @ 05/02/24 09:31:17.763
  STEP: Creating a pod to test atomic-volume-subpath @ 05/02/24 09:31:17.763
  E0502 09:31:18.636304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:19.636779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:20.637500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:21.637660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:22.638344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:23.638531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:24.638891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:25.639072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:26.639812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:27.640016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:28.640278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:29.640706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:30.641076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:31.641229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:32.641598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:33.641734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:34.642059      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:35.642186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:36.642704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:37.642860      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:38.643103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:39.643579      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:40.643730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:41.643862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:31:41.823
  I0502 09:31:41.825192 23 output.go:196] Trying to get logs from node mini-2 pod pod-subpath-test-secret-47wf container test-container-subpath-secret-47wf: <nil>
  STEP: delete the pod @ 05/02/24 09:31:41.829
  STEP: Deleting pod pod-subpath-test-secret-47wf @ 05/02/24 09:31:41.839
  I0502 09:31:41.839859 23 delete.go:62] Deleting pod "pod-subpath-test-secret-47wf" in namespace "subpath-858"
  I0502 09:31:41.841637 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-858" for this suite. @ 05/02/24 09:31:41.844
• [24.120 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 05/02/24 09:31:41.85
  I0502 09:31:41.850247 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 09:31:41.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:31:41.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:31:41.868
  STEP: Creating the pod @ 05/02/24 09:31:41.869
  E0502 09:31:42.644293      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:43.644452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:44.399159 23 pod_client.go:141] Successfully updated pod "annotationupdate358c8c0e-dabb-4a35-acf6-32992aa48bfb"
  E0502 09:31:44.644543      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:45.644699      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:31:46.409324 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1574" for this suite. @ 05/02/24 09:31:46.413
• [4.571 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 05/02/24 09:31:46.42
  I0502 09:31:46.420952 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename discovery @ 05/02/24 09:31:46.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:31:46.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:31:46.442
  STEP: Setting up server cert @ 05/02/24 09:31:46.445
  STEP: Requesting APIResourceList from "/api/v1" @ 05/02/24 09:31:46.629
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 05/02/24 09:31:46.631
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 05/02/24 09:31:46.632
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 05/02/24 09:31:46.632
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 05/02/24 09:31:46.633
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 05/02/24 09:31:46.635
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 05/02/24 09:31:46.636
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 05/02/24 09:31:46.637
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 05/02/24 09:31:46.637
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 05/02/24 09:31:46.638
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 05/02/24 09:31:46.639
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 05/02/24 09:31:46.64
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 05/02/24 09:31:46.641
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 05/02/24 09:31:46.642
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 05/02/24 09:31:46.642
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 05/02/24 09:31:46.643
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 05/02/24 09:31:46.644
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 05/02/24 09:31:46.645
  E0502 09:31:46.645067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 05/02/24 09:31:46.645
  I0502 09:31:46.646819 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-8534" for this suite. @ 05/02/24 09:31:46.65
• [0.237 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 05/02/24 09:31:46.658
  I0502 09:31:46.658236 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename security-context @ 05/02/24 09:31:46.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:31:46.68
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:31:46.683
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/02/24 09:31:46.685
  E0502 09:31:47.645963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:48.646107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:49.646544      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:50.646841      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:31:50.707
  I0502 09:31:50.710358 23 output.go:196] Trying to get logs from node mini-2 pod security-context-8916b5a2-3e5f-4dca-a2e8-4814f388afbd container test-container: <nil>
  STEP: delete the pod @ 05/02/24 09:31:50.714
  I0502 09:31:50.725090 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6996" for this suite. @ 05/02/24 09:31:50.728
• [4.075 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 05/02/24 09:31:50.733
  I0502 09:31:50.733451 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 09:31:50.733
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:31:50.748
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:31:50.751
  STEP: Counting existing ResourceQuota @ 05/02/24 09:31:50.753
  E0502 09:31:51.647111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:52.647968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:53.648032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:54.648149      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:55.649000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/02/24 09:31:55.755
  STEP: Ensuring resource quota status is calculated @ 05/02/24 09:31:55.759
  E0502 09:31:56.649904      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:57.650061      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 05/02/24 09:31:57.763
  STEP: Creating a NodePort Service @ 05/02/24 09:31:57.78
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 05/02/24 09:31:57.808
  STEP: Ensuring resource quota status captures service creation @ 05/02/24 09:31:57.834
  E0502 09:31:58.650076      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:31:59.650522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 05/02/24 09:31:59.837
  STEP: Ensuring resource quota status released usage @ 05/02/24 09:31:59.885
  E0502 09:32:00.651008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:01.651158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:32:01.888519 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3842" for this suite. @ 05/02/24 09:32:01.891
• [11.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 05/02/24 09:32:01.897
  I0502 09:32:01.897570 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 09:32:01.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:32:01.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:32:01.914
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 09:32:01.916
  E0502 09:32:02.651453      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:03.651709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:04.651847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:05.652008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:32:05.932
  I0502 09:32:05.936520 23 output.go:196] Trying to get logs from node mini-1 pod downwardapi-volume-8add04a7-c55d-4f13-807c-e8a0af5a5543 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 09:32:05.941
  I0502 09:32:05.957208 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9065" for this suite. @ 05/02/24 09:32:05.961
• [4.071 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 05/02/24 09:32:05.968
  I0502 09:32:05.968191 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/02/24 09:32:05.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:32:05.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:32:05.994
  STEP: create the container to handle the HTTPGet hook request. @ 05/02/24 09:32:06
  E0502 09:32:06.652514      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:07.652723      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/02/24 09:32:08.016
  E0502 09:32:08.653584      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:09.654299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/02/24 09:32:10.031
  E0502 09:32:10.654867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:11.655051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:12.655351      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:13.655551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/02/24 09:32:14.046
  I0502 09:32:14.050109 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-7251" for this suite. @ 05/02/24 09:32:14.053
• [8.092 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1537
  STEP: Creating a kubernetes client @ 05/02/24 09:32:14.06
  I0502 09:32:14.060563 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 09:32:14.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:32:14.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:32:14.079
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-5552 @ 05/02/24 09:32:14.081
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/02/24 09:32:14.094
  STEP: creating service externalsvc in namespace services-5552 @ 05/02/24 09:32:14.094
  STEP: creating replication controller externalsvc in namespace services-5552 @ 05/02/24 09:32:14.11
  I0502 09:32:14.120087      23 runners.go:198] Created replication controller with name: externalsvc, namespace: services-5552, replica count: 2
  E0502 09:32:14.655751      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:15.656067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:16.656923      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:32:17.170560      23 runners.go:198] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 05/02/24 09:32:17.173
  I0502 09:32:17.191274 23 resource.go:361] Creating new exec pod
  E0502 09:32:17.656957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:18.657257      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:32:19.209813 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-5552 exec execpod6jqbt -- /bin/sh -x -c nslookup nodeport-service.services-5552.svc.cluster.local'
  I0502 09:32:19.302024 23 builder.go:146] stderr: "+ nslookup nodeport-service.services-5552.svc.cluster.local\n"
  I0502 09:32:19.302050 23 builder.go:147] stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-5552.svc.cluster.local\tcanonical name = externalsvc.services-5552.svc.cluster.local.\nName:\texternalsvc.services-5552.svc.cluster.local\nAddress: 10.98.148.215\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-5552, will wait for the garbage collector to delete the pods @ 05/02/24 09:32:19.302
  I0502 09:32:19.360713 23 resources.go:139] Deleting ReplicationController externalsvc took: 6.373787ms
  I0502 09:32:19.461200 23 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.483383ms
  E0502 09:32:19.657704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:20.658371      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:21.659037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:32:22.088128 23 service.go:1548] Cleaning up the NodePort to ExternalName test service
  I0502 09:32:22.099950 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5552" for this suite. @ 05/02/24 09:32:22.105
• [8.052 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 05/02/24 09:32:22.112
  I0502 09:32:22.112534 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename podtemplate @ 05/02/24 09:32:22.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:32:22.124
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:32:22.127
  I0502 09:32:22.149608 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9835" for this suite. @ 05/02/24 09:32:22.152
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 05/02/24 09:32:22.158
  I0502 09:32:22.158269 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubelet-test @ 05/02/24 09:32:22.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:32:22.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:32:22.178
  E0502 09:32:22.659473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:23.659615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:32:24.205578 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9186" for this suite. @ 05/02/24 09:32:24.208
• [2.058 seconds]
------------------------------
SSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 05/02/24 09:32:24.215
  I0502 09:32:24.215963 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename taint-multiple-pods @ 05/02/24 09:32:24.216
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:32:24.23
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:32:24.234
  I0502 09:32:24.236943 23 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0502 09:32:24.660371      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:25.660493      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:26.661217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:27.661346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:28.662072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:29.662522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:30.663089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:31.663270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:32.663954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:33.663985      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:34.664578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:35.664724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:36.665252      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:37.665486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:38.665844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:39.666000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:40.666817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:41.667077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:42.667153      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:43.667775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:44.668433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:45.668714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:46.669538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:47.669665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:48.669774      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:49.670140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:50.670992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:51.671170      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:52.671983      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:53.672151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:54.672997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:55.673128      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:56.673852      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:57.674020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:58.674804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:32:59.675155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:00.675321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:01.675483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:02.675606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:03.675750      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:04.676367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:05.677005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:06.677185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:07.677386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:08.677982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:09.678515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:10.678739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:11.678895      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:12.679844      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:13.679989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:14.680843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:15.680998      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:16.681485      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:17.681641      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:18.681708      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:19.682119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:20.683001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:21.683152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:22.683977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:23.684134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:33:24.236998 23 util.go:400] Waiting for terminating namespaces to be deleted...
  I0502 09:33:24.240220 23 taints.go:150] Starting informer...
  STEP: Starting pods... @ 05/02/24 09:33:24.24
  I0502 09:33:24.456024 23 taints.go:469] Pod1 is running on mini-1. Tainting Node
  E0502 09:33:24.684901      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:25.684976      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:33:26.675478 23 taints.go:477] Pod2 is running on mini-1. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/02/24 09:33:26.675
  E0502 09:33:26.685108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/02/24 09:33:26.687
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 05/02/24 09:33:26.695
  E0502 09:33:27.685870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:28.686051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:29.686510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:30.686666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:31.687040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:32.687478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:33:32.831061 23 taints.go:498] Noticed Pod "taint-eviction-b1" gets evicted.
  E0502 09:33:33.687965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:34.688176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:35.688314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:36.688465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:37.688630      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:38.688768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:39.689018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:40.689171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:41.689310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:42.689469      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:43.689632      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:44.690060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:45.690200      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:46.690326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:47.690501      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:48.690647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:49.691101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:50.691259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:51.691508      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:52.692107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:33:52.856374 23 taints.go:498] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/02/24 09:33:52.867
  I0502 09:33:52.874556 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-2866" for this suite. @ 05/02/24 09:33:52.883
• [88.688 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 05/02/24 09:33:52.903
  I0502 09:33:52.903858 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename dns @ 05/02/24 09:33:52.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:33:52.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:33:52.957
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 05/02/24 09:33:52.96
  I0502 09:33:52.966988 23 dns.go:419] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-1632  f1e0ff0e-f4ce-4a4c-b9f4-ce84f2f1b13e 43323 0 2024-05-02 09:33:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-05-02 09:33:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bfj7p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bfj7p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0502 09:33:53.693087      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:54.693366      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 05/02/24 09:33:54.978
  I0502 09:33:54.978883 23 exec_util.go:55] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1632 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 09:33:54.978898 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 09:33:54.979173 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 09:33:54.979226 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-1632/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 05/02/24 09:33:55.022
  I0502 09:33:55.022685 23 exec_util.go:55] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1632 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 09:33:55.022694 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 09:33:55.022920 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 09:33:55.022978 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-1632/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0502 09:33:55.064362 23 dns.go:421] Deleting pod test-dns-nameservers...
  I0502 09:33:55.074742 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1632" for this suite. @ 05/02/24 09:33:55.078
• [2.183 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 05/02/24 09:33:55.087
  I0502 09:33:55.087296 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename var-expansion @ 05/02/24 09:33:55.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:33:55.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:33:55.111
  STEP: creating the pod @ 05/02/24 09:33:55.113
  STEP: waiting for pod running @ 05/02/24 09:33:55.121
  E0502 09:33:55.694375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:56.694620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 05/02/24 09:33:57.129
  I0502 09:33:57.131255 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3427 PodName:var-expansion-1829a3dc-9c30-4465-acc1-04df040ba8c1 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 09:33:57.131270 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 09:33:57.131664 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 09:33:57.131717 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-3427/pods/var-expansion-1829a3dc-9c30-4465-acc1-04df040ba8c1/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 05/02/24 09:33:57.169
  I0502 09:33:57.172318 23 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3427 PodName:var-expansion-1829a3dc-9c30-4465-acc1-04df040ba8c1 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0502 09:33:57.172328 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  I0502 09:33:57.172671 23 exec_util.go:62] ExecWithOptions: Clientset creation
  I0502 09:33:57.172721 23 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-3427/pods/var-expansion-1829a3dc-9c30-4465-acc1-04df040ba8c1/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 05/02/24 09:33:57.21
  E0502 09:33:57.695593      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:33:57.720214 23 pod_client.go:141] Successfully updated pod "var-expansion-1829a3dc-9c30-4465-acc1-04df040ba8c1"
  STEP: waiting for annotated pod running @ 05/02/24 09:33:57.72
  STEP: deleting the pod gracefully @ 05/02/24 09:33:57.723
  I0502 09:33:57.723818 23 delete.go:62] Deleting pod "var-expansion-1829a3dc-9c30-4465-acc1-04df040ba8c1" in namespace "var-expansion-3427"
  I0502 09:33:57.730016 23 delete.go:70] Wait up to 5m0s for pod "var-expansion-1829a3dc-9c30-4465-acc1-04df040ba8c1" to be fully deleted
  E0502 09:33:58.696060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:33:59.697073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:00.697169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:01.697326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:02.697492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:03.697675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:04.697790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:05.698587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:06.699545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:07.699690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:08.700341      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:09.700990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:10.701507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:11.701634      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:12.701909      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:13.702053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:14.702784      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:15.702932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:16.703032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:17.703297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:18.703777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:19.704139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:20.704299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:21.704507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:22.705289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:23.705421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:24.705992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:25.706745      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:26.706984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:27.707746      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:28.708216      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:29.708749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:30.709451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:31.710422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:34:31.794403 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3427" for this suite. @ 05/02/24 09:34:31.797
• [36.717 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 05/02/24 09:34:31.804
  I0502 09:34:31.804262 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename gc @ 05/02/24 09:34:31.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:34:31.822
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:34:31.824
  STEP: create the deployment @ 05/02/24 09:34:31.826
  W0502 09:34:31.830363      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/02/24 09:34:31.83
  STEP: delete the deployment @ 05/02/24 09:34:32.333
  STEP: wait for all rs to be garbage collected @ 05/02/24 09:34:32.338
  STEP: expected 0 rs, got 1 rs @ 05/02/24 09:34:32.34
  STEP: expected 0 pods, got 2 pods @ 05/02/24 09:34:32.343
  E0502 09:34:32.711476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/02/24 09:34:32.848
  I0502 09:34:32.912085 23 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0502 09:34:32.912183 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3610" for this suite. @ 05/02/24 09:34:32.916
• [1.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 05/02/24 09:34:32.924
  I0502 09:34:32.924789 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 09:34:32.925
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:34:32.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:34:32.941
  STEP: creating the pod @ 05/02/24 09:34:32.943
  STEP: submitting the pod to kubernetes @ 05/02/24 09:34:32.943
  E0502 09:34:33.712350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:34.712720      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/02/24 09:34:34.958
  STEP: updating the pod @ 05/02/24 09:34:34.96
  I0502 09:34:35.469724 23 pod_client.go:141] Successfully updated pod "pod-update-4cfd9180-beb4-4c72-b1c1-3d6bfed90cd0"
  STEP: verifying the updated pod is in kubernetes @ 05/02/24 09:34:35.472
  I0502 09:34:35.475057 23 pods.go:391] Pod update OK
  I0502 09:34:35.475127 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5002" for this suite. @ 05/02/24 09:34:35.478
• [2.561 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 05/02/24 09:34:35.485
  I0502 09:34:35.485816 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/02/24 09:34:35.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:34:35.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:34:35.505
  I0502 09:34:35.510107 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-1502" for this suite. @ 05/02/24 09:34:35.514
• [0.036 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 05/02/24 09:34:35.521
  I0502 09:34:35.521985 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:34:35.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:34:35.542
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:34:35.545
  STEP: Creating configMap with name projected-configmap-test-volume-d45376e2-ae69-4a0c-9f1f-fd243856cedb @ 05/02/24 09:34:35.547
  STEP: Creating a pod to test consume configMaps @ 05/02/24 09:34:35.551
  E0502 09:34:35.712838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:36.713007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:37.713457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:38.713583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:34:39.57
  I0502 09:34:39.572302 23 output.go:196] Trying to get logs from node mini-2 pod pod-projected-configmaps-74fa80c3-c421-456d-9dd7-8dff77dc1211 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:34:39.582
  I0502 09:34:39.594145 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9742" for this suite. @ 05/02/24 09:34:39.596
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 05/02/24 09:34:39.601
  I0502 09:34:39.601620 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:34:39.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:34:39.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:34:39.618
  STEP: Creating projection with secret that has name projected-secret-test-map-f6cefd52-3eee-42b4-bd6b-17232a836ad8 @ 05/02/24 09:34:39.619
  STEP: Creating a pod to test consume secrets @ 05/02/24 09:34:39.623
  E0502 09:34:39.714104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:40.714305      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:41.715262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:42.716035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:34:43.641
  I0502 09:34:43.643977 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-secrets-75e77be1-e8bc-4adc-9212-2967c747bbaf container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:34:43.654
  I0502 09:34:43.667492 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5493" for this suite. @ 05/02/24 09:34:43.67
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 05/02/24 09:34:43.676
  I0502 09:34:43.676321 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:34:43.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:34:43.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:34:43.697
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 09:34:43.698
  E0502 09:34:43.716525      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:44.716953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:45.717049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:46.717174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:34:47.716
  E0502 09:34:47.717454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:34:47.719119 23 output.go:196] Trying to get logs from node mini-1 pod downwardapi-volume-07d0ffcb-4317-42cd-94e2-e7a8b3ed8920 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 09:34:47.723
  I0502 09:34:47.735624 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5891" for this suite. @ 05/02/24 09:34:47.738
• [4.068 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 05/02/24 09:34:47.744
  I0502 09:34:47.744671 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pv @ 05/02/24 09:34:47.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:34:47.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:34:47.765
  STEP: Creating initial PV and PVC @ 05/02/24 09:34:47.767
  I0502 09:34:47.767773 23 pv.go:390] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-816" @ 05/02/24 09:34:47.787
  STEP: Listing PVCs in namespace "pv-816" @ 05/02/24 09:34:47.792
  STEP: Reading "pvc-rskq2" Status @ 05/02/24 09:34:47.794
  STEP: Reading "pv-816-vx875" Status @ 05/02/24 09:34:47.797
  STEP: Patching "pvc-rskq2" Status @ 05/02/24 09:34:47.8
  STEP: Patching "pv-816-vx875" Status @ 05/02/24 09:34:47.805
  STEP: Updating "pvc-rskq2" Status @ 05/02/24 09:34:47.816
  STEP: Updating "pv-816-vx875" Status @ 05/02/24 09:34:47.826
  I0502 09:34:47.837630 23 persistent_volumes.go:407] AfterEach: deleting 1 PVCs and 1 PVs...
  I0502 09:34:47.837642 23 pv.go:201] Deleting PersistentVolumeClaim "pvc-rskq2"
  I0502 09:34:47.843774 23 pv.go:189] Deleting PersistentVolume "pv-816-vx875"
  I0502 09:34:47.855609 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-816" for this suite. @ 05/02/24 09:34:47.863
• [0.133 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 05/02/24 09:34:47.877
  I0502 09:34:47.877381 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename container-probe @ 05/02/24 09:34:47.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:34:47.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:34:47.903
  STEP: Creating pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952 @ 05/02/24 09:34:47.907
  E0502 09:34:48.718248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:49.718760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/02/24 09:34:49.924
  I0502 09:34:49.926791 23 container_probe.go:1749] Initial restart count of pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 is 0
  I0502 09:34:49.928883 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:34:50.718791      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:51.719050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:34:51.932588 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:34:52.719370      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:53.719932      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:34:53.936079 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:34:54.720056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:55.720216      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:34:55.939585 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:34:56.720359      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:57.720555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:34:57.942608 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:34:58.721500      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:34:59.722008      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:34:59.946524 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:00.722301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:01.723108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:01.951564 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:02.723328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:03.723392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:03.954813 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:04.723760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:05.723905      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:05.958668 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:06.724463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:07.724642      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:07.962414 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:08.725145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:09.725619      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:09.965845 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:10.725740      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:11.725843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:11.969522 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:12.726837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:13.726969      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:13.973163 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:14.727050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:15.728079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:15.976516 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:16.728366      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:17.728531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:17.979920 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:18.728639      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:19.729039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:19.983600 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:20.729344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:21.730017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:21.987328 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:22.730175      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:23.731158      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:23.990589 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:24.731423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:25.731581      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:25.994623 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:26.732405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:27.732574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:27.998173 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:28.732881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:29.733164      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:30.001528 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:30.733313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:31.734043      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:32.005902 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:32.734570      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:33.734887      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:34.009261 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:34.735117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:35.735247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:36.013042 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:36.735712      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:37.735870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:38.016512 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  E0502 09:35:38.736218      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:39.736684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:40.020318 23 container_probe.go:1759] Get pod busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 in namespace container-probe-4952
  I0502 09:35:40.020336 23 container_probe.go:1763] Restart count of pod container-probe-4952/busybox-ada6838a-eb9f-46bb-9e81-554dc04f3bc3 is now 1 (50.093528637s elapsed)
  STEP: deleting the pod @ 05/02/24 09:35:40.02
  I0502 09:35:40.030573 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4952" for this suite. @ 05/02/24 09:35:40.035
• [52.164 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 05/02/24 09:35:40.041
  I0502 09:35:40.041312 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename csi-storageclass @ 05/02/24 09:35:40.041
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:35:40.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:35:40.06
  STEP: Creating a StorageClass @ 05/02/24 09:35:40.062
  STEP: Get StorageClass "e2e-bkvwc" @ 05/02/24 09:35:40.066
  STEP: Patching the StorageClass "e2e-bkvwc" @ 05/02/24 09:35:40.068
  STEP: Delete StorageClass "e2e-bkvwc" @ 05/02/24 09:35:40.075
  STEP: Confirm deletion of StorageClass "e2e-bkvwc" @ 05/02/24 09:35:40.079
  STEP: Create a replacement StorageClass @ 05/02/24 09:35:40.082
  STEP: Updating StorageClass "e2e-v2-82kck" @ 05/02/24 09:35:40.085
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-82kck=updated" @ 05/02/24 09:35:40.091
  STEP: Deleting StorageClass "e2e-v2-82kck" via DeleteCollection @ 05/02/24 09:35:40.093
  STEP: Confirm deletion of StorageClass "e2e-v2-82kck" @ 05/02/24 09:35:40.102
  I0502 09:35:40.104391 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-2987" for this suite. @ 05/02/24 09:35:40.107
• [0.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1858
  STEP: Creating a kubernetes client @ 05/02/24 09:35:40.113
  I0502 09:35:40.113552 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 09:35:40.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:35:40.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:35:40.132
  STEP: Starting the proxy @ 05/02/24 09:35:40.134
  I0502 09:35:40.134785 23 util.go:592] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-992 proxy --unix-socket=/tmp/kubectl-proxy-unix240488684/test'
  STEP: retrieving proxy /api/ output @ 05/02/24 09:35:40.16
  I0502 09:35:40.160957 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-992" for this suite. @ 05/02/24 09:35:40.165
• [0.058 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 05/02/24 09:35:40.171
  I0502 09:35:40.171878 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:35:40.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:35:40.191
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:35:40.194
  STEP: Creating secret with name secret-test-map-05ebe0c5-447a-4794-8f9d-0a372af27f6b @ 05/02/24 09:35:40.196
  STEP: Creating a pod to test consume secrets @ 05/02/24 09:35:40.199
  E0502 09:35:40.736747      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:41.737026      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:42.737093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:43.738072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:35:44.218
  I0502 09:35:44.221027 23 output.go:196] Trying to get logs from node mini-2 pod pod-secrets-d0cbfdad-cd0b-4713-b8c3-1207b93a057b container secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:35:44.225
  I0502 09:35:44.237428 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1610" for this suite. @ 05/02/24 09:35:44.24
• [4.075 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 05/02/24 09:35:44.246
  I0502 09:35:44.246812 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename disruption @ 05/02/24 09:35:44.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:35:44.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:35:44.265
  STEP: creating the pdb @ 05/02/24 09:35:44.266
  STEP: Waiting for the pdb to be processed @ 05/02/24 09:35:44.271
  STEP: updating the pdb @ 05/02/24 09:35:44.275
  STEP: Waiting for the pdb to be processed @ 05/02/24 09:35:44.281
  E0502 09:35:44.738400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:45.738568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 05/02/24 09:35:46.285
  STEP: Waiting for the pdb to be processed @ 05/02/24 09:35:46.291
  E0502 09:35:46.739534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:47.739682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 05/02/24 09:35:48.3
  I0502 09:35:48.302238 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8650" for this suite. @ 05/02/24 09:35:48.305
• [4.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2218
  STEP: Creating a kubernetes client @ 05/02/24 09:35:48.314
  I0502 09:35:48.314547 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 09:35:48.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:35:48.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:35:48.331
  STEP: creating service in namespace services-3975 @ 05/02/24 09:35:48.332
  STEP: creating service affinity-nodeport in namespace services-3975 @ 05/02/24 09:35:48.332
  STEP: creating replication controller affinity-nodeport in namespace services-3975 @ 05/02/24 09:35:48.36
  I0502 09:35:48.370124      23 runners.go:198] Created replication controller with name: affinity-nodeport, namespace: services-3975, replica count: 3
  E0502 09:35:48.740386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:49.741449      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:50.741584      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:51.421825      23 runners.go:198] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0502 09:35:51.432566 23 resource.go:361] Creating new exec pod
  E0502 09:35:51.742270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:52.742378      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:53.742510      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:54.447719 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-3975 exec execpod-affinity5qcrx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I0502 09:35:54.520214 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  I0502 09:35:54.520241 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:35:54.520282 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-3975 exec execpod-affinity5qcrx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.179.204 80'
  I0502 09:35:54.591727 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.179.204 80\nConnection to 10.96.179.204 80 port [tcp/http] succeeded!\n"
  I0502 09:35:54.591752 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:35:54.591794 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-3975 exec execpod-affinity5qcrx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.33 30227'
  I0502 09:35:54.667078 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.33 30227\nConnection to 10.221.190.33 30227 port [tcp/*] succeeded!\n"
  I0502 09:35:54.667103 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:35:54.667142 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-3975 exec execpod-affinity5qcrx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.221.190.32 30227'
  E0502 09:35:54.743298      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:54.743975 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.221.190.32 30227\nConnection to 10.221.190.32 30227 port [tcp/*] succeeded!\n"
  I0502 09:35:54.743998 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:35:54.744037 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-3975 exec execpod-affinity5qcrx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.221.190.31:30227/ ; done'
  I0502 09:35:54.850290 23 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.221.190.31:30227/\n"
  I0502 09:35:54.850317 23 builder.go:147] stdout: "\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx\naffinity-nodeport-jqkgx"
  I0502 09:35:54.850327 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850333 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850338 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850343 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850348 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850353 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850358 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850363 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850368 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850372 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850377 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850382 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850387 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850392 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850398 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850403 23 service.go:242] Received response from host: affinity-nodeport-jqkgx
  I0502 09:35:54.850441 23 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-3975, will wait for the garbage collector to delete the pods @ 05/02/24 09:35:54.861
  I0502 09:35:54.918704 23 resources.go:139] Deleting ReplicationController affinity-nodeport took: 4.238036ms
  I0502 09:35:55.019711 23 resources.go:163] Terminating ReplicationController affinity-nodeport pods took: 101.003321ms
  E0502 09:35:55.744103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:56.744989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:57.745072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:35:58.151823 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3975" for this suite. @ 05/02/24 09:35:58.155
• [9.846 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 05/02/24 09:35:58.16
  I0502 09:35:58.160809 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:35:58.161
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:35:58.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:35:58.181
  STEP: Creating secret with name s-test-opt-del-251feb6f-f7ee-43de-85e7-31f5d550efed @ 05/02/24 09:35:58.185
  STEP: Creating secret with name s-test-opt-upd-0be7af94-791e-4b43-8e80-2f0b971209f3 @ 05/02/24 09:35:58.189
  STEP: Creating the pod @ 05/02/24 09:35:58.193
  E0502 09:35:58.745755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:35:59.746188      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:00.746320      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:01.747038      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-251feb6f-f7ee-43de-85e7-31f5d550efed @ 05/02/24 09:36:02.228
  STEP: Updating secret s-test-opt-upd-0be7af94-791e-4b43-8e80-2f0b971209f3 @ 05/02/24 09:36:02.231
  STEP: Creating secret with name s-test-opt-create-f7a85514-17c2-48f0-9bd8-2d31ab70bce7 @ 05/02/24 09:36:02.237
  STEP: waiting to observe update in volume @ 05/02/24 09:36:02.242
  E0502 09:36:02.747522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:03.747922      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:04.748937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:05.749093      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:06.749142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:07.749283      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:08.749555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:09.750029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:10.750519      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:11.751037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:12.751437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:13.751696      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:14.752055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:15.752205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:16.752281      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:17.752443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:18.752721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:19.753150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:20.753208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:21.754030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:22.755053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:23.755179      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:24.755657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:25.755816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:26.756406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:27.756567      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:28.756734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:29.757123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:30.758054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:31.759094      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:32.759391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:33.759790      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:34.759877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:35.760310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:36.761017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:37.761185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:38.762021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:39.762660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:40.763102      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:41.764099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:42.764633      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:43.764786      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:44.765141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:45.765275      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:46.766122      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:47.766246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:48.766651      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:49.767030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:50.767979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:51.768035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:52.769031      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:53.769190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:54.769303      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:55.769422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:56.769718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:57.769893      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:58.770145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:36:59.770594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:00.771045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:01.772101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:02.772650      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:03.772805      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:04.773677      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:05.773814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:06.774715      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:07.774896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:08.775654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:09.775947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:10.776161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:11.777100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:37:12.508221 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8426" for this suite. @ 05/02/24 09:37:12.511
• [74.358 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 05/02/24 09:37:12.519
  I0502 09:37:12.519092 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 09:37:12.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:37:12.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:37:12.551
  STEP: Creating configMap configmap-8867/configmap-test-ac27f6fc-db47-4f52-bf34-71ce3e35f096 @ 05/02/24 09:37:12.553
  STEP: Creating a pod to test consume configMaps @ 05/02/24 09:37:12.557
  E0502 09:37:12.777933      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:13.778161      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:14.778195      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:15.778350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:37:16.575
  I0502 09:37:16.577778 23 output.go:196] Trying to get logs from node mini-2 pod pod-configmaps-07ef58c4-5206-4883-9b46-5809bd1d9dcd container env-test: <nil>
  STEP: delete the pod @ 05/02/24 09:37:16.588
  I0502 09:37:16.601387 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8867" for this suite. @ 05/02/24 09:37:16.604
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:531
  STEP: Creating a kubernetes client @ 05/02/24 09:37:16.611
  I0502 09:37:16.611259 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename security-context-test @ 05/02/24 09:37:16.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:37:16.628
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:37:16.63
  E0502 09:37:16.778396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:17.778590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:18.779138      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:19.779494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:37:20.655597 23 security_context.go:538] Got logs for pod "busybox-privileged-false-aed2f8b2-cb4c-48ff-9fab-09005926c699": "ip: RTNETLINK answers: Operation not permitted\n"
  I0502 09:37:20.655649 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3275" for this suite. @ 05/02/24 09:37:20.658
• [4.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 05/02/24 09:37:20.664
  I0502 09:37:20.664030 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename statefulset @ 05/02/24 09:37:20.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:37:20.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:37:20.685
  STEP: Creating service test in namespace statefulset-390 @ 05/02/24 09:37:20.686
  STEP: Creating statefulset ss in namespace statefulset-390 @ 05/02/24 09:37:20.696
  I0502 09:37:20.711180 23 wait.go:40] Found 0 stateful pods, waiting for 1
  E0502 09:37:20.780390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:21.780582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:22.780662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:23.780773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:24.781009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:25.781173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:26.781302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:27.781452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:28.781600      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:29.782079      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:37:30.708741 23 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 05/02/24 09:37:30.714
  STEP: Getting /status @ 05/02/24 09:37:30.719
  I0502 09:37:30.721957 23 statefulset.go:1067] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 05/02/24 09:37:30.721
  I0502 09:37:30.728853 23 statefulset.go:1087] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 05/02/24 09:37:30.728
  I0502 09:37:30.731118 23 statefulset.go:1115] Observed &StatefulSet event: ADDED
  I0502 09:37:30.731148 23 statefulset.go:1108] Found Statefulset ss in namespace statefulset-390 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0502 09:37:30.731170 23 statefulset.go:1119] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 05/02/24 09:37:30.731
  I0502 09:37:30.731196 23 statefulset.go:1123] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0502 09:37:30.736247 23 statefulset.go:1127] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 05/02/24 09:37:30.736
  I0502 09:37:30.737802 23 statefulset.go:1152] Observed &StatefulSet event: ADDED
  I0502 09:37:30.737846 23 statefulset.go:1148] Observed Statefulset ss in namespace statefulset-390 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0502 09:37:30.737926 23 statefulset.go:1152] Observed &StatefulSet event: MODIFIED
  I0502 09:37:30.737961 23 statefulset.go:135] Deleting all statefulset in ns statefulset-390
  I0502 09:37:30.739963 23 rest.go:150] Scaling statefulset ss to 0
  E0502 09:37:30.782872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:31.783795      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:32.783955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:33.784123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:34.784337      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:35.784498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:36.784684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:37.784850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:38.785029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:39.785577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:37:40.751904 23 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0502 09:37:40.754122 23 rest.go:88] Deleting statefulset ss
  I0502 09:37:40.767468 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-390" for this suite. @ 05/02/24 09:37:40.774
• [20.116 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 05/02/24 09:37:40.78
  I0502 09:37:40.780580 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename events @ 05/02/24 09:37:40.78
  E0502 09:37:40.785583      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:37:40.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:37:40.797
  STEP: Create set of events @ 05/02/24 09:37:40.798
  I0502 09:37:40.801778 23 core_events.go:198] created test-event-1
  I0502 09:37:40.804446 23 core_events.go:198] created test-event-2
  I0502 09:37:40.807719 23 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 05/02/24 09:37:40.807
  STEP: delete collection of events @ 05/02/24 09:37:40.809
  I0502 09:37:40.809513 23 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/02/24 09:37:40.819
  I0502 09:37:40.819798 23 core_events.go:230] requesting list of events to confirm quantity
  I0502 09:37:40.821567 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7407" for this suite. @ 05/02/24 09:37:40.823
• [0.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 05/02/24 09:37:40.83
  I0502 09:37:40.830047 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 09:37:40.83
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:37:40.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:37:40.845
  STEP: Setting up server cert @ 05/02/24 09:37:40.866
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 09:37:41.191
  STEP: Deploying the webhook pod @ 05/02/24 09:37:41.197
  STEP: Wait for the deployment to be ready @ 05/02/24 09:37:41.206
  I0502 09:37:41.217293 23 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0502 09:37:41.785953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:42.786098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 09:37:43.226
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 09:37:43.237
  E0502 09:37:43.786848      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:37:44.238585 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/02/24 09:37:44.244
  STEP: create a pod that should be denied by the webhook @ 05/02/24 09:37:44.256
  STEP: create a pod that causes the webhook to hang @ 05/02/24 09:37:44.263
  E0502 09:37:44.786862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:45.787021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:46.787185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:47.787446      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:48.787592      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:49.788074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:50.788217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:51.788380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:52.788534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:53.788695      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 05/02/24 09:37:54.269
  STEP: create a configmap that should be admitted by the webhook @ 05/02/24 09:37:54.276
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/02/24 09:37:54.282
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/02/24 09:37:54.288
  STEP: create a namespace that bypass the webhook @ 05/02/24 09:37:54.293
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 05/02/24 09:37:54.308
  I0502 09:37:54.375229 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7531" for this suite. @ 05/02/24 09:37:54.382
  STEP: Destroying namespace "webhook-markers-2961" for this suite. @ 05/02/24 09:37:54.388
  STEP: Destroying namespace "exempted-namespace-1714" for this suite. @ 05/02/24 09:37:54.395
• [13.574 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 05/02/24 09:37:54.404
  I0502 09:37:54.404376 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename var-expansion @ 05/02/24 09:37:54.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:37:54.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:37:54.435
  STEP: Creating a pod to test substitution in container's command @ 05/02/24 09:37:54.437
  E0502 09:37:54.788846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:55.789025      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:56.789134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:57.789270      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:37:58.454
  I0502 09:37:58.456382 23 output.go:196] Trying to get logs from node mini-1 pod var-expansion-7e960639-bef3-4ea3-a3ef-aee86a3c7db6 container dapi-container: <nil>
  STEP: delete the pod @ 05/02/24 09:37:58.46
  I0502 09:37:58.475359 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5330" for this suite. @ 05/02/24 09:37:58.478
• [4.082 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 05/02/24 09:37:58.486
  I0502 09:37:58.486010 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename chunking @ 05/02/24 09:37:58.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:37:58.503
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:37:58.507
  STEP: creating a large number of resources @ 05/02/24 09:37:58.509
  E0502 09:37:58.789568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:37:59.790237      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:00.791204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:01.791671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:02.791777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:03.792629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:04.793207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:05.793594      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:06.793953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:07.794438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:08.794688      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:09.795016      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:10.795949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:11.796520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:12.796568      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:13.796701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:14.797538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:15.798593      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 05/02/24 09:38:16.192
  I0502 09:38:16.240758 23 chunking.go:163] Retrieved 40/40 results with rv 45368 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 05/02/24 09:38:16.24
  E0502 09:38:16.799369      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:17.799551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:18.799704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:19.800233      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:20.800391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:21.800564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:22.800717      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:23.800850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:24.801359      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:25.801477      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:26.801793      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:27.802546      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:28.802881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:29.803287      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:30.803437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:31.803564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:32.803728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:33.803864      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:34.804204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:35.804481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:38:36.245478 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:38:36.804968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:37.805085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:38.805234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:39.805779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:40.805945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:41.805990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:42.807070      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:43.807247      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:44.807622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:45.807755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:46.807945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:47.808032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:48.808347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:49.808808      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:50.808974      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:51.808993      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:52.809130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:53.809463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:54.809775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:55.809919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:38:56.246570 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:38:56.810039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:57.810380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:58.810503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:38:59.811098      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:00.811243      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:01.811367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:02.811535      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:03.811654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:04.812040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:05.812172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:06.812326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:07.812478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:08.812634      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:09.813187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:10.813345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:11.813451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:12.813615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:13.813742      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:14.814106      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:15.814239      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:39:16.246264 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:39:16.814734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:17.814873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:18.815032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:19.815473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:20.815577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:21.815705      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:22.815873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:23.816039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:24.816354      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:25.816493      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:26.817091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:27.817248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:28.817365      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:29.817947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:30.818088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:31.818211      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:32.818374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:33.818845      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:34.819246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:35.819666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:39:36.245375 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:39:36.819819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:37.819977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:38.820119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:39.820745      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:40.820909      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:41.821030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:42.821202      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:43.821609      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:44.821910      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:45.822055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:46.822177      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:47.822342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:48.822476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:49.823053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:50.823186      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:51.823310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:52.823476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:53.823598      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:54.823955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:55.824088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:39:56.246071 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:39:56.824582      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:57.824739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:58.824914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:39:59.825279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:00.825405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:01.825523      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:02.826383      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:03.826465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:04.826788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:05.827057      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:06.827203      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:07.827350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:08.827465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:09.828078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:10.828189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:11.828309      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:12.828478      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:13.828620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:14.828941      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:15.829083      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:40:16.245906 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:40:16.829565      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:17.829722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:18.829866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:19.830366      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:20.830473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:21.831048      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:22.831212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:23.831329      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:24.831676      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:25.831817      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:26.831968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:27.832089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:28.832395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:29.832800      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:30.832933      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:31.833042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:32.833187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:33.833292      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:34.833566      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:35.833912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:40:36.245956 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:40:36.834486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:37.835077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:38.835492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:39.835754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:40.835840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:41.835925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:42.836081      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:43.836229      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:44.836308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:45.836975      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:46.836991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:47.837151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:48.837421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:49.837759      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:50.837883      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:51.838169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:52.838287      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:53.838398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:54.838544      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:55.838671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:40:56.246037 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:40:56.839646      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:57.839801      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:58.840417      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:40:59.840528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:00.841050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:01.841151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:02.841291      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:03.841435      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:04.841564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:05.841706      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:06.841839      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:07.842003      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:08.842390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:09.842511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:10.842690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:11.842765      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:12.842945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:13.843071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:14.843166      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:15.843308      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:41:16.245220 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:41:16.843678      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:17.843816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:18.844321      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:19.844462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:20.844629      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:21.844743      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:22.844866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:23.845039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:24.845337      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:25.845453      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:26.845601      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:27.845744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:28.846426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:29.846775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:30.846968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:31.846991      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:32.847112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:33.847238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:34.847361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:35.847481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:41:36.245353 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:41:36.847828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:37.847999      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:38.848357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:39.848727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:40.848854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:41.848989      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:42.849134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:43.849277      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:44.849574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:45.850039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:46.850382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:47.850531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:48.850947      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:49.851246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:50.851412      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:51.851579      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:52.851739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:53.851894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:54.852221      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:55.852350      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:41:56.245192 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:41:56.852696      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:57.852861      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:58.853266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:41:59.853552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:00.854088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:01.854234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:02.854395      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:03.854528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:04.854870      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:05.855023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:06.855211      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:07.855402      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:08.855830      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:09.856240      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:10.857060      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:11.857234      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:12.857399      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:13.857555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:14.857914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:15.858054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:42:16.245714 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:42:16.858263      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:17.858388      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:18.858786      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:19.859120      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:20.859167      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:21.859286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:22.859465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:23.859606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:24.859704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:25.859825      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:26.860013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:27.860118      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:28.860497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:29.860815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:30.860965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:31.861125      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:32.861265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:33.861410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:34.861509      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:35.862073      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:42:36.245021 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:42:36.862591      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:37.862757      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:38.863451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:39.863846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:40.863995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:41.864095      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:42.864268      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:43.864428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:44.864528      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:45.864660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:46.865495      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:47.865584      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:48.865966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:49.866379      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:50.866483      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:51.866610      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:52.866765      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:53.866919      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:54.867328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:55.867423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:42:56.245114 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:42:56.867682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:57.867834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:58.868473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:42:59.868869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:00.869022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:01.869117      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:02.869300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:03.869447      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:04.869555      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:05.869677      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:06.869793      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:07.869949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:08.870345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:09.870473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:10.870623      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:11.870745      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:12.870896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:13.871028      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:14.871268      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:15.871422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:43:16.245439 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:43:16.871520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:17.871681      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:18.871990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:19.872114      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:20.872290      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:21.872413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:22.872546      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:23.872703      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:24.873058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:25.873144      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:26.873306      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:27.873468      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:28.874461      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:29.874878      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:30.875015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:31.875103      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:32.875248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:33.875415      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:34.875545      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:35.875684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:43:36.246104 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:43:36.875725      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:37.875873      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:38.876271      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:39.876398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:40.876550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:41.876660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:42.876796      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:43.876917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:44.877309      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:45.877423      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:46.877518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:47.877675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:48.877981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:49.878119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:50.878187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:51.878311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:52.878479      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:53.878536      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:54.878917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:55.879047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:43:56.246356 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:43:56.880002      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:57.880172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:58.880515      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:43:59.880642      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:00.880752      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:01.880874      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:02.881022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:03.881140      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:04.881404      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:05.881524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:06.881682      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:07.881842      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:08.882232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:09.882513      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:10.882626      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:11.882753      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:12.882914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:13.883022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:14.883329      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:15.883481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:44:16.245668 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:44:16.884050      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:17.884238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:18.884414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:19.884814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:20.885761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:21.885863      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:22.886023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:23.887065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:24.887169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:25.887295      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:26.888107      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:27.889091      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:28.889486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:29.889883      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:30.890026      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:31.890121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:32.890264      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:33.890419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:34.890744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:35.891069      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:44:36.245611 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:44:36.891220      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:37.891378      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:38.891767      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:39.892169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:40.892316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:41.892444      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:42.892604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:43.892733      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:44.893101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:45.894067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:46.894224      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:47.894374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:48.894738      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:49.894979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:50.895074      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:51.896051      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:52.896179      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:53.896328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:54.896726      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:55.896957      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:44:56.246144 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:44:56.897854      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:57.898048      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:58.898482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:44:59.898914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:00.899032      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:01.899157      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:02.900065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:03.901071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:04.901364      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:05.901494      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:06.901637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:07.901788      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:08.902147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:09.902439      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:10.902579      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:11.903172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:12.903312      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:13.903437      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:14.903806      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:15.903959      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:45:16.245316 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:45:16.904936      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:17.905071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:18.905438      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:19.905850      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:20.906006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:21.907054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:22.907238      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:23.907373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:24.907880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:25.908035      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:26.908199      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:27.908344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:28.908620      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:29.908964      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:30.909131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:31.909254      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:32.909419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:33.909559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:34.909776      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:35.909936      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:45:36.245299 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:45:36.909961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:37.910123      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:38.910380      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:39.910775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:40.910908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:41.911052      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:42.911213      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:43.911316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:44.911737      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:45.911875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:46.911958      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:47.912127      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:48.912460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:49.912717      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:50.912861      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:51.912982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:52.913155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:53.913296      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:54.913656      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:55.913798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:45:56.247322 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:45:56.913920      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:57.914077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:58.914471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:45:59.914814      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:00.914945      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:01.915108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:02.915320      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:03.915365      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:04.916318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:05.916455      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:06.916548      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:07.917463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:08.917823      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:09.918315      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:10.918490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:11.918622      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:12.918778      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:13.918962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:14.919023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:15.919141      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:46:16.245754 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:46:16.919407      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:17.919559      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:18.920488      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:19.920848      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:20.920990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:21.921115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:22.921273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:23.921428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:24.921533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:25.921671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:26.921908      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:27.922056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:28.922405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:29.922819      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:30.922970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:31.923089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:32.923243      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:33.923386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:34.923499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:35.923832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:46:36.244799 23 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDUzNjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0502 09:46:36.924355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:37.924503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:38.924760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:39.924992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:40.925104      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:41.925273      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:42.925416      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:43.925542      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:44.925940      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:45.926109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:46.927071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:47.927182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:48.927464      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:49.927812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:50.927968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:51.928090      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:52.928192      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:53.928301      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:54.928681      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:55.929022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:46:56.244942 23 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0502 09:46:56.244958 23 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 05/02/24 09:46:56.244
  STEP: retrieving all remaining pages @ 05/02/24 09:46:56.248
  I0502 09:46:56.251437 23 chunking.go:221] Retrieved 40/40 results with rv 46846 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY4NDYsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  I0502 09:46:56.254145 23 chunking.go:221] Retrieved 40/40 results with rv 46846 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY4NDYsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  I0502 09:46:56.257128 23 chunking.go:221] Retrieved 40/40 results with rv 46846 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY4NDYsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  I0502 09:46:56.260647 23 chunking.go:221] Retrieved 40/40 results with rv 46846 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY4NDYsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  I0502 09:46:56.263588 23 chunking.go:221] Retrieved 40/40 results with rv 46846 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY4NDYsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  I0502 09:46:56.267449 23 chunking.go:221] Retrieved 40/40 results with rv 46846 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY4NDYsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  I0502 09:46:56.270590 23 chunking.go:221] Retrieved 40/40 results with rv 46846 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDY4NDYsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  I0502 09:46:56.274038 23 chunking.go:221] Retrieved 40/40 results with rv 46846 and continue 
  I0502 09:46:56.274137 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-6764" for this suite. @ 05/02/24 09:46:56.277
• [537.802 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 05/02/24 09:46:56.287
  I0502 09:46:56.287792 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 09:46:56.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:46:56.309
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:46:56.312
  STEP: Creating a pod to test downward api env vars @ 05/02/24 09:46:56.314
  E0502 09:46:56.929400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:57.929511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:58.930058      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:46:59.930228      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:47:00.333
  I0502 09:47:00.335931 23 output.go:196] Trying to get logs from node mini-1 pod downward-api-b919274b-5c2f-4a5e-a95c-4b3ca5869b4c container dapi-container: <nil>
  STEP: delete the pod @ 05/02/24 09:47:00.346
  I0502 09:47:00.359218 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2959" for this suite. @ 05/02/24 09:47:00.362
• [4.082 seconds]
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:789
  STEP: Creating a kubernetes client @ 05/02/24 09:47:00.369
  I0502 09:47:00.369414 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 09:47:00.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:00.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:00.389
  STEP: creating service endpoint-test2 in namespace services-4617 @ 05/02/24 09:47:00.391
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4617 to expose endpoints map[] @ 05/02/24 09:47:00.404
  I0502 09:47:00.407963 23 service.go:4226] Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0502 09:47:00.930564      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:01.413836 23 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4617 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-4617 @ 05/02/24 09:47:01.413
  E0502 09:47:01.931288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:02.931499      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4617 to expose endpoints map[pod1:[80]] @ 05/02/24 09:47:03.431
  I0502 09:47:03.438692 23 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4617 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 05/02/24 09:47:03.438
  I0502 09:47:03.438730 23 resource.go:361] Creating new exec pod
  E0502 09:47:03.931517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:04.931843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:05.932219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:06.451957 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-4617 exec execpodxlpld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0502 09:47:06.531246 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0502 09:47:06.531272 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:47:06.531317 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-4617 exec execpodxlpld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.136.92 80'
  I0502 09:47:06.604854 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.136.92 80\nConnection to 10.108.136.92 80 port [tcp/http] succeeded!\n"
  I0502 09:47:06.604878 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-4617 @ 05/02/24 09:47:06.604
  E0502 09:47:06.932333      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:07.932937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4617 to expose endpoints map[pod1:[80] pod2:[80]] @ 05/02/24 09:47:08.624
  I0502 09:47:08.633750 23 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4617 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 05/02/24 09:47:08.633
  E0502 09:47:08.933755      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:09.634821 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-4617 exec execpodxlpld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0502 09:47:09.719259 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0502 09:47:09.719283 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:47:09.719326 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-4617 exec execpodxlpld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.136.92 80'
  I0502 09:47:09.789100 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.136.92 80\nConnection to 10.108.136.92 80 port [tcp/http] succeeded!\n"
  I0502 09:47:09.789124 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-4617 @ 05/02/24 09:47:09.789
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4617 to expose endpoints map[pod2:[80]] @ 05/02/24 09:47:09.807
  I0502 09:47:09.818797 23 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4617 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 05/02/24 09:47:09.818
  E0502 09:47:09.934661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:10.819873 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-4617 exec execpodxlpld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0502 09:47:10.898339 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0502 09:47:10.898391 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:47:10.898461 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-4617 exec execpodxlpld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.136.92 80'
  E0502 09:47:10.935713      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:10.971875 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.136.92 80\nConnection to 10.108.136.92 80 port [tcp/http] succeeded!\n"
  I0502 09:47:10.971902 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-4617 @ 05/02/24 09:47:10.971
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4617 to expose endpoints map[] @ 05/02/24 09:47:10.984
  I0502 09:47:10.997502 23 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4617 exposes endpoints map[]
  I0502 09:47:11.030518 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4617" for this suite. @ 05/02/24 09:47:11.034
• [10.672 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 05/02/24 09:47:11.041
  I0502 09:47:11.041248 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 09:47:11.041
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:11.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:11.063
  STEP: Setting up server cert @ 05/02/24 09:47:11.093
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 09:47:11.288
  STEP: Deploying the webhook pod @ 05/02/24 09:47:11.294
  STEP: Wait for the deployment to be ready @ 05/02/24 09:47:11.303
  I0502 09:47:11.317702 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 09:47:11.936428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:12.936595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 09:47:13.326
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 09:47:13.338
  E0502 09:47:13.937567      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:14.339223 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 05/02/24 09:47:14.343
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 05/02/24 09:47:14.344
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 05/02/24 09:47:14.344
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 05/02/24 09:47:14.344
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 05/02/24 09:47:14.345
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/02/24 09:47:14.345
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/02/24 09:47:14.345
  I0502 09:47:14.388728 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-293" for this suite. @ 05/02/24 09:47:14.393
  STEP: Destroying namespace "webhook-markers-297" for this suite. @ 05/02/24 09:47:14.405
• [3.371 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:341
  STEP: Creating a kubernetes client @ 05/02/24 09:47:14.412
  I0502 09:47:14.412117 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename cronjob @ 05/02/24 09:47:14.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:14.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:14.429
  STEP: Creating a cronjob @ 05/02/24 09:47:14.431
  STEP: creating @ 05/02/24 09:47:14.431
  STEP: getting @ 05/02/24 09:47:14.434
  STEP: listing @ 05/02/24 09:47:14.436
  STEP: watching @ 05/02/24 09:47:14.438
  I0502 09:47:14.438440 23 cronjob.go:370] starting watch
  STEP: cluster-wide listing @ 05/02/24 09:47:14.439
  STEP: cluster-wide watching @ 05/02/24 09:47:14.441
  I0502 09:47:14.441149 23 cronjob.go:382] starting watch
  STEP: patching @ 05/02/24 09:47:14.441
  STEP: updating @ 05/02/24 09:47:14.445
  I0502 09:47:14.451069 23 cronjob.go:406] waiting for watch events with expected annotations
  I0502 09:47:14.451085 23 cronjob.go:420] saw patched and updated annotations
  STEP: patching /status @ 05/02/24 09:47:14.451
  STEP: updating /status @ 05/02/24 09:47:14.455
  STEP: get /status @ 05/02/24 09:47:14.46
  STEP: deleting @ 05/02/24 09:47:14.462
  STEP: deleting a collection @ 05/02/24 09:47:14.474
  I0502 09:47:14.480821 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3626" for this suite. @ 05/02/24 09:47:14.483
• [0.078 seconds]
------------------------------
S
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:668
  STEP: Creating a kubernetes client @ 05/02/24 09:47:14.489
  I0502 09:47:14.489712 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename job @ 05/02/24 09:47:14.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:14.509
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:14.512
  STEP: Creating a job @ 05/02/24 09:47:14.514
  STEP: Ensuring active pods == parallelism @ 05/02/24 09:47:14.52
  E0502 09:47:14.938493      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:15.939101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 05/02/24 09:47:16.525
  STEP: deleting Job.batch foo in namespace job-7632, will wait for the garbage collector to delete the pods @ 05/02/24 09:47:16.525
  I0502 09:47:16.584031 23 resources.go:139] Deleting Job.batch foo took: 5.914401ms
  I0502 09:47:16.684927 23 resources.go:163] Terminating Job.batch foo pods took: 100.882647ms
  E0502 09:47:16.939641      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:17.940248      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:18.940949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 05/02/24 09:47:18.985
  I0502 09:47:18.988002 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7632" for this suite. @ 05/02/24 09:47:18.991
• [4.508 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 05/02/24 09:47:18.998
  I0502 09:47:18.998074 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename proxy @ 05/02/24 09:47:18.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:19.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:19.017
  I0502 09:47:19.019101 23 proxy.go:293] Creating pod...
  E0502 09:47:19.942039      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:20.943047      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:21.033314 23 proxy.go:317] Creating service...
  I0502 09:47:21.045900 23 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/pods/agnhost/proxy/some/path/with/DELETE
  I0502 09:47:21.060292 23 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0502 09:47:21.060313 23 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/pods/agnhost/proxy/some/path/with/GET
  I0502 09:47:21.066102 23 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0502 09:47:21.066119 23 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/pods/agnhost/proxy/some/path/with/HEAD
  I0502 09:47:21.070595 23 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0502 09:47:21.070606 23 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/pods/agnhost/proxy/some/path/with/OPTIONS
  I0502 09:47:21.077040 23 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0502 09:47:21.077053 23 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/pods/agnhost/proxy/some/path/with/PATCH
  I0502 09:47:21.080079 23 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0502 09:47:21.080091 23 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/pods/agnhost/proxy/some/path/with/POST
  I0502 09:47:21.082803 23 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0502 09:47:21.082816 23 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/pods/agnhost/proxy/some/path/with/PUT
  I0502 09:47:21.085090 23 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0502 09:47:21.085101 23 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/services/test-service/proxy/some/path/with/DELETE
  I0502 09:47:21.088484 23 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0502 09:47:21.088495 23 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/services/test-service/proxy/some/path/with/GET
  I0502 09:47:21.092100 23 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0502 09:47:21.092111 23 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/services/test-service/proxy/some/path/with/HEAD
  I0502 09:47:21.096383 23 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0502 09:47:21.096415 23 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/services/test-service/proxy/some/path/with/OPTIONS
  I0502 09:47:21.099310 23 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0502 09:47:21.099322 23 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/services/test-service/proxy/some/path/with/PATCH
  I0502 09:47:21.102609 23 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0502 09:47:21.102620 23 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/services/test-service/proxy/some/path/with/POST
  I0502 09:47:21.105593 23 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0502 09:47:21.105604 23 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5916/services/test-service/proxy/some/path/with/PUT
  I0502 09:47:21.109019 23 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0502 09:47:21.109090 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-5916" for this suite. @ 05/02/24 09:47:21.112
• [2.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 05/02/24 09:47:21.118
  I0502 09:47:21.118964 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:47:21.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:21.133
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:21.136
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 09:47:21.138
  E0502 09:47:21.944131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:22.944259      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:23.944418      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:24.944777      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:47:25.155
  I0502 09:47:25.157742 23 output.go:196] Trying to get logs from node mini-1 pod downwardapi-volume-0e38858f-79dc-4c7c-88c5-26522e3da4e0 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 09:47:25.161
  I0502 09:47:25.173616 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-89" for this suite. @ 05/02/24 09:47:25.176
• [4.064 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:342
  STEP: Creating a kubernetes client @ 05/02/24 09:47:25.183
  I0502 09:47:25.183070 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 09:47:25.183
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:25.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:25.2
  STEP: creating a replication controller @ 05/02/24 09:47:25.203
  I0502 09:47:25.203588 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 create -f -'
  I0502 09:47:25.276533 23 builder.go:146] stderr: ""
  I0502 09:47:25.276556 23 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/02/24 09:47:25.276
  I0502 09:47:25.276600 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:47:25.323532 23 builder.go:146] stderr: ""
  I0502 09:47:25.323556 23 builder.go:147] stdout: "update-demo-nautilus-ghzwz update-demo-nautilus-vs279 "
  I0502 09:47:25.323584 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 get pods update-demo-nautilus-ghzwz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:47:25.358892 23 builder.go:146] stderr: ""
  I0502 09:47:25.358913 23 builder.go:147] stdout: ""
  I0502 09:47:25.358920 23 kubectl.go:2501] update-demo-nautilus-ghzwz is created but not running
  E0502 09:47:25.945649      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:26.946342      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:27.946470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:28.946733      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:29.947048      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:30.359622 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0502 09:47:30.400401 23 builder.go:146] stderr: ""
  I0502 09:47:30.400437 23 builder.go:147] stdout: "update-demo-nautilus-ghzwz update-demo-nautilus-vs279 "
  I0502 09:47:30.400476 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 get pods update-demo-nautilus-ghzwz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:47:30.437644 23 builder.go:146] stderr: ""
  I0502 09:47:30.437666 23 builder.go:147] stdout: "true"
  I0502 09:47:30.437693 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 get pods update-demo-nautilus-ghzwz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0502 09:47:30.474391 23 builder.go:146] stderr: ""
  I0502 09:47:30.474413 23 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0502 09:47:30.474421 23 kubectl.go:2392] validating pod update-demo-nautilus-ghzwz
  I0502 09:47:30.478360 23 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0502 09:47:30.478385 23 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0502 09:47:30.478392 23 kubectl.go:2519] update-demo-nautilus-ghzwz is verified up and running
  I0502 09:47:30.478412 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 get pods update-demo-nautilus-vs279 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0502 09:47:30.515856 23 builder.go:146] stderr: ""
  I0502 09:47:30.515878 23 builder.go:147] stdout: "true"
  I0502 09:47:30.515909 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 get pods update-demo-nautilus-vs279 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0502 09:47:30.552423 23 builder.go:146] stderr: ""
  I0502 09:47:30.552446 23 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0502 09:47:30.552454 23 kubectl.go:2392] validating pod update-demo-nautilus-vs279
  I0502 09:47:30.555912 23 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0502 09:47:30.555937 23 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0502 09:47:30.555947 23 kubectl.go:2519] update-demo-nautilus-vs279 is verified up and running
  STEP: using delete to clean up resources @ 05/02/24 09:47:30.555
  I0502 09:47:30.555988 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 delete --grace-period=0 --force -f -'
  I0502 09:47:30.596125 23 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0502 09:47:30.596147 23 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0502 09:47:30.596177 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 get rc,svc -l name=update-demo --no-headers'
  I0502 09:47:30.636007 23 builder.go:146] stderr: "No resources found in kubectl-5541 namespace.\n"
  I0502 09:47:30.636032 23 builder.go:147] stdout: ""
  I0502 09:47:30.636061 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5541 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0502 09:47:30.674838 23 builder.go:146] stderr: ""
  I0502 09:47:30.674865 23 builder.go:147] stdout: ""
  I0502 09:47:30.674921 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5541" for this suite. @ 05/02/24 09:47:30.678
• [5.503 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 05/02/24 09:47:30.685
  I0502 09:47:30.686009 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 09:47:30.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:30.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:30.707
  STEP: Creating a pod to test downward api env vars @ 05/02/24 09:47:30.709
  E0502 09:47:30.947217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:31.948056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:32.949018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:33.949159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:47:34.726
  I0502 09:47:34.728499 23 output.go:196] Trying to get logs from node mini-1 pod downward-api-735334b4-a699-4f9a-a633-972650e0733a container dapi-container: <nil>
  STEP: delete the pod @ 05/02/24 09:47:34.732
  I0502 09:47:34.742750 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4044" for this suite. @ 05/02/24 09:47:34.745
• [4.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1368
  STEP: Creating a kubernetes client @ 05/02/24 09:47:34.751
  I0502 09:47:34.751032 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 09:47:34.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:34.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:34.772
  STEP: validating cluster-info @ 05/02/24 09:47:34.775
  I0502 09:47:34.775152 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-5753 cluster-info'
  I0502 09:47:34.812854 23 builder.go:146] stderr: ""
  I0502 09:47:34.812880 23 builder.go:147] stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0502 09:47:34.812979 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5753" for this suite. @ 05/02/24 09:47:34.817
• [0.072 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 05/02/24 09:47:34.822
  I0502 09:47:34.822833 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename daemonsets @ 05/02/24 09:47:34.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:34.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:34.843
  I0502 09:47:34.857384 23 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/02/24 09:47:34.864
  I0502 09:47:34.869525 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:34.869547 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:34.869564 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:34.874757 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:47:34.874769 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:47:34.950009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:35.868666 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:35.868695 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:35.868722 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:35.871401 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:47:35.871413 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:47:35.950511      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:36.868984 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:36.869016 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:36.869052 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:36.872353 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0502 09:47:36.872367 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:47:36.951518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:37.869266 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:37.869293 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:37.869310 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:37.872446 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0502 09:47:37.872458 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 05/02/24 09:47:37.88
  STEP: Check that daemon pods images are updated. @ 05/02/24 09:47:37.893
  I0502 09:47:37.898941 23 daemon_set.go:1178] Wrong image for pod: daemon-set-59t9p. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:37.898955 23 daemon_set.go:1178] Wrong image for pod: daemon-set-h7lsg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:37.898962 23 daemon_set.go:1178] Wrong image for pod: daemon-set-k7vwd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:37.905264 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:37.905287 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:37.905302 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0502 09:47:37.952176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:38.896713 23 daemon_set.go:1178] Wrong image for pod: daemon-set-59t9p. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:38.896731 23 daemon_set.go:1178] Wrong image for pod: daemon-set-k7vwd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:38.899745 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:38.899768 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:38.899796 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0502 09:47:38.952684      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:39.896866 23 daemon_set.go:1178] Wrong image for pod: daemon-set-59t9p. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:39.896893 23 daemon_set.go:1178] Wrong image for pod: daemon-set-k7vwd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:39.896900 23 daemon_set.go:1183] Pod daemon-set-mctc9 is not available
  I0502 09:47:39.902273 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:39.902307 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:39.902333 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0502 09:47:39.953151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:40.897085 23 daemon_set.go:1178] Wrong image for pod: daemon-set-59t9p. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:40.897102 23 daemon_set.go:1178] Wrong image for pod: daemon-set-k7vwd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:40.897107 23 daemon_set.go:1183] Pod daemon-set-mctc9 is not available
  I0502 09:47:40.900220 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:40.900252 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:40.900295 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0502 09:47:40.954099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:41.896808 23 daemon_set.go:1178] Wrong image for pod: daemon-set-k7vwd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0502 09:47:41.896830 23 daemon_set.go:1183] Pod daemon-set-klrqk is not available
  I0502 09:47:41.900217 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:41.900238 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:41.900261 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0502 09:47:41.955183      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:42.897272 23 daemon_set.go:1183] Pod daemon-set-5nr86 is not available
  I0502 09:47:42.901060 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:42.901097 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:42.901122 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 05/02/24 09:47:42.901
  I0502 09:47:42.903949 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:42.903972 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:42.903984 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:42.906818 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0502 09:47:42.906830 23 fixtures.go:130] Node mini-2 is running 0 daemon pod, expected 1
  E0502 09:47:42.955835      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:43.905791 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:43.905845 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:43.905890 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:43.908129 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0502 09:47:43.908144 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/02/24 09:47:43.917
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8120, will wait for the garbage collector to delete the pods @ 05/02/24 09:47:43.917
  E0502 09:47:43.956111      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:43.973520 23 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 4.194586ms
  I0502 09:47:44.073800 23 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.277512ms
  E0502 09:47:44.956760      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:45.956837      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:46.956967      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:46.977162 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:47:46.977190 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0502 09:47:46.979437 23 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"48003"},"items":null}

  I0502 09:47:46.983292 23 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"48003"},"items":null}

  I0502 09:47:46.997230 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8120" for this suite. @ 05/02/24 09:47:47
• [12.186 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 05/02/24 09:47:47.009
  I0502 09:47:47.009432 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename var-expansion @ 05/02/24 09:47:47.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:47.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:47.036
  STEP: Creating a pod to test substitution in container's args @ 05/02/24 09:47:47.038
  E0502 09:47:47.957365      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:48.957443      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:49.958086      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:50.958208      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:47:51.065
  I0502 09:47:51.067666 23 output.go:196] Trying to get logs from node mini-2 pod var-expansion-6c914caf-99a7-4d1e-88ec-1977dfa8fa2a container dapi-container: <nil>
  STEP: delete the pod @ 05/02/24 09:47:51.077
  I0502 09:47:51.089809 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6141" for this suite. @ 05/02/24 09:47:51.093
• [4.089 seconds]
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 05/02/24 09:47:51.098
  I0502 09:47:51.098756 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename daemonsets @ 05/02/24 09:47:51.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:51.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:51.123
  STEP: Creating simple DaemonSet "daemon-set" @ 05/02/24 09:47:51.139
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/02/24 09:47:51.163
  I0502 09:47:51.191309 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:51.191328 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:51.191344 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:51.212298 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:47:51.212310 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:47:51.959265      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:52.168327 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:52.168360 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:52.168383 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:52.170522 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:47:52.170535 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:47:52.959390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:53.168843 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:53.168879 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:53.168918 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:53.171644 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0502 09:47:53.171660 23 fixtures.go:130] Node mini-3 is running 0 daemon pod, expected 1
  E0502 09:47:53.959463      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:47:54.168578 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:54.168616 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:54.168629 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:47:54.175347 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0502 09:47:54.175359 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 05/02/24 09:47:54.177
  STEP: DeleteCollection of the DaemonSets @ 05/02/24 09:47:54.179
  STEP: Verify that ReplicaSets have been deleted @ 05/02/24 09:47:54.184
  I0502 09:47:54.207669 23 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"48140"},"items":null}

  I0502 09:47:54.210563 23 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"48142"},"items":[{"metadata":{"name":"daemon-set-7gpkq","generateName":"daemon-set-","namespace":"daemonsets-215","uid":"2b284409-0161-48d2-98aa-2dd158abffa8","resourceVersion":"48140","creationTimestamp":"2024-05-02T09:47:51Z","deletionTimestamp":"2024-05-02T09:48:24Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"b3810543590b9a252e41ed153c299d2121ac68de7234ea868089b32d6dc3c47e","cni.projectcalico.org/podIP":"192.168.158.177/32","cni.projectcalico.org/podIPs":"192.168.158.177/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"5fed009f-8d25-4a66-97ba-772990f09227","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-05-02T09:47:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-02T09:47:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5fed009f-8d25-4a66-97ba-772990f09227\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-02T09:47:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.158.177\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-pw4xs","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-pw4xs","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"mini-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["mini-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:52Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:52Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:52Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:51Z"}],"hostIP":"10.221.190.32","hostIPs":[{"ip":"10.221.190.32"}],"podIP":"192.168.158.177","podIPs":[{"ip":"192.168.158.177"}],"startTime":"2024-05-02T09:47:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-02T09:47:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://0100478f4b88dd42d93d5ac064c99b22eb59943b7ead6dc1178d990bad71bd11","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-99x9x","generateName":"daemon-set-","namespace":"daemonsets-215","uid":"0f629692-5b33-485a-875b-5aac8b76bfc7","resourceVersion":"48141","creationTimestamp":"2024-05-02T09:47:51Z","deletionTimestamp":"2024-05-02T09:48:24Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"5a3815d2115c7454b6120415910791840f74e120b3af15e570d852c135fc9b33","cni.projectcalico.org/podIP":"192.168.125.234/32","cni.projectcalico.org/podIPs":"192.168.125.234/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"5fed009f-8d25-4a66-97ba-772990f09227","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-05-02T09:47:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-02T09:47:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5fed009f-8d25-4a66-97ba-772990f09227\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-02T09:47:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.125.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-nnnck","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-nnnck","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"mini-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["mini-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:52Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:52Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:52Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:51Z"}],"hostIP":"10.221.190.31","hostIPs":[{"ip":"10.221.190.31"}],"podIP":"192.168.125.234","podIPs":[{"ip":"192.168.125.234"}],"startTime":"2024-05-02T09:47:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-02T09:47:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://7c7fff2787f5a80a2478c9c749ee34a6a5a77d060557c23ced5cd82ffaa731b2","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-tffrf","generateName":"daemon-set-","namespace":"daemonsets-215","uid":"6a4694b8-c75b-4a93-a929-b2ae357b5a82","resourceVersion":"48142","creationTimestamp":"2024-05-02T09:47:51Z","deletionTimestamp":"2024-05-02T09:48:24Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"14f2d1555fc950a7f8927e5e49fd8e2375ae3c3247bae043e2ecd96dbf2c4756","cni.projectcalico.org/podIP":"192.168.32.4/32","cni.projectcalico.org/podIPs":"192.168.32.4/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"5fed009f-8d25-4a66-97ba-772990f09227","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-05-02T09:47:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-02T09:47:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5fed009f-8d25-4a66-97ba-772990f09227\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-02T09:47:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.32.4\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-lg7f5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-lg7f5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"mini-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["mini-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:53Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:53Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:53Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-02T09:47:51Z"}],"hostIP":"10.221.190.33","hostIPs":[{"ip":"10.221.190.33"}],"podIP":"192.168.32.4","podIPs":[{"ip":"192.168.32.4"}],"startTime":"2024-05-02T09:47:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-02T09:47:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://505d6a783b2401403126b987ad8f5ed36a8225b61d6449a515b22d0877fe5664","started":true}],"qosClass":"BestEffort"}}]}

  I0502 09:47:54.219582 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-215" for this suite. @ 05/02/24 09:47:54.222
• [3.129 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 05/02/24 09:47:54.227
  I0502 09:47:54.227913 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename gc @ 05/02/24 09:47:54.228
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:47:54.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:47:54.246
  STEP: create the rc1 @ 05/02/24 09:47:54.251
  STEP: create the rc2 @ 05/02/24 09:47:54.255
  E0502 09:47:54.960056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:55.960131      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:56.960145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:57.961027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:58.961960      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:47:59.963027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 05/02/24 09:48:00.302
  E0502 09:48:00.963498      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:01.964347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 05/02/24 09:48:02.705
  STEP: wait for the rc to be deleted @ 05/02/24 09:48:02.797
  E0502 09:48:02.965019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:03.965139      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:04.965385      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:05.966027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:06.967040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:07.810414 23 garbage_collector.go:762] 68 pods remaining
  I0502 09:48:07.810437 23 garbage_collector.go:769] 68 pods has nil DeletionTimestamp
  I0502 09:48:07.810443 23 garbage_collector.go:770] 
  E0502 09:48:07.967754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:08.968398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:09.969021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:10.970015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:11.971023      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:12.971261      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/02/24 09:48:13.21
  I0502 09:48:13.290536 23 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0502 09:48:13.290595 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2dhjw" in namespace "gc-1102"
  I0502 09:48:13.321529 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2hvz9" in namespace "gc-1102"
  I0502 09:48:13.334467 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2nfzq" in namespace "gc-1102"
  I0502 09:48:13.389321 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2nls6" in namespace "gc-1102"
  I0502 09:48:13.402874 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-44vnf" in namespace "gc-1102"
  I0502 09:48:13.459134 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4ctmb" in namespace "gc-1102"
  I0502 09:48:13.481769 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4dbh2" in namespace "gc-1102"
  I0502 09:48:13.496477 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4wqnv" in namespace "gc-1102"
  I0502 09:48:13.582298 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-552zt" in namespace "gc-1102"
  I0502 09:48:13.601163 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-55jm2" in namespace "gc-1102"
  I0502 09:48:13.611972 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5746l" in namespace "gc-1102"
  I0502 09:48:13.621870 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5hfv7" in namespace "gc-1102"
  I0502 09:48:13.632441 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5rd8c" in namespace "gc-1102"
  I0502 09:48:13.719076 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-66775" in namespace "gc-1102"
  I0502 09:48:13.767023 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6ck79" in namespace "gc-1102"
  I0502 09:48:13.791181 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6kbq7" in namespace "gc-1102"
  I0502 09:48:13.901009 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6kcx7" in namespace "gc-1102"
  E0502 09:48:13.972151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:13.978934 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6tsn6" in namespace "gc-1102"
  I0502 09:48:14.061265 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-726ff" in namespace "gc-1102"
  I0502 09:48:14.075651 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7fgbw" in namespace "gc-1102"
  I0502 09:48:14.116049 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7jrjw" in namespace "gc-1102"
  I0502 09:48:14.205948 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-82nnd" in namespace "gc-1102"
  I0502 09:48:14.310627 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8dwrm" in namespace "gc-1102"
  I0502 09:48:14.330707 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-92gh2" in namespace "gc-1102"
  I0502 09:48:14.403569 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-97p9b" in namespace "gc-1102"
  I0502 09:48:14.456881 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9hjvp" in namespace "gc-1102"
  I0502 09:48:14.481418 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9p674" in namespace "gc-1102"
  I0502 09:48:14.582253 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9wz9f" in namespace "gc-1102"
  I0502 09:48:14.775959 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-blqjt" in namespace "gc-1102"
  I0502 09:48:14.870008 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-brdmn" in namespace "gc-1102"
  E0502 09:48:14.973204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:14.973660 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bsqqc" in namespace "gc-1102"
  I0502 09:48:14.987823 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cldfg" in namespace "gc-1102"
  I0502 09:48:15.127780 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cldlv" in namespace "gc-1102"
  I0502 09:48:15.198796 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cprct" in namespace "gc-1102"
  I0502 09:48:15.217726 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cq9t8" in namespace "gc-1102"
  I0502 09:48:15.236732 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-d6v44" in namespace "gc-1102"
  I0502 09:48:15.329219 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-d6wtd" in namespace "gc-1102"
  I0502 09:48:15.344274 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-d7c65" in namespace "gc-1102"
  I0502 09:48:15.382131 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-d97bk" in namespace "gc-1102"
  I0502 09:48:15.557566 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dth6q" in namespace "gc-1102"
  I0502 09:48:15.569432 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dwx4q" in namespace "gc-1102"
  I0502 09:48:15.581792 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-g2ssq" in namespace "gc-1102"
  I0502 09:48:15.657858 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-g9ppt" in namespace "gc-1102"
  I0502 09:48:15.673257 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gjh96" in namespace "gc-1102"
  I0502 09:48:15.737804 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hbfvz" in namespace "gc-1102"
  I0502 09:48:15.762719 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hjjsc" in namespace "gc-1102"
  I0502 09:48:15.848597 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hlfmb" in namespace "gc-1102"
  I0502 09:48:15.951627 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jpr6l" in namespace "gc-1102"
  E0502 09:48:15.973828      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:16.029825 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-k8l5b" in namespace "gc-1102"
  I0502 09:48:16.044736 23 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-krhfb" in namespace "gc-1102"
  I0502 09:48:16.122829 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1102" for this suite. @ 05/02/24 09:48:16.126
• [21.911 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 05/02/24 09:48:16.138
  I0502 09:48:16.138678 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 09:48:16.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:48:16.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:48:16.168
  STEP: Setting up server cert @ 05/02/24 09:48:16.373
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 09:48:16.578
  STEP: Deploying the webhook pod @ 05/02/24 09:48:16.606
  STEP: Wait for the deployment to be ready @ 05/02/24 09:48:16.619
  I0502 09:48:16.638372 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 09:48:16.974798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:17.975017      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:18.645606 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 9, 48, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 48, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 9, 48, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 48, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 09:48:18.976066      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:19.976353      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 09:48:20.648
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 09:48:20.661
  E0502 09:48:20.976631      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:21.661403 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 05/02/24 09:48:21.678
  STEP: create a configmap that should be updated by the webhook @ 05/02/24 09:48:21.687
  I0502 09:48:21.751290 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4620" for this suite. @ 05/02/24 09:48:21.759
  STEP: Destroying namespace "webhook-markers-9900" for this suite. @ 05/02/24 09:48:21.767
• [5.636 seconds]
------------------------------
SS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 05/02/24 09:48:21.774
  I0502 09:48:21.774238 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename lease-test @ 05/02/24 09:48:21.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:48:21.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:48:21.799
  I0502 09:48:21.842901 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-6226" for this suite. @ 05/02/24 09:48:21.846
• [0.078 seconds]
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 05/02/24 09:48:21.852
  I0502 09:48:21.852472 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:48:21.852
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:48:21.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:48:21.879
  STEP: Creating configMap with name configmap-projected-all-test-volume-4c78ff31-fafd-4775-91c7-233619428e27 @ 05/02/24 09:48:21.88
  STEP: Creating secret with name secret-projected-all-test-volume-2659da43-22e3-4966-88e9-b1ba97bacad2 @ 05/02/24 09:48:21.883
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 05/02/24 09:48:21.888
  E0502 09:48:21.976812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:22.976987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:23.977452      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:24.977739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:48:25.91
  I0502 09:48:25.914397 23 output.go:196] Trying to get logs from node mini-1 pod projected-volume-a60dec4a-5d36-4feb-95b1-38e11b45ab6a container projected-all-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:48:25.918
  I0502 09:48:25.929866 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7169" for this suite. @ 05/02/24 09:48:25.933
• [4.086 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 05/02/24 09:48:25.938
  I0502 09:48:25.938962 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 09:48:25.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:48:25.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:48:25.96
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 09:48:25.963
  E0502 09:48:25.977767      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:26.977987      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:27.978481      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:28.979421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:29.979679      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:48:30.031
  I0502 09:48:30.033805 23 output.go:196] Trying to get logs from node mini-2 pod downwardapi-volume-77167efa-ae9c-4fc7-9ac2-8898574ed8f6 container client-container: <nil>
  STEP: delete the pod @ 05/02/24 09:48:30.039
  I0502 09:48:30.054011 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4368" for this suite. @ 05/02/24 09:48:30.057
• [4.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 05/02/24 09:48:30.065
  I0502 09:48:30.065406 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:48:30.065
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:48:30.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:48:30.084
  STEP: Creating secret with name secret-test-01f27286-c7c7-40f4-abf2-33eb507618bf @ 05/02/24 09:48:30.086
  STEP: Creating a pod to test consume secrets @ 05/02/24 09:48:30.09
  E0502 09:48:30.980194      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:31.980313      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:32.981019      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:33.982015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:48:34.107
  I0502 09:48:34.110371 23 output.go:196] Trying to get logs from node mini-2 pod pod-secrets-a27fc712-2fe4-4d74-97fb-3d0669a94638 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:48:34.114
  I0502 09:48:34.124510 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9996" for this suite. @ 05/02/24 09:48:34.127
• [4.068 seconds]
------------------------------
S
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 05/02/24 09:48:34.133
  I0502 09:48:34.133185 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename downward-api @ 05/02/24 09:48:34.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:48:34.149
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:48:34.152
  STEP: Creating a pod to test downward api env vars @ 05/02/24 09:48:34.153
  E0502 09:48:34.982724      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:35.982995      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:36.983606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:37.983727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:48:38.171
  I0502 09:48:38.173920 23 output.go:196] Trying to get logs from node mini-1 pod downward-api-44240cf1-b889-4a75-b846-3ae311a3f62b container dapi-container: <nil>
  STEP: delete the pod @ 05/02/24 09:48:38.179
  I0502 09:48:38.190560 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2717" for this suite. @ 05/02/24 09:48:38.193
• [4.067 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 05/02/24 09:48:38.2
  I0502 09:48:38.200164 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/02/24 09:48:38.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:48:38.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:48:38.215
  STEP: Creating 50 configmaps @ 05/02/24 09:48:38.221
  STEP: Creating RC which spawns configmap-volume pods @ 05/02/24 09:48:38.455
  I0502 09:48:38.561312 23 resource.go:87] Pod name wrapped-volume-race-9a25cc56-308b-430e-84f4-5023b3f0688b: Found 3 pods out of 5
  E0502 09:48:38.983763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:39.983918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:40.983970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:41.984615      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:42.984772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:43.566750 23 resource.go:87] Pod name wrapped-volume-race-9a25cc56-308b-430e-84f4-5023b3f0688b: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/02/24 09:48:43.566
  STEP: Creating RC which spawns configmap-volume pods @ 05/02/24 09:48:43.583
  I0502 09:48:43.600864 23 resource.go:87] Pod name wrapped-volume-race-e6a5a0b9-6d65-48be-9942-72371428e996: Found 0 pods out of 5
  E0502 09:48:43.985432      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:44.985728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:45.986310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:46.986448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:47.986644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:48.608254 23 resource.go:87] Pod name wrapped-volume-race-e6a5a0b9-6d65-48be-9942-72371428e996: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/02/24 09:48:48.608
  STEP: Creating RC which spawns configmap-volume pods @ 05/02/24 09:48:48.624
  I0502 09:48:48.640759 23 resource.go:87] Pod name wrapped-volume-race-57d46993-7871-484e-be5d-82e2cc4ec083: Found 0 pods out of 5
  E0502 09:48:48.987361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:49.988018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:50.989013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:51.989174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:52.989653      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:53.649799 23 resource.go:87] Pod name wrapped-volume-race-57d46993-7871-484e-be5d-82e2cc4ec083: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/02/24 09:48:53.649
  STEP: deleting ReplicationController wrapped-volume-race-57d46993-7871-484e-be5d-82e2cc4ec083 in namespace emptydir-wrapper-5429, will wait for the garbage collector to delete the pods @ 05/02/24 09:48:53.661
  I0502 09:48:53.719439 23 resources.go:139] Deleting ReplicationController wrapped-volume-race-57d46993-7871-484e-be5d-82e2cc4ec083 took: 6.010344ms
  I0502 09:48:53.820026 23 resources.go:163] Terminating ReplicationController wrapped-volume-race-57d46993-7871-484e-be5d-82e2cc4ec083 pods took: 100.583105ms
  E0502 09:48:53.990412      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-e6a5a0b9-6d65-48be-9942-72371428e996 in namespace emptydir-wrapper-5429, will wait for the garbage collector to delete the pods @ 05/02/24 09:48:54.92
  I0502 09:48:54.980792 23 resources.go:139] Deleting ReplicationController wrapped-volume-race-e6a5a0b9-6d65-48be-9942-72371428e996 took: 6.502652ms
  E0502 09:48:54.990926      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:55.081001 23 resources.go:163] Terminating ReplicationController wrapped-volume-race-e6a5a0b9-6d65-48be-9942-72371428e996 pods took: 100.205792ms
  E0502 09:48:55.991917      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-9a25cc56-308b-430e-84f4-5023b3f0688b in namespace emptydir-wrapper-5429, will wait for the garbage collector to delete the pods @ 05/02/24 09:48:56.681
  I0502 09:48:56.741624 23 resources.go:139] Deleting ReplicationController wrapped-volume-race-9a25cc56-308b-430e-84f4-5023b3f0688b took: 6.312422ms
  I0502 09:48:56.842021 23 resources.go:163] Terminating ReplicationController wrapped-volume-race-9a25cc56-308b-430e-84f4-5023b3f0688b pods took: 100.394009ms
  E0502 09:48:56.992377      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 05/02/24 09:48:57.943
  E0502 09:48:57.993197      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:48:58.151801 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-5429" for this suite. @ 05/02/24 09:48:58.154
• [19.960 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 05/02/24 09:48:58.16
  I0502 09:48:58.160147 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename statefulset @ 05/02/24 09:48:58.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:48:58.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:48:58.179
  STEP: Creating service test in namespace statefulset-4529 @ 05/02/24 09:48:58.18
  STEP: Looking for a node to schedule stateful set and pod @ 05/02/24 09:48:58.187
  STEP: Creating pod with conflicting port in namespace statefulset-4529 @ 05/02/24 09:48:58.196
  STEP: Waiting until pod test-pod will start running in namespace statefulset-4529 @ 05/02/24 09:48:58.204
  E0502 09:48:58.993331      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:48:59.993551      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:00.993831      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:01.994015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-4529 @ 05/02/24 09:49:02.215
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4529 @ 05/02/24 09:49:02.22
  I0502 09:49:02.237958 23 statefulset.go:866] Observed stateful pod in namespace: statefulset-4529, name: ss-0, uid: 77e4d52d-1d06-442e-b53e-dae7e17b7ecf, status phase: Pending. Waiting for statefulset controller to delete.
  I0502 09:49:02.250933 23 statefulset.go:866] Observed stateful pod in namespace: statefulset-4529, name: ss-0, uid: 77e4d52d-1d06-442e-b53e-dae7e17b7ecf, status phase: Failed. Waiting for statefulset controller to delete.
  I0502 09:49:02.275318 23 statefulset.go:866] Observed stateful pod in namespace: statefulset-4529, name: ss-0, uid: 77e4d52d-1d06-442e-b53e-dae7e17b7ecf, status phase: Failed. Waiting for statefulset controller to delete.
  I0502 09:49:02.279548 23 statefulset.go:860] Observed delete event for stateful pod ss-0 in namespace statefulset-4529
  STEP: Removing pod with conflicting port in namespace statefulset-4529 @ 05/02/24 09:49:02.279
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4529 and will be in running state @ 05/02/24 09:49:02.296
  E0502 09:49:02.994322      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:03.994424      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:04.995078      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:05.995173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:49:06.307716 23 statefulset.go:135] Deleting all statefulset in ns statefulset-4529
  I0502 09:49:06.311463 23 rest.go:150] Scaling statefulset ss to 0
  E0502 09:49:06.996153      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:07.996288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:08.996668      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:09.996918      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:10.997005      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:11.997173      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:12.998065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:13.999069      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:14.999357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:15.999487      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:49:16.322906 23 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0502 09:49:16.325136 23 rest.go:88] Deleting statefulset ss
  I0502 09:49:16.336333 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4529" for this suite. @ 05/02/24 09:49:16.34
• [18.188 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 05/02/24 09:49:16.348
  I0502 09:49:16.348534 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:49:16.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:49:16.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:49:16.372
  STEP: Creating a pod to test downward API volume plugin @ 05/02/24 09:49:16.373
  E0502 09:49:17.000538      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:18.000660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:19.001373      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:20.001671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:49:20.393
  I0502 09:49:20.395831 23 output.go:196] Trying to get logs from node mini-2 pod downwardapi-volume-79a057ec-b7af-49b6-b76a-eb5506d355ef container client-container: <nil>
  STEP: delete the pod @ 05/02/24 09:49:20.399
  I0502 09:49:20.412941 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3891" for this suite. @ 05/02/24 09:49:20.415
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2181
  STEP: Creating a kubernetes client @ 05/02/24 09:49:20.424
  I0502 09:49:20.424082 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename services @ 05/02/24 09:49:20.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:49:20.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:49:20.441
  STEP: creating service in namespace services-4008 @ 05/02/24 09:49:20.443
  STEP: creating service affinity-clusterip in namespace services-4008 @ 05/02/24 09:49:20.444
  STEP: creating replication controller affinity-clusterip in namespace services-4008 @ 05/02/24 09:49:20.459
  I0502 09:49:20.465495      23 runners.go:198] Created replication controller with name: affinity-clusterip, namespace: services-4008, replica count: 3
  E0502 09:49:21.001927      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:22.002662      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:23.003482      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:49:23.516256      23 runners.go:198] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0502 09:49:23.523510 23 resource.go:361] Creating new exec pod
  E0502 09:49:24.004475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:25.004718      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:26.005001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:49:26.538763 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-4008 exec execpod-affinity5vgkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I0502 09:49:26.609671 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  I0502 09:49:26.609710 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:49:26.609770 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-4008 exec execpod-affinity5vgkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.40.53 80'
  I0502 09:49:26.682200 23 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.40.53 80\nConnection to 10.108.40.53 80 port [tcp/http] succeeded!\n"
  I0502 09:49:26.682227 23 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0502 09:49:26.682271 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=services-4008 exec execpod-affinity5vgkc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.108.40.53:80/ ; done'
  I0502 09:49:26.789627 23 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.40.53:80/\n"
  I0502 09:49:26.789659 23 builder.go:147] stdout: "\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s\naffinity-clusterip-4w88s"
  I0502 09:49:26.789674 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789683 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789693 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789706 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789717 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789729 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789739 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789748 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789762 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789802 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789814 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789841 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789850 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789858 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789867 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789876 23 service.go:242] Received response from host: affinity-clusterip-4w88s
  I0502 09:49:26.789934 23 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-4008, will wait for the garbage collector to delete the pods @ 05/02/24 09:49:26.8
  I0502 09:49:26.862175 23 resources.go:139] Deleting ReplicationController affinity-clusterip took: 7.177112ms
  I0502 09:49:26.962275 23 resources.go:163] Terminating ReplicationController affinity-clusterip pods took: 100.097326ms
  E0502 09:49:27.005448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:28.005928      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:29.006071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:49:29.795204 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4008" for this suite. @ 05/02/24 09:49:29.798
• [9.381 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 05/02/24 09:49:29.805
  I0502 09:49:29.805268 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename subpath @ 05/02/24 09:49:29.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:49:29.822
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:49:29.824
  STEP: Setting up data @ 05/02/24 09:49:29.826
  STEP: Creating pod pod-subpath-test-configmap-strf @ 05/02/24 09:49:29.834
  STEP: Creating a pod to test atomic-volume-subpath @ 05/02/24 09:49:29.834
  E0502 09:49:30.006392      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:31.006595      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:32.007089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:33.007207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:34.007952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:35.008279      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:36.008516      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:37.008658      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:38.009084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:39.009465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:40.010007      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:41.010147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:42.010283      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:43.010428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:44.011254      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:45.011880      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:46.012457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:47.012573      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:48.013605      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:49.013761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:50.014599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:51.014763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:52.015767      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:53.016000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:49:53.892
  I0502 09:49:53.895070 23 output.go:196] Trying to get logs from node mini-1 pod pod-subpath-test-configmap-strf container test-container-subpath-configmap-strf: <nil>
  STEP: delete the pod @ 05/02/24 09:49:53.899
  STEP: Deleting pod pod-subpath-test-configmap-strf @ 05/02/24 09:49:53.913
  I0502 09:49:53.913243 23 delete.go:62] Deleting pod "pod-subpath-test-configmap-strf" in namespace "subpath-1225"
  I0502 09:49:53.915135 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1225" for this suite. @ 05/02/24 09:49:53.917
• [24.119 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 05/02/24 09:49:53.923
  I0502 09:49:53.924002 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename replication-controller @ 05/02/24 09:49:53.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:49:53.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:49:53.941
  I0502 09:49:53.943467 23 rc.go:544] Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0502 09:49:54.016147      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 05/02/24 09:49:54.955
  STEP: Checking rc "condition-test" has the desired failure condition set @ 05/02/24 09:49:54.96
  E0502 09:49:55.016337      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 05/02/24 09:49:55.97
  I0502 09:49:55.978398 23 rc.go:730] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 05/02/24 09:49:55.978
  E0502 09:49:56.016843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:49:56.986284 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5081" for this suite. @ 05/02/24 09:49:56.989
• [3.072 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 05/02/24 09:49:56.996
  I0502 09:49:56.996422 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename projected @ 05/02/24 09:49:56.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:49:57.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:49:57.013
  STEP: Creating configMap with name projected-configmap-test-volume-028982b0-15b5-4d27-96a7-135d5609775a @ 05/02/24 09:49:57.015
  E0502 09:49:57.017541      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a pod to test consume configMaps @ 05/02/24 09:49:57.019
  E0502 09:49:58.017875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:49:59.018029      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:00.018142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:01.018288      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:50:01.038
  I0502 09:50:01.042584 23 output.go:196] Trying to get logs from node mini-1 pod pod-projected-configmaps-6339f9eb-7990-4e7b-b5ca-6909b250f74f container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 09:50:01.046
  I0502 09:50:01.056897 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2778" for this suite. @ 05/02/24 09:50:01.06
• [4.071 seconds]
------------------------------
SS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 05/02/24 09:50:01.067
  I0502 09:50:01.067962 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename cronjob @ 05/02/24 09:50:01.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:50:01.086
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:50:01.088
  STEP: Creating a suspended cronjob @ 05/02/24 09:50:01.093
  STEP: Ensuring no jobs are scheduled @ 05/02/24 09:50:01.097
  E0502 09:50:02.018731      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:03.019119      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:04.020135      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:05.020409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:06.020804      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:07.021006      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:08.021286      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:09.021486      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:10.021914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:11.022012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:12.022660      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:13.022815      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:14.022881      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:15.022986      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:16.023367      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:17.023549      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:18.023742      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:19.024077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:20.024356      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:21.024503      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:22.025386      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:23.025573      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:24.025593      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:25.025937      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:26.025890      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:27.025990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:28.026492      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:29.027454      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:30.028357      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:31.028517      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:32.028608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:33.028768      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:34.029535      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:35.030009      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:36.031040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:37.031192      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:38.031647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:39.031970      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:40.032176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:41.032318      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:42.033056      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:43.033190      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:44.033436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:45.033722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:46.033730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:47.033882      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:48.034246      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:49.034553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:50.034925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:51.035061      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:52.035647      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:53.035813      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:54.036460      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:55.036799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:56.037189      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:57.037348      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:58.037701      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:50:59.037926      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:00.038524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:01.038665      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:02.038992      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:03.039152      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:04.039744      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:05.040022      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:06.040046      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:07.040196      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:08.040603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:09.040789      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:10.040955      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:11.041122      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:12.041931      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:13.042084      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:14.043040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:15.043404      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:16.043465      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:17.043609      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:18.043773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:19.043949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:20.044512      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:21.044638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:22.044845      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:23.044994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:24.045493      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:25.045827      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:26.046359      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:27.046488      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:28.046953      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:29.047156      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:30.047894      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:31.048212      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:32.048390      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:33.048525      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:34.049055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:35.049476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:36.049671      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:37.049830      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:38.050219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:39.050716      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:40.051100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:41.051243      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:42.052297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:43.052426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:44.052966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:45.053328      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:46.054042      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:47.054150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:48.055204      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:49.055576      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:50.056603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:51.056749      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:52.057734      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:53.057910      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:54.058209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:55.058470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:56.058574      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:57.058775      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:58.059475      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:51:59.059739      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:00.060450      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:01.060604      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:02.060714      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:03.060867      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:04.061403      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:05.061700      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:06.061981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:07.062159      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:08.062558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:09.062823      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:10.063421      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:11.063577      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:12.064287      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:13.064427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:14.064687      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:15.065382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:16.065405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:17.065586      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:18.066000      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:19.066553      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:20.066994      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:21.067302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:22.068134      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:23.068262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:24.068362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:25.068505      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:26.069163      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:27.069345      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:28.069624      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:29.069891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:30.070346      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:31.070661      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:32.071184      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:33.071347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:34.071728      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:35.072055      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:36.072150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:37.072311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:38.073314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:39.073567      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:40.073674      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:41.073816      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:42.073877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:43.074044      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:44.074563      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:45.074963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:46.076030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:47.076343      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:48.076572      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:49.076853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:50.077362      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:51.077529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:52.077802      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:53.077968      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:54.077962      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:55.078382      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:56.078690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:57.078876      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:58.079185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:52:59.079422      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:00.080299      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:01.080558      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:02.080675      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:03.080832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:04.081278      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:05.081550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:06.081690      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:07.081853      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:08.081899      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:09.082176      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:10.082779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:11.082912      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:12.083037      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:13.083151      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:14.083792      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:15.084169      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:16.084685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:17.084848      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:18.085285      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:19.085550      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:20.086457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:21.086608      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:22.087473      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:23.087596      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:24.088440      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:25.088811      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:26.089155      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:27.089282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:28.090330      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:29.090587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:30.091507      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:31.091840      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:32.092013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:33.092137      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:34.093013      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:35.093518      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:36.093779      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:37.093921      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:38.093961      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:39.094217      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:40.095206      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:41.095311      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:42.095531      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:43.095670      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:44.096649      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:45.096990      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:46.097948      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:47.098080      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:48.098182      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:49.099203      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:50.099763      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:51.099877      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:52.100704      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:53.100812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:54.101532      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:55.101875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:56.102956      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:57.103071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:58.103457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:53:59.103950      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:00.104215      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:01.104862      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:02.105977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:03.105979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:04.106533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:05.106901      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:06.107935      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:07.108054      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:08.108781      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:09.108997      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:10.109307      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:11.109428      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:12.109683      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:13.109798      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:14.109938      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:15.110433      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:16.110572      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:17.110745      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:18.111101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:19.111426      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:20.112010      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:21.112121      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:22.112400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:23.112534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:24.112996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:25.113385      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:26.113914      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:27.114080      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:28.115105      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:29.115372      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:30.116435      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:31.116578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:32.116981      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:33.117125      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:34.117210      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:35.117534      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:36.117896      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:37.118045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:38.118205      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:39.118497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:40.118946      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:41.119072      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:42.119297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:43.119409      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:44.119599      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:45.119984      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:46.120314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:47.120474      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:48.120827      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:49.121099      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:50.121980      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:51.122101      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:52.123165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:53.123320      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:54.123761      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:55.124045      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:56.124875      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:57.125172      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:58.125396      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:54:59.125674      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:00.126307      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 05/02/24 09:55:01.098
  STEP: Removing cronjob @ 05/02/24 09:55:01.101
  I0502 09:55:01.106201 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9859" for this suite. @ 05/02/24 09:55:01.11
• [300.053 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 05/02/24 09:55:01.121
  I0502 09:55:01.121507 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename cronjob @ 05/02/24 09:55:01.122
  E0502 09:55:01.126654      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:55:01.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:55:01.148
  STEP: Creating a cronjob @ 05/02/24 09:55:01.15
  STEP: Ensuring more than one job is running at a time @ 05/02/24 09:55:01.154
  E0502 09:55:02.126965      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:03.127095      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:04.127300      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:05.127666      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:06.127795      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:07.127978      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:08.128180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:09.128585      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:10.128925      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:11.129049      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:12.129727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:13.129860      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:14.130012      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:15.130361      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:16.130578      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:17.130722      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:18.131069      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:19.131347      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:20.132048      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:21.132171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:22.132316      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:23.132467      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:24.132954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:25.133272      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:26.133406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:27.133536      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:28.134326      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:29.134570      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:30.135162      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:31.135752      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:32.136001      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:33.137026      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:34.137982      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:35.138295      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:36.138832      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:37.138988      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:38.139030      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:39.139457      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:40.139846      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:41.139977      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:42.140587      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:43.140731      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:44.140872      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:45.141219      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:46.141458      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:47.142089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:48.142445      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:49.142685      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:50.143374      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:51.143497      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:52.143561      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:53.143697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:54.143940      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:55.144021      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:56.144266      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:57.144414      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:58.144996      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:55:59.145448      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:00.145580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:01.145689      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:02.146603      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:03.146742      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:04.147338      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:05.147472      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:06.147546      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:07.147709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:08.148089      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:09.148462      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:10.148606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:11.148773      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:12.148952      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:13.149071      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:14.149812      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:15.149920      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:16.150053      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:17.151088      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:18.151491      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:19.151983      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:20.152289      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:21.152432      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:22.153310      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:23.153459      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:24.153742      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:25.153883      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:26.154207      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:27.154375      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:28.154476      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:29.155015      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:30.155109      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:31.155258      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:32.155857      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:33.156135      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:34.157142      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:35.157522      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:36.158100      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:37.158302      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:38.158436      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:39.159115      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:40.159232      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:41.159427      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:42.159590      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:43.160526      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:44.160954      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:45.161966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:46.162108      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:47.162721      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:48.162902      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:49.163866      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:50.164018      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:51.164759      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:52.164888      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:53.165413      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:54.165827      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:55.166391      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:56.166490      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:57.166772      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:58.166939      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:56:59.167795      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:00.167976      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 05/02/24 09:57:01.158
  STEP: Removing cronjob @ 05/02/24 09:57:01.16
  I0502 09:57:01.165694 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0502 09:57:01.168869      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "cronjob-8890" for this suite. @ 05/02/24 09:57:01.171
• [120.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 05/02/24 09:57:01.196
  I0502 09:57:01.196569 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename gc @ 05/02/24 09:57:01.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:01.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:01.245
  STEP: create the deployment @ 05/02/24 09:57:01.247
  W0502 09:57:01.252084      23 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/02/24 09:57:01.252
  STEP: delete the deployment @ 05/02/24 09:57:01.757
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 05/02/24 09:57:01.761
  E0502 09:57:02.169209      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/02/24 09:57:02.273
  I0502 09:57:02.336243 23 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0502 09:57:02.336368 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-180" for this suite. @ 05/02/24 09:57:02.34
• [1.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 05/02/24 09:57:02.346
  I0502 09:57:02.346840 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubelet-test @ 05/02/24 09:57:02.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:02.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:02.367
  I0502 09:57:02.391808 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1189" for this suite. @ 05/02/24 09:57:02.394
• [0.054 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 05/02/24 09:57:02.4
  I0502 09:57:02.400973 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename resourcequota @ 05/02/24 09:57:02.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:02.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:02.422
  STEP: Creating a ResourceQuota @ 05/02/24 09:57:02.424
  STEP: Getting a ResourceQuota @ 05/02/24 09:57:02.428
  STEP: Listing all ResourceQuotas with LabelSelector @ 05/02/24 09:57:02.432
  STEP: Patching the ResourceQuota @ 05/02/24 09:57:02.434
  STEP: Deleting a Collection of ResourceQuotas @ 05/02/24 09:57:02.438
  STEP: Verifying the deleted ResourceQuota @ 05/02/24 09:57:02.447
  I0502 09:57:02.449682 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4701" for this suite. @ 05/02/24 09:57:02.452
• [0.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 05/02/24 09:57:02.458
  I0502 09:57:02.458338 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename conformance-tests @ 05/02/24 09:57:02.458
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:02.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:02.483
  STEP: Getting node addresses @ 05/02/24 09:57:02.485
  I0502 09:57:02.485272 23 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I0502 09:57:02.489508 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-6" for this suite. @ 05/02/24 09:57:02.492
• [0.039 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1793
  STEP: Creating a kubernetes client @ 05/02/24 09:57:02.497
  I0502 09:57:02.497820 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename kubectl @ 05/02/24 09:57:02.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:02.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:02.515
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/02/24 09:57:02.516
  I0502 09:57:02.516802 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-1052 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0502 09:57:02.560853 23 builder.go:146] stderr: ""
  I0502 09:57:02.560875 23 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 05/02/24 09:57:02.56
  E0502 09:57:03.169355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:04.170077      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:05.170222      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:06.170343      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:07.170471      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/02/24 09:57:07.611
  I0502 09:57:07.612004 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-1052 get pod e2e-test-httpd-pod -o json'
  I0502 09:57:07.649154 23 builder.go:146] stderr: ""
  I0502 09:57:07.649215 23 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"5f1a07acb7ed8968fbf0d506dc468b7772ed03a07549b2d6f041ebf089adeba0\",\n            \"cni.projectcalico.org/podIP\": \"192.168.158.161/32\",\n            \"cni.projectcalico.org/podIPs\": \"192.168.158.161/32\"\n        },\n        \"creationTimestamp\": \"2024-05-02T09:57:02Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1052\",\n        \"resourceVersion\": \"53532\",\n        \"uid\": \"236e4904-2cca-4ba8-bb57-a41357c6f62e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-f7bqf\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"mini-2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-f7bqf\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-02T09:57:04Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-02T09:57:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-02T09:57:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-02T09:57:04Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-02T09:57:02Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://ea2339e17ab578f1847a903c972737d24e587816bfa2ebd0532dd3c6e98fca6b\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-05-02T09:57:03Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.221.190.32\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"10.221.190.32\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.158.161\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.158.161\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-05-02T09:57:02Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 05/02/24 09:57:07.649
  I0502 09:57:07.649269 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-1052 replace -f -'
  I0502 09:57:07.724772 23 builder.go:146] stderr: ""
  I0502 09:57:07.724794 23 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 05/02/24 09:57:07.724
  I0502 09:57:07.730481 23 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4055516140 --namespace=kubectl-1052 delete pods e2e-test-httpd-pod'
  E0502 09:57:08.171527      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:09.171963      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:10.081840 23 builder.go:146] stderr: ""
  I0502 09:57:10.081872 23 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0502 09:57:10.081943 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1052" for this suite. @ 05/02/24 09:57:10.085
• [7.594 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:673
  STEP: Creating a kubernetes client @ 05/02/24 09:57:10.092
  I0502 09:57:10.092373 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/02/24 09:57:10.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:10.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:10.116
  STEP: getting /apis @ 05/02/24 09:57:10.122
  STEP: getting /apis/admissionregistration.k8s.io @ 05/02/24 09:57:10.126
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 05/02/24 09:57:10.127
  STEP: creating @ 05/02/24 09:57:10.128
  STEP: getting @ 05/02/24 09:57:10.14
  STEP: listing @ 05/02/24 09:57:10.141
  STEP: watching @ 05/02/24 09:57:10.143
  I0502 09:57:10.143565 23 validatingadmissionpolicy.go:768] starting watch
  STEP: patching @ 05/02/24 09:57:10.144
  STEP: updating @ 05/02/24 09:57:10.15
  I0502 09:57:10.155397 23 validatingadmissionpolicy.go:796] waiting for watch events with expected annotations
  STEP: deleting @ 05/02/24 09:57:10.155
  STEP: deleting a collection @ 05/02/24 09:57:10.162
  E0502 09:57:10.172171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:10.177831 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-1103" for this suite. @ 05/02/24 09:57:10.18
• [0.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 05/02/24 09:57:10.187
  I0502 09:57:10.187138 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 09:57:10.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:10.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:10.206
  STEP: creating pod @ 05/02/24 09:57:10.207
  E0502 09:57:11.172940      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:12.173087      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:12.224113 23 pods.go:83] Pod pod-hostip-e1a68751-1afb-4ae8-b541-0b57ad880e7e has hostIP: 10.221.190.31
  I0502 09:57:12.224161 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8589" for this suite. @ 05/02/24 09:57:12.227
• [2.046 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 05/02/24 09:57:12.232
  I0502 09:57:12.232900 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename watch @ 05/02/24 09:57:12.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:12.249
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:12.251
  STEP: creating a watch on configmaps with a certain label @ 05/02/24 09:57:12.253
  STEP: creating a new configmap @ 05/02/24 09:57:12.253
  STEP: modifying the configmap once @ 05/02/24 09:57:12.257
  STEP: changing the label value of the configmap @ 05/02/24 09:57:12.262
  STEP: Expecting to observe a delete notification for the watched object @ 05/02/24 09:57:12.267
  I0502 09:57:12.267343 23 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5388  3d63adf6-c402-4216-a148-2c9cfc0f47f8 53656 0 2024-05-02 09:57:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-02 09:57:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 09:57:12.267403 23 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5388  3d63adf6-c402-4216-a148-2c9cfc0f47f8 53657 0 2024-05-02 09:57:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-02 09:57:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 09:57:12.267446 23 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5388  3d63adf6-c402-4216-a148-2c9cfc0f47f8 53658 0 2024-05-02 09:57:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-02 09:57:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 05/02/24 09:57:12.267
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 05/02/24 09:57:12.272
  E0502 09:57:13.173868      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:14.174171      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:15.174355      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:16.174506      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:17.174644      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:18.174727      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:19.175249      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:20.175405      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:21.175547      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:22.176183      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 05/02/24 09:57:22.272
  STEP: modifying the configmap a third time @ 05/02/24 09:57:22.28
  STEP: deleting the configmap @ 05/02/24 09:57:22.286
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 05/02/24 09:57:22.291
  I0502 09:57:22.291065 23 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5388  3d63adf6-c402-4216-a148-2c9cfc0f47f8 53720 0 2024-05-02 09:57:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-02 09:57:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 09:57:22.291126 23 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5388  3d63adf6-c402-4216-a148-2c9cfc0f47f8 53721 0 2024-05-02 09:57:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-02 09:57:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 09:57:22.291188 23 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5388  3d63adf6-c402-4216-a148-2c9cfc0f47f8 53722 0 2024-05-02 09:57:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-02 09:57:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0502 09:57:22.291237 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5388" for this suite. @ 05/02/24 09:57:22.294
• [10.067 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 05/02/24 09:57:22.3
  I0502 09:57:22.300378 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename pods @ 05/02/24 09:57:22.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:22.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:22.321
  I0502 09:57:22.323432 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: creating the pod @ 05/02/24 09:57:22.323
  STEP: submitting the pod to kubernetes @ 05/02/24 09:57:22.323
  E0502 09:57:23.176949      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:24.177241      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:24.384999 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7164" for this suite. @ 05/02/24 09:57:24.388
• [2.096 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 05/02/24 09:57:24.396
  I0502 09:57:24.396033 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename daemonsets @ 05/02/24 09:57:24.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:24.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:24.415
  STEP: Creating a simple DaemonSet "daemon-set" @ 05/02/24 09:57:24.433
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/02/24 09:57:24.437
  I0502 09:57:24.443646 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:24.443665 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:24.443677 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:24.449684 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:57:24.449697 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:57:25.178020      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:25.441854 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:25.441899 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:25.441925 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:25.444190 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:57:25.444202 23 fixtures.go:130] Node mini-1 is running 0 daemon pod, expected 1
  E0502 09:57:26.178951      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:26.441771 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:26.441808 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:26.441834 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:26.444375 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0502 09:57:26.444387 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 05/02/24 09:57:26.446
  I0502 09:57:26.460181 23 fixtures.go:89] DaemonSet pods can't tolerate node master-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:26.460207 23 fixtures.go:89] DaemonSet pods can't tolerate node master-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:26.460219 23 fixtures.go:89] DaemonSet pods can't tolerate node master-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0502 09:57:26.467750 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0502 09:57:26.467770 23 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 05/02/24 09:57:26.467
  E0502 09:57:27.179781      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting DaemonSet "daemon-set" @ 05/02/24 09:57:27.473
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2790, will wait for the garbage collector to delete the pods @ 05/02/24 09:57:27.473
  I0502 09:57:27.532287 23 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 5.680197ms
  I0502 09:57:27.633268 23 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.978743ms
  E0502 09:57:28.180593      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:29.181451      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:29.336546 23 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0502 09:57:29.336567 23 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0502 09:57:29.338339 23 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"53867"},"items":null}

  I0502 09:57:29.339971 23 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"53867"},"items":null}

  I0502 09:57:29.348295 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2790" for this suite. @ 05/02/24 09:57:29.351
• [4.964 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 05/02/24 09:57:29.359
  I0502 09:57:29.359797 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:57:29.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:29.391
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:29.395
  STEP: Creating projection with secret that has name secret-emptykey-test-01c92679-c8df-4ac8-be70-b7d848b060dc @ 05/02/24 09:57:29.397
  I0502 09:57:29.400138 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1232" for this suite. @ 05/02/24 09:57:29.404
• [0.054 seconds]
------------------------------
SS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 05/02/24 09:57:29.413
  I0502 09:57:29.413513 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename dns @ 05/02/24 09:57:29.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:57:29.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:57:29.441
  STEP: Creating a test headless service @ 05/02/24 09:57:29.443
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-457.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-457.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-457.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-457.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-457.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-457.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-457.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-457.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-457.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-457.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 32.226.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.226.32_udp@PTR;check="$$(dig +tcp +noall +answer +search 32.226.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.226.32_tcp@PTR;sleep 1; done
   @ 05/02/24 09:57:29.486
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-457.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-457.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-457.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-457.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-457.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-457.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-457.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-457.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-457.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-457.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 32.226.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.226.32_udp@PTR;check="$$(dig +tcp +noall +answer +search 32.226.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.226.32_tcp@PTR;sleep 1; done
   @ 05/02/24 09:57:29.486
  STEP: creating a pod to probe DNS @ 05/02/24 09:57:29.486
  STEP: submitting the pod to kubernetes @ 05/02/24 09:57:29.487
  E0502 09:57:30.182174      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:31.182304      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:32.182419      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:33.183520      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/02/24 09:57:33.522
  STEP: looking for the results for each expected name from probers @ 05/02/24 09:57:33.525
  I0502 09:57:33.528027 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:33.530340 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:33.532554 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:33.534710 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:33.545050 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:33.546960 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:33.548904 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:33.550970 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:33.559116 23 dns_common.go:489] Lookups using dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a failed for: [wheezy_udp@dns-test-service.dns-457.svc.cluster.local wheezy_tcp@dns-test-service.dns-457.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_udp@dns-test-service.dns-457.svc.cluster.local jessie_tcp@dns-test-service.dns-457.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local]

  I0502 09:57:33.568939 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:57:33.572932 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:57:33.577585 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:57:34.184524      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:35.184638      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:36.184786      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:37.184966      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:38.184959      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:38.528790 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:38.532159 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:38.534696 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:38.537825 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:38.547509 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:38.549558 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:38.551580 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:38.553591 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:38.562101 23 dns_common.go:489] Lookups using dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a failed for: [wheezy_udp@dns-test-service.dns-457.svc.cluster.local wheezy_tcp@dns-test-service.dns-457.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_udp@dns-test-service.dns-457.svc.cluster.local jessie_tcp@dns-test-service.dns-457.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local]

  I0502 09:57:38.565657 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:57:38.569359 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:57:38.572790 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:57:39.185799      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:40.186065      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:41.186202      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:42.186344      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:43.187398      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:43.529574 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:43.532028 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:43.534157 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:43.536069 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:43.546085 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:43.548130 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:43.550127 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:43.551968 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:43.559977 23 dns_common.go:489] Lookups using dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a failed for: [wheezy_udp@dns-test-service.dns-457.svc.cluster.local wheezy_tcp@dns-test-service.dns-457.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_udp@dns-test-service.dns-457.svc.cluster.local jessie_tcp@dns-test-service.dns-457.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local]

  I0502 09:57:43.563275 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:57:43.566438 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:57:43.569423 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:57:44.188401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:45.188556      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:46.188697      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:47.188843      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:48.189040      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:48.528952 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:48.531647 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:48.534049 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:48.536291 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:48.546608 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:48.548598 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:48.551040 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:48.554295 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:48.563909 23 dns_common.go:489] Lookups using dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a failed for: [wheezy_udp@dns-test-service.dns-457.svc.cluster.local wheezy_tcp@dns-test-service.dns-457.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_udp@dns-test-service.dns-457.svc.cluster.local jessie_tcp@dns-test-service.dns-457.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local]

  I0502 09:57:48.567567 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:57:48.571485 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:57:48.574936 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:57:49.189820      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:50.189956      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:51.190112      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:52.191027      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:53.191150      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:53.529879 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:53.533823 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:53.537035 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:53.540362 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:53.552776 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:53.554892 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:53.557484 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:53.560136 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:53.569684 23 dns_common.go:489] Lookups using dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a failed for: [wheezy_udp@dns-test-service.dns-457.svc.cluster.local wheezy_tcp@dns-test-service.dns-457.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_udp@dns-test-service.dns-457.svc.cluster.local jessie_tcp@dns-test-service.dns-457.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local]

  I0502 09:57:53.573451 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:57:53.577236 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:57:53.580535 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:57:54.191529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:55.191657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:56.191809      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:57.191979      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:57:58.192580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:57:58.530140 23 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:58.533000 23 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:58.535602 23 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:58.538446 23 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:58.550400 23 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:58.552565 23 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:58.555017 23 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:58.557050 23 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local from pod dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a: the server could not find the requested resource (get pods dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a)
  I0502 09:57:58.565526 23 dns_common.go:489] Lookups using dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a failed for: [wheezy_udp@dns-test-service.dns-457.svc.cluster.local wheezy_tcp@dns-test-service.dns-457.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_udp@dns-test-service.dns-457.svc.cluster.local jessie_tcp@dns-test-service.dns-457.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-457.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-457.svc.cluster.local]

  I0502 09:57:58.569508 23 dns_common.go:495] Pod client logs for webserver: 
  I0502 09:57:58.573091 23 dns_common.go:495] Pod client logs for querier: 
  I0502 09:57:58.576228 23 dns_common.go:495] Pod client logs for jessie-querier: 
  E0502 09:57:59.193180      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:00.193338      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:01.193529      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:02.193655      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:03.193710      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:58:03.560132 23 dns_common.go:527] DNS probes using dns-457/dns-test-0479bbe1-506e-4a0c-a966-0a346664d35a succeeded

  STEP: deleting the pod @ 05/02/24 09:58:03.56
  STEP: deleting the test service @ 05/02/24 09:58:03.574
  STEP: deleting the test headless service @ 05/02/24 09:58:03.617
  I0502 09:58:03.627412 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-457" for this suite. @ 05/02/24 09:58:03.631
• [34.228 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 05/02/24 09:58:03.642
  I0502 09:58:03.642380 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename podtemplate @ 05/02/24 09:58:03.642
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:58:03.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:58:03.663
  STEP: Create set of pod templates @ 05/02/24 09:58:03.665
  I0502 09:58:03.668472 23 podtemplates.go:143] created test-podtemplate-1
  I0502 09:58:03.674437 23 podtemplates.go:143] created test-podtemplate-2
  I0502 09:58:03.678524 23 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 05/02/24 09:58:03.678
  STEP: delete collection of pod templates @ 05/02/24 09:58:03.68
  I0502 09:58:03.680643 23 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 05/02/24 09:58:03.69
  I0502 09:58:03.690370 23 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I0502 09:58:03.692174 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9455" for this suite. @ 05/02/24 09:58:03.694
• [0.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 05/02/24 09:58:03.7
  I0502 09:58:03.700917 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename secrets @ 05/02/24 09:58:03.701
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:58:03.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:58:03.716
  STEP: Creating secret with name secret-test-3fdc80b5-b1df-4d83-a59d-55101ac5be9d @ 05/02/24 09:58:03.717
  STEP: Creating a pod to test consume secrets @ 05/02/24 09:58:03.72
  E0502 09:58:04.194214      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:05.194400      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:06.195251      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:07.195410      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:58:07.736
  I0502 09:58:07.737827 23 output.go:196] Trying to get logs from node mini-2 pod pod-secrets-0eecabcc-3ceb-483b-88a8-ca13f4e754b9 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/02/24 09:58:07.741
  I0502 09:58:07.782153 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8854" for this suite. @ 05/02/24 09:58:07.786
• [4.093 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 05/02/24 09:58:07.794
  I0502 09:58:07.794223 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 09:58:07.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:58:07.808
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:58:07.811
  STEP: Setting up server cert @ 05/02/24 09:58:07.857
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 09:58:08.029
  STEP: Deploying the webhook pod @ 05/02/24 09:58:08.036
  STEP: Wait for the deployment to be ready @ 05/02/24 09:58:08.063
  I0502 09:58:08.077776 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 09:58:08.195888      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:09.196323      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:58:10.085782 23 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 2, 9, 58, 8, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 58, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 2, 9, 58, 8, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 2, 9, 58, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0502 09:58:10.197024      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:11.197187      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 09:58:12.089
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 09:58:12.1
  E0502 09:58:12.197267      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:58:13.100217 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 05/02/24 09:58:13.106
  STEP: create a namespace for the webhook @ 05/02/24 09:58:13.116
  STEP: create a configmap should be unconditionally rejected by the webhook @ 05/02/24 09:58:13.133
  I0502 09:58:13.185570 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9072" for this suite. @ 05/02/24 09:58:13.194
  E0502 09:58:13.197297      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-markers-2445" for this suite. @ 05/02/24 09:58:13.204
  STEP: Destroying namespace "fail-closed-namespace-3982" for this suite. @ 05/02/24 09:58:13.225
• [5.440 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 05/02/24 09:58:13.234
  I0502 09:58:13.234318 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename var-expansion @ 05/02/24 09:58:13.234
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:58:13.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:58:13.253
  E0502 09:58:14.197606      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:15.197709      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:58:15.269200 23 delete.go:62] Deleting pod "var-expansion-6664550c-623b-49cb-ba08-b244d5cd418b" in namespace "var-expansion-5504"
  I0502 09:58:15.274233 23 delete.go:70] Wait up to 5m0s for pod "var-expansion-6664550c-623b-49cb-ba08-b244d5cd418b" to be fully deleted
  E0502 09:58:16.198068      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:17.198165      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:58:17.280095 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5504" for this suite. @ 05/02/24 09:58:17.283
• [4.056 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 05/02/24 09:58:17.29
  I0502 09:58:17.290278 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename disruption @ 05/02/24 09:58:17.29
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:58:17.305
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:58:17.307
  STEP: Waiting for the pdb to be processed @ 05/02/24 09:58:17.316
  E0502 09:58:18.198740      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:19.199085      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 05/02/24 09:58:19.32
  STEP: Waiting for all pods to be running @ 05/02/24 09:58:19.326
  I0502 09:58:19.331624 23 disruption.go:578] running pods: 0 < 1
  E0502 09:58:20.199552      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:21.199717      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/02/24 09:58:21.33
  STEP: Waiting for the pdb to be processed @ 05/02/24 09:58:21.338
  STEP: Patching PodDisruptionBudget status @ 05/02/24 09:58:21.344
  STEP: Waiting for the pdb to be processed @ 05/02/24 09:58:21.349
  I0502 09:58:21.353158 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8967" for this suite. @ 05/02/24 09:58:21.356
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 05/02/24 09:58:21.361
  I0502 09:58:21.361797 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename subpath @ 05/02/24 09:58:21.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:58:21.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:58:21.379
  STEP: Setting up data @ 05/02/24 09:58:21.38
  STEP: Creating pod pod-subpath-test-configmap-dnlr @ 05/02/24 09:58:21.387
  STEP: Creating a pod to test atomic-volume-subpath @ 05/02/24 09:58:21.387
  E0502 09:58:22.200092      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:23.200672      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:24.201533      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:25.201657      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:26.202432      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:27.202580      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:28.203314      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:29.203754      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:30.204262      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:31.204401      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:32.204807      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:33.205067      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:34.205708      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:35.205838      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:36.206732      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:37.206891      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:38.207470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:39.207834      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:40.208130      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:41.208282      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:42.209086      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:43.209185      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:44.209255      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:45.209406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:58:45.443
  I0502 09:58:45.446048 23 output.go:196] Trying to get logs from node mini-2 pod pod-subpath-test-configmap-dnlr container test-container-subpath-configmap-dnlr: <nil>
  STEP: delete the pod @ 05/02/24 09:58:45.45
  STEP: Deleting pod pod-subpath-test-configmap-dnlr @ 05/02/24 09:58:45.461
  I0502 09:58:45.461958 23 delete.go:62] Deleting pod "pod-subpath-test-configmap-dnlr" in namespace "subpath-3152"
  I0502 09:58:45.468162 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3152" for this suite. @ 05/02/24 09:58:45.471
• [24.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 05/02/24 09:58:45.478
  I0502 09:58:45.478070 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename configmap @ 05/02/24 09:58:45.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:58:45.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:58:45.495
  STEP: Creating configMap with name configmap-test-volume-map-c952f9c9-3e97-4253-904b-8f0184f2ca52 @ 05/02/24 09:58:45.497
  STEP: Creating a pod to test consume configMaps @ 05/02/24 09:58:45.5
  E0502 09:58:46.210201      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:47.210406      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:48.210730      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:49.211145      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/02/24 09:58:49.552
  I0502 09:58:49.555096 23 output.go:196] Trying to get logs from node mini-2 pod pod-configmaps-c5dc14d0-51bf-40bc-80b4-af8b5ca7c9f7 container agnhost-container: <nil>
  STEP: delete the pod @ 05/02/24 09:58:49.559
  I0502 09:58:49.571090 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4470" for this suite. @ 05/02/24 09:58:49.574
• [4.102 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 05/02/24 09:58:49.579
  I0502 09:58:49.579712 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename webhook @ 05/02/24 09:58:49.58
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:58:49.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:58:49.6
  STEP: Setting up server cert @ 05/02/24 09:58:49.621
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/02/24 09:58:49.797
  STEP: Deploying the webhook pod @ 05/02/24 09:58:49.805
  STEP: Wait for the deployment to be ready @ 05/02/24 09:58:49.814
  I0502 09:58:49.825289 23 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0502 09:58:50.211847      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0502 09:58:51.212470      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/02/24 09:58:51.832
  STEP: Verifying the service has paired with the endpoint @ 05/02/24 09:58:51.843
  E0502 09:58:52.212637      23 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0502 09:58:52.843356 23 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 05/02/24 09:58:52.848
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/02/24 09:58:52.858
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 05/02/24 09:58:52.863
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/02/24 09:58:52.871
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 05/02/24 09:58:52.88
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/02/24 09:58:52.885
  I0502 09:58:52.955665 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4883" for this suite. @ 05/02/24 09:58:52.959
  STEP: Destroying namespace "webhook-markers-8173" for this suite. @ 05/02/24 09:58:52.97
• [3.402 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 05/02/24 09:58:52.981
  I0502 09:58:52.981661 23 util.go:506] >>> kubeConfig: /tmp/kubeconfig-4055516140
  STEP: Building a namespace api object, basename ingress @ 05/02/24 09:58:52.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/02/24 09:58:52.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/02/24 09:58:53.001
  STEP: getting /apis @ 05/02/24 09:58:53.002
  STEP: getting /apis/networking.k8s.io @ 05/02/24 09:58:53.005
  STEP: getting /apis/networking.k8s.iov1 @ 05/02/24 09:58:53.006
  STEP: creating @ 05/02/24 09:58:53.006
  STEP: getting @ 05/02/24 09:58:53.018
  STEP: listing @ 05/02/24 09:58:53.02
  STEP: watching @ 05/02/24 09:58:53.022
  I0502 09:58:53.022754 23 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 05/02/24 09:58:53.023
  STEP: cluster-wide watching @ 05/02/24 09:58:53.025
  I0502 09:58:53.025689 23 ingress.go:198] starting watch
  STEP: patching @ 05/02/24 09:58:53.026
  STEP: updating @ 05/02/24 09:58:53.03
  I0502 09:58:53.037560 23 ingress.go:221] waiting for watch events with expected annotations
  I0502 09:58:53.037575 23 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 05/02/24 09:58:53.037
  STEP: updating /status @ 05/02/24 09:58:53.042
  STEP: get /status @ 05/02/24 09:58:53.05
  STEP: deleting @ 05/02/24 09:58:53.053
  STEP: deleting a collection @ 05/02/24 09:58:53.061
  I0502 09:58:53.073488 23 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-7245" for this suite. @ 05/02/24 09:58:53.076
• [0.102 seconds]
------------------------------
SSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0502 09:58:53.084247 23 suites.go:34] Running AfterSuite actions on node 1
  I0502 09:58:53.084255 23 util.go:614] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:612
[ReportAfterSuite] PASSED [0.030 seconds]
------------------------------

Ran 402 of 7197 Specs in 6553.815 seconds
SUCCESS! -- 402 Passed | 0 Failed | 0 Pending | 6795 Skipped
PASS

Ginkgo ran 1 suite in 1h49m14.301315253s
Test Suite Passed
