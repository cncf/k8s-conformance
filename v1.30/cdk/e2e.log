  I0711 05:34:36.067625      20 e2e.go:109] Starting e2e run "b5d2bce4-72e0-469e-9b87-8839b2fc22bf" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1720676075 - will randomize all specs

Will run 402 of 7197 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0711 05:34:36.280208 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 05:34:36.280970 20 helper.go:48] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0711 05:34:36.308151 20 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0711 05:34:36.312048 20 e2e.go:153] 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  I0711 05:34:36.312081 20 e2e.go:245] e2e test version: v1.30.2
  I0711 05:34:36.312876 20 e2e.go:254] kube-apiserver version: v1.30.2
  I0711 05:34:36.312978 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 05:34:36.317271 20 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 07/11/24 05:34:36.432
  I0711 05:34:36.432551 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubelet-test @ 07/11/24 05:34:36.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:34:36.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:34:36.451
  I0711 05:34:36.479246 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3124" for this suite. @ 07/11/24 05:34:36.482
• [0.058 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 07/11/24 05:34:36.49
  I0711 05:34:36.490358 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 05:34:36.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:34:36.503
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:34:36.506
  STEP: Creating projection with secret that has name projected-secret-test-ffd9876d-a540-4a9a-b766-669c2d1b20d2 @ 07/11/24 05:34:36.509
  STEP: Creating a pod to test consume secrets @ 07/11/24 05:34:36.513
  STEP: Saw pod success @ 07/11/24 05:35:02.602
  I0711 05:35:02.606264 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-secrets-fe43a14e-1587-4c9a-bf27-72d9875fa8cf container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 05:35:02.625
  I0711 05:35:02.643312 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9349" for this suite. @ 07/11/24 05:35:02.646
• [26.165 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 07/11/24 05:35:02.655
  I0711 05:35:02.655190 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 05:35:02.655
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:35:02.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:35:02.675
  STEP: Creating configMap with name cm-test-opt-del-c8ca95c7-35cc-4db0-bfce-d48b936fc13c @ 07/11/24 05:35:02.68
  STEP: Creating configMap with name cm-test-opt-upd-fecd87c2-0e40-47b2-b685-c22b5bc1ca24 @ 07/11/24 05:35:02.684
  STEP: Creating the pod @ 07/11/24 05:35:02.689
  STEP: Deleting configmap cm-test-opt-del-c8ca95c7-35cc-4db0-bfce-d48b936fc13c @ 07/11/24 05:35:04.733
  STEP: Updating configmap cm-test-opt-upd-fecd87c2-0e40-47b2-b685-c22b5bc1ca24 @ 07/11/24 05:35:04.739
  STEP: Creating configMap with name cm-test-opt-create-b2dd3420-8c78-479e-8e27-e2f52c96ee02 @ 07/11/24 05:35:04.744
  STEP: waiting to observe update in volume @ 07/11/24 05:35:04.748
  I0711 05:36:21.108979 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8374" for this suite. @ 07/11/24 05:36:21.112
• [78.465 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 07/11/24 05:36:21.12
  I0711 05:36:21.120092 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename deployment @ 07/11/24 05:36:21.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:36:21.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:36:21.138
  I0711 05:36:21.141070 20 deployment.go:792] Creating deployment "test-recreate-deployment"
  I0711 05:36:21.146808 20 deployment.go:798] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0711 05:36:21.154500 20 deployment.go:222] deployment "test-recreate-deployment" doesn't have the required revision set
  I0711 05:36:23.163137 20 deployment.go:802] Waiting deployment "test-recreate-deployment" to complete
  I0711 05:36:23.166205 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 5, 36, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 5, 36, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 5, 36, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 5, 36, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6b6d9cd7b6\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0711 05:36:25.171753 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 5, 36, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 5, 36, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 5, 36, 21, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 5, 36, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6b6d9cd7b6\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0711 05:36:27.172042 20 deployment.go:807] Triggering a new rollout for deployment "test-recreate-deployment"
  I0711 05:36:27.183033 20 deployment.go:313] Updating deployment test-recreate-deployment
  I0711 05:36:27.183061 20 deployment.go:814] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0711 05:36:27.263146 20 deployment.go:633] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1959",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "90e5f4ab-7ccb-4512-9ab9-183603ae39d6",
      ResourceVersion: (string) (len=4) "4197",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856272981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272981,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=64) "ReplicaSet \"test-recreate-deployment-66b65d9f8f\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0711 05:36:27.267841 20 deployment.go:39] New ReplicaSet "test-recreate-deployment-66b65d9f8f" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-66b65d9f8f",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1959",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0dd43b76-e189-4088-8c69-b1d442780b00",
      ResourceVersion: (string) (len=4) "4196",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856272987,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "90e5f4ab-7ccb-4512-9ab9-183603ae39d6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 30 65 35 66 34  61 62 2d 37 63 63 62 2d  |\"90e5f4ab-7ccb-|
              00000120  34 35 31 32 2d 39 61 62  39 2d 31 38 33 36 30 33  |4512-9ab9-183603|
              00000130  61 65 33 39 64 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |ae39d6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f",
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 05:36:27.268829 20 deployment.go:44] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0711 05:36:27.269094 20 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-6b6d9cd7b6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1959",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3f48cf2e-3e0a-4cfb-b22a-6e20b71405eb",
      ResourceVersion: (string) (len=4) "4186",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856272981,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "90e5f4ab-7ccb-4512-9ab9-183603ae39d6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 30 65 35 66 34  61 62 2d 37 63 63 62 2d  |\"90e5f4ab-7ccb-|
              00000120  34 35 31 32 2d 39 61 62  39 2d 31 38 33 36 30 33  |4512-9ab9-183603|
              00000130  61 65 33 39 64 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |ae39d6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 05:36:27.273857 20 deployment.go:67] Pod "test-recreate-deployment-66b65d9f8f-8k5s9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-recreate-deployment-66b65d9f8f-8k5s9",
      GenerateName: (string) (len=36) "test-recreate-deployment-66b65d9f8f-",
      Namespace: (string) (len=15) "deployment-1959",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5d58c35f-62b7-488b-a67d-d0c4e19b3319",
      ResourceVersion: (string) (len=4) "4198",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856272987,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-recreate-deployment-66b65d9f8f",
          UID: (types.UID) (len=36) "0dd43b76-e189-4088-8c69-b1d442780b00",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 64  64 34 33 62 37 36 2d 65  |d\":\"0dd43b76-e|
              00000090  31 38 39 2d 34 30 38 38  2d 38 63 36 39 2d 62 31  |189-4088-8c69-b1|
              000000a0  64 34 34 32 37 38 30 62  30 30 5c 22 7d 22 3a 7b  |d442780b00\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bpgdd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bpgdd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856272987,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856272987,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 05:36:27.275655 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1959" for this suite. @ 07/11/24 05:36:27.279
• [6.167 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 07/11/24 05:36:27.287
  I0711 05:36:27.287129 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename discovery @ 07/11/24 05:36:27.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:36:27.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:36:27.304
  STEP: Setting up server cert @ 07/11/24 05:36:27.307
  I0711 05:36:27.487618 20 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0711 05:36:27.488570 20 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0711 05:36:27.488592 20 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0711 05:36:27.488598 20 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0711 05:36:27.488604 20 discovery.go:139] Checking APIGroup: apps
  I0711 05:36:27.489424 20 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0711 05:36:27.489436 20 discovery.go:148] Versions found [{apps/v1 v1}]
  I0711 05:36:27.489442 20 discovery.go:154] apps/v1 matches apps/v1
  I0711 05:36:27.489460 20 discovery.go:139] Checking APIGroup: events.k8s.io
  I0711 05:36:27.490190 20 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0711 05:36:27.490198 20 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0711 05:36:27.490211 20 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0711 05:36:27.490217 20 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0711 05:36:27.490993 20 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0711 05:36:27.491003 20 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0711 05:36:27.491010 20 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0711 05:36:27.491015 20 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0711 05:36:27.491735 20 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0711 05:36:27.491752 20 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0711 05:36:27.491758 20 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0711 05:36:27.491771 20 discovery.go:139] Checking APIGroup: autoscaling
  I0711 05:36:27.492516 20 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0711 05:36:27.492526 20 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0711 05:36:27.492532 20 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0711 05:36:27.492549 20 discovery.go:139] Checking APIGroup: batch
  I0711 05:36:27.493287 20 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0711 05:36:27.493296 20 discovery.go:148] Versions found [{batch/v1 v1}]
  I0711 05:36:27.493316 20 discovery.go:154] batch/v1 matches batch/v1
  I0711 05:36:27.493328 20 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0711 05:36:27.494032 20 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0711 05:36:27.494047 20 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0711 05:36:27.494066 20 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0711 05:36:27.494077 20 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0711 05:36:27.494783 20 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0711 05:36:27.494794 20 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0711 05:36:27.494800 20 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0711 05:36:27.494841 20 discovery.go:139] Checking APIGroup: policy
  I0711 05:36:27.495540 20 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0711 05:36:27.495548 20 discovery.go:148] Versions found [{policy/v1 v1}]
  I0711 05:36:27.495554 20 discovery.go:154] policy/v1 matches policy/v1
  I0711 05:36:27.495559 20 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0711 05:36:27.496321 20 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0711 05:36:27.496340 20 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0711 05:36:27.496345 20 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0711 05:36:27.496352 20 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0711 05:36:27.497133 20 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0711 05:36:27.497142 20 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0711 05:36:27.497148 20 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0711 05:36:27.497155 20 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0711 05:36:27.497881 20 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0711 05:36:27.497894 20 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0711 05:36:27.497900 20 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0711 05:36:27.497928 20 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0711 05:36:27.498617 20 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0711 05:36:27.498633 20 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0711 05:36:27.498654 20 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0711 05:36:27.498666 20 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0711 05:36:27.499376 20 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0711 05:36:27.499411 20 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0711 05:36:27.499417 20 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0711 05:36:27.499423 20 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0711 05:36:27.500103 20 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0711 05:36:27.500133 20 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0711 05:36:27.500145 20 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0711 05:36:27.500150 20 discovery.go:139] Checking APIGroup: node.k8s.io
  I0711 05:36:27.500908 20 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0711 05:36:27.500940 20 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0711 05:36:27.500945 20 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0711 05:36:27.500951 20 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0711 05:36:27.501675 20 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0711 05:36:27.501692 20 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0711 05:36:27.501697 20 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0711 05:36:27.501712 20 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0711 05:36:27.502418 20 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0711 05:36:27.502441 20 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  I0711 05:36:27.502446 20 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0711 05:36:27.502457 20 discovery.go:139] Checking APIGroup: metrics.k8s.io
  I0711 05:36:27.503170 20 discovery.go:147] PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  I0711 05:36:27.503181 20 discovery.go:148] Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  I0711 05:36:27.503186 20 discovery.go:154] metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  I0711 05:36:27.503304 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-7925" for this suite. @ 07/11/24 05:36:27.508
• [0.228 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 07/11/24 05:36:27.515
  I0711 05:36:27.515490 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename statefulset @ 07/11/24 05:36:27.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:36:27.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:36:27.53
  STEP: Creating service test in namespace statefulset-4966 @ 07/11/24 05:36:27.533
  I0711 05:36:27.550955 20 wait.go:40] Found 0 stateful pods, waiting for 1
  I0711 05:36:37.554131 20 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 07/11/24 05:36:37.565
  W0711 05:36:37.572762      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  I0711 05:36:37.586428 20 wait.go:40] Found 1 stateful pods, waiting for 2
  I0711 05:36:47.583858 20 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0711 05:36:57.585113 20 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0711 05:36:57.585147 20 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 07/11/24 05:36:57.592
  STEP: Delete all of the StatefulSets @ 07/11/24 05:36:57.597
  STEP: Verify that StatefulSets have been deleted @ 07/11/24 05:36:57.608
  I0711 05:36:57.611690 20 statefulset.go:135] Deleting all statefulset in ns statefulset-4966
  I0711 05:36:57.628278 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4966" for this suite. @ 07/11/24 05:36:57.635
• [30.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 07/11/24 05:36:57.643
  I0711 05:36:57.643199 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 05:36:57.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:36:57.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:36:57.661
  I0711 05:36:57.700756 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3271" for this suite. @ 07/11/24 05:36:57.704
• [0.068 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 07/11/24 05:36:57.711
  I0711 05:36:57.711288 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename daemonsets @ 07/11/24 05:36:57.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:36:57.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:36:57.729
  I0711 05:36:57.753667 20 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I0711 05:36:57.759009 20 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I0711 05:36:57.764606 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:36:57.764654 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:36:57.767421 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 05:36:57.767434 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  I0711 05:36:58.764199 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:36:58.764236 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:36:58.767925 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 05:36:58.767941 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  I0711 05:36:59.764703 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:36:59.764758 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:36:59.768963 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0711 05:36:59.768981 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  I0711 05:37:00.765335 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:00.765375 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:00.769041 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0711 05:37:00.769058 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  I0711 05:37:01.763553 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:01.763597 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:01.767385 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0711 05:37:01.767414 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  I0711 05:37:02.764189 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:02.764238 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:02.767625 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0711 05:37:02.767645 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  I0711 05:37:02.767658 20 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I0711 05:37:02.776591 20 daemon_set.go:102] Updating DaemonSet daemon-set
  I0711 05:37:04.789571 20 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I0711 05:37:04.799869 20 daemon_set.go:102] Updating DaemonSet daemon-set
  I0711 05:37:04.799905 20 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I0711 05:37:04.805949 20 daemon_set.go:1178] Wrong image for pod: daemon-set-rlkdh. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I0711 05:37:04.805973 20 daemon_set.go:1183] Pod daemon-set-rlkdh is not available
  I0711 05:37:04.809959 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:04.809991 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:05.810810 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:05.810846 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:06.804526 20 daemon_set.go:1183] Pod daemon-set-tvdv6 is not available
  I0711 05:37:06.807781 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:06.807830 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 07/11/24 05:37:06.818
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6759, will wait for the garbage collector to delete the pods @ 07/11/24 05:37:06.818
  I0711 05:37:06.880339 20 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.534989ms
  I0711 05:37:06.980934 20 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.590142ms
  I0711 05:37:11.385766 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 05:37:11.385816 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0711 05:37:11.390875 20 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4625"},"items":null}

  I0711 05:37:11.394892 20 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4625"},"items":null}

  I0711 05:37:11.408820 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6759" for this suite. @ 07/11/24 05:37:11.413
• [13.712 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 07/11/24 05:37:11.423
  I0711 05:37:11.423289 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 05:37:11.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:11.438
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:11.44
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 05:37:11.443
  STEP: Saw pod success @ 07/11/24 05:37:15.469
  I0711 05:37:15.473704 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-73421f8a-3a66-4a47-b17f-e0da1949da63 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 05:37:15.481
  I0711 05:37:15.497693 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1818" for this suite. @ 07/11/24 05:37:15.5
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 07/11/24 05:37:15.51
  I0711 05:37:15.510232 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 05:37:15.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:15.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:15.53
  STEP: Creating configMap with name configmap-test-volume-map-e58adb20-6dbc-4df1-a243-254f54bea544 @ 07/11/24 05:37:15.533
  STEP: Creating a pod to test consume configMaps @ 07/11/24 05:37:15.537
  STEP: Saw pod success @ 07/11/24 05:37:19.561
  I0711 05:37:19.565080 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-configmaps-e1138e8f-2a4b-4f2e-a72c-65caa783a16a container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 05:37:19.572
  I0711 05:37:19.592364 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5150" for this suite. @ 07/11/24 05:37:19.596
• [4.095 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 07/11/24 05:37:19.605
  I0711 05:37:19.605034 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 05:37:19.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:19.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:19.622
  STEP: Creating projection with secret that has name projected-secret-test-33105757-2fc2-4d47-8c81-5c8d7a071770 @ 07/11/24 05:37:19.625
  STEP: Creating a pod to test consume secrets @ 07/11/24 05:37:19.632
  STEP: Saw pod success @ 07/11/24 05:37:23.661
  I0711 05:37:23.665831 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-secrets-7a6ae101-61b0-485a-8a70-ae35554e30d9 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 05:37:23.672
  I0711 05:37:23.689640 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7329" for this suite. @ 07/11/24 05:37:23.693
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 07/11/24 05:37:23.7
  I0711 05:37:23.700585 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename disruption @ 07/11/24 05:37:23.701
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:23.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:23.719
  STEP: Creating a kubernetes client @ 07/11/24 05:37:23.722
  I0711 05:37:23.722296 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename disruption-2 @ 07/11/24 05:37:23.722
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:23.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:23.738
  STEP: Waiting for the pdb to be processed @ 07/11/24 05:37:23.747
  STEP: Waiting for the pdb to be processed @ 07/11/24 05:37:25.758
  STEP: Waiting for the pdb to be processed @ 07/11/24 05:37:27.77
  STEP: listing a collection of PDBs across all namespaces @ 07/11/24 05:37:27.775
  STEP: listing a collection of PDBs in namespace disruption-2582 @ 07/11/24 05:37:27.779
  STEP: deleting a collection of PDBs @ 07/11/24 05:37:27.784
  STEP: Waiting for the PDB collection to be deleted @ 07/11/24 05:37:27.798
  I0711 05:37:27.801700 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-186" for this suite. @ 07/11/24 05:37:27.806
  I0711 05:37:27.814038 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2582" for this suite. @ 07/11/24 05:37:27.817
• [4.123 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 07/11/24 05:37:27.824
  I0711 05:37:27.824035 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 05:37:27.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:27.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:27.841
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 05:37:27.843
  STEP: Saw pod success @ 07/11/24 05:37:31.871
  I0711 05:37:31.875140 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-ef66ed3e-cb35-434b-b572-2b2b2a82b9f3 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 05:37:31.883
  I0711 05:37:31.898357 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9933" for this suite. @ 07/11/24 05:37:31.901
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 07/11/24 05:37:31.909
  I0711 05:37:31.909526 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename security-context-test @ 07/11/24 05:37:31.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:31.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:31.929
  I0711 05:37:35.963334 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9831" for this suite. @ 07/11/24 05:37:35.969
• [4.069 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 07/11/24 05:37:35.978
  I0711 05:37:35.978508 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename daemonsets @ 07/11/24 05:37:35.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:35.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:36.002
  STEP: Creating simple DaemonSet "daemon-set" @ 07/11/24 05:37:36.026
  STEP: Check that daemon pods launch on every node of the cluster. @ 07/11/24 05:37:36.03
  I0711 05:37:36.034038 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:36.034086 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:36.039716 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 05:37:36.039735 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  I0711 05:37:37.034621 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:37.034663 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:37.038166 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0711 05:37:37.038187 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  I0711 05:37:38.035394 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:38.035443 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:38.038749 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0711 05:37:38.038761 20 fixtures.go:130] Node ip-172-31-80-240 is running 0 daemon pod, expected 1
  I0711 05:37:39.035036 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:39.035073 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 05:37:39.039366 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0711 05:37:39.039388 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 07/11/24 05:37:39.042
  I0711 05:37:39.046804 20 daemon_set.go:912] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 07/11/24 05:37:39.046
  I0711 05:37:39.057964 20 daemon_set.go:932] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 07/11/24 05:37:39.057
  I0711 05:37:39.059431 20 daemon_set.go:957] Observed &DaemonSet event: ADDED
  I0711 05:37:39.059491 20 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0711 05:37:39.059539 20 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0711 05:37:39.059667 20 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0711 05:37:39.059789 20 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0711 05:37:39.059823 20 daemon_set.go:950] Found daemon set daemon-set in namespace daemonsets-6709 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0711 05:37:39.059831 20 daemon_set.go:961] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 07/11/24 05:37:39.059
  STEP: watching for the daemon set status to be patched @ 07/11/24 05:37:39.067
  I0711 05:37:39.068942 20 daemon_set.go:1001] Observed &DaemonSet event: ADDED
  I0711 05:37:39.069000 20 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0711 05:37:39.069050 20 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0711 05:37:39.069212 20 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0711 05:37:39.069356 20 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0711 05:37:39.069374 20 daemon_set.go:997] Observed daemon set daemon-set in namespace daemonsets-6709 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0711 05:37:39.069524 20 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0711 05:37:39.069540 20 daemon_set.go:994] Found daemon set daemon-set in namespace daemonsets-6709 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0711 05:37:39.069550 20 daemon_set.go:1005] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 07/11/24 05:37:39.075
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6709, will wait for the garbage collector to delete the pods @ 07/11/24 05:37:39.075
  I0711 05:37:39.137736 20 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.925391ms
  I0711 05:37:39.238140 20 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.398015ms
  I0711 05:37:41.042815 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 05:37:41.042850 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0711 05:37:41.046274 20 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"5012"},"items":null}

  I0711 05:37:41.049882 20 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"5012"},"items":null}

  I0711 05:37:41.064687 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6709" for this suite. @ 07/11/24 05:37:41.067
• [5.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:342
  STEP: Creating a kubernetes client @ 07/11/24 05:37:41.074
  I0711 05:37:41.074939 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 05:37:41.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:41.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:41.093
  STEP: creating a replication controller @ 07/11/24 05:37:41.095
  I0711 05:37:41.095757 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 create -f -'
  I0711 05:37:41.187405 20 builder.go:146] stderr: ""
  I0711 05:37:41.187445 20 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 07/11/24 05:37:41.187
  I0711 05:37:41.187657 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0711 05:37:41.245895 20 builder.go:146] stderr: ""
  I0711 05:37:41.245941 20 builder.go:147] stdout: "update-demo-nautilus-6m6kx update-demo-nautilus-967fl "
  I0711 05:37:41.245981 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 get pods update-demo-nautilus-6m6kx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 05:37:41.303597 20 builder.go:146] stderr: ""
  I0711 05:37:41.303634 20 builder.go:147] stdout: ""
  I0711 05:37:41.303643 20 kubectl.go:2501] update-demo-nautilus-6m6kx is created but not running
  I0711 05:37:46.303838 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0711 05:37:46.344451 20 builder.go:146] stderr: ""
  I0711 05:37:46.344489 20 builder.go:147] stdout: "update-demo-nautilus-6m6kx update-demo-nautilus-967fl "
  I0711 05:37:46.344528 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 get pods update-demo-nautilus-6m6kx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 05:37:46.383123 20 builder.go:146] stderr: ""
  I0711 05:37:46.383175 20 builder.go:147] stdout: "true"
  I0711 05:37:46.383214 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 get pods update-demo-nautilus-6m6kx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0711 05:37:46.427849 20 builder.go:146] stderr: ""
  I0711 05:37:46.427884 20 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0711 05:37:46.427896 20 kubectl.go:2392] validating pod update-demo-nautilus-6m6kx
  I0711 05:37:46.433690 20 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0711 05:37:46.433807 20 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0711 05:37:46.433825 20 kubectl.go:2519] update-demo-nautilus-6m6kx is verified up and running
  I0711 05:37:46.433903 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 get pods update-demo-nautilus-967fl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 05:37:46.474600 20 builder.go:146] stderr: ""
  I0711 05:37:46.474629 20 builder.go:147] stdout: "true"
  I0711 05:37:46.474726 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 get pods update-demo-nautilus-967fl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0711 05:37:46.516000 20 builder.go:146] stderr: ""
  I0711 05:37:46.516050 20 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0711 05:37:46.516063 20 kubectl.go:2392] validating pod update-demo-nautilus-967fl
  I0711 05:37:46.521396 20 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0711 05:37:46.521463 20 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0711 05:37:46.521480 20 kubectl.go:2519] update-demo-nautilus-967fl is verified up and running
  STEP: using delete to clean up resources @ 07/11/24 05:37:46.521
  I0711 05:37:46.521585 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 delete --grace-period=0 --force -f -'
  I0711 05:37:46.568027 20 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0711 05:37:46.568072 20 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0711 05:37:46.568120 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 get rc,svc -l name=update-demo --no-headers'
  I0711 05:37:46.614598 20 builder.go:146] stderr: "No resources found in kubectl-5891 namespace.\n"
  I0711 05:37:46.614653 20 builder.go:147] stdout: ""
  I0711 05:37:46.614698 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5891 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0711 05:37:46.656411 20 builder.go:146] stderr: ""
  I0711 05:37:46.656454 20 builder.go:147] stdout: ""
  I0711 05:37:46.656546 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5891" for this suite. @ 07/11/24 05:37:46.661
• [5.595 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 07/11/24 05:37:46.669
  I0711 05:37:46.669989 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename cronjob @ 07/11/24 05:37:46.67
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:37:46.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:37:46.688
  STEP: Creating a cronjob @ 07/11/24 05:37:46.695
  STEP: Ensuring more than one job is running at a time @ 07/11/24 05:37:46.701
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 07/11/24 05:39:00.706
  STEP: Removing cronjob @ 07/11/24 05:39:00.71
  I0711 05:39:00.718680 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2293" for this suite. @ 07/11/24 05:39:00.722
• [74.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:195
  STEP: Creating a kubernetes client @ 07/11/24 05:39:00.734
  I0711 05:39:00.734059 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-publish-openapi @ 07/11/24 05:39:00.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:39:00.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:39:00.808
  I0711 05:39:00.811327 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 07/11/24 05:39:02.224
  I0711 05:39:02.224539 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-4586 --namespace=crd-publish-openapi-4586 create -f -'
  I0711 05:39:02.283476 20 builder.go:146] stderr: ""
  I0711 05:39:02.283536 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8710-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0711 05:39:02.283749 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-4586 --namespace=crd-publish-openapi-4586 delete e2e-test-crd-publish-openapi-8710-crds test-cr'
  I0711 05:39:02.339317 20 builder.go:146] stderr: ""
  I0711 05:39:02.339371 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8710-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I0711 05:39:02.339414 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-4586 --namespace=crd-publish-openapi-4586 apply -f -'
  I0711 05:39:02.391740 20 builder.go:146] stderr: ""
  I0711 05:39:02.391781 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8710-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0711 05:39:02.391930 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-4586 --namespace=crd-publish-openapi-4586 delete e2e-test-crd-publish-openapi-8710-crds test-cr'
  I0711 05:39:02.442747 20 builder.go:146] stderr: ""
  I0711 05:39:02.442793 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8710-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 07/11/24 05:39:02.442
  I0711 05:39:02.442869 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-4586 explain e2e-test-crd-publish-openapi-8710-crds'
  I0711 05:39:02.483490 20 builder.go:146] stderr: ""
  I0711 05:39:02.483540 20 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-8710-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  I0711 05:39:03.691869 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4586" for this suite. @ 07/11/24 05:39:03.698
• [2.971 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 07/11/24 05:39:03.705
  I0711 05:39:03.705504 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename gc @ 07/11/24 05:39:03.706
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:39:03.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:39:03.725
  STEP: create the rc @ 07/11/24 05:39:03.731
  W0711 05:39:03.736532      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 07/11/24 05:39:07.745
  STEP: wait for the rc to be deleted @ 07/11/24 05:39:07.756
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 07/11/24 05:39:12.76
  STEP: Gathering metrics @ 07/11/24 05:39:42.768
  W0711 05:39:42.774071      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0711 05:39:42.774107 20 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0711 05:39:42.774165 20 delete.go:95] Deleting pod "simpletest.rc-26hm4" in namespace "gc-8957"
  I0711 05:39:42.785859 20 delete.go:95] Deleting pod "simpletest.rc-2hbbq" in namespace "gc-8957"
  I0711 05:39:42.798826 20 delete.go:95] Deleting pod "simpletest.rc-2mhtf" in namespace "gc-8957"
  I0711 05:39:42.809410 20 delete.go:95] Deleting pod "simpletest.rc-2mjck" in namespace "gc-8957"
  I0711 05:39:42.821259 20 delete.go:95] Deleting pod "simpletest.rc-2mskw" in namespace "gc-8957"
  I0711 05:39:42.832573 20 delete.go:95] Deleting pod "simpletest.rc-2xcxm" in namespace "gc-8957"
  I0711 05:39:42.844550 20 delete.go:95] Deleting pod "simpletest.rc-4nnh7" in namespace "gc-8957"
  I0711 05:39:42.857030 20 delete.go:95] Deleting pod "simpletest.rc-4qkts" in namespace "gc-8957"
  I0711 05:39:42.868332 20 delete.go:95] Deleting pod "simpletest.rc-5d6hq" in namespace "gc-8957"
  I0711 05:39:42.882289 20 delete.go:95] Deleting pod "simpletest.rc-5n5cw" in namespace "gc-8957"
  I0711 05:39:42.899385 20 delete.go:95] Deleting pod "simpletest.rc-5n8jp" in namespace "gc-8957"
  I0711 05:39:42.910625 20 delete.go:95] Deleting pod "simpletest.rc-5pr8s" in namespace "gc-8957"
  I0711 05:39:42.922509 20 delete.go:95] Deleting pod "simpletest.rc-5sjj7" in namespace "gc-8957"
  I0711 05:39:42.937373 20 delete.go:95] Deleting pod "simpletest.rc-62qpn" in namespace "gc-8957"
  I0711 05:39:42.952161 20 delete.go:95] Deleting pod "simpletest.rc-68mc5" in namespace "gc-8957"
  I0711 05:39:42.962755 20 delete.go:95] Deleting pod "simpletest.rc-6kwfv" in namespace "gc-8957"
  I0711 05:39:42.974771 20 delete.go:95] Deleting pod "simpletest.rc-6pvpn" in namespace "gc-8957"
  I0711 05:39:42.986791 20 delete.go:95] Deleting pod "simpletest.rc-6pvtj" in namespace "gc-8957"
  I0711 05:39:43.001990 20 delete.go:95] Deleting pod "simpletest.rc-6qswj" in namespace "gc-8957"
  I0711 05:39:43.012950 20 delete.go:95] Deleting pod "simpletest.rc-6trsx" in namespace "gc-8957"
  I0711 05:39:43.025495 20 delete.go:95] Deleting pod "simpletest.rc-76mmf" in namespace "gc-8957"
  I0711 05:39:43.039939 20 delete.go:95] Deleting pod "simpletest.rc-7826l" in namespace "gc-8957"
  I0711 05:39:43.052958 20 delete.go:95] Deleting pod "simpletest.rc-85gmv" in namespace "gc-8957"
  I0711 05:39:43.064371 20 delete.go:95] Deleting pod "simpletest.rc-895qm" in namespace "gc-8957"
  I0711 05:39:43.075906 20 delete.go:95] Deleting pod "simpletest.rc-8cqbz" in namespace "gc-8957"
  I0711 05:39:43.089517 20 delete.go:95] Deleting pod "simpletest.rc-92n28" in namespace "gc-8957"
  I0711 05:39:43.100907 20 delete.go:95] Deleting pod "simpletest.rc-9tl4g" in namespace "gc-8957"
  I0711 05:39:43.112138 20 delete.go:95] Deleting pod "simpletest.rc-9ztn7" in namespace "gc-8957"
  I0711 05:39:43.125956 20 delete.go:95] Deleting pod "simpletest.rc-b2mtn" in namespace "gc-8957"
  I0711 05:39:43.137872 20 delete.go:95] Deleting pod "simpletest.rc-bfrn8" in namespace "gc-8957"
  I0711 05:39:43.157033 20 delete.go:95] Deleting pod "simpletest.rc-btfgz" in namespace "gc-8957"
  I0711 05:39:43.170287 20 delete.go:95] Deleting pod "simpletest.rc-c4xbj" in namespace "gc-8957"
  I0711 05:39:43.181753 20 delete.go:95] Deleting pod "simpletest.rc-c6h7j" in namespace "gc-8957"
  I0711 05:39:43.193665 20 delete.go:95] Deleting pod "simpletest.rc-cc6m7" in namespace "gc-8957"
  I0711 05:39:43.208845 20 delete.go:95] Deleting pod "simpletest.rc-crchn" in namespace "gc-8957"
  I0711 05:39:43.221545 20 delete.go:95] Deleting pod "simpletest.rc-dl7zc" in namespace "gc-8957"
  I0711 05:39:43.233283 20 delete.go:95] Deleting pod "simpletest.rc-f78l6" in namespace "gc-8957"
  I0711 05:39:43.250303 20 delete.go:95] Deleting pod "simpletest.rc-fvjjm" in namespace "gc-8957"
  I0711 05:39:43.264520 20 delete.go:95] Deleting pod "simpletest.rc-fwf9b" in namespace "gc-8957"
  I0711 05:39:43.277270 20 delete.go:95] Deleting pod "simpletest.rc-g28k7" in namespace "gc-8957"
  I0711 05:39:43.289199 20 delete.go:95] Deleting pod "simpletest.rc-hbzlz" in namespace "gc-8957"
  I0711 05:39:43.308722 20 delete.go:95] Deleting pod "simpletest.rc-hjfcf" in namespace "gc-8957"
  I0711 05:39:43.329967 20 delete.go:95] Deleting pod "simpletest.rc-htb4q" in namespace "gc-8957"
  I0711 05:39:43.344677 20 delete.go:95] Deleting pod "simpletest.rc-kj9cz" in namespace "gc-8957"
  I0711 05:39:43.357709 20 delete.go:95] Deleting pod "simpletest.rc-kjvm9" in namespace "gc-8957"
  I0711 05:39:43.368800 20 delete.go:95] Deleting pod "simpletest.rc-kpvb4" in namespace "gc-8957"
  I0711 05:39:43.383500 20 delete.go:95] Deleting pod "simpletest.rc-l49rd" in namespace "gc-8957"
  I0711 05:39:43.401845 20 delete.go:95] Deleting pod "simpletest.rc-l7hnn" in namespace "gc-8957"
  I0711 05:39:43.422580 20 delete.go:95] Deleting pod "simpletest.rc-l8h8p" in namespace "gc-8957"
  I0711 05:39:43.438625 20 delete.go:95] Deleting pod "simpletest.rc-ldljr" in namespace "gc-8957"
  I0711 05:39:43.456651 20 delete.go:95] Deleting pod "simpletest.rc-ldrdw" in namespace "gc-8957"
  I0711 05:39:43.476284 20 delete.go:95] Deleting pod "simpletest.rc-lkpbz" in namespace "gc-8957"
  I0711 05:39:43.491477 20 delete.go:95] Deleting pod "simpletest.rc-lnzmq" in namespace "gc-8957"
  I0711 05:39:43.510330 20 delete.go:95] Deleting pod "simpletest.rc-lpjs8" in namespace "gc-8957"
  I0711 05:39:43.521594 20 delete.go:95] Deleting pod "simpletest.rc-lrkmz" in namespace "gc-8957"
  I0711 05:39:43.532735 20 delete.go:95] Deleting pod "simpletest.rc-ml2v2" in namespace "gc-8957"
  I0711 05:39:43.544866 20 delete.go:95] Deleting pod "simpletest.rc-mvpvw" in namespace "gc-8957"
  I0711 05:39:43.558719 20 delete.go:95] Deleting pod "simpletest.rc-mwv7n" in namespace "gc-8957"
  I0711 05:39:43.572466 20 delete.go:95] Deleting pod "simpletest.rc-mzrcc" in namespace "gc-8957"
  I0711 05:39:43.605133 20 delete.go:95] Deleting pod "simpletest.rc-n2cbq" in namespace "gc-8957"
  I0711 05:39:43.623106 20 delete.go:95] Deleting pod "simpletest.rc-nkqkl" in namespace "gc-8957"
  I0711 05:39:43.636051 20 delete.go:95] Deleting pod "simpletest.rc-pbdq6" in namespace "gc-8957"
  I0711 05:39:43.657147 20 delete.go:95] Deleting pod "simpletest.rc-pjpks" in namespace "gc-8957"
  I0711 05:39:43.668418 20 delete.go:95] Deleting pod "simpletest.rc-qc9bn" in namespace "gc-8957"
  I0711 05:39:43.680583 20 delete.go:95] Deleting pod "simpletest.rc-qfzqx" in namespace "gc-8957"
  I0711 05:39:43.694970 20 delete.go:95] Deleting pod "simpletest.rc-qlvxn" in namespace "gc-8957"
  I0711 05:39:43.712090 20 delete.go:95] Deleting pod "simpletest.rc-qnm6f" in namespace "gc-8957"
  I0711 05:39:43.723541 20 delete.go:95] Deleting pod "simpletest.rc-qrhgz" in namespace "gc-8957"
  I0711 05:39:43.775846 20 delete.go:95] Deleting pod "simpletest.rc-qspt4" in namespace "gc-8957"
  I0711 05:39:43.823844 20 delete.go:95] Deleting pod "simpletest.rc-rs8fm" in namespace "gc-8957"
  I0711 05:39:43.874296 20 delete.go:95] Deleting pod "simpletest.rc-s7nf8" in namespace "gc-8957"
  I0711 05:39:43.932068 20 delete.go:95] Deleting pod "simpletest.rc-sb5wn" in namespace "gc-8957"
  I0711 05:39:43.979278 20 delete.go:95] Deleting pod "simpletest.rc-srm9c" in namespace "gc-8957"
  I0711 05:39:44.023140 20 delete.go:95] Deleting pod "simpletest.rc-szkdn" in namespace "gc-8957"
  I0711 05:39:44.098166 20 delete.go:95] Deleting pod "simpletest.rc-szqq2" in namespace "gc-8957"
  I0711 05:39:44.128039 20 delete.go:95] Deleting pod "simpletest.rc-t5qzl" in namespace "gc-8957"
  I0711 05:39:44.194515 20 delete.go:95] Deleting pod "simpletest.rc-t64rc" in namespace "gc-8957"
  I0711 05:39:44.221951 20 delete.go:95] Deleting pod "simpletest.rc-t9rpj" in namespace "gc-8957"
  I0711 05:39:44.274055 20 delete.go:95] Deleting pod "simpletest.rc-tfmsc" in namespace "gc-8957"
  I0711 05:39:44.319868 20 delete.go:95] Deleting pod "simpletest.rc-tsgjn" in namespace "gc-8957"
  I0711 05:39:44.391909 20 delete.go:95] Deleting pod "simpletest.rc-vkx7t" in namespace "gc-8957"
  I0711 05:39:44.440940 20 delete.go:95] Deleting pod "simpletest.rc-vwzm4" in namespace "gc-8957"
  I0711 05:39:44.486303 20 delete.go:95] Deleting pod "simpletest.rc-w7rmn" in namespace "gc-8957"
  I0711 05:39:44.608653 20 delete.go:95] Deleting pod "simpletest.rc-w7xcq" in namespace "gc-8957"
  I0711 05:39:44.621582 20 delete.go:95] Deleting pod "simpletest.rc-w8xpp" in namespace "gc-8957"
  I0711 05:39:44.635755 20 delete.go:95] Deleting pod "simpletest.rc-wcxbv" in namespace "gc-8957"
  I0711 05:39:44.706438 20 delete.go:95] Deleting pod "simpletest.rc-wfn5q" in namespace "gc-8957"
  I0711 05:39:44.733955 20 delete.go:95] Deleting pod "simpletest.rc-whzlq" in namespace "gc-8957"
  I0711 05:39:44.778952 20 delete.go:95] Deleting pod "simpletest.rc-wr6cp" in namespace "gc-8957"
  I0711 05:39:44.825914 20 delete.go:95] Deleting pod "simpletest.rc-wtbl4" in namespace "gc-8957"
  I0711 05:39:44.879763 20 delete.go:95] Deleting pod "simpletest.rc-wv94z" in namespace "gc-8957"
  I0711 05:39:44.924122 20 delete.go:95] Deleting pod "simpletest.rc-x54k9" in namespace "gc-8957"
  I0711 05:39:44.972940 20 delete.go:95] Deleting pod "simpletest.rc-xkbqk" in namespace "gc-8957"
  I0711 05:39:45.028311 20 delete.go:95] Deleting pod "simpletest.rc-xkt2t" in namespace "gc-8957"
  I0711 05:39:45.072194 20 delete.go:95] Deleting pod "simpletest.rc-xq45g" in namespace "gc-8957"
  I0711 05:39:45.123187 20 delete.go:95] Deleting pod "simpletest.rc-xqklm" in namespace "gc-8957"
  I0711 05:39:45.186254 20 delete.go:95] Deleting pod "simpletest.rc-xr99k" in namespace "gc-8957"
  I0711 05:39:45.221564 20 delete.go:95] Deleting pod "simpletest.rc-z8fds" in namespace "gc-8957"
  I0711 05:39:45.274504 20 delete.go:95] Deleting pod "simpletest.rc-zh5t8" in namespace "gc-8957"
  I0711 05:39:45.324770 20 delete.go:95] Deleting pod "simpletest.rc-zkmh7" in namespace "gc-8957"
  I0711 05:39:45.373908 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8957" for this suite. @ 07/11/24 05:39:45.415
• [41.791 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 07/11/24 05:39:45.496
  I0711 05:39:45.496595 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 05:39:45.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:39:45.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:39:45.525
  STEP: Creating secret with name secret-test-map-5b117b93-f5b8-4c53-a15f-a44958f79e81 @ 07/11/24 05:39:45.527
  STEP: Creating a pod to test consume secrets @ 07/11/24 05:39:45.532
  STEP: Saw pod success @ 07/11/24 05:39:49.558
  I0711 05:39:49.561529 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-secrets-1b8f269a-ff11-40e8-a25e-039ba3cf3b05 container secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 05:39:49.573
  I0711 05:39:49.595289 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5191" for this suite. @ 07/11/24 05:39:49.599
• [4.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 07/11/24 05:39:49.605
  I0711 05:39:49.605642 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename cronjob @ 07/11/24 05:39:49.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:39:49.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:39:49.624
  STEP: Creating a ReplaceConcurrent cronjob @ 07/11/24 05:39:49.626
  STEP: Ensuring a job is scheduled @ 07/11/24 05:39:49.631
  STEP: Ensuring exactly one is scheduled @ 07/11/24 05:40:01.638
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 07/11/24 05:40:01.641
  STEP: Ensuring the job is replaced with a new one @ 07/11/24 05:40:01.645
  STEP: Removing cronjob @ 07/11/24 05:41:01.65
  I0711 05:41:01.658626 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-288" for this suite. @ 07/11/24 05:41:01.663
• [72.069 seconds]
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 07/11/24 05:41:01.674
  I0711 05:41:01.674875 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename var-expansion @ 07/11/24 05:41:01.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:01.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:01.7
  STEP: Creating a pod to test substitution in volume subpath @ 07/11/24 05:41:01.702
  STEP: Saw pod success @ 07/11/24 05:41:05.735
  I0711 05:41:05.739455 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod var-expansion-39b79c97-9bc4-4b47-94d2-95fe6b9fcee8 container dapi-container: <nil>
  STEP: delete the pod @ 07/11/24 05:41:05.755
  I0711 05:41:05.771863 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-558" for this suite. @ 07/11/24 05:41:05.776
• [4.109 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 07/11/24 05:41:05.784
  I0711 05:41:05.784306 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 05:41:05.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:05.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:05.803
  I0711 05:41:05.846495 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3093" for this suite. @ 07/11/24 05:41:05.85
• [0.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 07/11/24 05:41:05.859
  I0711 05:41:05.859598 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 05:41:05.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:05.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:05.876
  STEP: Creating secret with name secret-test-2fbf8add-fbb9-4bd1-8957-4cb1d7ceb1b0 @ 07/11/24 05:41:05.878
  STEP: Creating a pod to test consume secrets @ 07/11/24 05:41:05.885
  STEP: Saw pod success @ 07/11/24 05:41:09.913
  I0711 05:41:09.916491 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-secrets-1ba0c2a6-8308-4bae-b8c3-a386d6ec6383 container secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 05:41:09.923
  I0711 05:41:09.940773 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7785" for this suite. @ 07/11/24 05:41:09.944
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 07/11/24 05:41:09.951
  I0711 05:41:09.951821 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename svcaccounts @ 07/11/24 05:41:09.952
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:09.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:09.97
  I0711 05:41:09.992753 20 service_accounts.go:253] created pod pod-service-account-defaultsa
  I0711 05:41:09.992775 20 service_accounts.go:267] pod pod-service-account-defaultsa service account token volume mount: true
  I0711 05:41:09.998931 20 service_accounts.go:253] created pod pod-service-account-mountsa
  I0711 05:41:09.998952 20 service_accounts.go:267] pod pod-service-account-mountsa service account token volume mount: true
  I0711 05:41:10.006872 20 service_accounts.go:253] created pod pod-service-account-nomountsa
  I0711 05:41:10.006891 20 service_accounts.go:267] pod pod-service-account-nomountsa service account token volume mount: false
  I0711 05:41:10.014951 20 service_accounts.go:253] created pod pod-service-account-defaultsa-mountspec
  I0711 05:41:10.015078 20 service_accounts.go:267] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0711 05:41:10.024539 20 service_accounts.go:253] created pod pod-service-account-mountsa-mountspec
  I0711 05:41:10.024666 20 service_accounts.go:267] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0711 05:41:10.034076 20 service_accounts.go:253] created pod pod-service-account-nomountsa-mountspec
  I0711 05:41:10.034160 20 service_accounts.go:267] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0711 05:41:10.041504 20 service_accounts.go:253] created pod pod-service-account-defaultsa-nomountspec
  I0711 05:41:10.041520 20 service_accounts.go:267] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0711 05:41:10.056477 20 service_accounts.go:253] created pod pod-service-account-mountsa-nomountspec
  I0711 05:41:10.056545 20 service_accounts.go:267] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0711 05:41:10.064494 20 service_accounts.go:253] created pod pod-service-account-nomountsa-nomountspec
  I0711 05:41:10.064586 20 service_accounts.go:267] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0711 05:41:10.064760 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5792" for this suite. @ 07/11/24 05:41:10.075
• [0.131 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 07/11/24 05:41:10.083
  I0711 05:41:10.083186 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replicaset @ 07/11/24 05:41:10.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:10.103
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:10.106
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 07/11/24 05:41:10.108
  I0711 05:41:10.117536 20 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  I0711 05:41:15.124176 20 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 07/11/24 05:41:15.124
  STEP: getting scale subresource @ 07/11/24 05:41:15.124
  STEP: updating a scale subresource @ 07/11/24 05:41:15.128
  STEP: verifying the replicaset Spec.Replicas was modified @ 07/11/24 05:41:15.135
  STEP: Patch a scale subresource @ 07/11/24 05:41:15.141
  I0711 05:41:15.162196 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3254" for this suite. @ 07/11/24 05:41:15.168
• [5.099 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 07/11/24 05:41:15.181
  I0711 05:41:15.181958 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename events @ 07/11/24 05:41:15.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:15.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:15.2
  STEP: creating a test event @ 07/11/24 05:41:15.204
  STEP: listing events in all namespaces @ 07/11/24 05:41:15.209
  STEP: listing events in test namespace @ 07/11/24 05:41:15.221
  STEP: listing events with field selection filtering on source @ 07/11/24 05:41:15.224
  STEP: listing events with field selection filtering on reportingController @ 07/11/24 05:41:15.227
  STEP: getting the test event @ 07/11/24 05:41:15.23
  STEP: patching the test event @ 07/11/24 05:41:15.234
  STEP: getting the test event @ 07/11/24 05:41:15.245
  STEP: updating the test event @ 07/11/24 05:41:15.25
  STEP: getting the test event @ 07/11/24 05:41:15.257
  STEP: deleting the test event @ 07/11/24 05:41:15.262
  STEP: listing events in all namespaces @ 07/11/24 05:41:15.274
  STEP: listing events in test namespace @ 07/11/24 05:41:15.283
  I0711 05:41:15.286896 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6801" for this suite. @ 07/11/24 05:41:15.29
• [0.115 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 07/11/24 05:41:15.297
  I0711 05:41:15.297804 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-runtime @ 07/11/24 05:41:15.298
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:15.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:15.315
  STEP: create the container @ 07/11/24 05:41:15.317
  W0711 05:41:15.326537      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 07/11/24 05:41:15.326
  STEP: get the container status @ 07/11/24 05:41:18.347
  STEP: the container should be terminated @ 07/11/24 05:41:18.352
  STEP: the termination message should be set @ 07/11/24 05:41:18.352
  I0711 05:41:18.352130 20 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 07/11/24 05:41:18.352
  I0711 05:41:18.374265 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1333" for this suite. @ 07/11/24 05:41:18.378
• [3.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 07/11/24 05:41:18.386
  I0711 05:41:18.386897 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-pred @ 07/11/24 05:41:18.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:18.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:18.403
  I0711 05:41:18.405912 20 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0711 05:41:18.412264 20 util.go:400] Waiting for terminating namespaces to be deleted...
  I0711 05:41:18.415645 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-11-2 before test
  I0711 05:41:18.420606 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-vst4d from ingress-nginx-kubernetes-worker started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.420621 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 05:41:18.420628 20 predicates.go:887] calico-node-9r7js from kube-system started at 2024-07-11 05:31:26 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.420633 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 05:41:18.420639 20 predicates.go:887] coredns-5c6d979c47-sb7z6 from kube-system started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.420644 20 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0711 05:41:18.420649 20 predicates.go:887] kube-state-metrics-77cc559b76-46cmg from kube-system started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.420654 20 predicates.go:889] 	Container kube-state-metrics ready: true, restart count 1
  I0711 05:41:18.420660 20 predicates.go:887] metrics-server-v0.7.0-7995f698bf-5zlw4 from kube-system started at 2024-07-11 05:25:49 +0000 UTC (2 container statuses recorded)
  I0711 05:41:18.420664 20 predicates.go:889] 	Container metrics-server ready: true, restart count 0
  I0711 05:41:18.420669 20 predicates.go:889] 	Container metrics-server-nanny ready: true, restart count 0
  I0711 05:41:18.420674 20 predicates.go:887] dashboard-metrics-scraper-55584b484c-j4mdq from kubernetes-dashboard started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.420690 20 predicates.go:889] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I0711 05:41:18.420696 20 predicates.go:887] kubernetes-dashboard-6fd7bf4447-4xclp from kubernetes-dashboard started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.420700 20 predicates.go:889] 	Container kubernetes-dashboard ready: true, restart count 1
  I0711 05:41:18.420706 20 predicates.go:887] test-rs-k6dhx from replicaset-3254 started at 2024-07-11 05:41:15 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.420711 20 predicates.go:889] 	Container httpd ready: false, restart count 0
  I0711 05:41:18.420716 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-fccgk from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 05:41:18.420721 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 05:41:18.420726 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0711 05:41:18.420732 20 predicates.go:887] pod-service-account-mountsa-nomountspec from svcaccounts-5792 started at 2024-07-11 05:41:10 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.420736 20 predicates.go:889] 	Container token-test ready: true, restart count 0
  I0711 05:41:18.420743 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-17-237 before test
  I0711 05:41:18.426379 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-7fjdd from ingress-nginx-kubernetes-worker started at 2024-07-11 05:31:54 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.426394 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 05:41:18.426530 20 predicates.go:887] calico-node-795zl from kube-system started at 2024-07-11 05:31:35 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.426568 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 05:41:18.426627 20 predicates.go:887] test-rs-82jbr from replicaset-3254 started at 2024-07-11 05:41:10 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.426657 20 predicates.go:889] 	Container httpd ready: true, restart count 0
  I0711 05:41:18.426706 20 predicates.go:887] sonobuoy-e2e-job-46eff94557cb4446 from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 05:41:18.426737 20 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0711 05:41:18.426767 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 05:41:18.426773 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-ll2lq from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 05:41:18.426779 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 05:41:18.426789 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0711 05:41:18.426795 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-80-240 before test
  I0711 05:41:18.431498 20 predicates.go:887] replace-28677940-dlfcn from cronjob-288 started at 2024-07-11 05:40:00 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.431512 20 predicates.go:889] 	Container c ready: true, restart count 0
  I0711 05:41:18.431519 20 predicates.go:887] replace-28677941-5q26x from cronjob-288 started at 2024-07-11 05:41:00 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.431603 20 predicates.go:889] 	Container c ready: true, restart count 0
  I0711 05:41:18.431660 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-hfpt6 from ingress-nginx-kubernetes-worker started at 2024-07-11 05:26:13 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.431712 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 05:41:18.431752 20 predicates.go:887] calico-node-fcrzw from kube-system started at 2024-07-11 05:32:46 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.431796 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 05:41:18.431865 20 predicates.go:887] test-rs-jhll2 from replicaset-3254 started at 2024-07-11 05:41:15 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.431897 20 predicates.go:889] 	Container httpd ready: false, restart count 0
  I0711 05:41:18.431948 20 predicates.go:887] sonobuoy from sonobuoy started at 2024-07-11 05:34:19 +0000 UTC (1 container statuses recorded)
  I0711 05:41:18.431991 20 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0711 05:41:18.432029 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-9fdzf from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 05:41:18.432083 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 05:41:18.432130 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-11-2 @ 07/11/24 05:41:18.446
  STEP: verifying the node has the label node ip-172-31-17-237 @ 07/11/24 05:41:18.462
  STEP: verifying the node has the label node ip-172-31-80-240 @ 07/11/24 05:41:18.474
  I0711 05:41:18.486047 20 predicates.go:374] Pod replace-28677940-dlfcn requesting resource cpu=0m on Node ip-172-31-80-240
  I0711 05:41:18.486148 20 predicates.go:374] Pod replace-28677941-5q26x requesting resource cpu=0m on Node ip-172-31-80-240
  I0711 05:41:18.486179 20 predicates.go:374] Pod nginx-ingress-controller-kubernetes-worker-7fjdd requesting resource cpu=0m on Node ip-172-31-17-237
  I0711 05:41:18.486220 20 predicates.go:374] Pod nginx-ingress-controller-kubernetes-worker-hfpt6 requesting resource cpu=0m on Node ip-172-31-80-240
  I0711 05:41:18.486249 20 predicates.go:374] Pod nginx-ingress-controller-kubernetes-worker-vst4d requesting resource cpu=0m on Node ip-172-31-11-2
  I0711 05:41:18.486294 20 predicates.go:374] Pod calico-node-795zl requesting resource cpu=250m on Node ip-172-31-17-237
  I0711 05:41:18.486321 20 predicates.go:374] Pod calico-node-9r7js requesting resource cpu=250m on Node ip-172-31-11-2
  I0711 05:41:18.486363 20 predicates.go:374] Pod calico-node-fcrzw requesting resource cpu=250m on Node ip-172-31-80-240
  I0711 05:41:18.486391 20 predicates.go:374] Pod coredns-5c6d979c47-sb7z6 requesting resource cpu=100m on Node ip-172-31-11-2
  I0711 05:41:18.486417 20 predicates.go:374] Pod kube-state-metrics-77cc559b76-46cmg requesting resource cpu=0m on Node ip-172-31-11-2
  I0711 05:41:18.486458 20 predicates.go:374] Pod metrics-server-v0.7.0-7995f698bf-5zlw4 requesting resource cpu=5m on Node ip-172-31-11-2
  I0711 05:41:18.486487 20 predicates.go:374] Pod dashboard-metrics-scraper-55584b484c-j4mdq requesting resource cpu=0m on Node ip-172-31-11-2
  I0711 05:41:18.486527 20 predicates.go:374] Pod kubernetes-dashboard-6fd7bf4447-4xclp requesting resource cpu=0m on Node ip-172-31-11-2
  I0711 05:41:18.486556 20 predicates.go:374] Pod test-rs-82jbr requesting resource cpu=0m on Node ip-172-31-17-237
  I0711 05:41:18.486594 20 predicates.go:374] Pod test-rs-jhll2 requesting resource cpu=0m on Node ip-172-31-80-240
  I0711 05:41:18.486623 20 predicates.go:374] Pod test-rs-k6dhx requesting resource cpu=0m on Node ip-172-31-11-2
  I0711 05:41:18.486650 20 predicates.go:374] Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-80-240
  I0711 05:41:18.486690 20 predicates.go:374] Pod sonobuoy-e2e-job-46eff94557cb4446 requesting resource cpu=0m on Node ip-172-31-17-237
  I0711 05:41:18.486722 20 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-9fdzf requesting resource cpu=0m on Node ip-172-31-80-240
  I0711 05:41:18.486765 20 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-fccgk requesting resource cpu=0m on Node ip-172-31-11-2
  I0711 05:41:18.486794 20 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-ll2lq requesting resource cpu=0m on Node ip-172-31-17-237
  I0711 05:41:18.486833 20 predicates.go:374] Pod pod-service-account-mountsa-nomountspec requesting resource cpu=0m on Node ip-172-31-11-2
  STEP: Starting Pods to consume most of the cluster CPU. @ 07/11/24 05:41:18.486
  I0711 05:41:18.486913 20 predicates.go:384] Creating a pod which consumes cpu=1151m on Node ip-172-31-11-2
  I0711 05:41:18.495714 20 predicates.go:384] Creating a pod which consumes cpu=1225m on Node ip-172-31-17-237
  I0711 05:41:18.503371 20 predicates.go:384] Creating a pod which consumes cpu=1225m on Node ip-172-31-80-240
  STEP: Creating another pod that requires unavailable amount of CPU. @ 07/11/24 05:41:22.533
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-76241b8c-cd67-4536-9061-5b7e70d360f3.17e11224032b69a9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-80/filler-pod-76241b8c-cd67-4536-9061-5b7e70d360f3 to ip-172-31-80-240] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-76241b8c-cd67-4536-9061-5b7e70d360f3.17e112241fd0ce74], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-76241b8c-cd67-4536-9061-5b7e70d360f3.17e1122420f71945], Reason = [Created], Message = [Created container filler-pod-76241b8c-cd67-4536-9061-5b7e70d360f3] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-76241b8c-cd67-4536-9061-5b7e70d360f3.17e1122423c8810b], Reason = [Started], Message = [Started container filler-pod-76241b8c-cd67-4536-9061-5b7e70d360f3] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c0faf716-23f4-4596-a653-3ba192290435.17e11224027f68dc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-80/filler-pod-c0faf716-23f4-4596-a653-3ba192290435 to ip-172-31-11-2] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c0faf716-23f4-4596-a653-3ba192290435.17e112248abf4b53], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.9"] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c0faf716-23f4-4596-a653-3ba192290435.17e112248ffd17fb], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.9" in 87ms (87ms including waiting). Image size: 321520 bytes.] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c0faf716-23f4-4596-a653-3ba192290435.17e112249136c186], Reason = [Created], Message = [Created container filler-pod-c0faf716-23f4-4596-a653-3ba192290435] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-c0faf716-23f4-4596-a653-3ba192290435.17e1122496665b97], Reason = [Started], Message = [Started container filler-pod-c0faf716-23f4-4596-a653-3ba192290435] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-f4d6c71b-e234-4d9a-8195-562de47542f1.17e11224030d3fbb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-80/filler-pod-f4d6c71b-e234-4d9a-8195-562de47542f1 to ip-172-31-17-237] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-f4d6c71b-e234-4d9a-8195-562de47542f1.17e112241fd609f9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-f4d6c71b-e234-4d9a-8195-562de47542f1.17e1122420ba6512], Reason = [Created], Message = [Created container filler-pod-f4d6c71b-e234-4d9a-8195-562de47542f1] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-f4d6c71b-e234-4d9a-8195-562de47542f1.17e1122423fea61f], Reason = [Started], Message = [Started container filler-pod-f4d6c71b-e234-4d9a-8195-562de47542f1] @ 07/11/24 05:41:22.537
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17e11224f375f405], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] @ 07/11/24 05:41:22.552
  STEP: removing the label node off the node ip-172-31-11-2 @ 07/11/24 05:41:23.552
  STEP: verifying the node doesn't have the label node @ 07/11/24 05:41:23.563
  STEP: removing the label node off the node ip-172-31-17-237 @ 07/11/24 05:41:23.566
  STEP: verifying the node doesn't have the label node @ 07/11/24 05:41:23.58
  STEP: removing the label node off the node ip-172-31-80-240 @ 07/11/24 05:41:23.588
  STEP: verifying the node doesn't have the label node @ 07/11/24 05:41:23.599
  I0711 05:41:23.603664 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-80" for this suite. @ 07/11/24 05:41:23.61
• [5.231 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:779
  STEP: Creating a kubernetes client @ 07/11/24 05:41:23.618
  I0711 05:41:23.618543 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 05:41:23.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:23.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:23.639
  I0711 05:41:23.645550 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1882" for this suite. @ 07/11/24 05:41:23.649
• [0.038 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 07/11/24 05:41:23.656
  I0711 05:41:23.656380 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 05:41:23.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:23.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:23.673
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 05:41:23.675
  STEP: Saw pod success @ 07/11/24 05:41:25.693
  I0711 05:41:25.697777 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod downwardapi-volume-0b76c6fb-70a9-4a6d-8d08-57ed21d4db8f container client-container: <nil>
  STEP: delete the pod @ 07/11/24 05:41:25.704
  I0711 05:41:25.718899 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5328" for this suite. @ 07/11/24 05:41:25.722
• [2.075 seconds]
------------------------------
S
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 07/11/24 05:41:25.731
  I0711 05:41:25.731380 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pv @ 07/11/24 05:41:25.731
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:25.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:25.745
  STEP: Creating initial PV and PVC @ 07/11/24 05:41:25.747
  I0711 05:41:25.747725 20 pv.go:390] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-4381" @ 07/11/24 05:41:25.761
  STEP: Listing PVCs in namespace "pv-4381" @ 07/11/24 05:41:25.764
  STEP: Reading "pvc-697kh" Status @ 07/11/24 05:41:25.77
  STEP: Reading "pv-4381-lj5br" Status @ 07/11/24 05:41:25.774
  STEP: Patching "pvc-697kh" Status @ 07/11/24 05:41:25.778
  STEP: Patching "pv-4381-lj5br" Status @ 07/11/24 05:41:25.785
  STEP: Updating "pvc-697kh" Status @ 07/11/24 05:41:25.802
  STEP: Updating "pv-4381-lj5br" Status @ 07/11/24 05:41:25.816
  I0711 05:41:25.824390 20 persistent_volumes.go:407] AfterEach: deleting 1 PVCs and 1 PVs...
  I0711 05:41:25.824411 20 pv.go:201] Deleting PersistentVolumeClaim "pvc-697kh"
  I0711 05:41:25.833020 20 pv.go:189] Deleting PersistentVolume "pv-4381-lj5br"
  I0711 05:41:25.841248 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-4381" for this suite. @ 07/11/24 05:41:25.844
• [0.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 07/11/24 05:41:25.853
  I0711 05:41:25.853439 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 05:41:25.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:41:25.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:41:25.874
  STEP: Creating pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150 @ 07/11/24 05:41:25.877
  STEP: checking the pod's current state and verifying that restartCount is present @ 07/11/24 05:41:27.898
  I0711 05:41:27.902461 20 container_probe.go:1749] Initial restart count of pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf is 0
  I0711 05:41:27.906189 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:29.911801 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:31.916762 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:33.921584 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:35.927628 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:37.932271 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:39.937679 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:41.942935 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:43.948454 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:45.953364 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:47.958998 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:49.964737 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:51.969421 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:53.976038 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:55.981928 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:57.988158 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:41:59.992720 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:01.998018 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:04.002706 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:06.008784 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:08.013732 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:10.019770 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:12.025458 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:14.030482 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:16.036044 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:18.041602 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:20.046980 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:22.053389 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:24.058713 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:26.065513 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:28.070858 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:30.077661 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:32.082428 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:34.088128 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:36.094171 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:38.099342 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:40.105157 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:42.110378 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:44.117583 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:46.122141 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:48.127604 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:50.131855 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:52.137491 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:54.141689 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:56.146583 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:42:58.151790 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:00.157071 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:02.162910 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:04.169071 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:06.175028 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:08.181535 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:10.186873 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:12.193023 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:14.198939 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:16.204474 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:18.209753 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:20.214509 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:22.220329 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:24.226429 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:26.231868 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:28.236492 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:30.241124 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:32.245732 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:34.252308 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:36.257995 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:38.262993 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:40.268442 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:42.273721 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:44.279488 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:46.285222 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:48.290636 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:50.297005 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:52.302382 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:54.307304 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:56.313170 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:43:58.317436 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:00.323201 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:02.329346 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:04.334058 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:06.338906 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:08.344006 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:10.348727 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:12.354550 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:14.360298 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:16.366115 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:18.372150 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:20.376930 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:22.382263 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:24.387621 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:26.393174 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:28.397859 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:30.403243 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:32.408465 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:34.414346 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:36.420654 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:38.426352 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:40.430694 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:42.436921 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:44.441937 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:46.447689 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:48.452843 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:50.457842 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:52.464093 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:54.469916 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:56.475085 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:44:58.481014 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:00.486825 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:02.493161 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:04.500179 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:06.506059 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:08.511879 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:10.517623 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:12.522547 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:14.529047 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:16.533700 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:18.538705 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:20.543432 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:22.547923 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:24.553148 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  I0711 05:45:26.559618 20 container_probe.go:1759] Get pod busybox-8d68c7e3-fc75-4f68-929a-fda4a90f2acf in namespace container-probe-7150
  STEP: deleting the pod @ 07/11/24 05:45:28.56
  I0711 05:45:28.575617 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7150" for this suite. @ 07/11/24 05:45:28.579
• [242.734 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 07/11/24 05:45:28.587
  I0711 05:45:28.587267 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 05:45:28.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:45:28.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:45:28.602
  STEP: Creating secret with name secret-test-d4209cab-ba87-4a13-9df4-c124ef385a1e @ 07/11/24 05:45:28.604
  STEP: Creating a pod to test consume secrets @ 07/11/24 05:45:28.608
  STEP: Saw pod success @ 07/11/24 05:45:30.629
  I0711 05:45:30.633619 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-secrets-f8056c90-4d44-4ab3-8b37-b13b26ae76f7 container secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 05:45:30.649
  I0711 05:45:30.665753 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1886" for this suite. @ 07/11/24 05:45:30.669
• [2.089 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 07/11/24 05:45:30.676
  I0711 05:45:30.676309 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename custom-resource-definition @ 07/11/24 05:45:30.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:45:30.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:45:30.694
  I0711 05:45:30.695946 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 05:45:31.237430 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4539" for this suite. @ 07/11/24 05:45:31.244
• [0.576 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 07/11/24 05:45:31.255
  I0711 05:45:31.255509 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pod-network-test @ 07/11/24 05:45:31.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:45:31.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:45:31.272
  STEP: Performing setup for networking test in namespace pod-network-test-6762 @ 07/11/24 05:45:31.275
  STEP: creating a selector @ 07/11/24 05:45:31.275
  STEP: Creating the service pods in kubernetes @ 07/11/24 05:45:31.275
  I0711 05:45:31.275771 20 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 07/11/24 05:45:43.356
  I0711 05:45:45.393407 20 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0711 05:45:45.393441 20 utils.go:472] Going to poll 192.168.122.107 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0711 05:45:45.397230 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.122.107:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6762 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 05:45:45.397255 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 05:45:45.397683 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 05:45:45.397726 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6762/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.122.107%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0711 05:45:45.459529 20 utils.go:489] Found all 1 expected endpoints: [netserver-0]
  I0711 05:45:45.459561 20 utils.go:472] Going to poll 192.168.133.117 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0711 05:45:45.464014 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.133.117:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6762 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 05:45:45.464031 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 05:45:45.464490 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 05:45:45.464533 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6762/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.133.117%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0711 05:45:45.514668 20 utils.go:489] Found all 1 expected endpoints: [netserver-1]
  I0711 05:45:45.514721 20 utils.go:472] Going to poll 192.168.37.54 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I0711 05:45:45.519249 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.37.54:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6762 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 05:45:45.519266 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 05:45:45.519701 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 05:45:45.519749 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6762/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.37.54%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0711 05:45:45.569809 20 utils.go:489] Found all 1 expected endpoints: [netserver-2]
  I0711 05:45:45.569965 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6762" for this suite. @ 07/11/24 05:45:45.575
• [14.326 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 07/11/24 05:45:45.582
  I0711 05:45:45.582057 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename watch @ 07/11/24 05:45:45.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:45:45.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:45:45.6
  STEP: creating a watch on configmaps @ 07/11/24 05:45:45.602
  STEP: creating a new configmap @ 07/11/24 05:45:45.603
  STEP: modifying the configmap once @ 07/11/24 05:45:45.608
  STEP: closing the watch once it receives two notifications @ 07/11/24 05:45:45.616
  I0711 05:45:45.616590 20 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6902  25228f4b-6a2c-47b7-9a20-dd55a4598394 9592 0 2024-07-11 05:45:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-07-11 05:45:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 05:45:45.616706 20 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6902  25228f4b-6a2c-47b7-9a20-dd55a4598394 9593 0 2024-07-11 05:45:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-07-11 05:45:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 07/11/24 05:45:45.616
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 07/11/24 05:45:45.624
  STEP: deleting the configmap @ 07/11/24 05:45:45.625
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 07/11/24 05:45:45.631
  I0711 05:45:45.631739 20 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6902  25228f4b-6a2c-47b7-9a20-dd55a4598394 9594 0 2024-07-11 05:45:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-07-11 05:45:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 05:45:45.631869 20 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6902  25228f4b-6a2c-47b7-9a20-dd55a4598394 9595 0 2024-07-11 05:45:45 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-07-11 05:45:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 05:45:45.631947 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6902" for this suite. @ 07/11/24 05:45:45.636
• [0.061 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 07/11/24 05:45:45.642
  I0711 05:45:45.643002 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 05:45:45.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:45:45.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:45:45.66
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 07/11/24 05:45:45.662
  STEP: Saw pod success @ 07/11/24 05:45:49.685
  I0711 05:45:49.690022 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-2ed98bfc-7fe2-438c-a360-86e311f44fd0 container test-container: <nil>
  STEP: delete the pod @ 07/11/24 05:45:49.701
  I0711 05:45:49.717384 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7412" for this suite. @ 07/11/24 05:45:49.721
• [4.086 seconds]
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 07/11/24 05:45:49.729
  I0711 05:45:49.729554 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename chunking @ 07/11/24 05:45:49.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:45:49.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:45:49.752
  STEP: creating a large number of resources @ 07/11/24 05:45:49.754
  STEP: retrieving the first page @ 07/11/24 05:46:07.436
  I0711 05:46:07.485844 20 chunking.go:163] Retrieved 40/40 results with rv 10145 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 07/11/24 05:46:07.485
  I0711 05:46:27.492104 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:46:47.491938 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:47:07.492671 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:47:27.493275 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:47:47.491756 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:48:07.491249 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:48:27.493754 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:48:47.491280 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:49:07.491923 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:49:27.490969 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:49:47.492515 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:50:07.491702 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:50:27.491552 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:50:47.493424 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:51:07.492260 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:51:27.492499 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:51:47.491887 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:52:07.491950 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:52:27.492038 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:52:47.491941 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:53:07.492217 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:53:27.491310 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:53:47.491322 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:54:07.491682 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:54:27.490873 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:54:47.492134 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:55:07.492691 20 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTAxNDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  I0711 05:55:27.491131 20 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0711 05:55:27.491170 20 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 07/11/24 05:55:27.491
  STEP: retrieving all remaining pages @ 07/11/24 05:55:27.496
  I0711 05:55:27.500011 20 chunking.go:221] Retrieved 40/40 results with rv 11212 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTEyMTIsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  I0711 05:55:27.503862 20 chunking.go:221] Retrieved 40/40 results with rv 11212 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTEyMTIsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  I0711 05:55:27.508166 20 chunking.go:221] Retrieved 40/40 results with rv 11212 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTEyMTIsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  I0711 05:55:27.511474 20 chunking.go:221] Retrieved 40/40 results with rv 11212 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTEyMTIsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  I0711 05:55:27.515751 20 chunking.go:221] Retrieved 40/40 results with rv 11212 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTEyMTIsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  I0711 05:55:27.520241 20 chunking.go:221] Retrieved 40/40 results with rv 11212 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTEyMTIsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  I0711 05:55:27.524189 20 chunking.go:221] Retrieved 40/40 results with rv 11212 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTEyMTIsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  I0711 05:55:27.527910 20 chunking.go:221] Retrieved 40/40 results with rv 11212 and continue 
  I0711 05:55:27.528019 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-4869" for this suite. @ 07/11/24 05:55:27.532
• [577.809 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 07/11/24 05:55:27.539
  I0711 05:55:27.539089 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename statefulset @ 07/11/24 05:55:27.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:55:27.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:55:27.555
  STEP: Creating service test in namespace statefulset-7484 @ 07/11/24 05:55:27.557
  STEP: Creating statefulset ss in namespace statefulset-7484 @ 07/11/24 05:55:27.569
  I0711 05:55:27.577206 20 wait.go:40] Found 0 stateful pods, waiting for 1
  I0711 05:55:37.579857 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 07/11/24 05:55:37.586
  STEP: Getting /status @ 07/11/24 05:55:37.592
  I0711 05:55:37.596722 20 statefulset.go:1067] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 07/11/24 05:55:37.596
  I0711 05:55:37.607097 20 statefulset.go:1087] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 07/11/24 05:55:37.607
  I0711 05:55:37.608510 20 statefulset.go:1115] Observed &StatefulSet event: ADDED
  I0711 05:55:37.608533 20 statefulset.go:1108] Found Statefulset ss in namespace statefulset-7484 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0711 05:55:37.608542 20 statefulset.go:1119] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 07/11/24 05:55:37.608
  I0711 05:55:37.608561 20 statefulset.go:1123] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0711 05:55:37.615524 20 statefulset.go:1127] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 07/11/24 05:55:37.615
  I0711 05:55:37.616906 20 statefulset.go:1152] Observed &StatefulSet event: ADDED
  I0711 05:55:37.616971 20 statefulset.go:135] Deleting all statefulset in ns statefulset-7484
  I0711 05:55:37.619726 20 rest.go:150] Scaling statefulset ss to 0
  I0711 05:55:47.634409 20 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0711 05:55:47.638595 20 rest.go:88] Deleting statefulset ss
  I0711 05:55:47.652559 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7484" for this suite. @ 07/11/24 05:55:47.656
• [20.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 07/11/24 05:55:47.663
  I0711 05:55:47.663452 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename limitrange @ 07/11/24 05:55:47.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:55:47.68
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:55:47.682
  STEP: Creating LimitRange "e2e-limitrange-jxwhk" in namespace "limitrange-2803" @ 07/11/24 05:55:47.684
  STEP: Creating another limitRange in another namespace @ 07/11/24 05:55:47.689
  I0711 05:55:47.703897 20 limit_range.go:299] Namespace "e2e-limitrange-jxwhk-2318" created
  I0711 05:55:47.703918 20 limit_range.go:300] Creating LimitRange "e2e-limitrange-jxwhk" in namespace "e2e-limitrange-jxwhk-2318"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-jxwhk" @ 07/11/24 05:55:47.711
  I0711 05:55:47.714015 20 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-jxwhk" in "limitrange-2803" namespace @ 07/11/24 05:55:47.714
  I0711 05:55:47.719819 20 limit_range.go:335] LimitRange "e2e-limitrange-jxwhk" has been patched
  STEP: Delete LimitRange "e2e-limitrange-jxwhk" by Collection with labelSelector: "e2e-limitrange-jxwhk=patched" @ 07/11/24 05:55:47.719
  STEP: Confirm that the limitRange "e2e-limitrange-jxwhk" has been deleted @ 07/11/24 05:55:47.728
  I0711 05:55:47.728160 20 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I0711 05:55:47.731362 20 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-jxwhk=patched"
  I0711 05:55:47.731374 20 limit_range.go:344] LimitRange "e2e-limitrange-jxwhk" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-jxwhk" @ 07/11/24 05:55:47.731
  I0711 05:55:47.733997 20 limit_range.go:350] Found 1 limitRange
  I0711 05:55:47.734089 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-2803" for this suite. @ 07/11/24 05:55:47.737
  STEP: Destroying namespace "e2e-limitrange-jxwhk-2318" for this suite. @ 07/11/24 05:55:47.745
• [0.088 seconds]
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 07/11/24 05:55:47.752
  I0711 05:55:47.752122 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename lease-test @ 07/11/24 05:55:47.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:55:47.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:55:47.768
  I0711 05:55:47.826527 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-8908" for this suite. @ 07/11/24 05:55:47.83
• [0.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1759
  STEP: Creating a kubernetes client @ 07/11/24 05:55:47.841
  I0711 05:55:47.841331 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 05:55:47.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:55:47.854
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:55:47.856
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 07/11/24 05:55:47.858
  I0711 05:55:47.859066 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-1363 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I0711 05:55:47.905264 20 builder.go:146] stderr: ""
  I0711 05:55:47.905304 20 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 07/11/24 05:55:47.905
  I0711 05:55:47.910323 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-1363 delete pods e2e-test-httpd-pod'
  I0711 05:55:49.359193 20 builder.go:146] stderr: ""
  I0711 05:55:49.359229 20 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0711 05:55:49.359472 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1363" for this suite. @ 07/11/24 05:55:49.362
• [1.529 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 07/11/24 05:55:49.37
  I0711 05:55:49.370289 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename gc @ 07/11/24 05:55:49.37
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:55:49.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:55:49.388
  STEP: create the rc @ 07/11/24 05:55:49.39
  W0711 05:55:49.395318      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 07/11/24 05:55:54.399
  STEP: wait for all pods to be garbage collected @ 07/11/24 05:55:54.409
  STEP: Gathering metrics @ 07/11/24 05:55:59.421
  W0711 05:55:59.426419      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0711 05:55:59.426461 20 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0711 05:55:59.426585 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5042" for this suite. @ 07/11/24 05:55:59.43
• [10.068 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 07/11/24 05:55:59.438
  I0711 05:55:59.438583 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 05:55:59.439
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:55:59.454
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:55:59.456
  STEP: Creating configMap with name projected-configmap-test-volume-map-51dcc38d-f897-4d67-bedd-f788e0dcff11 @ 07/11/24 05:55:59.458
  STEP: Creating a pod to test consume configMaps @ 07/11/24 05:55:59.464
  STEP: Saw pod success @ 07/11/24 05:56:03.485
  I0711 05:56:03.489428 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-configmaps-57759933-ac62-4bb1-b99a-9838273319c4 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 05:56:03.508
  I0711 05:56:03.526042 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1861" for this suite. @ 07/11/24 05:56:03.529
• [4.098 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 07/11/24 05:56:03.536
  I0711 05:56:03.536344 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename dns @ 07/11/24 05:56:03.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:56:03.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:56:03.553
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 07/11/24 05:56:03.555
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 07/11/24 05:56:03.555
  STEP: creating a pod to probe DNS @ 07/11/24 05:56:03.555
  STEP: submitting the pod to kubernetes @ 07/11/24 05:56:03.555
  STEP: retrieving the pod @ 07/11/24 05:56:11.592
  STEP: looking for the results for each expected name from probers @ 07/11/24 05:56:11.596
  I0711 05:56:11.612056 20 dns_common.go:527] DNS probes using dns-5855/dns-test-40ef2ea4-6679-4030-a8e7-6bd0716edb9c succeeded

  STEP: deleting the pod @ 07/11/24 05:56:11.612
  I0711 05:56:11.625610 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5855" for this suite. @ 07/11/24 05:56:11.629
• [8.100 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 07/11/24 05:56:11.636
  I0711 05:56:11.636537 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename dns @ 07/11/24 05:56:11.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:56:11.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:56:11.654
  STEP: Creating a test headless service @ 07/11/24 05:56:11.656
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8689 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8689;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8689 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8689;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8689.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8689.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8689.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8689.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8689.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8689.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8689.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8689.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8689.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8689.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8689.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8689.svc;check="$$(dig +notcp +noall +answer +search 94.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.94_udp@PTR;check="$$(dig +tcp +noall +answer +search 94.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.94_tcp@PTR;sleep 1; done
   @ 07/11/24 05:56:11.68
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8689 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8689;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8689 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8689;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8689.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8689.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8689.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8689.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8689.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8689.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8689.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8689.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8689.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8689.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8689.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8689.svc;check="$$(dig +notcp +noall +answer +search 94.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.94_udp@PTR;check="$$(dig +tcp +noall +answer +search 94.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.94_tcp@PTR;sleep 1; done
   @ 07/11/24 05:56:11.68
  STEP: creating a pod to probe DNS @ 07/11/24 05:56:11.68
  STEP: submitting the pod to kubernetes @ 07/11/24 05:56:11.68
  STEP: retrieving the pod @ 07/11/24 05:56:13.707
  STEP: looking for the results for each expected name from probers @ 07/11/24 05:56:13.71
  I0711 05:56:13.715518 20 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.719797 20 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.723179 20 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8689 from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.726714 20 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8689 from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.730288 20 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8689.svc from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.733579 20 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8689.svc from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.737363 20 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8689.svc from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.741294 20 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8689.svc from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.762784 20 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.766793 20 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.770245 20 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8689 from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.774172 20 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8689 from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.778067 20 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8689.svc from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.781628 20 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8689.svc from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.785673 20 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8689.svc from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.789580 20 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8689.svc from pod dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f: the server could not find the requested resource (get pods dns-test-f0261c7b-65ee-4788-b964-90a881e0312f)
  I0711 05:56:13.802429 20 dns_common.go:489] Lookups using dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8689 wheezy_tcp@dns-test-service.dns-8689 wheezy_udp@dns-test-service.dns-8689.svc wheezy_tcp@dns-test-service.dns-8689.svc wheezy_udp@_http._tcp.dns-test-service.dns-8689.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8689.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8689 jessie_tcp@dns-test-service.dns-8689 jessie_udp@dns-test-service.dns-8689.svc jessie_tcp@dns-test-service.dns-8689.svc jessie_udp@_http._tcp.dns-test-service.dns-8689.svc jessie_tcp@_http._tcp.dns-test-service.dns-8689.svc]

  I0711 05:56:13.809507 20 dns_common.go:495] Pod client logs for webserver: 
  I0711 05:56:13.816136 20 dns_common.go:495] Pod client logs for querier: 
  I0711 05:56:13.822843 20 dns_common.go:495] Pod client logs for jessie-querier: 
  I0711 05:56:18.800357 20 dns_common.go:527] DNS probes using dns-8689/dns-test-f0261c7b-65ee-4788-b964-90a881e0312f succeeded

  STEP: deleting the pod @ 07/11/24 05:56:18.8
  STEP: deleting the test service @ 07/11/24 05:56:18.828
  STEP: deleting the test headless service @ 07/11/24 05:56:18.854
  I0711 05:56:18.866566 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8689" for this suite. @ 07/11/24 05:56:18.871
• [7.241 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 07/11/24 05:56:18.877
  I0711 05:56:18.877959 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 05:56:18.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:56:18.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:56:18.895
  STEP: Setting up server cert @ 07/11/24 05:56:18.923
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 05:56:19.033
  STEP: Deploying the webhook pod @ 07/11/24 05:56:19.042
  STEP: Wait for the deployment to be ready @ 07/11/24 05:56:19.055
  I0711 05:56:19.063070 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  I0711 05:56:21.076928 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 5, 56, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 5, 56, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 5, 56, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 5, 56, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I0711 05:56:23.083119 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 5, 56, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 5, 56, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 5, 56, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 5, 56, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 07/11/24 05:56:25.082
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 05:56:25.092
  I0711 05:56:26.092970 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 07/11/24 05:56:26.172
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 07/11/24 05:56:26.196
  STEP: Deleting the collection of validation webhooks @ 07/11/24 05:56:26.218
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 07/11/24 05:56:26.277
  I0711 05:56:26.333395 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9907" for this suite. @ 07/11/24 05:56:26.336
  STEP: Destroying namespace "webhook-markers-7256" for this suite. @ 07/11/24 05:56:26.345
• [7.474 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 07/11/24 05:56:26.352
  I0711 05:56:26.352546 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replication-controller @ 07/11/24 05:56:26.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:56:26.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:56:26.367
  STEP: creating a ReplicationController @ 07/11/24 05:56:26.374
  STEP: waiting for RC to be added @ 07/11/24 05:56:26.379
  STEP: waiting for available Replicas @ 07/11/24 05:56:26.379
  STEP: patching ReplicationController @ 07/11/24 05:56:27.416
  STEP: waiting for RC to be modified @ 07/11/24 05:56:27.424
  STEP: patching ReplicationController status @ 07/11/24 05:56:27.424
  STEP: waiting for RC to be modified @ 07/11/24 05:56:27.429
  STEP: waiting for available Replicas @ 07/11/24 05:56:27.43
  STEP: fetching ReplicationController status @ 07/11/24 05:56:27.434
  STEP: patching ReplicationController scale @ 07/11/24 05:56:27.437
  STEP: waiting for RC to be modified @ 07/11/24 05:56:27.443
  STEP: waiting for ReplicationController's scale to be the max amount @ 07/11/24 05:56:27.443
  STEP: fetching ReplicationController; ensuring that it's patched @ 07/11/24 05:56:28.767
  STEP: updating ReplicationController status @ 07/11/24 05:56:28.77
  STEP: waiting for RC to be modified @ 07/11/24 05:56:28.777
  STEP: listing all ReplicationControllers @ 07/11/24 05:56:28.777
  STEP: checking that ReplicationController has expected values @ 07/11/24 05:56:28.782
  STEP: deleting ReplicationControllers by collection @ 07/11/24 05:56:28.782
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 07/11/24 05:56:28.792
  I0711 05:56:28.838029 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0711 05:56:28.838248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-7631" for this suite. @ 07/11/24 05:56:28.841
• [2.496 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 07/11/24 05:56:28.849
  I0711 05:56:28.849182 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 05:56:28.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:56:28.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:56:28.866
  STEP: Creating pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111 @ 07/11/24 05:56:28.868
  E0711 05:56:29.838544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:30.838749      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 07/11/24 05:56:30.888
  I0711 05:56:30.892369 20 container_probe.go:1749] Initial restart count of pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a is 0
  I0711 05:56:30.895865 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:31.839039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:32.839231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:32.901631 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:33.839636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:34.839976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:34.906807 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:35.841035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:36.841172      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:36.913011 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:37.841938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:38.842051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:38.917226 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:39.842739      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:40.842828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:40.923265 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:41.843445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:42.843518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:42.928106 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:43.843953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:44.845027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:44.932951 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:45.845085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:46.845186      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:46.938167 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:47.846064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:48.846257      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:48.942839 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:49.846827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:50.847194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:50.947629 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:51.847719      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:52.847980      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:52.952578 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:53.849046      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:54.849171      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:54.958520 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:55.849577      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:56.850024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:56.963561 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:57.850530      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:56:58.850809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:56:58.969291 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:56:59.851145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:00.851384      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:00.973880 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:01.851988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:02.852315      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:02.979270 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:03.852976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:04.853197      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:04.984427 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:05.853325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:06.853816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:06.990273 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:07.853919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:08.854281      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:08.995099 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:09.855052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:10.855271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:11.000845 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:11.855418      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:12.855558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:13.006909 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:13.855901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:14.855972      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:15.011694 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:15.856305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:16.856149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:17.017563 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:17.856204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:18.857040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:19.023163 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  E0711 05:57:19.857510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:20.858094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:21.027786 20 container_probe.go:1759] Get pod busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a in namespace container-probe-7111
  I0711 05:57:21.027841 20 container_probe.go:1763] Restart count of pod container-probe-7111/busybox-aaeb4d9f-9582-4664-b066-54ac0f5e6d8a is now 1 (50.135445874s elapsed)
  STEP: deleting the pod @ 07/11/24 05:57:21.028
  I0711 05:57:21.040547 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7111" for this suite. @ 07/11/24 05:57:21.044
• [52.205 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 07/11/24 05:57:21.054
  I0711 05:57:21.054227 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replication-controller @ 07/11/24 05:57:21.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:57:21.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:57:21.071
  I0711 05:57:21.074058 20 rc.go:544] Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0711 05:57:21.858214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 07/11/24 05:57:22.099
  STEP: Checking rc "condition-test" has the desired failure condition set @ 07/11/24 05:57:22.107
  E0711 05:57:22.858292      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 07/11/24 05:57:23.117
  I0711 05:57:23.127329 20 rc.go:730] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 07/11/24 05:57:23.127
  E0711 05:57:23.858350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:57:24.137524 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7429" for this suite. @ 07/11/24 05:57:24.142
• [3.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 07/11/24 05:57:24.151
  I0711 05:57:24.151256 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-preemption @ 07/11/24 05:57:24.151
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:57:24.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:57:24.171
  I0711 05:57:24.186288 20 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0711 05:57:24.858445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:25.858824      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:26.858944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:27.859063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:28.859201      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:29.859789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:30.859972      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:31.860049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:32.860177      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:33.860244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:34.860359      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:35.860518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:36.860622      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:37.860695      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:38.860801      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:39.860892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:40.861296      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:41.861391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:42.861769      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:43.861748      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:44.862431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:45.862672      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:46.863177      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:47.863258      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:48.863371      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:49.863429      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:50.864015      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:51.865011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:52.865125      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:53.865193      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:54.865313      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:55.865803      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:56.865885      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:57.866146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:58.866243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:57:59.866298      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:00.866427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:01.867239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:02.868331      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:03.868409      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:04.868545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:05.868625      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:06.868722      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:07.868967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:08.869182      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:09.869464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:10.870269      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:11.870653      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:12.871467      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:13.871708      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:14.871940      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:15.872746      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:16.873412      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:17.873662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:18.873939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:19.874137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:20.875056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:21.875271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:22.875755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:23.876041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:24.191628 20 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 07/11/24 05:58:24.195
  I0711 05:58:24.215126 20 preemption.go:269] Created pod: pod0-0-sched-preemption-low-priority
  I0711 05:58:24.223627 20 preemption.go:269] Created pod: pod0-1-sched-preemption-medium-priority
  I0711 05:58:24.238381 20 preemption.go:269] Created pod: pod1-0-sched-preemption-medium-priority
  I0711 05:58:24.248062 20 preemption.go:269] Created pod: pod1-1-sched-preemption-medium-priority
  I0711 05:58:24.267385 20 preemption.go:269] Created pod: pod2-0-sched-preemption-medium-priority
  I0711 05:58:24.273764 20 preemption.go:269] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 07/11/24 05:58:24.273
  E0711 05:58:24.876178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:25.876657      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 07/11/24 05:58:26.304
  E0711 05:58:26.876726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:27.876835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:28.400626 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2159" for this suite. @ 07/11/24 05:58:28.404
• [64.260 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1627
  STEP: Creating a kubernetes client @ 07/11/24 05:58:28.411
  I0711 05:58:28.411518 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 05:58:28.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:58:28.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:58:28.429
  STEP: creating the pod @ 07/11/24 05:58:28.431
  I0711 05:58:28.432067 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5231 create -f -'
  I0711 05:58:28.510977 20 builder.go:146] stderr: ""
  I0711 05:58:28.511014 20 builder.go:147] stdout: "pod/pause created\n"
  E0711 05:58:28.877070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:29.877255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 07/11/24 05:58:30.519
  I0711 05:58:30.519694 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5231 label pods pause testing-label=testing-label-value'
  I0711 05:58:30.567390 20 builder.go:146] stderr: ""
  I0711 05:58:30.567425 20 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 07/11/24 05:58:30.567
  I0711 05:58:30.567569 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5231 get pod pause -L testing-label'
  I0711 05:58:30.608078 20 builder.go:146] stderr: ""
  I0711 05:58:30.608114 20 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 07/11/24 05:58:30.608
  I0711 05:58:30.608307 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5231 label pods pause testing-label-'
  I0711 05:58:30.657089 20 builder.go:146] stderr: ""
  I0711 05:58:30.657125 20 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 07/11/24 05:58:30.657
  I0711 05:58:30.657198 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5231 get pod pause -L testing-label'
  I0711 05:58:30.696781 20 builder.go:146] stderr: ""
  I0711 05:58:30.696825 20 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 07/11/24 05:58:30.696
  I0711 05:58:30.696947 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5231 delete --grace-period=0 --force -f -'
  I0711 05:58:30.749117 20 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0711 05:58:30.749154 20 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I0711 05:58:30.749200 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5231 get rc,svc -l name=pause --no-headers'
  I0711 05:58:30.794385 20 builder.go:146] stderr: "No resources found in kubectl-5231 namespace.\n"
  I0711 05:58:30.794421 20 builder.go:147] stdout: ""
  I0711 05:58:30.794468 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5231 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0711 05:58:30.834758 20 builder.go:146] stderr: ""
  I0711 05:58:30.834798 20 builder.go:147] stdout: ""
  I0711 05:58:30.834923 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5231" for this suite. @ 07/11/24 05:58:30.839
• [2.436 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 07/11/24 05:58:30.848
  I0711 05:58:30.848159 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replication-controller @ 07/11/24 05:58:30.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:58:30.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:58:30.863
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 07/11/24 05:58:30.866
  E0711 05:58:30.877683      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:31.878715      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:32.878922      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 07/11/24 05:58:32.888
  STEP: Then the orphan pod is adopted @ 07/11/24 05:58:32.893
  E0711 05:58:33.879005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:33.901838 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5909" for this suite. @ 07/11/24 05:58:33.906
• [3.067 seconds]
------------------------------
S
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3136
  STEP: Creating a kubernetes client @ 07/11/24 05:58:33.914
  I0711 05:58:33.914947 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 05:58:33.915
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:58:33.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:58:33.932
  STEP: fetching services @ 07/11/24 05:58:33.934
  I0711 05:58:33.939215 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-630" for this suite. @ 07/11/24 05:58:33.942
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 07/11/24 05:58:33.963
  I0711 05:58:33.963722 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename discovery @ 07/11/24 05:58:33.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:58:33.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:58:33.985
  STEP: Setting up server cert @ 07/11/24 05:58:33.989
  STEP: Requesting APIResourceList from "/api/v1" @ 07/11/24 05:58:34.152
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 07/11/24 05:58:34.154
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 07/11/24 05:58:34.155
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 07/11/24 05:58:34.155
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 07/11/24 05:58:34.156
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 07/11/24 05:58:34.157
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 07/11/24 05:58:34.158
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 07/11/24 05:58:34.159
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 07/11/24 05:58:34.16
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 07/11/24 05:58:34.161
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 07/11/24 05:58:34.162
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 07/11/24 05:58:34.162
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 07/11/24 05:58:34.164
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 07/11/24 05:58:34.165
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 07/11/24 05:58:34.165
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 07/11/24 05:58:34.166
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 07/11/24 05:58:34.167
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 07/11/24 05:58:34.168
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 07/11/24 05:58:34.169
  I0711 05:58:34.170271 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-8438" for this suite. @ 07/11/24 05:58:34.175
• [0.218 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 07/11/24 05:58:34.181
  I0711 05:58:34.181803 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 05:58:34.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:58:34.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:58:34.199
  STEP: Setting up server cert @ 07/11/24 05:58:34.22
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 05:58:34.422
  STEP: Deploying the webhook pod @ 07/11/24 05:58:34.427
  STEP: Wait for the deployment to be ready @ 07/11/24 05:58:34.438
  I0711 05:58:34.447100 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 05:58:34.879561      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:35.879653      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 05:58:36.459
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 05:58:36.472
  E0711 05:58:36.879842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:37.472530 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 07/11/24 05:58:37.481
  STEP: create a pod that should be updated by the webhook @ 07/11/24 05:58:37.494
  I0711 05:58:37.572393 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8366" for this suite. @ 07/11/24 05:58:37.576
  STEP: Destroying namespace "webhook-markers-2637" for this suite. @ 07/11/24 05:58:37.583
• [3.409 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:277
  STEP: Creating a kubernetes client @ 07/11/24 05:58:37.591
  I0711 05:58:37.591130 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-publish-openapi @ 07/11/24 05:58:37.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:58:37.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:58:37.607
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 07/11/24 05:58:37.61
  I0711 05:58:37.610590 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 05:58:37.880009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:38.879718 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 05:58:38.880465      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:39.880568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:40.880689      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:41.881064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:42.881177      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:43.856353 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-928" for this suite. @ 07/11/24 05:58:43.861
• [6.278 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 07/11/24 05:58:43.869
  I0711 05:58:43.869919 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename events @ 07/11/24 05:58:43.87
  E0711 05:58:43.881938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:58:43.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:58:43.887
  STEP: Create set of events @ 07/11/24 05:58:43.889
  I0711 05:58:43.894684 20 core_events.go:198] created test-event-1
  I0711 05:58:43.900086 20 core_events.go:198] created test-event-2
  I0711 05:58:43.904938 20 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 07/11/24 05:58:43.904
  STEP: delete collection of events @ 07/11/24 05:58:43.907
  I0711 05:58:43.907936 20 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 07/11/24 05:58:43.932
  I0711 05:58:43.932556 20 core_events.go:230] requesting list of events to confirm quantity
  I0711 05:58:43.936008 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8756" for this suite. @ 07/11/24 05:58:43.939
• [0.077 seconds]
------------------------------
S
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 07/11/24 05:58:43.946
  I0711 05:58:43.946777 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 05:58:43.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:58:43.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:58:43.964
  STEP: Creating pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251 @ 07/11/24 05:58:43.966
  E0711 05:58:44.882085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:45.882624      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 07/11/24 05:58:45.985
  I0711 05:58:45.989614 20 container_probe.go:1749] Initial restart count of pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 is 0
  I0711 05:58:45.993040 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:58:46.882686      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:47.882988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:47.996835 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:58:48.883089      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:49.883283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:50.002130 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:58:50.883961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:51.884063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:52.006614 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:58:52.884170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:53.884234      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:54.012195 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:58:54.885125      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:55.885213      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:56.017809 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:58:56.885309      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:57.885419      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:58:58.024084 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:58:58.885956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:58:59.886191      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:59:00.028684 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:59:00.886597      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:01.887134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:59:02.034279 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:59:02.887208      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:03.887445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:59:04.039466 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  E0711 05:59:04.888076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:05.888898      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 05:59:06.044940 20 container_probe.go:1759] Get pod liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 in namespace container-probe-1251
  I0711 05:59:06.044976 20 container_probe.go:1763] Restart count of pod container-probe-1251/liveness-c8cb5caa-4886-4daf-9891-831d3c52ef96 is now 1 (20.05533557s elapsed)
  STEP: deleting the pod @ 07/11/24 05:59:06.045
  I0711 05:59:06.061326 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1251" for this suite. @ 07/11/24 05:59:06.065
• [22.126 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 07/11/24 05:59:06.073
  I0711 05:59:06.073404 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 05:59:06.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:59:06.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:59:06.091
  E0711 05:59:06.889032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:07.889307      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:08.889717      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:09.890057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:10.890893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:11.891557      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 05:59:12.16
  I0711 05:59:12.164272 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod client-envvars-3b322d74-84a0-4b65-b0c2-5efc2faef027 container env3cont: <nil>
  STEP: delete the pod @ 07/11/24 05:59:12.179
  I0711 05:59:12.194498 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-205" for this suite. @ 07/11/24 05:59:12.198
• [6.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 07/11/24 05:59:12.205
  I0711 05:59:12.205570 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 05:59:12.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:59:12.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:59:12.221
  STEP: Creating configMap with name projected-configmap-test-volume-c00c418d-53e3-4a69-af70-4108f224dd01 @ 07/11/24 05:59:12.223
  STEP: Creating a pod to test consume configMaps @ 07/11/24 05:59:12.227
  E0711 05:59:12.892568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:13.892718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:14.893281      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:15.893588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 05:59:16.251
  I0711 05:59:16.255637 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-configmaps-068d2646-1a79-46ab-a871-c3c4a38d1e2d container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 05:59:16.266
  I0711 05:59:16.281431 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9824" for this suite. @ 07/11/24 05:59:16.285
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 07/11/24 05:59:16.293
  I0711 05:59:16.293438 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-preemption @ 07/11/24 05:59:16.293
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 05:59:16.309
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 05:59:16.312
  I0711 05:59:16.328626 20 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0711 05:59:16.893792      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:17.893882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:18.893984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:19.894165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:20.895170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:21.895285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:22.895469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:23.895726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:24.895934      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:25.896073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:26.897161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:27.897357      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:28.897600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:29.897731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:30.897824      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:31.898045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:32.898156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:33.898406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:34.898615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:35.898909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:36.898999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:37.899184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:38.899416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:39.899660      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:40.899826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:41.900030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:42.900760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:43.901101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:44.901201      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:45.901238      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:46.901687      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:47.902013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:48.902778      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:49.902865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:50.903306      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:51.903674      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:52.903945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:53.905009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:54.905300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:55.905533      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:56.905709      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:57.906049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:58.906274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 05:59:59.906482      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:00.906783      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:01.907223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:02.907416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:03.907554      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:04.907689      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:05.908812      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:06.908869      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:07.909076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:08.910003      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:09.910214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:10.910537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:11.911127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:12.911274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:13.911494      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:14.911943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:15.912397      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:16.334075 20 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 07/11/24 06:00:16.338
  I0711 06:00:16.338520 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-preemption-path @ 07/11/24 06:00:16.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:00:16.354
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:00:16.357
  STEP: Finding an available node @ 07/11/24 06:00:16.358
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 07/11/24 06:00:16.358
  E0711 06:00:16.912963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:17.913082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 07/11/24 06:00:18.389
  I0711 06:00:18.408942 20 preemption.go:583] found a healthy node: ip-172-31-80-240
  E0711 06:00:18.913175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:19.913636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:20.913858      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:21.913920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:22.914254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:23.914800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:24.471947 20 preemption.go:706] pods created so far: [1 1 1]
  I0711 06:00:24.471977 20 preemption.go:707] length of pods created so far: 3
  E0711 06:00:24.915552      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:25.916550      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:26.485384 20 preemption.go:724] pods created so far: [2 2 1]
  E0711 06:00:26.917485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:27.917710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:28.918127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:29.918313      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:30.918519      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:31.918659      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:32.918815      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:33.565249 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2917" for this suite. @ 07/11/24 06:00:33.57
  I0711 06:00:33.576894 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1413" for this suite. @ 07/11/24 06:00:33.58
• [77.295 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:766
  STEP: Creating a kubernetes client @ 07/11/24 06:00:33.588
  I0711 06:00:33.588801 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:00:33.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:00:33.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:00:33.607
  STEP: Setting up server cert @ 07/11/24 06:00:33.629
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:00:33.827
  STEP: Deploying the webhook pod @ 07/11/24 06:00:33.837
  STEP: Wait for the deployment to be ready @ 07/11/24 06:00:33.85
  I0711 06:00:33.858620 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:00:33.919849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:34.919974      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:00:35.871
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:00:35.888
  E0711 06:00:35.920417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:36.889008 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 07/11/24 06:00:36.898
  STEP: verifying the mutating webhook match conditions @ 07/11/24 06:00:36.917
  E0711 06:00:36.921213      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the mutating webhook match conditions @ 07/11/24 06:00:36.921
  STEP: verifying the mutating webhook match conditions @ 07/11/24 06:00:36.929
  I0711 06:00:36.982131 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8065" for this suite. @ 07/11/24 06:00:36.986
  STEP: Destroying namespace "webhook-markers-1105" for this suite. @ 07/11/24 06:00:36.998
• [3.419 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 07/11/24 06:00:37.008
  I0711 06:00:37.008544 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sysctl @ 07/11/24 06:00:37.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:00:37.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:00:37.024
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 07/11/24 06:00:37.026
  STEP: Watching for error events or started pod @ 07/11/24 06:00:37.034
  E0711 06:00:37.921425      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:38.921524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 07/11/24 06:00:39.038
  E0711 06:00:39.921606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:40.921723      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 07/11/24 06:00:41.051
  STEP: Getting logs from the pod @ 07/11/24 06:00:41.051
  STEP: Checking that the sysctl is actually updated @ 07/11/24 06:00:41.062
  I0711 06:00:41.062704 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-8916" for this suite. @ 07/11/24 06:00:41.066
• [4.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 07/11/24 06:00:41.073
  I0711 06:00:41.073423 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:00:41.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:00:41.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:00:41.09
  STEP: Setting up server cert @ 07/11/24 06:00:41.112
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:00:41.366
  STEP: Deploying the webhook pod @ 07/11/24 06:00:41.372
  STEP: Wait for the deployment to be ready @ 07/11/24 06:00:41.385
  I0711 06:00:41.394370 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:00:41.921904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:42.922442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:00:43.407
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:00:43.422
  E0711 06:00:43.923104      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:44.423758 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 07/11/24 06:00:44.431
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 07/11/24 06:00:44.444
  STEP: Creating a dummy validating-webhook-configuration object @ 07/11/24 06:00:44.456
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 07/11/24 06:00:44.463
  STEP: Creating a dummy mutating-webhook-configuration object @ 07/11/24 06:00:44.469
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 07/11/24 06:00:44.477
  I0711 06:00:44.541341 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5467" for this suite. @ 07/11/24 06:00:44.544
  STEP: Destroying namespace "webhook-markers-1648" for this suite. @ 07/11/24 06:00:44.551
• [3.486 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3572
  STEP: Creating a kubernetes client @ 07/11/24 06:00:44.559
  I0711 06:00:44.559282 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 06:00:44.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:00:44.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:00:44.576
  STEP: creating a collection of services @ 07/11/24 06:00:44.578
  I0711 06:00:44.578301 20 service.go:3608] Creating e2e-svc-a-hskk4
  I0711 06:00:44.588872 20 service.go:3608] Creating e2e-svc-b-lfw8l
  I0711 06:00:44.598967 20 service.go:3608] Creating e2e-svc-c-cx5sh
  STEP: deleting service collection @ 07/11/24 06:00:44.613
  I0711 06:00:44.651280 20 service.go:3643] Collection of services has been deleted
  I0711 06:00:44.651391 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2074" for this suite. @ 07/11/24 06:00:44.654
• [0.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 07/11/24 06:00:44.662
  I0711 06:00:44.662196 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 06:00:44.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:00:44.676
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:00:44.679
  STEP: Creating pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657 @ 07/11/24 06:00:44.682
  E0711 06:00:44.924164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:45.924636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 07/11/24 06:00:46.702
  I0711 06:00:46.706350 20 container_probe.go:1749] Initial restart count of pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 is 0
  I0711 06:00:46.710816 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:00:46.925110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:47.925346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:48.716078 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:00:48.925410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:49.925821      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:50.721468 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:00:50.925885      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:51.926137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:52.726824 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:00:52.926174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:53.926437      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:54.731691 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:00:54.927040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:55.927305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:56.737695 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:00:56.928008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:57.928073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:00:58.742562 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:00:58.929092      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:00:59.929396      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:00.747107 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:00.930434      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:01.930757      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:02.751561 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:02.931121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:03.931301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:04.756667 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:04.932069      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:05.932624      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:06.761589 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:06.932817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:07.932921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:08.766020 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:08.933250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:09.933461      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:10.770616 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:10.933901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:11.934276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:12.775688 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:12.935040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:13.935193      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:14.780957 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:14.935309      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:15.935606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:16.787236 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:16.936584      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:17.936695      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:18.792882 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:18.937118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:19.937212      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:20.797314 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:20.937575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:21.937799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:22.802095 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:22.938358      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:23.938507      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:24.807423 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:24.938779      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:25.939011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:26.813295 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:26.939706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:27.939976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:28.818850 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:28.940048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:29.940150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:30.823589 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:30.940893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:31.941322      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:32.829116 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:32.942350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:33.942453      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:34.834466 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:34.942680      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:35.942953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:36.838942 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:36.943082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:37.943298      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:38.844058 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:38.944265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:39.944354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:40.849258 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:40.944455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:41.945143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:42.854256 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:42.945469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:43.945575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:44.859862 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:44.946123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:45.946446      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:46.865195 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:46.947451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:47.947673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:48.871380 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:48.948724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:49.948906      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:50.876038 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:50.949238      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:51.949299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:52.880794 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:52.949967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:53.950220      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:54.884862 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:54.951037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:55.951156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:56.890380 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:56.951697      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:57.951789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:01:58.895770 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:01:58.951939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:01:59.952089      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:02:00.900609 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  E0711 06:02:00.952741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:01.952955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:02:02.906195 20 container_probe.go:1759] Get pod test-grpc-3463130a-196d-4374-8721-ca2b4d153337 in namespace container-probe-2657
  I0711 06:02:02.906233 20 container_probe.go:1763] Restart count of pod container-probe-2657/test-grpc-3463130a-196d-4374-8721-ca2b4d153337 is now 1 (1m16.199849479s elapsed)
  STEP: deleting the pod @ 07/11/24 06:02:02.906
  I0711 06:02:02.921441 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2657" for this suite. @ 07/11/24 06:02:02.925
• [78.269 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 07/11/24 06:02:02.932
  I0711 06:02:02.932030 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-preemption @ 07/11/24 06:02:02.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:02:02.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:02:02.948
  E0711 06:02:02.953805      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:02:02.963993 20 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0711 06:02:03.954249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:04.954312      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:05.954602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:06.954751      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:07.954945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:08.955128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:09.955250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:10.955409      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:11.955963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:12.956057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:13.956177      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:14.956244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:15.956852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:16.957790      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:17.957884      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:18.958085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:19.958265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:20.958535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:21.958744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:22.959064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:23.959353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:24.959587      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:25.960565      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:26.960635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:27.960913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:28.961101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:29.961275      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:30.961372      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:31.961989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:32.962099      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:33.962196      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:34.962386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:35.962615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:36.963490      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:37.963984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:38.964059      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:39.964175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:40.964219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:41.965258      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:42.965247      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:43.965435      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:44.965696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:45.966783      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:46.966847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:47.967015      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:48.967619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:49.967980      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:50.968162      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:51.969209      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:52.969511      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:53.969689      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:54.970540      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:55.970837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:56.974222      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:57.974321      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:58.975261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:02:59.975429      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:00.976267      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:01.976419      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:03:02.969533 20 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 07/11/24 06:03:02.973
  E0711 06:03:02.976944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:03:02.994454 20 preemption.go:178] Created pod: pod0-0-sched-preemption-low-priority
  I0711 06:03:03.001060 20 preemption.go:178] Created pod: pod0-1-sched-preemption-medium-priority
  I0711 06:03:03.018075 20 preemption.go:178] Created pod: pod1-0-sched-preemption-medium-priority
  I0711 06:03:03.030304 20 preemption.go:178] Created pod: pod1-1-sched-preemption-medium-priority
  I0711 06:03:03.046387 20 preemption.go:178] Created pod: pod2-0-sched-preemption-medium-priority
  I0711 06:03:03.053771 20 preemption.go:178] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 07/11/24 06:03:03.053
  E0711 06:03:03.977137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:04.977218      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 07/11/24 06:03:05.081
  E0711 06:03:05.978024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:06.978265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:07.978452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:08.978664      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:09.978860      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:10.978953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:03:11.176870 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-7735" for this suite. @ 07/11/24 06:03:11.18
• [68.257 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 07/11/24 06:03:11.188
  I0711 06:03:11.188994 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 06:03:11.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:03:11.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:03:11.207
  STEP: Creating configMap with name configmap-test-volume-map-2461c88c-560d-45ab-b830-ed7c0da128c5 @ 07/11/24 06:03:11.209
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:03:11.213
  E0711 06:03:11.979097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:12.979302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:13.979546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:14.979770      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:03:15.237
  I0711 06:03:15.240798 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-configmaps-15c8136f-58bd-485f-8264-1852a5cb72dd container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:03:15.257
  I0711 06:03:15.277329 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2870" for this suite. @ 07/11/24 06:03:15.281
• [4.099 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 07/11/24 06:03:15.288
  I0711 06:03:15.288324 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename deployment @ 07/11/24 06:03:15.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:03:15.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:03:15.314
  I0711 06:03:15.316939 20 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0711 06:03:15.328416 20 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0711 06:03:15.980742      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:16.981041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:17.981329      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:18.981470      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:19.981584      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:03:20.332483 20 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 07/11/24 06:03:20.332
  I0711 06:03:20.332640 20 deployment.go:763] Creating deployment "test-rolling-update-deployment"
  I0711 06:03:20.338881 20 deployment.go:769] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0711 06:03:20.346194 20 deployment.go:222] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0711 06:03:20.981903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:21.982093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:03:22.354782 20 deployment.go:773] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0711 06:03:22.358694 20 deployment.go:778] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0711 06:03:22.367874 20 deployment.go:633] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6132",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3aff6f3a-fdfe-4787-a56d-3196ad80c3a0",
      ResourceVersion: (string) (len=5) "14520",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274600,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274601,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274601,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-6f4b778cd6\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0711 06:03:22.373761 20 deployment.go:39] New ReplicaSet "test-rolling-update-deployment-6f4b778cd6" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-6f4b778cd6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6132",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b4846664-3713-456f-bc32-03c20a444d1e",
      ResourceVersion: (string) (len=5) "14510",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274600,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "3aff6f3a-fdfe-4787-a56d-3196ad80c3a0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 61 66 66 36 66  33 61 2d 66 64 66 65 2d  |\"3aff6f3a-fdfe-|
              00000120  34 37 38 37 2d 61 35 36  64 2d 33 31 39 36 61 64  |4787-a56d-3196ad|
              00000130  38 30 63 33 61 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |80c3a0\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274601,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 06:03:22.374452 20 deployment.go:44] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0711 06:03:22.374741 20 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6132",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "141e3f06-0b02-41c7-84b0-dbc7f1eb29dc",
      ResourceVersion: (string) (len=5) "14519",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274595,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "pod": (string) (len=5) "httpd",
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "3aff6f3a-fdfe-4787-a56d-3196ad80c3a0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274601,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 33 61 66 66 36 66 33  |"uid\":\"3aff6f3|
              000000b0  61 2d 66 64 66 65 2d 34  37 38 37 2d 61 35 36 64  |a-fdfe-4787-a56d|
              000000c0  2d 33 31 39 36 61 64 38  30 63 33 61 30 5c 22 7d  |-3196ad80c3a0\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274601,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 06:03:22.379957 20 deployment.go:67] Pod "test-rolling-update-deployment-6f4b778cd6-zbrht" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-6f4b778cd6-zbrht",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-6f4b778cd6-",
      Namespace: (string) (len=15) "deployment-6132",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5d9a18ad-c4c1-4079-948f-da3d5e733ec3",
      ResourceVersion: (string) (len=5) "14509",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274600,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-6f4b778cd6",
          UID: (types.UID) (len=36) "b4846664-3713-456f-bc32-03c20a444d1e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 34  38 34 36 36 36 34 2d 33  |d\":\"b4846664-3|
              00000090  37 31 33 2d 34 35 36 66  2d 62 63 33 32 2d 30 33  |713-456f-bc32-03|
              000000a0  63 32 30 61 34 34 34 64  31 65 5c 22 7d 22 3a 7b  |c20a444d1e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274601,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 37  2e 33 39 5c 22 7d 22 3a  |2.168.37.39\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8q88j",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8q88j",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274601,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274601,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274601,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274600,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) (len=13) "192.168.37.39",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.37.39"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274600,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856274600,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://1bc0e6c08d4e98bef795f35927d98a99fae1f492a00dcbcfda22ac26a1ff2060",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:03:22.381802 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6132" for this suite. @ 07/11/24 06:03:22.386
• [7.107 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 07/11/24 06:03:22.395
  I0711 06:03:22.395457 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename custom-resource-definition @ 07/11/24 06:03:22.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:03:22.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:03:22.411
  I0711 06:03:22.414867 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:03:22.983138      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:03:23.438946 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3426" for this suite. @ 07/11/24 06:03:23.443
• [1.057 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 07/11/24 06:03:23.452
  I0711 06:03:23.452880 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 06:03:23.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:03:23.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:03:23.468
  STEP: Creating configMap configmap-3243/configmap-test-24a264e8-580a-45ae-b233-b312b0e8882f @ 07/11/24 06:03:23.47
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:03:23.475
  E0711 06:03:23.984195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:24.985051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:25.985940      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:26.986137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:03:27.501
  I0711 06:03:27.504613 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-configmaps-da1a4cd6-9b82-429e-b19f-3ecae4c11ba9 container env-test: <nil>
  STEP: delete the pod @ 07/11/24 06:03:27.516
  I0711 06:03:27.534016 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3243" for this suite. @ 07/11/24 06:03:27.538
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 07/11/24 06:03:27.546
  I0711 06:03:27.546248 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename csiinlinevolumes @ 07/11/24 06:03:27.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:03:27.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:03:27.57
  STEP: creating @ 07/11/24 06:03:27.574
  STEP: getting @ 07/11/24 06:03:27.594
  STEP: listing in namespace @ 07/11/24 06:03:27.597
  STEP: patching @ 07/11/24 06:03:27.6
  STEP: deleting @ 07/11/24 06:03:27.608
  I0711 06:03:27.622090 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-6011" for this suite. @ 07/11/24 06:03:27.628
• [0.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 07/11/24 06:03:27.636
  I0711 06:03:27.636121 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename var-expansion @ 07/11/24 06:03:27.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:03:27.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:03:27.653
  STEP: Creating a pod to test substitution in container's command @ 07/11/24 06:03:27.654
  E0711 06:03:27.986404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:28.986678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:29.987171      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:30.988055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:03:31.679
  I0711 06:03:31.683368 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod var-expansion-40b90624-2202-4bef-97ca-e2c9b04aa586 container dapi-container: <nil>
  STEP: delete the pod @ 07/11/24 06:03:31.69
  I0711 06:03:31.706047 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6274" for this suite. @ 07/11/24 06:03:31.71
• [4.082 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 07/11/24 06:03:31.718
  I0711 06:03:31.718211 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:03:31.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:03:31.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:03:31.737
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-2167a96d-9e03-45d2-aa9e-d5d6ce0c85f9 @ 07/11/24 06:03:31.742
  STEP: Creating the pod @ 07/11/24 06:03:31.748
  E0711 06:03:31.988939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:32.989034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-2167a96d-9e03-45d2-aa9e-d5d6ce0c85f9 @ 07/11/24 06:03:33.777
  STEP: waiting to observe update in volume @ 07/11/24 06:03:33.782
  E0711 06:03:33.989527      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:34.989749      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:35.990696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:36.990848      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:37.991054      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:38.991226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:39.992028      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:40.992876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:41.993683      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:42.993771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:43.994288      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:44.994520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:45.994546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:46.994731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:47.995299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:48.995400      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:49.995488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:50.995585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:51.996448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:52.997160      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:53.998140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:54.998320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:55.999094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:56.999233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:57.999718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:03:58.999992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:00.000653      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:01.000931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:02.001107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:03.001361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:04.002365      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:05.002566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:06.002874      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:07.002940      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:08.003463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:09.003564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:10.003738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:11.003913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:12.004266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:13.005050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:14.005304      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:15.005532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:16.006224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:17.006345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:18.006655      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:19.006835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:20.007169      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:21.007278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:22.008219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:23.009173      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:24.009293      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:25.009498      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:26.009765      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:27.010079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:28.010249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:29.010431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:30.010531      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:31.010743      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:32.010951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:33.011072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:34.011268      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:35.011320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:36.011498      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:37.011970      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:38.012016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:39.012854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:40.012954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:41.014014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:42.014139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:43.014455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:44.014552      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:45.014781      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:46.014961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:47.015110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:48.015299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:49.015493      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:50.015715      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:51.016031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:52.016188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:53.016285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:54.016391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:55.016493      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:56.016800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:57.017162      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:58.017067      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:04:59.017119      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:00.017413      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:05:00.176998 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6234" for this suite. @ 07/11/24 06:05:00.181
• [88.470 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 07/11/24 06:05:00.188
  I0711 06:05:00.188853 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename init-container @ 07/11/24 06:05:00.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:05:00.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:05:00.206
  STEP: creating the pod @ 07/11/24 06:05:00.208
  I0711 06:05:00.208765 20 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E0711 06:05:01.018355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:02.018480      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:03.018620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:04.018835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:05:04.490153 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3066" for this suite. @ 07/11/24 06:05:04.494
• [4.316 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:841
  STEP: Creating a kubernetes client @ 07/11/24 06:05:04.505
  I0711 06:05:04.505083 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:05:04.505
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:05:04.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:05:04.523
  STEP: Setting up server cert @ 07/11/24 06:05:04.548
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:05:04.712
  STEP: Deploying the webhook pod @ 07/11/24 06:05:04.723
  STEP: Wait for the deployment to be ready @ 07/11/24 06:05:04.742
  I0711 06:05:04.748810 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:05:05.018941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:06.019146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:05:06.76
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:05:06.771
  E0711 06:05:07.019571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:05:07.771441 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 07/11/24 06:05:07.779
  I0711 06:05:07.827863 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5469" for this suite. @ 07/11/24 06:05:07.832
  STEP: Destroying namespace "webhook-markers-2042" for this suite. @ 07/11/24 06:05:07.84
• [3.342 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 07/11/24 06:05:07.847
  I0711 06:05:07.847574 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename watch @ 07/11/24 06:05:07.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:05:07.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:05:07.862
  STEP: creating a new configmap @ 07/11/24 06:05:07.864
  STEP: modifying the configmap once @ 07/11/24 06:05:07.927
  STEP: modifying the configmap a second time @ 07/11/24 06:05:07.935
  STEP: deleting the configmap @ 07/11/24 06:05:07.943
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 07/11/24 06:05:07.949
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 07/11/24 06:05:07.95
  I0711 06:05:07.951054 20 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1795  1449bfeb-0b50-43b0-bc36-aebbb833efee 14995 0 2024-07-11 06:05:07 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-07-11 06:05:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 06:05:07.951152 20 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1795  1449bfeb-0b50-43b0-bc36-aebbb833efee 14996 0 2024-07-11 06:05:07 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-07-11 06:05:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 06:05:07.951210 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1795" for this suite. @ 07/11/24 06:05:07.956
• [0.116 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 07/11/24 06:05:07.964
  I0711 06:05:07.964090 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:05:07.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:05:07.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:05:07.982
  STEP: Setting up server cert @ 07/11/24 06:05:08.007
  E0711 06:05:08.020472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:05:08.28
  STEP: Deploying the webhook pod @ 07/11/24 06:05:08.288
  STEP: Wait for the deployment to be ready @ 07/11/24 06:05:08.301
  I0711 06:05:08.311594 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:05:09.021187      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:10.021413      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:05:10.324
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:05:10.337
  E0711 06:05:11.021639      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:05:11.338543 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 07/11/24 06:05:11.347
  STEP: create a pod that should be denied by the webhook @ 07/11/24 06:05:11.359
  STEP: create a pod that causes the webhook to hang @ 07/11/24 06:05:11.366
  E0711 06:05:12.022215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:13.022381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:14.022613      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:15.022705      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:16.022779      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:17.022881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:18.023003      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:19.023205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:20.023368      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:21.023798      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 07/11/24 06:05:21.374
  STEP: create a configmap that should be admitted by the webhook @ 07/11/24 06:05:21.517
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 07/11/24 06:05:21.525
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 07/11/24 06:05:21.535
  STEP: create a namespace that bypass the webhook @ 07/11/24 06:05:21.54
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 07/11/24 06:05:21.553
  I0711 06:05:21.617008 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6215" for this suite. @ 07/11/24 06:05:21.622
  STEP: Destroying namespace "webhook-markers-5459" for this suite. @ 07/11/24 06:05:21.63
  STEP: Destroying namespace "exempted-namespace-1094" for this suite. @ 07/11/24 06:05:21.637
• [13.679 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 07/11/24 06:05:21.643
  I0711 06:05:21.643290 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename taint-single-pod @ 07/11/24 06:05:21.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:05:21.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:05:21.66
  I0711 06:05:21.662906 20 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0711 06:05:22.024038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:23.024113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:24.025069      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:25.025159      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:26.025267      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:27.025339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:28.026118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:29.026241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:30.026428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:31.026679      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:32.027553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:33.027835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:34.028080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:35.028194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:36.028279      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:37.028387      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:38.028470      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:39.028576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:40.028683      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:41.028785      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:42.028888      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:43.029768      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:44.029951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:45.030127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:46.030973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:47.031109      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:48.031778      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:49.031987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:50.032088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:51.032186      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:52.032911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:53.033203      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:54.033725      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:55.033892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:56.035018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:57.035576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:58.035944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:05:59.036076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:00.036172      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:01.037123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:02.037197      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:03.037301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:04.038023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:05.038217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:06.039150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:07.039502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:08.040103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:09.040341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:10.041007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:11.041123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:12.041879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:13.041987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:14.042236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:15.042924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:16.043841      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:17.043985      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:18.045007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:19.045211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:20.045484      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:21.045667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:06:21.663609 20 util.go:400] Waiting for terminating namespaces to be deleted...
  I0711 06:06:21.668625 20 taints.go:150] Starting informer...
  STEP: Starting pod... @ 07/11/24 06:06:21.668
  I0711 06:06:21.885896 20 taints.go:300] Pod is running on ip-172-31-80-240. Tainting Node
  STEP: Trying to apply a taint on the Node @ 07/11/24 06:06:21.885
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 07/11/24 06:06:21.895
  STEP: Waiting short time to make sure Pod is queued for deletion @ 07/11/24 06:06:21.899
  I0711 06:06:21.899793 20 taints.go:319] Pod wasn't evicted. Proceeding
  I0711 06:06:21.899888 20 taints.go:326] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 07/11/24 06:06:21.914
  STEP: Waiting some time to make sure that toleration time passed. @ 07/11/24 06:06:21.926
  E0711 06:06:22.046466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:23.046608      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:24.046787      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:25.046973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:26.047914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:27.048035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:28.049031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:29.049207      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:30.049310      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:31.049507      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:32.050272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:33.050463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:34.050741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:35.050966      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:36.051290      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:37.051753      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:38.051986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:39.052151      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:40.052305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:41.053012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:42.053178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:43.053603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:44.053738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:45.053929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:46.055043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:47.055185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:48.055309      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:49.055551      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:50.055727      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:51.056009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:52.056081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:53.057081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:54.057285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:55.057616      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:56.057897      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:57.058048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:58.058257      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:06:59.058468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:00.058656      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:01.058847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:02.059254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:03.059507      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:04.059737      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:05.059945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:06.059979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:07.061045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:08.061255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:09.061430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:10.061763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:11.062368      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:12.063220      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:13.063430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:14.063597      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:15.063691      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:16.063926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:17.064999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:18.065191      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:19.065381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:20.065564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:21.065751      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:22.066162      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:23.066307      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:24.066403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:25.066578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:26.066895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:27.067011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:28.067127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:29.067319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:30.067572      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:31.067769      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:32.068001      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:33.069042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:34.069146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:35.069347      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:36.069975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:07:36.927076 20 taints.go:335] Pod wasn't evicted. Test successful
  I0711 06:07:36.927436 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-6777" for this suite. @ 07/11/24 06:07:36.932
• [135.297 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 07/11/24 06:07:36.94
  I0711 06:07:36.940142 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename subjectreview @ 07/11/24 06:07:36.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:07:36.956
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:07:36.958
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-3118" @ 07/11/24 06:07:36.96
  I0711 06:07:36.965379 20 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-3118:e2e"
  I0711 06:07:36.965402 20 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-3118"}
  I0711 06:07:36.965419 20 subjectreviews.go:71] saUID: "17ec4c9b-9594-4032-93a0-0d908026aa94"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-3118:e2e" @ 07/11/24 06:07:36.965
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-3118:e2e" @ 07/11/24 06:07:36.965
  I0711 06:07:36.966906 20 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-3118:e2e" api 'list' configmaps in "subjectreview-3118" namespace @ 07/11/24 06:07:36.966
  I0711 06:07:36.967927 20 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-3118:e2e" @ 07/11/24 06:07:36.967
  I0711 06:07:36.969221 20 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0711 06:07:36.969233 20 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0711 06:07:36.969324 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-3118" for this suite. @ 07/11/24 06:07:36.972
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 07/11/24 06:07:36.979
  I0711 06:07:36.979692 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename statefulset @ 07/11/24 06:07:36.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:07:36.993
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:07:36.996
  STEP: Creating service test in namespace statefulset-9995 @ 07/11/24 06:07:36.998
  STEP: Creating stateful set ss in namespace statefulset-9995 @ 07/11/24 06:07:37.003
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9995 @ 07/11/24 06:07:37.013
  I0711 06:07:37.017754 20 wait.go:40] Found 0 stateful pods, waiting for 1
  E0711 06:07:37.071032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:38.071129      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:39.071232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:40.071430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:41.072327      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:42.072630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:43.072489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:44.072561      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:45.073010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:46.073889      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:07:47.019016 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 07/11/24 06:07:47.019
  I0711 06:07:47.023951 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-9995 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0711 06:07:47.074280      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:07:47.126898 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 06:07:47.126947 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 06:07:47.126957 20 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0711 06:07:47.131704 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0711 06:07:48.074741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:49.074953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:50.075164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:51.076165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:52.076248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:53.076351      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:54.076483      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:55.076585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:56.077198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:07:57.077304      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:07:57.132614 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0711 06:07:57.132655 20 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0711 06:07:57.151631 20 resource.go:168] POD   NODE              PHASE    GRACE  CONDITIONS
  I0711 06:07:57.151685 20 resource.go:175] ss-0  ip-172-31-80-240  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:38 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:37 +0000 UTC  }]
  I0711 06:07:57.151691 20 resource.go:178] 
  I0711 06:07:57.151697 20 statefulset.go:2147] StatefulSet ss has not reached scale 3, at 1
  E0711 06:07:58.077666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:07:58.156017 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 8.99529674s
  E0711 06:07:59.077858      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:07:59.161014 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 7.990081856s
  E0711 06:08:00.078117      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:00.166573 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 6.985819868s
  E0711 06:08:01.078287      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:01.171958 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 5.979664375s
  E0711 06:08:02.078377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:02.177604 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 4.974565711s
  E0711 06:08:03.078712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:03.182968 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 3.969073597s
  E0711 06:08:04.078868      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:04.187923 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 2.964099263s
  E0711 06:08:05.079767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:05.193258 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 1.959202047s
  E0711 06:08:06.080607      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:06.198406 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 953.352911ms
  E0711 06:08:07.080997      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9995 @ 07/11/24 06:08:07.199
  I0711 06:08:07.204927 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-9995 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0711 06:08:07.313751 20 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0711 06:08:07.313800 20 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0711 06:08:07.313810 20 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0711 06:08:07.313979 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-9995 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0711 06:08:07.412573 20 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0711 06:08:07.412627 20 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0711 06:08:07.412636 20 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0711 06:08:07.412684 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-9995 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0711 06:08:07.509785 20 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0711 06:08:07.509823 20 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0711 06:08:07.509831 20 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0711 06:08:07.514433 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0711 06:08:07.514457 20 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0711 06:08:07.514462 20 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 07/11/24 06:08:07.514
  I0711 06:08:07.517554 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-9995 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0711 06:08:07.606141 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 06:08:07.606185 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 06:08:07.606194 20 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0711 06:08:07.606246 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-9995 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0711 06:08:07.698517 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 06:08:07.698555 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 06:08:07.698564 20 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0711 06:08:07.698694 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-9995 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0711 06:08:07.788330 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 06:08:07.788381 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 06:08:07.788392 20 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0711 06:08:07.788401 20 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0711 06:08:07.792627 20 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0711 06:08:08.082085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:09.082184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:10.083113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:11.084167      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:12.084271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:13.085055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:14.085112      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:15.085319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:16.085910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:17.086225      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:17.797077 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0711 06:08:17.797109 20 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0711 06:08:17.797115 20 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0711 06:08:17.812422 20 resource.go:168] POD   NODE              PHASE    GRACE  CONDITIONS
  I0711 06:08:17.812524 20 resource.go:175] ss-0  ip-172-31-80-240  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:38 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:08:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:08:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:37 +0000 UTC  }]
  I0711 06:08:17.812550 20 resource.go:175] ss-1  ip-172-31-11-2    Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:58 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:08:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:08:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:57 +0000 UTC  }]
  I0711 06:08:17.812565 20 resource.go:175] ss-2  ip-172-31-17-237  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:57 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:08:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:08:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:57 +0000 UTC  }]
  I0711 06:08:17.812621 20 resource.go:178] 
  I0711 06:08:17.812627 20 statefulset.go:2147] StatefulSet ss has not reached scale 0, at 3
  E0711 06:08:18.086673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:18.817556 20 resource.go:168] POD   NODE              PHASE      GRACE  CONDITIONS
  I0711 06:08:18.817616 20 resource.go:175] ss-2  ip-172-31-17-237  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:08:18 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:57 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:08:08 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:08:08 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 06:07:57 +0000 UTC  }]
  I0711 06:08:18.817623 20 resource.go:178] 
  I0711 06:08:18.817629 20 statefulset.go:2147] StatefulSet ss has not reached scale 0, at 1
  E0711 06:08:19.086832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:19.821954 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 7.990781565s
  E0711 06:08:20.087515      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:20.827198 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 6.9864506s
  E0711 06:08:21.087957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:21.831972 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 5.981146693s
  E0711 06:08:22.088564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:22.837295 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 4.976424287s
  E0711 06:08:23.088673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:23.844004 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 3.970202048s
  E0711 06:08:24.089455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:24.849343 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 2.964404028s
  E0711 06:08:25.089650      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:25.854303 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 1.959060172s
  E0711 06:08:26.089971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:26.858521 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 954.10628ms
  E0711 06:08:27.091013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9995 @ 07/11/24 06:08:27.858
  I0711 06:08:27.863503 20 rest.go:150] Scaling statefulset ss to 0
  I0711 06:08:27.870345 20 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0711 06:08:27.873723 20 statefulset.go:135] Deleting all statefulset in ns statefulset-9995
  I0711 06:08:27.877503 20 rest.go:150] Scaling statefulset ss to 0
  I0711 06:08:27.883882 20 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0711 06:08:27.887259 20 rest.go:88] Deleting statefulset ss
  I0711 06:08:27.901324 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9995" for this suite. @ 07/11/24 06:08:27.905
• [50.933 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:397
  STEP: Creating a kubernetes client @ 07/11/24 06:08:27.913
  I0711 06:08:27.913612 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 06:08:27.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:08:27.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:08:27.936
  STEP: creating all guestbook components @ 07/11/24 06:08:27.938
  I0711 06:08:27.938137 20 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0711 06:08:27.938234 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 create -f -'
  I0711 06:08:28.026162 20 builder.go:146] stderr: ""
  I0711 06:08:28.026209 20 builder.go:147] stdout: "service/agnhost-replica created\n"
  I0711 06:08:28.026250 20 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0711 06:08:28.026308 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 create -f -'
  E0711 06:08:28.091697      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:28.120405 20 builder.go:146] stderr: ""
  I0711 06:08:28.120456 20 builder.go:147] stdout: "service/agnhost-primary created\n"
  I0711 06:08:28.120498 20 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0711 06:08:28.120558 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 create -f -'
  I0711 06:08:28.205360 20 builder.go:146] stderr: ""
  I0711 06:08:28.205402 20 builder.go:147] stdout: "service/frontend created\n"
  I0711 06:08:28.205469 20 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0711 06:08:28.205598 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 create -f -'
  I0711 06:08:28.269255 20 builder.go:146] stderr: ""
  I0711 06:08:28.269305 20 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I0711 06:08:28.269370 20 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0711 06:08:28.269474 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 create -f -'
  I0711 06:08:28.335092 20 builder.go:146] stderr: ""
  I0711 06:08:28.335138 20 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I0711 06:08:28.335265 20 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0711 06:08:28.335382 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 create -f -'
  I0711 06:08:28.392707 20 builder.go:146] stderr: ""
  I0711 06:08:28.392754 20 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 07/11/24 06:08:28.392
  I0711 06:08:28.392793 20 kubectl.go:2271] Waiting for all frontend pods to be Running.
  E0711 06:08:29.091992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:30.092779      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:31.093035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:32.093280      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:33.093474      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:33.443863 20 kubectl.go:2275] Waiting for frontend to serve content.
  I0711 06:08:33.454145 20 kubectl.go:2280] Trying to add a new entry to the guestbook.
  I0711 06:08:33.466151 20 kubectl.go:2285] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 07/11/24 06:08:33.474
  I0711 06:08:33.474512 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 delete --grace-period=0 --force -f -'
  I0711 06:08:33.538393 20 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0711 06:08:33.538441 20 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 07/11/24 06:08:33.538
  I0711 06:08:33.538562 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 delete --grace-period=0 --force -f -'
  I0711 06:08:33.604365 20 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0711 06:08:33.604401 20 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 07/11/24 06:08:33.604
  I0711 06:08:33.604531 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 delete --grace-period=0 --force -f -'
  I0711 06:08:33.660756 20 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0711 06:08:33.660800 20 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 07/11/24 06:08:33.66
  I0711 06:08:33.660970 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 delete --grace-period=0 --force -f -'
  I0711 06:08:33.706693 20 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0711 06:08:33.706736 20 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 07/11/24 06:08:33.706
  I0711 06:08:33.706857 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 delete --grace-period=0 --force -f -'
  I0711 06:08:33.757642 20 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0711 06:08:33.757685 20 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 07/11/24 06:08:33.757
  I0711 06:08:33.757844 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3127 delete --grace-period=0 --force -f -'
  I0711 06:08:33.804711 20 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0711 06:08:33.804746 20 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I0711 06:08:33.804954 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3127" for this suite. @ 07/11/24 06:08:33.809
• [5.903 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 07/11/24 06:08:33.817
  I0711 06:08:33.817237 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename csi-storageclass @ 07/11/24 06:08:33.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:08:33.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:08:33.838
  STEP: Creating a StorageClass @ 07/11/24 06:08:33.84
  STEP: Get StorageClass "e2e-rj97x" @ 07/11/24 06:08:33.845
  STEP: Patching the StorageClass "e2e-rj97x" @ 07/11/24 06:08:33.85
  STEP: Delete StorageClass "e2e-rj97x" @ 07/11/24 06:08:33.855
  STEP: Confirm deletion of StorageClass "e2e-rj97x" @ 07/11/24 06:08:33.862
  STEP: Create a replacement StorageClass @ 07/11/24 06:08:33.865
  STEP: Updating StorageClass "e2e-v2-vtbrt" @ 07/11/24 06:08:33.871
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-vtbrt=updated" @ 07/11/24 06:08:33.879
  STEP: Deleting StorageClass "e2e-v2-vtbrt" via DeleteCollection @ 07/11/24 06:08:33.882
  STEP: Confirm deletion of StorageClass "e2e-v2-vtbrt" @ 07/11/24 06:08:33.89
  I0711 06:08:33.893343 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-9859" for this suite. @ 07/11/24 06:08:33.896
• [0.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 07/11/24 06:08:33.903
  I0711 06:08:33.903914 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 06:08:33.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:08:33.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:08:33.921
  I0711 06:08:33.928779 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: creating the pod @ 07/11/24 06:08:33.929
  STEP: submitting the pod to kubernetes @ 07/11/24 06:08:33.929
  E0711 06:08:34.096038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:35.097067      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:36.018340 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2966" for this suite. @ 07/11/24 06:08:36.023
• [2.128 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
  STEP: Creating a kubernetes client @ 07/11/24 06:08:36.032
  I0711 06:08:36.032297 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 06:08:36.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:08:36.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:08:36.049
  STEP: create deployment with httpd image @ 07/11/24 06:08:36.051
  I0711 06:08:36.051931 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-932 create -f -'
  E0711 06:08:36.097460      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:36.115108 20 builder.go:146] stderr: ""
  I0711 06:08:36.115163 20 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 07/11/24 06:08:36.115
  I0711 06:08:36.115246 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-932 diff -f -'
  E0711 06:08:37.098474      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:38.098745      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:39.098954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:40.099164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:40.398732 20 builder.go:135] rc: 1
  I0711 06:08:40.398819 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-932 delete -f -'
  I0711 06:08:40.445780 20 builder.go:146] stderr: ""
  I0711 06:08:40.445816 20 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I0711 06:08:40.445903 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-932" for this suite. @ 07/11/24 06:08:40.449
• [4.424 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 07/11/24 06:08:40.456
  I0711 06:08:40.456974 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 06:08:40.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:08:40.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:08:40.476
  STEP: Creating configMap with name configmap-test-volume-1e7b8fea-0722-40ce-ad99-31a44528d519 @ 07/11/24 06:08:40.482
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:08:40.488
  E0711 06:08:41.100108      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:42.100215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:43.100319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:44.100570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:08:44.515
  I0711 06:08:44.519642 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-configmaps-2ba16f11-5639-4fb0-ac0b-d0dd688ca40a container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:08:44.533
  I0711 06:08:44.550938 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5690" for this suite. @ 07/11/24 06:08:44.555
• [4.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 07/11/24 06:08:44.566
  I0711 06:08:44.566728 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename init-container @ 07/11/24 06:08:44.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:08:44.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:08:44.585
  STEP: creating the pod @ 07/11/24 06:08:44.587
  I0711 06:08:44.587271 20 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E0711 06:08:45.101026      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:46.102088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:47.102188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:47.838612 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1395" for this suite. @ 07/11/24 06:08:47.842
• [3.284 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 07/11/24 06:08:47.85
  I0711 06:08:47.850677 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 06:08:47.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:08:47.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:08:47.867
  STEP: Counting existing ResourceQuota @ 07/11/24 06:08:47.869
  E0711 06:08:48.103139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:49.103768      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:50.103871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:51.103989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:52.104068      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 07/11/24 06:08:52.873
  STEP: Ensuring resource quota status is calculated @ 07/11/24 06:08:52.878
  E0711 06:08:53.104323      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:54.104421      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 07/11/24 06:08:54.884
  STEP: Creating a NodePort Service @ 07/11/24 06:08:54.905
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 07/11/24 06:08:54.932
  STEP: Ensuring resource quota status captures service creation @ 07/11/24 06:08:54.959
  E0711 06:08:55.104959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:56.105239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 07/11/24 06:08:56.964
  STEP: Ensuring resource quota status released usage @ 07/11/24 06:08:57.007
  E0711 06:08:57.105714      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:08:58.105812      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:08:59.013451 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3502" for this suite. @ 07/11/24 06:08:59.017
• [11.175 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 07/11/24 06:08:59.025
  I0711 06:08:59.025574 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename deployment @ 07/11/24 06:08:59.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:08:59.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:08:59.044
  I0711 06:08:59.054686 20 resource.go:87] Pod name cleanup-pod: Found 0 pods out of 1
  E0711 06:08:59.105987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:00.106203      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:01.106229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:02.106423      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:03.106559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:04.060888 20 resource.go:87] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 07/11/24 06:09:04.06
  I0711 06:09:04.061064 20 deployment.go:841] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 07/11/24 06:09:04.07
  I0711 06:09:04.084013 20 deployment.go:633] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2976",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e5087de2-30a0-47ff-8224-a800ca87983d",
      ResourceVersion: (string) (len=5) "16351",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0711 06:09:04.096075 20 deployment.go:39] New ReplicaSet "test-cleanup-deployment-7c4d497584" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-7c4d497584",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2976",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6919362e-a3ea-4d92-9386-ae8f91087e5b",
      ResourceVersion: (string) (len=5) "16354",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "e5087de2-30a0-47ff-8224-a800ca87983d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 35 30 38 37 64  65 32 2d 33 30 61 30 2d  |\"e5087de2-30a0-|
              00000120  34 37 66 66 2d 38 32 32  34 2d 61 38 30 30 63 61  |47ff-8224-a800ca|
              00000130  38 37 39 38 33 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |87983d\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 0,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 06:09:04.097407 20 deployment.go:44] All old ReplicaSets of Deployment "test-cleanup-deployment":
  I0711 06:09:04.097610 20 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2976",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d32593d0-dd8b-48ce-9952-fd60a00d84c9",
      ResourceVersion: (string) (len=5) "16352",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274939,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "e5087de2-30a0-47ff-8224-a800ca87983d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 65 35 30 38 37 64 65  |"uid\":\"e5087de|
              00000040  32 2d 33 30 61 30 2d 34  37 66 66 2d 38 32 32 34  |2-30a0-47ff-8224|
              00000050  2d 61 38 30 30 63 61 38  37 39 38 33 64 5c 22 7d  |-a800ca87983d\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 06:09:04.104797 20 deployment.go:67] Pod "test-cleanup-controller-cpzwf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-cpzwf",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-2976",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9a3a1493-c372-4f40-a9d4-4370abf4275d",
      ResourceVersion: (string) (len=5) "16340",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274939,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "d32593d0-dd8b-48ce-9952-fd60a00d84c9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  64 33 32 35 39 33 64 30  |uid\":\"d32593d0|
              00000080  2d 64 64 38 62 2d 34 38  63 65 2d 39 39 35 32 2d  |-dd8b-48ce-9952-|
              00000090  66 64 36 30 61 30 30 64  38 34 63 39 5c 22 7d 22  |fd60a00d84c9\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 37  2e 33 31 5c 22 7d 22 3a  |2.168.37.31\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gbcbp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gbcbp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274939,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) (len=13) "192.168.37.31",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.37.31"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274939,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856274939,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://4793ff17767c76ace29acbf917ba2a083d845674e8cb51af5e195db604d130eb",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:09:04.105954 20 deployment.go:67] Pod "test-cleanup-deployment-7c4d497584-sk782" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-7c4d497584-sk782",
      GenerateName: (string) (len=35) "test-cleanup-deployment-7c4d497584-",
      Namespace: (string) (len=15) "deployment-2976",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5d2e3d55-7546-4007-bbd6-da62c6e0a2c2",
      ResourceVersion: (string) (len=5) "16357",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856274944,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7c4d497584"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-7c4d497584",
          UID: (types.UID) (len=36) "6919362e-a3ea-4d92-9386-ae8f91087e5b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856274944,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 39  31 39 33 36 32 65 2d 61  |d\":\"6919362e-a|
              00000090  33 65 61 2d 34 64 39 32  2d 39 33 38 36 2d 61 65  |3ea-4d92-9386-ae|
              000000a0  38 66 39 31 30 38 37 65  35 62 5c 22 7d 22 3a 7b  |8f91087e5b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bb49q",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bb49q",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  E0711 06:09:04.106539      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:04.106606 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2976" for this suite. @ 07/11/24 06:09:04.118
• [5.105 seconds]
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 07/11/24 06:09:04.13
  I0711 06:09:04.130825 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename var-expansion @ 07/11/24 06:09:04.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:09:04.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:09:04.149
  STEP: Creating a pod to test env composition @ 07/11/24 06:09:04.154
  E0711 06:09:05.106852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:06.107080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:09:06.175
  I0711 06:09:06.180066 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod var-expansion-7ecef5b5-fe6b-4e91-b31e-590dbf6d5474 container dapi-container: <nil>
  STEP: delete the pod @ 07/11/24 06:09:06.191
  I0711 06:09:06.205995 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-272" for this suite. @ 07/11/24 06:09:06.21
• [2.088 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:789
  STEP: Creating a kubernetes client @ 07/11/24 06:09:06.219
  I0711 06:09:06.219358 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 06:09:06.219
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:09:06.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:09:06.236
  STEP: creating service endpoint-test2 in namespace services-4169 @ 07/11/24 06:09:06.238
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4169 to expose endpoints map[] @ 07/11/24 06:09:06.249
  I0711 06:09:06.253402 20 service.go:4226] Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0711 06:09:07.107271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:07.263773 20 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4169 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-4169 @ 07/11/24 06:09:07.263
  E0711 06:09:08.107448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:09.107528      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4169 to expose endpoints map[pod1:[80]] @ 07/11/24 06:09:09.285
  I0711 06:09:09.297348 20 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4169 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 07/11/24 06:09:09.297
  I0711 06:09:09.297460 20 resource.go:361] Creating new exec pod
  E0711 06:09:10.108548      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:11.109051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:12.110034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:12.313365 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-4169 exec execpodcctgn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0711 06:09:12.400974 20 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0711 06:09:12.401020 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:09:12.401101 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-4169 exec execpodcctgn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.22 80'
  I0711 06:09:12.486719 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.22 80\n+ echo hostName\nConnection to 10.152.183.22 80 port [tcp/http] succeeded!\n"
  I0711 06:09:12.486759 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-4169 @ 07/11/24 06:09:12.486
  E0711 06:09:13.110159      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:14.110240      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4169 to expose endpoints map[pod1:[80] pod2:[80]] @ 07/11/24 06:09:14.507
  I0711 06:09:14.521205 20 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4169 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 07/11/24 06:09:14.521
  E0711 06:09:15.110336      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:15.522053 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-4169 exec execpodcctgn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0711 06:09:15.611959 20 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0711 06:09:15.612001 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:09:15.612078 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-4169 exec execpodcctgn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.22 80'
  I0711 06:09:15.706798 20 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.22 80\nConnection to 10.152.183.22 80 port [tcp/http] succeeded!\n"
  I0711 06:09:15.706845 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-4169 @ 07/11/24 06:09:15.706
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4169 to expose endpoints map[pod2:[80]] @ 07/11/24 06:09:15.72
  E0711 06:09:16.110990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:16.744966 20 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4169 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 07/11/24 06:09:16.745
  E0711 06:09:17.111114      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:17.746158 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-4169 exec execpodcctgn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0711 06:09:17.834579 20 builder.go:146] stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0711 06:09:17.834619 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:09:17.834687 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-4169 exec execpodcctgn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.22 80'
  I0711 06:09:17.922936 20 builder.go:146] stderr: "+ + ncecho -v -t hostName -w\n 2 10.152.183.22 80\nConnection to 10.152.183.22 80 port [tcp/http] succeeded!\n"
  I0711 06:09:17.922985 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-4169 @ 07/11/24 06:09:17.923
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4169 to expose endpoints map[] @ 07/11/24 06:09:17.946
  I0711 06:09:17.955269 20 service.go:4258] successfully validated that service endpoint-test2 in namespace services-4169 exposes endpoints map[]
  I0711 06:09:17.976671 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4169" for this suite. @ 07/11/24 06:09:17.981
• [11.769 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 07/11/24 06:09:17.988
  I0711 06:09:17.988653 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename events @ 07/11/24 06:09:17.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:09:18.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:09:18.006
  STEP: Create set of events @ 07/11/24 06:09:18.008
  STEP: get a list of Events with a label in the current namespace @ 07/11/24 06:09:18.021
  STEP: delete a list of events @ 07/11/24 06:09:18.024
  I0711 06:09:18.024816 20 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 07/11/24 06:09:18.049
  I0711 06:09:18.052658 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-914" for this suite. @ 07/11/24 06:09:18.056
• [0.077 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1497
  STEP: Creating a kubernetes client @ 07/11/24 06:09:18.065
  I0711 06:09:18.065791 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 06:09:18.066
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:09:18.081
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:09:18.083
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-201 @ 07/11/24 06:09:18.085
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 07/11/24 06:09:18.099
  STEP: creating service externalsvc in namespace services-201 @ 07/11/24 06:09:18.099
  E0711 06:09:18.112130      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating replication controller externalsvc in namespace services-201 @ 07/11/24 06:09:18.113
  I0711 06:09:18.122197      20 runners.go:198] Created replication controller with name: externalsvc, namespace: services-201, replica count: 2
  E0711 06:09:19.112631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:20.112719      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:21.113214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:21.173504      20 runners.go:198] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 07/11/24 06:09:21.178
  I0711 06:09:21.194745 20 resource.go:361] Creating new exec pod
  E0711 06:09:22.113330      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:23.113427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:23.212076 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-201 exec execpods7fwz -- /bin/sh -x -c nslookup clusterip-service.services-201.svc.cluster.local'
  I0711 06:09:23.320390 20 builder.go:146] stderr: "+ nslookup clusterip-service.services-201.svc.cluster.local\n"
  I0711 06:09:23.320442 20 builder.go:147] stdout: "Server:\t\t10.152.183.195\nAddress:\t10.152.183.195#53\n\nclusterip-service.services-201.svc.cluster.local\tcanonical name = externalsvc.services-201.svc.cluster.local.\nName:\texternalsvc.services-201.svc.cluster.local\nAddress: 10.152.183.89\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-201, will wait for the garbage collector to delete the pods @ 07/11/24 06:09:23.32
  I0711 06:09:23.383367 20 resources.go:139] Deleting ReplicationController externalsvc took: 8.068902ms
  I0711 06:09:23.484179 20 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.807209ms
  E0711 06:09:24.113600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:25.113803      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:26.104640 20 service.go:1506] Cleaning up the ClusterIP to ExternalName test service
  E0711 06:09:26.114768      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:26.118338 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-201" for this suite. @ 07/11/24 06:09:26.122
• [8.065 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 07/11/24 06:09:26.13
  I0711 06:09:26.130874 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 06:09:26.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:09:26.149
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:09:26.151
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 07/11/24 06:09:26.153
  E0711 06:09:27.114973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:28.115033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:09:28.168
  I0711 06:09:28.172277 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-a77fd8aa-0287-42ec-b4c0-14125c33b5d3 container test-container: <nil>
  STEP: delete the pod @ 07/11/24 06:09:28.179
  I0711 06:09:28.194272 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8764" for this suite. @ 07/11/24 06:09:28.198
• [2.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 07/11/24 06:09:28.206
  I0711 06:09:28.207087 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename subpath @ 07/11/24 06:09:28.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:09:28.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:09:28.223
  STEP: Setting up data @ 07/11/24 06:09:28.226
  STEP: Creating pod pod-subpath-test-secret-n76x @ 07/11/24 06:09:28.235
  STEP: Creating a pod to test atomic-volume-subpath @ 07/11/24 06:09:28.235
  E0711 06:09:29.115189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:30.115295      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:31.116092      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:32.116203      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:33.116301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:34.116379      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:35.116509      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:36.117200      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:37.117309      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:38.117412      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:39.117526      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:40.117759      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:41.117915      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:42.118405      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:43.118927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:44.119121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:45.119286      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:46.120238      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:47.120341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:48.121050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:49.122086      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:50.122354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:09:50.307
  I0711 06:09:50.311740 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-subpath-test-secret-n76x container test-container-subpath-secret-n76x: <nil>
  STEP: delete the pod @ 07/11/24 06:09:50.318
  STEP: Deleting pod pod-subpath-test-secret-n76x @ 07/11/24 06:09:50.334
  I0711 06:09:50.334335 20 delete.go:62] Deleting pod "pod-subpath-test-secret-n76x" in namespace "subpath-1243"
  I0711 06:09:50.338052 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1243" for this suite. @ 07/11/24 06:09:50.342
• [22.143 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 07/11/24 06:09:50.35
  I0711 06:09:50.350165 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 06:09:50.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:09:50.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:09:50.367
  STEP: Creating pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189 @ 07/11/24 06:09:50.37
  E0711 06:09:51.123066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:52.123168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 07/11/24 06:09:52.389
  I0711 06:09:52.394040 20 container_probe.go:1749] Initial restart count of pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d is 0
  I0711 06:09:52.397322 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:09:53.124222      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:54.124317      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:54.404974 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:09:55.124765      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:56.125135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:56.411191 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:09:57.126048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:09:58.126293      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:09:58.416648 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:09:59.126451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:00.126582      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:00.420945 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:01.126908      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:02.127131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:02.426715 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:03.127403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:04.127543      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:04.431474 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:05.127964      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:06.128781      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:06.437519 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:07.129277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:08.129382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:08.442556 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:09.130295      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:10.130393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:10.447619 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:11.131198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:12.131436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:12.453383 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:13.132121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:14.132198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:14.458332 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:15.133032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:16.133549      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:16.464463 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:17.134160      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:18.134406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:18.469749 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:19.134568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:20.134675      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:20.474745 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:21.135701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:22.135909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:22.480134 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:23.135937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:24.136071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:24.485847 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:25.136171      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:26.136871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:26.491509 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:27.137191      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:28.137290      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:28.496120 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:29.137377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:30.137468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:30.501726 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:31.137545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:32.137744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:32.506549 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:33.138252      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:34.138443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:34.511691 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:35.139469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:36.140015      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:36.517845 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:37.140967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:38.141203      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:38.523876 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:39.141488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:40.141594      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:40.528374 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:41.142150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:42.142243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:42.533191 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:43.142344      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:44.142430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:44.538104 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:45.142580      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:46.143043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:46.544007 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:47.143651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:48.143879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:48.549668 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:49.143967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:50.144064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:50.555975 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:51.144982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:52.145092      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:52.561525 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:53.145847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:54.145914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:54.566801 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:55.146463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:56.146996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:56.574317 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:57.147033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:10:58.147132      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:10:58.579532 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:10:59.147228      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:00.147367      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:00.584912 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:01.147958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:02.148119      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:02.590363 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:03.149111      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:04.149391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:04.596483 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:05.150123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:06.150718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:06.601427 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:07.151063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:08.151219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:08.607042 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:09.152272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:10.152371      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:10.613329 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:11.152975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:12.153339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:12.618197 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:13.153776      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:14.153988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:14.623689 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:15.154194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:16.154747      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:16.629669 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:17.155231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:18.155418      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:18.634393 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:19.155971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:20.156060      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:20.639071 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:21.157018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:22.157124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:22.643885 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:23.157463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:24.157712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:24.648142 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:25.157823      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:26.158505      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:26.654427 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:27.158654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:28.158745      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:28.660092 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:29.159673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:30.159767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:30.665706 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:31.160183      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:32.160270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:32.670300 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:33.160833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:34.161022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:34.675979 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:35.161275      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:36.161898      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:36.681550 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:37.161969      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:38.162061      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:38.686856 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:39.162215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:40.162434      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:40.691790 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:41.162537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:42.162861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:42.697507 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:43.162968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:44.163158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:44.702660 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:45.163193      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:46.163631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:46.708152 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:47.163839      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:48.163941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:48.712746 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:49.164097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:50.165008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:50.718823 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:51.165687      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:52.165931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:52.724153 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:53.166774      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:54.167014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:54.729937 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:55.167475      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:56.168120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:56.735882 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:57.169045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:11:58.169315      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:11:58.740799 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:11:59.170353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:00.170594      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:00.746632 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:01.171385      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:02.171696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:02.752873 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:03.172352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:04.172448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:04.757879 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:05.173424      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:06.174030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:06.763616 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:07.174205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:08.174406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:08.768129 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:09.174489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:10.174694      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:10.772765 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:11.175536      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:12.175724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:12.777922 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:13.176557      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:14.177083      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:14.784053 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:15.177650      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:16.178236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:16.790220 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:17.178445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:18.178631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:18.795189 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:19.179717      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:20.179892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:20.800615 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:21.180250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:22.180352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:22.806017 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:23.180461      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:24.181109      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:24.811236 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:25.181760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:26.182182      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:26.817168 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:27.182339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:28.183078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:28.822555 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:29.183968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:30.184117      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:30.827649 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:31.185068      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:32.185301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:32.831902 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:33.185334      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:34.185523      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:34.836677 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:35.186082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:36.186604      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:36.842382 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:37.186881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:38.187093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:38.847583 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:39.188072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:40.188174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:40.852876 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:41.188844      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:42.189035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:42.858962 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:43.189113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:44.189330      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:44.865227 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:45.189436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:46.190145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:46.870145 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:47.190329      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:48.190674      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:48.875371 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:49.191732      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:50.191876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:50.881598 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:51.192300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:52.193013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:52.886479 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:53.193650      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:54.193749      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:54.891911 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:55.194412      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:56.194992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:56.897130 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:57.195678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:12:58.195914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:12:58.902581 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:12:59.196065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:00.196171      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:00.907701 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:01.196273      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:02.197144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:02.912679 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:03.198386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:04.198646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:04.916932 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:05.199353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:06.199799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:06.923409 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:07.199854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:08.200026      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:08.929043 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:09.200387      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:10.201009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:10.934831 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:11.201431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:12.202378      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:12.940150 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:13.202468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:14.202852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:14.945433 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:15.203750      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:16.204124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:16.950337 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:17.204684      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:18.204911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:18.955712 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:19.205042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:20.205237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:20.961160 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:21.205727      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:22.205843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:22.965989 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:23.206353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:24.206601      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:24.971050 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:25.207572      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:26.208178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:26.977684 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:27.209183      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:28.209369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:28.982909 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:29.210271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:30.210464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:30.988455 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:31.211037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:32.211141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:32.993778 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:33.212105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:34.213100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:34.998943 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:35.213222      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:36.213861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:37.004108 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:37.214551      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:38.214770      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:39.009798 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:39.215071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:40.215307      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:41.015895 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:41.215482      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:42.215763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:43.020527 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:43.215878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:44.215962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:45.026048 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:45.216418      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:46.217084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:47.031030 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:47.217277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:48.217395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:49.036141 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:49.218627      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:50.218794      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:13:51.041976 20 container_probe.go:1759] Get pod test-webserver-b7b2d481-e54c-4d87-b848-fa43ae53827d in namespace container-probe-2189
  E0711 06:13:51.219545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:52.219701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 07/11/24 06:13:53.042
  I0711 06:13:53.059554 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2189" for this suite. @ 07/11/24 06:13:53.063
• [242.721 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 07/11/24 06:13:53.07
  I0711 06:13:53.070998 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename field-validation @ 07/11/24 06:13:53.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:13:53.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:13:53.088
  I0711 06:13:53.091050 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:13:53.220290      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:54.221288      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:55.221478      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0711 06:13:55.624790      20 warnings.go:70] unknown field "alpha"
  W0711 06:13:55.624809      20 warnings.go:70] unknown field "beta"
  W0711 06:13:55.624812      20 warnings.go:70] unknown field "delta"
  W0711 06:13:55.624815      20 warnings.go:70] unknown field "epsilon"
  W0711 06:13:55.624818      20 warnings.go:70] unknown field "gamma"
  I0711 06:13:56.183167 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6268" for this suite. @ 07/11/24 06:13:56.187
• [3.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 07/11/24 06:13:56.196
  I0711 06:13:56.196439 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:13:56.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:13:56.209
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:13:56.211
  STEP: Creating secret with name s-test-opt-del-ad9f3897-d300-4545-aa8c-1712b958960d @ 07/11/24 06:13:56.217
  E0711 06:13:56.221891      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating secret with name s-test-opt-upd-2fcd6bd8-e7aa-4db3-af8b-0564e652b05f @ 07/11/24 06:13:56.222
  STEP: Creating the pod @ 07/11/24 06:13:56.226
  E0711 06:13:57.222121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:13:58.222255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-ad9f3897-d300-4545-aa8c-1712b958960d @ 07/11/24 06:13:58.279
  STEP: Updating secret s-test-opt-upd-2fcd6bd8-e7aa-4db3-af8b-0564e652b05f @ 07/11/24 06:13:58.287
  STEP: Creating secret with name s-test-opt-create-fdd309f5-e8b2-411f-9e87-646f01f4d50d @ 07/11/24 06:13:58.293
  STEP: waiting to observe update in volume @ 07/11/24 06:13:58.297
  E0711 06:13:59.222316      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:00.222446      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:01.223255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:02.223488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:03.223970      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:04.224048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:05.224143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:06.224772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:07.225009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:08.225270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:09.225365      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:10.225675      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:11.226227      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:12.226532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:13.227272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:14.227386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:15.227986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:16.228082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:17.228184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:18.228278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:19.229058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:20.229156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:21.229352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:22.229441      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:23.229658      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:24.229843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:25.229899      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:26.230319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:27.230698      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:28.231033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:29.232057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:30.233040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:31.233141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:32.233356      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:33.233437      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:34.233510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:35.233752      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:36.234074      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:37.234141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:38.234254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:39.234349      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:40.234557      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:41.235063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:42.235197      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:43.235520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:44.235613      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:45.235980      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:46.236345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:47.237145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:48.237243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:49.237346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:50.237454      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:51.238102      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:52.238544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:53.238819      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:54.238937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:55.239936      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:56.240339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:57.240436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:58.240541      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:14:59.241177      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:00.241382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:01.241896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:02.242015      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:03.242428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:04.242478      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:05.242976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:06.243685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:07.243887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:08.243975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:09.244731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:10.244951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:11.245298      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:12.245360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:12.688489 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7608" for this suite. @ 07/11/24 06:15:12.692
• [76.504 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 07/11/24 06:15:12.701
  I0711 06:15:12.701494 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename var-expansion @ 07/11/24 06:15:12.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:15:12.72
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:15:12.723
  E0711 06:15:13.246280      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:14.246518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:14.744763 20 delete.go:62] Deleting pod "var-expansion-80b131ca-feb7-4ebc-bddf-ce764262f6cd" in namespace "var-expansion-6593"
  I0711 06:15:14.754048 20 delete.go:70] Wait up to 5m0s for pod "var-expansion-80b131ca-feb7-4ebc-bddf-ce764262f6cd" to be fully deleted
  E0711 06:15:15.246609      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:16.247086      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:16.763580 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6593" for this suite. @ 07/11/24 06:15:16.767
• [4.085 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 07/11/24 06:15:16.786
  I0711 06:15:16.786295 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename field-validation @ 07/11/24 06:15:16.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:15:16.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:15:16.803
  I0711 06:15:16.806728 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  W0711 06:15:16.807434      20 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0054055d0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0711 06:15:17.247282      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:18.247634      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:19.247846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0711 06:15:19.342592      20 warnings.go:70] unknown field "alpha"
  W0711 06:15:19.342610      20 warnings.go:70] unknown field "beta"
  W0711 06:15:19.342613      20 warnings.go:70] unknown field "delta"
  W0711 06:15:19.342617      20 warnings.go:70] unknown field "epsilon"
  W0711 06:15:19.342619      20 warnings.go:70] unknown field "gamma"
  I0711 06:15:19.888393 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-40" for this suite. @ 07/11/24 06:15:19.895
• [3.116 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 07/11/24 06:15:19.902
  I0711 06:15:19.902661 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 06:15:19.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:15:19.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:15:19.921
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 06:15:19.923
  E0711 06:15:20.248471      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:21.249180      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:22.249879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:23.250116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:15:23.949
  I0711 06:15:23.953319 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-497205d7-dd94-4893-834d-e666eb05c24e container client-container: <nil>
  STEP: delete the pod @ 07/11/24 06:15:23.96
  I0711 06:15:23.976383 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3179" for this suite. @ 07/11/24 06:15:23.98
• [4.086 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 07/11/24 06:15:23.989
  I0711 06:15:23.989177 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:15:23.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:15:24.002
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:15:24.004
  STEP: Creating configMap with name projected-configmap-test-volume-map-07ce82d8-4e30-4af3-b220-589c14fc8a21 @ 07/11/24 06:15:24.006
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:15:24.01
  E0711 06:15:24.250404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:25.250800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:26.251100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:27.251182      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:15:28.035
  I0711 06:15:28.039098 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-configmaps-1e39dd6e-1ea8-4de8-be3b-796d933f0910 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:15:28.047
  I0711 06:15:28.064420 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-562" for this suite. @ 07/11/24 06:15:28.068
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 07/11/24 06:15:28.077
  I0711 06:15:28.077382 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 06:15:28.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:15:28.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:15:28.092
  STEP: Creating pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638 @ 07/11/24 06:15:28.094
  E0711 06:15:28.251703      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:29.252410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 07/11/24 06:15:30.114
  I0711 06:15:30.117651 20 container_probe.go:1749] Initial restart count of pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 is 0
  I0711 06:15:30.121561 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:30.252772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:31.253573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:32.126909 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:32.254134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:33.254349      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:34.131767 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:34.255116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:35.255232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:36.138020 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:36.256201      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:37.256277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:38.142844 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:38.257027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:39.257232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:40.148357 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:40.257619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:41.258061      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:42.153455 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:42.258367      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:43.258472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:44.159134 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:44.259513      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:45.259714      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:46.165610 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:46.259857      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:47.259951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:48.170638 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:48.260868      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:49.260912      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:50.174945 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  I0711 06:15:50.174981 20 container_probe.go:1763] Restart count of pod container-probe-1638/liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 is now 1 (20.057304309s elapsed)
  E0711 06:15:50.261192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:51.261549      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:52.180497 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:52.261569      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:53.261760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:54.185414 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:54.262533      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:55.262749      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:56.190615 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:56.263795      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:57.263935      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:15:58.197146 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:15:58.264301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:15:59.265075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:00.203673 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:00.265859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:01.266172      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:02.208629 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:02.266898      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:03.267070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:04.214464 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:04.267592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:05.267830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:06.219702 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:06.267859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:07.268031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:08.225677 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:08.269022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:09.269208      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:10.230676 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  I0711 06:16:10.230711 20 container_probe.go:1763] Restart count of pod container-probe-1638/liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 is now 2 (40.113034252s elapsed)
  E0711 06:16:10.269831      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:11.270265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:12.235497 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:12.270773      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:13.271438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:14.240834 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:14.272015      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:15.272118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:16.247139 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:16.272195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:17.273015      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:18.253862 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:18.274001      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:19.274218      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:20.258314 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:20.274420      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:21.275271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:22.263318 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:22.275629      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:23.275840      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:24.268753 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:24.275884      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:25.276128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:26.274835 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:26.277052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:27.277191      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:28.277512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:28.280005 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:29.278055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:30.278279      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:30.286533 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  I0711 06:16:30.286566 20 container_probe.go:1763] Restart count of pod container-probe-1638/liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 is now 3 (1m0.168888652s elapsed)
  E0711 06:16:31.278344      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:32.278533      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:32.291231 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:33.278661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:34.278948      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:34.296566 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:35.279032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:36.279266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:36.302291 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:37.279303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:38.279510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:38.307207 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:39.279976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:40.280027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:40.313737 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:41.281068      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:42.281979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:42.319695 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:43.282195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:44.282943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:44.324566 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:45.283043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:46.283224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:46.330154 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:47.283976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:48.284074      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:48.334735 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:49.285052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:50.285272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:50.340373 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  I0711 06:16:50.340410 20 container_probe.go:1763] Restart count of pod container-probe-1638/liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 is now 4 (1m20.222732005s elapsed)
  E0711 06:16:51.286282      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:52.286392      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:52.344944 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:53.286606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:54.286913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:54.349767 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:55.287045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:56.287844      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:56.354550 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:57.287994      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:16:58.289040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:16:58.360295 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:16:59.289150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:00.289254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:00.365467 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:01.290302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:02.290477      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:02.370643 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:03.290708      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:04.290877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:04.376303 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:05.291045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:06.291203      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:06.381366 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:07.291342      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:08.291447      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:08.386899 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:09.292367      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:10.292631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:10.393087 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:11.293090      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:12.293558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:12.399086 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:13.293809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:14.293957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:14.404228 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:15.294037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:16.294317      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:16.410181 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:17.294439      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:18.294699      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:18.415595 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:19.295510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:20.295712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:20.420611 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:21.296322      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:22.296389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:22.426813 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:23.296497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:24.296606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:24.432479 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:25.297361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:26.297919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:26.438262 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:27.298129      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:28.298382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:28.443322 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:29.299283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:30.299407      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:30.448882 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:31.299960      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:32.300108      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:32.453874 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:33.300210      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:34.300309      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:34.459910 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:35.301205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:36.301669      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:36.464681 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:37.302519      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:38.302620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:38.469992 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:39.303199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:40.303421      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:40.475954 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:41.303939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:42.304339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:42.481415 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:43.305058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:44.305225      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:44.486844 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:45.305703      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:46.306235      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:46.493039 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:47.306408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:48.306616      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:48.499012 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:49.306865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:50.307066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:50.505152 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:51.307116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:52.307311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:52.509846 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:53.307716      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:54.307962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:54.515091 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:55.309011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:56.309715      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:56.520529 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:57.309872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:17:58.310845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:17:58.526555 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:17:59.311412      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:00.311532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:00.531879 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  E0711 06:18:01.312345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:02.313145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:02.536893 20 container_probe.go:1759] Get pod liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 in namespace container-probe-1638
  I0711 06:18:02.536930 20 container_probe.go:1763] Restart count of pod container-probe-1638/liveness-c20d36b5-2e85-4e2f-b523-422f4c30f465 is now 5 (2m32.419252826s elapsed)
  STEP: deleting the pod @ 07/11/24 06:18:02.537
  I0711 06:18:02.554307 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1638" for this suite. @ 07/11/24 06:18:02.558
• [154.488 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 07/11/24 06:18:02.565
  I0711 06:18:02.565503 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 06:18:02.566
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:18:02.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:18:02.586
  STEP: Creating a ResourceQuota with best effort scope @ 07/11/24 06:18:02.588
  STEP: Ensuring ResourceQuota status is calculated @ 07/11/24 06:18:02.593
  E0711 06:18:03.314176      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:04.314304      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 07/11/24 06:18:04.598
  STEP: Ensuring ResourceQuota status is calculated @ 07/11/24 06:18:04.603
  E0711 06:18:05.314443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:06.315170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 07/11/24 06:18:06.608
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 07/11/24 06:18:06.624
  E0711 06:18:07.316259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:08.316312      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 07/11/24 06:18:08.629
  E0711 06:18:09.316755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:10.316922      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 07/11/24 06:18:10.633
  STEP: Ensuring resource quota status released the pod usage @ 07/11/24 06:18:10.646
  E0711 06:18:11.317830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:12.317945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 07/11/24 06:18:12.651
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 07/11/24 06:18:12.663
  E0711 06:18:13.318281      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:14.318393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 07/11/24 06:18:14.668
  E0711 06:18:15.318425      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:16.319117      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 07/11/24 06:18:16.674
  STEP: Ensuring resource quota status released the pod usage @ 07/11/24 06:18:16.693
  E0711 06:18:17.319381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:18.319570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:18.698823 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8582" for this suite. @ 07/11/24 06:18:18.702
• [16.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3656
  STEP: Creating a kubernetes client @ 07/11/24 06:18:18.711
  I0711 06:18:18.711623 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 06:18:18.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:18:18.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:18:18.727
  STEP: creating service multiprotocol-test in namespace services-9355 @ 07/11/24 06:18:18.73
  STEP: creating pod pod1 in namespace services-9355 @ 07/11/24 06:18:18.742
  STEP: Creating pod pod1 in namespace services-9355 @ 07/11/24 06:18:18.742
  E0711 06:18:19.320651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:20.320746      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-9355 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 07/11/24 06:18:20.77
  I0711 06:18:20.781835 20 service.go:4351] successfully validated that service multiprotocol-test in namespace services-9355 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 07/11/24 06:18:20.781
  I0711 06:18:20.781919 20 resource.go:361] Creating new exec pod
  E0711 06:18:21.321335      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:22.321444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:22.799589 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.145 80'
  I0711 06:18:22.901978 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.145 80\nConnection to 10.152.183.145 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0711 06:18:22.902019 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:18:22.902142 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.145 80'
  E0711 06:18:23.322323      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:24.323315      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:25.323968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:26.324028      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:26.998988 20 builder.go:146] stderr: "+ nc -v -u -w 2 10.152.183.145 80\n+ echo hostName\nConnection to 10.152.183.145 80 port [udp/*] succeeded!\n"
  I0711 06:18:26.999026 20 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 07/11/24 06:18:26.999
  I0711 06:18:27.009320 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.145 80'
  I0711 06:18:27.117576 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.145 80\n+ echo hostName\nConnection to 10.152.183.145 80 port [tcp/http] succeeded!\n"
  I0711 06:18:27.117614 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:18:27.117831 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.145 80'
  E0711 06:18:27.324266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:28.324473      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:29.324926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:30.325157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:31.191020 20 builder.go:146] stderr: "+ nc -v -u -w 2 10.152.183.145 80\n+ echo hostName\nConnection to 10.152.183.145 80 port [udp/*] succeeded!\n"
  I0711 06:18:31.191072 20 builder.go:147] stdout: ""
  I0711 06:18:31.191134 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.145 80'
  E0711 06:18:31.325887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:32.326067      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:33.326571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:34.326819      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:35.286869 20 builder.go:146] stderr: "+ nc -v -u -w 2 10.152.183.145 80\n+ echo hostName\nConnection to 10.152.183.145 80 port [udp/*] succeeded!\n"
  I0711 06:18:35.286913 20 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 07/11/24 06:18:35.286
  I0711 06:18:35.297344 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.145 80'
  E0711 06:18:35.327635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:36.328405      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:37.328857      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:38.329406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:39.329796      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:39.398926 20 builder.go:146] stderr: "+ nc -v -u -w 2 10.152.183.145 80\n+ echo hostName\nConnection to 10.152.183.145 80 port [udp/*] succeeded!\n"
  I0711 06:18:39.398967 20 builder.go:147] stdout: "pod1"
  I0711 06:18:39.399071 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.145 80'
  E0711 06:18:40.329989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:41.330206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:41.486948 20 builder.go:135] rc: 1
  I0711 06:18:41.487008 20 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.145 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.145 80
  + echo hostName
  nc: connect to 10.152.183.145 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0711 06:18:41.487199 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.145 80'
  E0711 06:18:42.330619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:43.330809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:43.571098 20 builder.go:135] rc: 1
  I0711 06:18:43.571152 20 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.145 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.145 80
  + echo hostName
  nc: connect to 10.152.183.145 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0711 06:18:43.571275 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.145 80'
  E0711 06:18:44.331830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:45.331970      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:45.654942 20 builder.go:135] rc: 1
  I0711 06:18:45.655007 20 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-9355 exec execpodfzm6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.145 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.145 80
  + echo hostName
  nc: connect to 10.152.183.145 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0711 06:18:45.655123 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9355" for this suite. @ 07/11/24 06:18:45.659
• [26.956 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 07/11/24 06:18:45.669
  I0711 06:18:45.669156 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubelet-test @ 07/11/24 06:18:45.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:18:45.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:18:45.687
  E0711 06:18:46.332538      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:47.332648      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:48.332715      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:49.332805      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:49.708281 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7959" for this suite. @ 07/11/24 06:18:49.713
• [4.051 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 07/11/24 06:18:49.72
  I0711 06:18:49.720840 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 06:18:49.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:18:49.736
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:18:49.738
  STEP: Creating the pod @ 07/11/24 06:18:49.74
  E0711 06:18:50.333744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:51.334204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:52.290487 20 pod_client.go:141] Successfully updated pod "labelsupdate2aee8f27-e00b-4aec-8158-51e524a6b982"
  E0711 06:18:52.334608      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:53.334841      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:54.307326 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4246" for this suite. @ 07/11/24 06:18:54.312
• [4.600 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 07/11/24 06:18:54.32
  I0711 06:18:54.320708 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename deployment @ 07/11/24 06:18:54.321
  E0711 06:18:54.335348      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:18:54.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:18:54.339
  I0711 06:18:54.350876 20 resource.go:87] Pod name rollover-pod: Found 0 pods out of 1
  E0711 06:18:55.336081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:56.336373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:57.337205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:58.337315      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:18:59.337512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:18:59.358273 20 resource.go:87] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 07/11/24 06:18:59.358
  I0711 06:18:59.358358 20 deployment.go:911] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0711 06:19:00.337757      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:01.338347      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:01.362969 20 deployment.go:921] Creating deployment "test-rollover-deployment"
  I0711 06:19:01.372459 20 deployment.go:934] Make sure deployment "test-rollover-deployment" performs scaling operations
  E0711 06:19:02.338487      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:03.338738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:03.381969 20 deployment.go:939] Check revision of new replica set for deployment "test-rollover-deployment"
  I0711 06:19:03.390478 20 deployment.go:943] Ensure that both replica sets have 1 created replica
  I0711 06:19:03.398026 20 deployment.go:952] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0711 06:19:03.407746 20 deployment.go:313] Updating deployment test-rollover-deployment
  I0711 06:19:03.407781 20 deployment.go:961] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0711 06:19:04.338869      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:05.338992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:05.421535 20 deployment.go:966] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0711 06:19:05.428839 20 deployment.go:970] Make sure deployment "test-rollover-deployment" is complete
  I0711 06:19:05.437054 20 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0711 06:19:05.437099 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 06:19:06.339110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:07.339245      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:07.445998 20 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0711 06:19:07.446056 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 06:19:08.339901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:09.340041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:09.445887 20 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0711 06:19:09.445942 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 06:19:10.341043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:11.341283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:11.445795 20 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0711 06:19:11.445853 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 06:19:12.341680      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:13.342016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:13.446415 20 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0711 06:19:13.446478 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 6, 19, 4, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 6, 19, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 06:19:14.342052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:15.342132      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:15.445949 20 deployment.go:94] 
  I0711 06:19:15.445991 20 deployment.go:974] Ensure that both old replica sets have no replicas
  I0711 06:19:15.457135 20 deployment.go:633] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a2c433d2-ac44-4dfc-b89c-fa70f1c76f06",
      ResourceVersion: (string) (len=5) "18479",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856275541,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-679c966bdf\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0711 06:19:15.461917 20 deployment.go:39] New ReplicaSet "test-rollover-deployment-679c966bdf" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-679c966bdf",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d343b1b6-172e-4447-8391-e2f9ce9d3a30",
      ResourceVersion: (string) (len=5) "18469",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856275543,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "a2c433d2-ac44-4dfc-b89c-fa70f1c76f06",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 61 32 63 34 33 33  64 32 2d 61 63 34 34 2d  |\"a2c433d2-ac44-|
              00000120  34 64 66 63 2d 62 38 39  63 2d 66 61 37 30 66 31  |4dfc-b89c-fa70f1|
              00000130  63 37 36 66 30 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c76f06\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 06:19:15.463948 20 deployment.go:44] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0711 06:19:15.464184 20 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7c6dc765-4dd1-4b72-8c46-196679264f5a",
      ResourceVersion: (string) (len=5) "18478",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856275534,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "a2c433d2-ac44-4dfc-b89c-fa70f1c76f06",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275534,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  61 32 63 34 33 33 64 32  2d 61 63 34 34 2d 34 64  |a2c433d2-ac44-4d|
              000000c0  66 63 2d 62 38 39 63 2d  66 61 37 30 66 31 63 37  |fc-b89c-fa70f1c7|
              000000d0  36 66 30 36 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |6f06\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275554,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 06:19:15.464974 20 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-65bd487b4b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cb9f93de-0694-4cf7-bd2f-682b6f7378bc",
      ResourceVersion: (string) (len=5) "18425",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856275541,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "a2c433d2-ac44-4dfc-b89c-fa70f1c76f06",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 61 32 63 34 33 33  64 32 2d 61 63 34 34 2d  |\"a2c433d2-ac44-|
              00000120  34 64 66 63 2d 62 38 39  63 2d 66 61 37 30 66 31  |4dfc-b89c-fa70f1|
              00000130  63 37 36 66 30 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c76f06\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 06:19:15.471101 20 deployment.go:67] Pod "test-rollover-deployment-679c966bdf-srwsl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-679c966bdf-srwsl",
      GenerateName: (string) (len=36) "test-rollover-deployment-679c966bdf-",
      Namespace: (string) (len=15) "deployment-7954",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f389e79e-e5e6-4f74-a28c-ab66254e2807",
      ResourceVersion: (string) (len=5) "18444",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856275543,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-679c966bdf",
          UID: (types.UID) (len=36) "d343b1b6-172e-4447-8391-e2f9ce9d3a30",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 33  34 33 62 31 62 36 2d 31  |d\":\"d343b1b6-1|
              00000090  37 32 65 2d 34 34 34 37  2d 38 33 39 31 2d 65 32  |72e-4447-8391-e2|
              000000a0  66 39 63 65 39 64 33 61  33 30 5c 22 7d 22 3a 7b  |f9ce9d3a30\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 37  2e 32 39 5c 22 7d 22 3a  |2.168.37.29\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hc6w6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hc6w6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275544,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856275543,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) (len=13) "192.168.37.29",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.37.29"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856275543,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856275544,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://c3a188200520d605bef20fe1dcd1fa7fe7e9f03ec8cec4d413b7128bf9258d3e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:19:15.473590 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7954" for this suite. @ 07/11/24 06:19:15.478
• [21.165 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 07/11/24 06:19:15.486
  I0711 06:19:15.486478 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubelet-test @ 07/11/24 06:19:15.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:19:15.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:19:15.504
  E0711 06:19:16.342760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:17.342861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:17.536293 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6688" for this suite. @ 07/11/24 06:19:17.539
• [2.083 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:341
  STEP: Creating a kubernetes client @ 07/11/24 06:19:17.57
  I0711 06:19:17.570045 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename cronjob @ 07/11/24 06:19:17.57
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:19:17.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:19:17.591
  STEP: Creating a cronjob @ 07/11/24 06:19:17.593
  STEP: creating @ 07/11/24 06:19:17.593
  STEP: getting @ 07/11/24 06:19:17.596
  STEP: listing @ 07/11/24 06:19:17.601
  STEP: watching @ 07/11/24 06:19:17.606
  I0711 06:19:17.606957 20 cronjob.go:370] starting watch
  STEP: cluster-wide listing @ 07/11/24 06:19:17.607
  STEP: cluster-wide watching @ 07/11/24 06:19:17.61
  I0711 06:19:17.610973 20 cronjob.go:382] starting watch
  STEP: patching @ 07/11/24 06:19:17.611
  STEP: updating @ 07/11/24 06:19:17.617
  I0711 06:19:17.626322 20 cronjob.go:406] waiting for watch events with expected annotations
  I0711 06:19:17.626356 20 cronjob.go:420] saw patched and updated annotations
  STEP: patching /status @ 07/11/24 06:19:17.626
  STEP: updating /status @ 07/11/24 06:19:17.637
  STEP: get /status @ 07/11/24 06:19:17.644
  STEP: deleting @ 07/11/24 06:19:17.648
  STEP: deleting a collection @ 07/11/24 06:19:17.662
  I0711 06:19:17.674914 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2438" for this suite. @ 07/11/24 06:19:17.678
• [0.116 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 07/11/24 06:19:17.686
  I0711 06:19:17.686118 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:19:17.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:19:17.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:19:17.705
  STEP: Setting up server cert @ 07/11/24 06:19:17.744
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:19:17.915
  STEP: Deploying the webhook pod @ 07/11/24 06:19:17.926
  STEP: Wait for the deployment to be ready @ 07/11/24 06:19:17.94
  I0711 06:19:17.947611 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:19:18.343025      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:19.343418      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:19:19.96
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:19:19.975
  E0711 06:19:20.344425      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:20.976086 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0711 06:19:20.984226 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:19:21.345133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 07/11/24 06:19:21.495
  STEP: Creating a custom resource that should be denied by the webhook @ 07/11/24 06:19:21.508
  E0711 06:19:22.345389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:23.345583      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 07/11/24 06:19:23.522
  STEP: Updating the custom resource with disallowed data should be denied @ 07/11/24 06:19:23.528
  STEP: Deleting the custom resource should be denied @ 07/11/24 06:19:23.543
  STEP: Remove the offending key and value from the custom resource data @ 07/11/24 06:19:23.549
  STEP: Deleting the updated custom resource should be successful @ 07/11/24 06:19:23.559
  I0711 06:19:24.136906 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4560" for this suite. @ 07/11/24 06:19:24.141
  STEP: Destroying namespace "webhook-markers-3139" for this suite. @ 07/11/24 06:19:24.148
• [6.470 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 07/11/24 06:19:24.155
  I0711 06:19:24.155981 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:19:24.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:19:24.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:19:24.173
  STEP: Creating projection with secret that has name projected-secret-test-cd36e9ac-488b-4d1d-a3ae-66110a103aad @ 07/11/24 06:19:24.176
  STEP: Creating a pod to test consume secrets @ 07/11/24 06:19:24.181
  E0711 06:19:24.345927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:25.346137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:26.346462      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:27.346673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:19:28.209
  I0711 06:19:28.213499 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-secrets-9768d071-ee2e-44e8-8e36-70245e087fa1 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 06:19:28.23
  I0711 06:19:28.246441 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2367" for this suite. @ 07/11/24 06:19:28.249
• [4.101 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:601
  STEP: Creating a kubernetes client @ 07/11/24 06:19:28.257
  I0711 06:19:28.257076 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename job @ 07/11/24 06:19:28.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:19:28.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:19:28.275
  STEP: Creating a job @ 07/11/24 06:19:28.277
  STEP: Ensuring job reaches completions @ 07/11/24 06:19:28.283
  E0711 06:19:28.347038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:29.347244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:30.347313      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:31.347402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:32.347957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:33.348067      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:34.349148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:35.349261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:36.349973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:37.350060      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:38.289216 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4739" for this suite. @ 07/11/24 06:19:38.293
• [10.046 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 07/11/24 06:19:38.303
  I0711 06:19:38.303342 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir-wrapper @ 07/11/24 06:19:38.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:19:38.318
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:19:38.321
  STEP: Creating 50 configmaps @ 07/11/24 06:19:38.323
  E0711 06:19:38.350009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 07/11/24 06:19:38.559
  I0711 06:19:38.701447 20 resource.go:87] Pod name wrapped-volume-race-4ac31a0b-e4e9-4921-bacc-c2470d9a9beb: Found 3 pods out of 5
  E0711 06:19:39.352065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:40.352145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:41.352233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:42.352581      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:43.352697      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:43.708166 20 resource.go:87] Pod name wrapped-volume-race-4ac31a0b-e4e9-4921-bacc-c2470d9a9beb: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 07/11/24 06:19:43.708
  STEP: Creating RC which spawns configmap-volume pods @ 07/11/24 06:19:43.729
  I0711 06:19:43.750160 20 resource.go:87] Pod name wrapped-volume-race-dcb58e6f-e2bd-45f0-ba2c-d082612baa7b: Found 0 pods out of 5
  E0711 06:19:44.352784      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:45.352881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:46.353110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:47.353224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:48.353489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:48.757785 20 resource.go:87] Pod name wrapped-volume-race-dcb58e6f-e2bd-45f0-ba2c-d082612baa7b: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 07/11/24 06:19:48.757
  STEP: Creating RC which spawns configmap-volume pods @ 07/11/24 06:19:48.781
  I0711 06:19:48.795582 20 resource.go:87] Pod name wrapped-volume-race-ad46b78a-3795-438e-880a-cce78358ebeb: Found 0 pods out of 5
  E0711 06:19:49.354297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:50.354411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:51.354489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:52.354610      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:53.354854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:53.804098 20 resource.go:87] Pod name wrapped-volume-race-ad46b78a-3795-438e-880a-cce78358ebeb: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 07/11/24 06:19:53.804
  STEP: deleting ReplicationController wrapped-volume-race-ad46b78a-3795-438e-880a-cce78358ebeb in namespace emptydir-wrapper-7000, will wait for the garbage collector to delete the pods @ 07/11/24 06:19:53.825
  I0711 06:19:53.889616 20 resources.go:139] Deleting ReplicationController wrapped-volume-race-ad46b78a-3795-438e-880a-cce78358ebeb took: 10.112485ms
  I0711 06:19:53.990078 20 resources.go:163] Terminating ReplicationController wrapped-volume-race-ad46b78a-3795-438e-880a-cce78358ebeb pods took: 100.456505ms
  E0711 06:19:54.354986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:55.355234      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-dcb58e6f-e2bd-45f0-ba2c-d082612baa7b in namespace emptydir-wrapper-7000, will wait for the garbage collector to delete the pods @ 07/11/24 06:19:55.79
  I0711 06:19:55.858040 20 resources.go:139] Deleting ReplicationController wrapped-volume-race-dcb58e6f-e2bd-45f0-ba2c-d082612baa7b took: 11.76958ms
  I0711 06:19:55.959176 20 resources.go:163] Terminating ReplicationController wrapped-volume-race-dcb58e6f-e2bd-45f0-ba2c-d082612baa7b pods took: 101.133997ms
  E0711 06:19:56.355602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:19:57.356216      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-4ac31a0b-e4e9-4921-bacc-c2470d9a9beb in namespace emptydir-wrapper-7000, will wait for the garbage collector to delete the pods @ 07/11/24 06:19:57.76
  I0711 06:19:57.827417 20 resources.go:139] Deleting ReplicationController wrapped-volume-race-4ac31a0b-e4e9-4921-bacc-c2470d9a9beb took: 9.806891ms
  I0711 06:19:57.927535 20 resources.go:163] Terminating ReplicationController wrapped-volume-race-4ac31a0b-e4e9-4921-bacc-c2470d9a9beb pods took: 100.110824ms
  E0711 06:19:58.356508      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 07/11/24 06:19:59.228
  E0711 06:19:59.356614      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:19:59.702000 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-7000" for this suite. @ 07/11/24 06:19:59.705
• [21.410 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:866
  STEP: Creating a kubernetes client @ 07/11/24 06:19:59.713
  I0711 06:19:59.713570 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:19:59.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:19:59.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:19:59.731
  STEP: Setting up server cert @ 07/11/24 06:19:59.754
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:19:59.913
  STEP: Deploying the webhook pod @ 07/11/24 06:19:59.923
  STEP: Wait for the deployment to be ready @ 07/11/24 06:19:59.936
  I0711 06:19:59.953299 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:20:00.356697      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:01.357206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:20:01.966
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:20:01.98
  E0711 06:20:02.357935      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:02.980577 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 07/11/24 06:20:02.989
  STEP: create the configmap with a random name @ 07/11/24 06:20:03.005
  STEP: verify the configmap is mutated @ 07/11/24 06:20:03.015
  STEP: create the configmap with 'skip-me' name @ 07/11/24 06:20:03.015
  I0711 06:20:03.088500 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-705" for this suite. @ 07/11/24 06:20:03.092
  STEP: Destroying namespace "webhook-markers-9318" for this suite. @ 07/11/24 06:20:03.099
• [3.392 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 07/11/24 06:20:03.106
  I0711 06:20:03.106242 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replication-controller @ 07/11/24 06:20:03.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:20:03.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:20:03.123
  STEP: Creating ReplicationController "e2e-rc-j7lbd" @ 07/11/24 06:20:03.125
  I0711 06:20:03.130406 20 rc.go:792] Get Replication Controller "e2e-rc-j7lbd" to confirm replicas
  E0711 06:20:03.358048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:04.131145 20 rc.go:792] Get Replication Controller "e2e-rc-j7lbd" to confirm replicas
  I0711 06:20:04.135731 20 rc.go:801] Found 1 replicas for "e2e-rc-j7lbd" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-j7lbd" @ 07/11/24 06:20:04.135
  STEP: Updating a scale subresource @ 07/11/24 06:20:04.14
  STEP: Verifying replicas where modified for replication controller "e2e-rc-j7lbd" @ 07/11/24 06:20:04.151
  I0711 06:20:04.151886 20 rc.go:792] Get Replication Controller "e2e-rc-j7lbd" to confirm replicas
  E0711 06:20:04.358639      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:05.151985 20 rc.go:792] Get Replication Controller "e2e-rc-j7lbd" to confirm replicas
  I0711 06:20:05.156004 20 rc.go:801] Found 2 replicas for "e2e-rc-j7lbd" replication controller
  I0711 06:20:05.156188 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9459" for this suite. @ 07/11/24 06:20:05.16
• [2.063 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 07/11/24 06:20:05.169
  I0711 06:20:05.169752 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename runtimeclass @ 07/11/24 06:20:05.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:20:05.191
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:20:05.194
  I0711 06:20:05.229150 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9860" for this suite. @ 07/11/24 06:20:05.232
• [0.074 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 07/11/24 06:20:05.243
  I0711 06:20:05.243726 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename ingress @ 07/11/24 06:20:05.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:20:05.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:20:05.261
  STEP: getting /apis @ 07/11/24 06:20:05.263
  STEP: getting /apis/networking.k8s.io @ 07/11/24 06:20:05.266
  STEP: getting /apis/networking.k8s.iov1 @ 07/11/24 06:20:05.267
  STEP: creating @ 07/11/24 06:20:05.268
  STEP: getting @ 07/11/24 06:20:05.29
  STEP: listing @ 07/11/24 06:20:05.296
  STEP: watching @ 07/11/24 06:20:05.299
  I0711 06:20:05.299180 20 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 07/11/24 06:20:05.3
  STEP: cluster-wide watching @ 07/11/24 06:20:05.304
  I0711 06:20:05.304327 20 ingress.go:198] starting watch
  STEP: patching @ 07/11/24 06:20:05.305
  STEP: updating @ 07/11/24 06:20:05.311
  I0711 06:20:05.323631 20 ingress.go:221] waiting for watch events with expected annotations
  I0711 06:20:05.324125 20 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 07/11/24 06:20:05.324
  STEP: updating /status @ 07/11/24 06:20:05.336
  STEP: get /status @ 07/11/24 06:20:05.348
  STEP: deleting @ 07/11/24 06:20:05.357
  E0711 06:20:05.358913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting a collection @ 07/11/24 06:20:05.371
  I0711 06:20:05.390636 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-6188" for this suite. @ 07/11/24 06:20:05.395
• [0.162 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 07/11/24 06:20:05.406
  I0711 06:20:05.407061 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename ingressclass @ 07/11/24 06:20:05.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:20:05.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:20:05.435
  STEP: getting /apis @ 07/11/24 06:20:05.444
  STEP: getting /apis/networking.k8s.io @ 07/11/24 06:20:05.45
  STEP: getting /apis/networking.k8s.iov1 @ 07/11/24 06:20:05.451
  STEP: creating @ 07/11/24 06:20:05.452
  STEP: getting @ 07/11/24 06:20:05.471
  STEP: listing @ 07/11/24 06:20:05.475
  STEP: watching @ 07/11/24 06:20:05.479
  I0711 06:20:05.479183 20 ingressclass.go:348] starting watch
  STEP: patching @ 07/11/24 06:20:05.48
  STEP: updating @ 07/11/24 06:20:05.485
  I0711 06:20:05.490268 20 ingressclass.go:364] waiting for watch events with expected annotations
  I0711 06:20:05.490458 20 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 07/11/24 06:20:05.49
  STEP: deleting a collection @ 07/11/24 06:20:05.505
  I0711 06:20:05.521865 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-8253" for this suite. @ 07/11/24 06:20:05.525
• [0.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 07/11/24 06:20:05.533
  I0711 06:20:05.533292 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 06:20:05.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:20:05.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:20:05.552
  STEP: Creating a pod to test downward api env vars @ 07/11/24 06:20:05.554
  E0711 06:20:06.359104      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:07.359348      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:08.359397      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:09.359512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:20:09.581
  I0711 06:20:09.585256 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downward-api-190f4815-5b2a-48b9-966f-6fb0438b552d container dapi-container: <nil>
  STEP: delete the pod @ 07/11/24 06:20:09.592
  I0711 06:20:09.612874 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5638" for this suite. @ 07/11/24 06:20:09.617
• [4.091 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 07/11/24 06:20:09.624
  I0711 06:20:09.624080 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename csistoragecapacity @ 07/11/24 06:20:09.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:20:09.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:20:09.639
  STEP: getting /apis @ 07/11/24 06:20:09.688
  STEP: getting /apis/storage.k8s.io @ 07/11/24 06:20:09.691
  STEP: getting /apis/storage.k8s.io/v1 @ 07/11/24 06:20:09.692
  STEP: creating @ 07/11/24 06:20:09.693
  STEP: watching @ 07/11/24 06:20:09.711
  I0711 06:20:09.711145 20 csistoragecapacity.go:143] starting watch
  STEP: getting @ 07/11/24 06:20:09.718
  STEP: listing in namespace @ 07/11/24 06:20:09.721
  STEP: listing across namespaces @ 07/11/24 06:20:09.724
  STEP: patching @ 07/11/24 06:20:09.728
  STEP: updating @ 07/11/24 06:20:09.734
  I0711 06:20:09.740472 20 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I0711 06:20:09.740676 20 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 07/11/24 06:20:09.74
  STEP: deleting a collection @ 07/11/24 06:20:09.753
  I0711 06:20:09.771261 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-2924" for this suite. @ 07/11/24 06:20:09.775
• [0.159 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 07/11/24 06:20:09.783
  I0711 06:20:09.783328 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename aggregateddiscovery @ 07/11/24 06:20:09.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:20:09.799
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:20:09.801
  I0711 06:20:09.806159 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-5939" for this suite. @ 07/11/24 06:20:09.809
• [0.035 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 07/11/24 06:20:09.818
  I0711 06:20:09.818584 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 06:20:09.819
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:20:09.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:20:09.842
  STEP: Creating pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569 @ 07/11/24 06:20:09.844
  E0711 06:20:10.359638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:11.359799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 07/11/24 06:20:11.866
  I0711 06:20:11.870272 20 container_probe.go:1749] Initial restart count of pod liveness-10c9ae13-2411-489a-aa47-da7993002342 is 0
  I0711 06:20:11.873702 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:12.359987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:13.360087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:13.879203 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:14.360804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:15.361044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:15.884641 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:16.361154      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:17.361283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:17.890054 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:18.361542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:19.362155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:19.895787 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:20.363062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:21.363333      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:21.901051 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:22.363444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:23.363607      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:23.906574 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:24.364358      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:25.364455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:25.912426 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:26.365028      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:27.365331      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:27.917423 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:28.366000      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:29.366192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:29.922837 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:30.366288      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:31.366477      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:31.927273 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:32.366590      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:33.366794      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:33.931435 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:34.366918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:35.367495      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:35.936773 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:36.368446      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:37.369303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:37.942090 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:38.369375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:39.369578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:39.947372 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:40.369818      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:41.370249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:41.953483 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:42.370975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:43.371242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:43.958016 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:44.371480      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:45.371718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:45.964109 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:46.372731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:47.372816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:47.969525 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:48.372942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:49.373136      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:49.974339 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:50.373910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:51.374444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:51.980221 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:52.374606      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:53.374834      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:53.984967 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:54.375559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:55.375711      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:55.989660 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:56.376532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:57.376642      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:20:57.994600 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:20:58.376709      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:20:59.376807      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:00.000162 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:00.377689      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:01.378234      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:02.005383 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:02.379157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:03.379380      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:04.010426 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:04.379959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:05.380146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:06.016115 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:06.380949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:07.381076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:08.021482 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:08.382057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:09.382266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:10.026124 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:10.382385      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:11.383382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:12.031229 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:12.383512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:13.383671      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:14.035498 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:14.383920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:15.383994      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:16.040755 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:16.384459      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:17.384528      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:18.046670 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:18.385050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:19.385283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:20.051954 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:20.385393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:21.386389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:22.057324 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:22.386808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:23.386883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:24.061888 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:24.387272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:25.387791      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:26.067304 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:26.388850      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:27.388950      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:28.071195 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:28.389643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:29.389812      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:30.076343 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:30.390847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:31.391066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:32.081972 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:32.391371      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:33.391457      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:34.087390 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:34.391778      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:35.391982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:36.093230 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:36.392758      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:37.393086      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:38.097862 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:38.393315      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:39.393405      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:40.103712 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:40.394297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:41.394399      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:42.108461 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:42.394698      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:43.394937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:44.112615 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:44.395042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:45.395164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:46.117461 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:46.395943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:47.395996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:48.122190 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:48.396564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:49.397021      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:50.128073 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:50.397502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:51.398035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:52.133894 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:52.398432      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:53.398667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:54.139485 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:54.399078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:55.399255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:56.145820 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:56.400287      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:57.400408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:21:58.150789 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:21:58.401116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:21:59.401334      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:00.155621 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:00.402012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:01.402266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:02.159914 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:02.403262      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:03.403354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:04.164730 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:04.404079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:05.405032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:06.170255 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:06.405583      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:07.405666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:08.174594 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:08.405841      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:09.405876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:10.180034 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:10.406354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:11.407051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:12.186585 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:12.407901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:13.407976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:14.191741 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:14.409024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:15.409137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:16.197894 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:16.409214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:17.409290      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:18.203525 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:18.409835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:19.409926      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:20.208507 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:20.410802      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:21.411446      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:22.214434 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:22.411729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:23.411832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:24.219978 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:24.412237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:25.413047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:26.225640 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:26.413944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:27.414095      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:28.230459 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:28.414817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:29.414922      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:30.236099 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:30.415418      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:31.416474      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:32.241275 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:32.416505      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:33.417052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:34.246655 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:34.417938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:35.418113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:36.251221 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:36.418571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:37.418971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:38.257046 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:38.419380      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:39.419510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:40.262818 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:40.420185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:41.420354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:42.268580 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:42.420836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:43.421097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:44.274324 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:44.421614      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:45.421720      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:46.279626 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:46.421948      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:47.422063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:48.285472 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:48.422914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:49.423101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:50.290232 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:50.423405      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:51.424427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:52.295103 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:52.425374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:53.425573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:54.300194 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:54.426387      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:55.426791      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:56.306305 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:56.427665      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:57.427925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:22:58.311161 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:22:58.428363      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:22:59.428469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:00.315962 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:00.429199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:01.429402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:02.320993 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:02.430255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:03.430470      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:04.326098 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:04.431315      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:05.431510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:06.331678 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:06.432039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:07.432262      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:08.336769 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:08.433035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:09.433586      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:10.342758 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:10.433917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:11.434286      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:12.347962 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:12.435179      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:13.435390      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:14.353838 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:14.436014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:15.436150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:16.358653 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:16.436832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:17.437020      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:18.364046 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:18.437229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:19.437556      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:20.370214 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:20.438415      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:21.439153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:22.374941 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:22.439224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:23.439360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:24.380918 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:24.440153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:25.441067      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:26.385646 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:26.441864      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:27.441958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:28.391126 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:28.442282      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:29.443325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:30.396934 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:30.444060      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:31.444540      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:32.402357 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:32.445560      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:33.445670      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:34.408220 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:34.446389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:35.446563      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:36.414506 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:36.446609      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:37.446830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:38.419449 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:38.447872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:39.448088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:40.424542 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:40.448768      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:41.448885      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:42.431760 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:42.449225      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:43.449545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:44.436705 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:44.449872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:45.450045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:46.442118 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:46.450262      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:47.450544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:48.448138 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:48.451268      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:49.451504      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:50.452072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:50.454313 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:51.452381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:52.453169      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:52.460894 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:53.453257      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:54.453871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:54.466422 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:55.454438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:56.455048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:56.471650 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:57.455677      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:23:58.455907      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:23:58.477350 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:23:59.456110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:00.457096      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:24:00.482814 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:24:01.457211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:02.457427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:24:02.488970 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:24:03.457654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:04.457811      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:24:04.494239 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:24:05.458258      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:06.458451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:24:06.499771 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:24:07.458832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:08.459010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:24:08.505021 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:24:09.459969      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:10.460017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:24:10.509858 20 container_probe.go:1759] Get pod liveness-10c9ae13-2411-489a-aa47-da7993002342 in namespace container-probe-6569
  E0711 06:24:11.460094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:12.461061      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 07/11/24 06:24:12.51
  I0711 06:24:12.524111 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6569" for this suite. @ 07/11/24 06:24:12.528
• [242.717 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 07/11/24 06:24:12.536
  I0711 06:24:12.536241 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 06:24:12.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:24:12.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:24:12.566
  STEP: Creating a pod to test emptydir volume type on node default medium @ 07/11/24 06:24:12.568
  E0711 06:24:13.461782      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:14.461901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:15.462145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:16.463146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:24:16.591
  I0711 06:24:16.595239 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-72049b56-e56a-4eb3-bf9d-a01ca1f00b6a container test-container: <nil>
  STEP: delete the pod @ 07/11/24 06:24:16.605
  I0711 06:24:16.622911 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2725" for this suite. @ 07/11/24 06:24:16.626
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 07/11/24 06:24:16.634
  I0711 06:24:16.634258 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 07/11/24 06:24:16.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:24:16.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:24:16.656
  STEP: create the container to handle the HTTPGet hook request. @ 07/11/24 06:24:16.662
  E0711 06:24:17.463230      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:18.463319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 07/11/24 06:24:18.683
  E0711 06:24:19.463418      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:20.463487      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 07/11/24 06:24:20.709
  STEP: delete the pod with lifecycle hook @ 07/11/24 06:24:20.717
  E0711 06:24:21.464344      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:22.464435      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:24:22.735443 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1640" for this suite. @ 07/11/24 06:24:22.739
• [6.113 seconds]
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 07/11/24 06:24:22.747
  I0711 06:24:22.747431 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename taint-multiple-pods @ 07/11/24 06:24:22.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:24:22.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:24:22.765
  I0711 06:24:22.768219 20 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0711 06:24:23.465023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:24.465483      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:25.465604      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:26.466131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:27.466673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:28.466875      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:29.466971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:30.467133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:31.468188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:32.469044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:33.469137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:34.469348      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:35.469607      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:36.470260      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:37.470472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:38.470642      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:39.470884      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:40.471110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:41.472036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:42.472107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:43.472152      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:44.473023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:45.473107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:46.473444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:47.473943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:48.474132      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:49.474283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:50.474516      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:51.475344      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:52.475664      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:53.475947      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:54.476951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:55.477056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:56.477399      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:57.477471      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:58.477676      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:24:59.478761      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:00.478830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:01.478953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:02.479176      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:03.479358      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:04.479631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:05.479946      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:06.480389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:07.481012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:08.481178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:09.481358      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:10.481603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:11.482246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:12.482336      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:13.482666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:14.483534      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:15.484027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:16.484127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:17.485024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:18.485280      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:19.485379      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:20.485560      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:21.485768      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:22.486000      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:25:22.769596 20 util.go:400] Waiting for terminating namespaces to be deleted...
  I0711 06:25:22.774320 20 taints.go:150] Starting informer...
  STEP: Starting pods... @ 07/11/24 06:25:22.774
  I0711 06:25:22.995156 20 taints.go:469] Pod1 is running on ip-172-31-80-240. Tainting Node
  E0711 06:25:23.486846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:24.487685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:25:25.218342 20 taints.go:477] Pod2 is running on ip-172-31-80-240. Tainting Node
  STEP: Trying to apply a taint on the Node @ 07/11/24 06:25:25.218
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 07/11/24 06:25:25.228
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 07/11/24 06:25:25.232
  E0711 06:25:25.488414      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:26.489010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:27.489254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:28.489463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:29.489651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:30.489921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:25:31.354884 20 taints.go:498] Noticed Pod "taint-eviction-b1" gets evicted.
  E0711 06:25:31.490005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:32.490248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:33.490438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:34.490560      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:35.490732      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:36.491426      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:37.491548      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:38.491620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:39.491887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:40.492073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:41.492205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:42.492352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:43.492419      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:44.492492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:45.493432      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:46.494041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:47.494530      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:48.494643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:49.494920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:50.496035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:25:51.378467 20 taints.go:498] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 07/11/24 06:25:51.388
  I0711 06:25:51.391687 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-7273" for this suite. @ 07/11/24 06:25:51.394
• [88.660 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 07/11/24 06:25:51.407
  I0711 06:25:51.407449 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename custom-resource-definition @ 07/11/24 06:25:51.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:25:51.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:25:51.428
  STEP: fetching the /apis discovery document @ 07/11/24 06:25:51.43
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 07/11/24 06:25:51.431
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 07/11/24 06:25:51.431
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 07/11/24 06:25:51.431
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 07/11/24 06:25:51.433
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 07/11/24 06:25:51.433
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 07/11/24 06:25:51.434
  I0711 06:25:51.434119 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9568" for this suite. @ 07/11/24 06:25:51.437
• [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 07/11/24 06:25:51.444
  I0711 06:25:51.444707 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename namespaces @ 07/11/24 06:25:51.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:25:51.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:25:51.462
  STEP: Creating a test namespace @ 07/11/24 06:25:51.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:25:51.479
  STEP: Creating a pod in the namespace @ 07/11/24 06:25:51.482
  STEP: Waiting for the pod to have running status @ 07/11/24 06:25:51.492
  E0711 06:25:51.496266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:52.496444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:53.496524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 07/11/24 06:25:53.502
  STEP: Waiting for the namespace to be removed. @ 07/11/24 06:25:53.511
  E0711 06:25:54.497338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:55.497917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:56.498530      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:57.498771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:58.498858      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:25:59.499099      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:00.499266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:01.500049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:02.500146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:03.500306      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:04.501199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 07/11/24 06:26:04.516
  STEP: Verifying there are no pods in the namespace @ 07/11/24 06:26:04.533
  I0711 06:26:04.537256 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9488" for this suite. @ 07/11/24 06:26:04.542
  STEP: Destroying namespace "nsdeletetest-5951" for this suite. @ 07/11/24 06:26:04.548
  I0711 06:26:04.552869 20 framework.go:370] Namespace nsdeletetest-5951 was already deleted
  STEP: Destroying namespace "nsdeletetest-8338" for this suite. @ 07/11/24 06:26:04.552
• [13.115 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 07/11/24 06:26:04.559
  I0711 06:26:04.559714 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 06:26:04.56
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:04.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:04.577
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 07/11/24 06:26:04.583
  E0711 06:26:05.501687      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:06.502257      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:26:06.603
  I0711 06:26:06.607270 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-4bb70cf1-e2d6-4547-a9b9-d551af8fcb96 container test-container: <nil>
  STEP: delete the pod @ 07/11/24 06:26:06.624
  I0711 06:26:06.641411 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6448" for this suite. @ 07/11/24 06:26:06.644
• [2.092 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 07/11/24 06:26:06.651
  I0711 06:26:06.651769 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename runtimeclass @ 07/11/24 06:26:06.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:06.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:06.675
  E0711 06:26:07.502324      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:08.502421      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:26:08.707952 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2743" for this suite. @ 07/11/24 06:26:08.712
• [2.068 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 07/11/24 06:26:08.719
  I0711 06:26:08.719549 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename var-expansion @ 07/11/24 06:26:08.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:08.737
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:08.739
  STEP: Creating a pod to test substitution in container's args @ 07/11/24 06:26:08.741
  E0711 06:26:09.503110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:10.503341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:26:10.76
  I0711 06:26:10.763387 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod var-expansion-d69792c9-d369-48c9-9b48-d2f43d9a2a6f container dapi-container: <nil>
  STEP: delete the pod @ 07/11/24 06:26:10.77
  I0711 06:26:10.790077 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9457" for this suite. @ 07/11/24 06:26:10.793
• [2.081 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 07/11/24 06:26:10.801
  I0711 06:26:10.801097 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 06:26:10.801
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:10.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:10.818
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 06:26:10.82
  E0711 06:26:11.504260      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:12.504349      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:13.505211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:14.505341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:26:14.846
  I0711 06:26:14.849797 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-9ddff3a8-52f2-47fd-b5c6-4160720c3ee0 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 06:26:14.856
  I0711 06:26:14.877010 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3058" for this suite. @ 07/11/24 06:26:14.88
• [4.087 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2181
  STEP: Creating a kubernetes client @ 07/11/24 06:26:14.888
  I0711 06:26:14.888656 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 06:26:14.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:14.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:14.907
  STEP: creating service in namespace services-1226 @ 07/11/24 06:26:14.909
  STEP: creating service affinity-clusterip in namespace services-1226 @ 07/11/24 06:26:14.909
  STEP: creating replication controller affinity-clusterip in namespace services-1226 @ 07/11/24 06:26:14.927
  I0711 06:26:14.938037      20 runners.go:198] Created replication controller with name: affinity-clusterip, namespace: services-1226, replica count: 3
  E0711 06:26:15.506293      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:16.507134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:17.507236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:26:17.988980      20 runners.go:198] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0711 06:26:17.998395 20 resource.go:361] Creating new exec pod
  E0711 06:26:18.508261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:19.508370      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:20.508445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:26:21.015351 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1226 exec execpod-affinityrl2x9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I0711 06:26:21.111573 20 builder.go:146] stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  I0711 06:26:21.111629 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:26:21.111714 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1226 exec execpod-affinityrl2x9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.231 80'
  I0711 06:26:21.202517 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.231 80\n+ echo hostName\nConnection to 10.152.183.231 80 port [tcp/http] succeeded!\n"
  I0711 06:26:21.202560 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:26:21.202630 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1226 exec execpod-affinityrl2x9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.231:80/ ; done'
  I0711 06:26:21.360382 20 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.231:80/\n"
  I0711 06:26:21.360425 20 builder.go:147] stdout: "\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj\naffinity-clusterip-s2lsj"
  I0711 06:26:21.360438 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360445 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360452 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360457 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360463 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360469 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360474 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360478 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360484 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360514 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360519 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360542 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360548 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360579 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360585 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360590 20 service.go:242] Received response from host: affinity-clusterip-s2lsj
  I0711 06:26:21.360681 20 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-1226, will wait for the garbage collector to delete the pods @ 07/11/24 06:26:21.378
  I0711 06:26:21.441895 20 resources.go:139] Deleting ReplicationController affinity-clusterip took: 9.315864ms
  E0711 06:26:21.509272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:26:21.542529 20 resources.go:163] Terminating ReplicationController affinity-clusterip pods took: 100.630917ms
  E0711 06:26:22.509567      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:23.509876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:24.510347      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:26:24.662123 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1226" for this suite. @ 07/11/24 06:26:24.666
• [9.785 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 07/11/24 06:26:24.673
  I0711 06:26:24.673785 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename field-validation @ 07/11/24 06:26:24.674
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:24.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:24.689
  I0711 06:26:24.691960 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:26:25.511277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:26.512118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0711 06:26:27.225113      20 warnings.go:70] unknown field "alpha"
  W0711 06:26:27.225134      20 warnings.go:70] unknown field "beta"
  W0711 06:26:27.225142      20 warnings.go:70] unknown field "delta"
  W0711 06:26:27.225145      20 warnings.go:70] unknown field "epsilon"
  W0711 06:26:27.225148      20 warnings.go:70] unknown field "gamma"
  E0711 06:26:27.512703      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:26:27.770411 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9512" for this suite. @ 07/11/24 06:26:27.773
• [3.107 seconds]
------------------------------
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 07/11/24 06:26:27.78
  I0711 06:26:27.780888 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-runtime @ 07/11/24 06:26:27.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:27.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:27.8
  STEP: create the container @ 07/11/24 06:26:27.802
  W0711 06:26:27.812652      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 07/11/24 06:26:27.812
  E0711 06:26:28.513493      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:29.513578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:30.514633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 07/11/24 06:26:30.83
  STEP: the container should be terminated @ 07/11/24 06:26:30.834
  STEP: the termination message should be set @ 07/11/24 06:26:30.834
  I0711 06:26:30.834272 20 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 07/11/24 06:26:30.834
  I0711 06:26:30.851081 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7676" for this suite. @ 07/11/24 06:26:30.855
• [3.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 07/11/24 06:26:30.864
  I0711 06:26:30.864166 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename svcaccounts @ 07/11/24 06:26:30.864
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:30.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:30.88
  STEP: Creating a pod to test service account token:  @ 07/11/24 06:26:30.887
  E0711 06:26:31.515637      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:32.516088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:33.516196      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:34.516270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:26:34.912
  I0711 06:26:34.915992 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod test-pod-92079c73-2850-4fab-a2ab-f851d58bd271 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:26:34.923
  I0711 06:26:34.942721 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5466" for this suite. @ 07/11/24 06:26:34.946
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 07/11/24 06:26:34.954
  I0711 06:26:34.954331 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename field-validation @ 07/11/24 06:26:34.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:34.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:34.972
  STEP: apply creating a deployment @ 07/11/24 06:26:34.974
  I0711 06:26:34.988720 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1204" for this suite. @ 07/11/24 06:26:34.992
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 07/11/24 06:26:35
  I0711 06:26:35.000799 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 06:26:35.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:35.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:35.017
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 06:26:35.019
  E0711 06:26:35.517163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:36.517437      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:37.517600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:38.517820      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:26:39.047
  I0711 06:26:39.051985 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-489b3800-de9c-4040-b5f9-316f1b819bc8 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 06:26:39.059
  I0711 06:26:39.076506 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2003" for this suite. @ 07/11/24 06:26:39.079
• [4.087 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 07/11/24 06:26:39.087
  I0711 06:26:39.087477 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:26:39.088
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:39.103
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:39.105
  STEP: Creating configMap with name projected-configmap-test-volume-f5df883f-b810-4b96-9300-84d34645ff0f @ 07/11/24 06:26:39.107
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:26:39.113
  E0711 06:26:39.518866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:40.519132      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:41.519744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:42.519851      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:26:43.138
  I0711 06:26:43.143311 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-configmaps-c5511c5a-91e5-4813-8701-906d975f6f1c container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:26:43.151
  I0711 06:26:43.166625 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-58" for this suite. @ 07/11/24 06:26:43.17
• [4.091 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 07/11/24 06:26:43.178
  I0711 06:26:43.178726 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:26:43.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:43.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:43.201
  STEP: Setting up server cert @ 07/11/24 06:26:43.223
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:26:43.48
  STEP: Deploying the webhook pod @ 07/11/24 06:26:43.49
  STEP: Wait for the deployment to be ready @ 07/11/24 06:26:43.504
  I0711 06:26:43.515335 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:26:43.520526      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:44.521018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:45.521030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:26:45.527
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:26:45.537
  E0711 06:26:46.522012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:26:46.538321 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 07/11/24 06:26:46.545
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 07/11/24 06:26:46.558
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 07/11/24 06:26:46.563
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 07/11/24 06:26:46.574
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 07/11/24 06:26:46.586
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 07/11/24 06:26:46.593
  I0711 06:26:46.653833 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5991" for this suite. @ 07/11/24 06:26:46.658
  STEP: Destroying namespace "webhook-markers-7727" for this suite. @ 07/11/24 06:26:46.671
• [3.500 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 07/11/24 06:26:46.678
  I0711 06:26:46.678998 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 06:26:46.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:46.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:46.7
  STEP: Creating a pod to test downward api env vars @ 07/11/24 06:26:46.702
  E0711 06:26:47.522286      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:48.522353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:26:48.721
  I0711 06:26:48.725754 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downward-api-cc93eac9-f10e-41cb-b141-12f111b91b88 container dapi-container: <nil>
  STEP: delete the pod @ 07/11/24 06:26:48.732
  I0711 06:26:48.749083 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7212" for this suite. @ 07/11/24 06:26:48.753
• [2.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 07/11/24 06:26:48.761
  I0711 06:26:48.761947 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename endpointslice @ 07/11/24 06:26:48.762
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:48.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:48.78
  STEP: getting /apis @ 07/11/24 06:26:48.782
  STEP: getting /apis/discovery.k8s.io @ 07/11/24 06:26:48.784
  STEP: getting /apis/discovery.k8s.iov1 @ 07/11/24 06:26:48.785
  STEP: creating @ 07/11/24 06:26:48.786
  STEP: getting @ 07/11/24 06:26:48.8
  STEP: listing @ 07/11/24 06:26:48.804
  STEP: watching @ 07/11/24 06:26:48.807
  I0711 06:26:48.807649 20 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 07/11/24 06:26:48.808
  STEP: cluster-wide watching @ 07/11/24 06:26:48.812
  I0711 06:26:48.812440 20 endpointslice.go:459] starting watch
  STEP: patching @ 07/11/24 06:26:48.813
  STEP: updating @ 07/11/24 06:26:48.819
  I0711 06:26:48.826750 20 endpointslice.go:482] waiting for watch events with expected annotations
  I0711 06:26:48.826782 20 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 07/11/24 06:26:48.826
  STEP: deleting a collection @ 07/11/24 06:26:48.839
  I0711 06:26:48.856850 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8787" for this suite. @ 07/11/24 06:26:48.86
• [0.107 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 07/11/24 06:26:48.869
  I0711 06:26:48.869191 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:26:48.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:48.883
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:48.885
  STEP: Creating configMap with name projected-configmap-test-volume-2199cf88-2387-4f2c-b81d-a025c066a7d0 @ 07/11/24 06:26:48.887
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:26:48.894
  E0711 06:26:49.523080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:50.523575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:51.523959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:52.525023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:26:52.919
  I0711 06:26:52.922620 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-configmaps-1b710295-891d-442b-8563-2f22565f2ba9 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:26:52.929
  I0711 06:26:52.944696 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7916" for this suite. @ 07/11/24 06:26:52.948
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 07/11/24 06:26:52.956
  I0711 06:26:52.956819 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename prestop @ 07/11/24 06:26:52.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:26:52.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:26:52.975
  STEP: Creating server pod server in namespace prestop-1025 @ 07/11/24 06:26:52.977
  STEP: Waiting for pods to come up. @ 07/11/24 06:26:52.986
  E0711 06:26:53.525149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:54.525379      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-1025 @ 07/11/24 06:26:54.999
  E0711 06:26:55.525586      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:56.526276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 07/11/24 06:26:57.016
  E0711 06:26:57.526375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:58.526579      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:26:59.526678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:00.526854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:01.527311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:27:02.032027 20 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 07/11/24 06:27:02.032
  I0711 06:27:02.048363 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-1025" for this suite. @ 07/11/24 06:27:02.052
• [9.103 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 07/11/24 06:27:02.059
  I0711 06:27:02.059940 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 06:27:02.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:27:02.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:27:02.077
  STEP: creating a ConfigMap @ 07/11/24 06:27:02.08
  STEP: fetching the ConfigMap @ 07/11/24 06:27:02.086
  STEP: patching the ConfigMap @ 07/11/24 06:27:02.089
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 07/11/24 06:27:02.094
  STEP: deleting the ConfigMap by collection with a label selector @ 07/11/24 06:27:02.098
  STEP: listing all ConfigMaps in test namespace @ 07/11/24 06:27:02.106
  I0711 06:27:02.109540 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5054" for this suite. @ 07/11/24 06:27:02.113
• [0.061 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 07/11/24 06:27:02.121
  I0711 06:27:02.121360 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 06:27:02.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:27:02.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:27:02.139
  STEP: Creating secret with name secret-test-d87a9236-98b8-44ed-8f2d-16c3bec4127f @ 07/11/24 06:27:02.16
  STEP: Creating a pod to test consume secrets @ 07/11/24 06:27:02.167
  E0711 06:27:02.527842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:03.527974      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:04.528846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:05.529052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:27:06.192
  I0711 06:27:06.197156 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-secrets-3e5bedf9-e558-4b6e-a883-ba623c957b67 container secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 06:27:06.214
  I0711 06:27:06.230543 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2101" for this suite. @ 07/11/24 06:27:06.234
  STEP: Destroying namespace "secret-namespace-7666" for this suite. @ 07/11/24 06:27:06.241
• [4.128 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 07/11/24 06:27:06.249
  I0711 06:27:06.249292 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 06:27:06.249
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:27:06.265
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:27:06.267
  STEP: Creating the pod @ 07/11/24 06:27:06.269
  E0711 06:27:06.529907      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:07.530113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:08.530321      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:27:08.816951 20 pod_client.go:141] Successfully updated pod "annotationupdate8def0239-6908-4665-9759-d5c2f8c52e11"
  E0711 06:27:09.530795      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:10.530915      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:11.531032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:12.531239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:27:12.840440 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5974" for this suite. @ 07/11/24 06:27:12.845
• [6.604 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 07/11/24 06:27:12.854
  I0711 06:27:12.854253 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename cronjob @ 07/11/24 06:27:12.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:27:12.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:27:12.874
  STEP: Creating a ForbidConcurrent cronjob @ 07/11/24 06:27:12.877
  STEP: Ensuring a job is scheduled @ 07/11/24 06:27:12.883
  E0711 06:27:13.531360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:14.531480      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:15.532445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:16.533113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:17.533228      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:18.533343      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:19.533437      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:20.533531      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:21.533630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:22.533831      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:23.534855      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:24.535045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:25.535703      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:26.536266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:27.536394      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:28.536502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:29.537107      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:30.537446      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:31.537600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:32.537826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:33.538765      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:34.538950      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:35.539072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:36.539262      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:37.539386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:38.539586      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:39.539895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:40.540012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:41.540852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:42.540985      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:43.541071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:44.541339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:45.541556      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:46.542232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:47.542469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:48.542566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:49.543121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:50.543206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:51.543305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:52.543392      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:53.543582      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:54.543671      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:55.543974      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:56.544541      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:57.545106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:58.545207      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:27:59.545298      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:00.545410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 07/11/24 06:28:00.889
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 07/11/24 06:28:00.892
  STEP: Ensuring no more jobs are scheduled @ 07/11/24 06:28:00.895
  STEP: Removing cronjob @ 07/11/24 06:28:00.899
  I0711 06:28:00.906429 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8252" for this suite. @ 07/11/24 06:28:00.91
• [48.063 seconds]
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 07/11/24 06:28:00.917
  I0711 06:28:00.917246 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pv @ 07/11/24 06:28:00.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:00.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:00.938
  STEP: Creating initial PV and PVC @ 07/11/24 06:28:00.94
  I0711 06:28:00.940675 20 pv.go:390] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-687" @ 07/11/24 06:28:00.955
  STEP: Listing PVCs in namespace "pv-687" @ 07/11/24 06:28:00.959
  STEP: Patching the PV "pv-687-fftkl" @ 07/11/24 06:28:00.964
  STEP: Patching the PVC "pvc-vz6g2" @ 07/11/24 06:28:00.974
  STEP: Getting PV "pv-687-fftkl" @ 07/11/24 06:28:00.987
  STEP: Getting PVC "pvc-vz6g2" @ 07/11/24 06:28:00.991
  STEP: Deleting PVC "pvc-vz6g2" @ 07/11/24 06:28:00.994
  STEP: Confirm deletion of PVC "pvc-vz6g2" @ 07/11/24 06:28:01.001
  E0711 06:28:01.546157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:02.546381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-687-fftkl" @ 07/11/24 06:28:03.01
  STEP: Confirm deletion of PV "pv-687-fftkl" @ 07/11/24 06:28:03.018
  STEP: Recreating another PV & PVC @ 07/11/24 06:28:03.133
  I0711 06:28:03.133166 20 pv.go:390] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-687-77ggg" @ 07/11/24 06:28:03.145
  STEP: Updating the PVC "pvc-7tv2d" @ 07/11/24 06:28:03.176
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-7tv2d=updated" @ 07/11/24 06:28:03.185
  STEP: Deleting PVC "pvc-7tv2d" via DeleteCollection @ 07/11/24 06:28:03.189
  STEP: Confirm deletion of PVC "pvc-7tv2d" @ 07/11/24 06:28:03.198
  E0711 06:28:03.547091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:04.547350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-687-77ggg" via DeleteCollection @ 07/11/24 06:28:05.208
  STEP: Confirm deletion of PV "pv-687-77ggg" @ 07/11/24 06:28:05.22
  E0711 06:28:05.547490      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:06.547705      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:07.228326 20 persistent_volumes.go:407] AfterEach: deleting 1 PVCs and 1 PVs...
  I0711 06:28:07.228356 20 pv.go:201] Deleting PersistentVolumeClaim "pvc-7tv2d"
  I0711 06:28:07.231950 20 pv.go:189] Deleting PersistentVolume "pv-687-77ggg"
  I0711 06:28:07.236600 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-687" for this suite. @ 07/11/24 06:28:07.24
• [6.330 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 07/11/24 06:28:07.248
  I0711 06:28:07.248377 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replicaset @ 07/11/24 06:28:07.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:07.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:07.265
  I0711 06:28:07.282580 20 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0711 06:28:07.547978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:08.548077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:09.548174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:10.548253      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:11.548512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:12.287184 20 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 07/11/24 06:28:12.287
  STEP: Scaling up "test-rs" replicaset @ 07/11/24 06:28:12.287
  I0711 06:28:12.297226 20 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 07/11/24 06:28:12.297
  I0711 06:28:12.306397 20 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-258 with ReadyReplicas 1, AvailableReplicas 1
  I0711 06:28:12.319325 20 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-258 with ReadyReplicas 1, AvailableReplicas 1
  I0711 06:28:12.332420 20 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-258 with ReadyReplicas 1, AvailableReplicas 1
  I0711 06:28:12.338586 20 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-258 with ReadyReplicas 1, AvailableReplicas 1
  E0711 06:28:12.549110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:13.354036 20 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-258 with ReadyReplicas 2, AvailableReplicas 2
  E0711 06:28:13.549326      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:13.754919 20 replica_set.go:545] observed Replicaset test-rs in namespace replicaset-258 with ReadyReplicas 3 found true
  I0711 06:28:13.755057 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-258" for this suite. @ 07/11/24 06:28:13.759
• [6.518 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 07/11/24 06:28:13.766
  I0711 06:28:13.766698 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 06:28:13.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:13.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:13.786
  STEP: Creating a ResourceQuota @ 07/11/24 06:28:13.788
  STEP: Getting a ResourceQuota @ 07/11/24 06:28:13.793
  STEP: Updating a ResourceQuota @ 07/11/24 06:28:13.799
  STEP: Verifying a ResourceQuota was modified @ 07/11/24 06:28:13.805
  STEP: Deleting a ResourceQuota @ 07/11/24 06:28:13.808
  STEP: Verifying the deleted ResourceQuota @ 07/11/24 06:28:13.815
  I0711 06:28:13.818243 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-309" for this suite. @ 07/11/24 06:28:13.821
• [0.062 seconds]
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 07/11/24 06:28:13.828
  I0711 06:28:13.828877 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:28:13.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:13.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:13.847
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 06:28:13.849
  E0711 06:28:14.550201      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:15.550406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:16.550589      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:17.550869      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:28:17.874
  I0711 06:28:17.878139 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod downwardapi-volume-39af0f19-2a37-4e23-aa12-271f3c9d8b74 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 06:28:17.885
  I0711 06:28:17.905063 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1170" for this suite. @ 07/11/24 06:28:17.908
• [4.087 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 07/11/24 06:28:17.916
  I0711 06:28:17.916292 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:28:17.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:17.933
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:17.935
  STEP: Setting up server cert @ 07/11/24 06:28:17.958
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:28:18.109
  STEP: Deploying the webhook pod @ 07/11/24 06:28:18.119
  STEP: Wait for the deployment to be ready @ 07/11/24 06:28:18.131
  I0711 06:28:18.139674 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:28:18.550954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:19.551429      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:28:20.153
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:28:20.166
  E0711 06:28:20.552160      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:21.167090 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 07/11/24 06:28:21.176
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 07/11/24 06:28:21.193
  STEP: Creating a configMap that should not be mutated @ 07/11/24 06:28:21.2
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 07/11/24 06:28:21.212
  STEP: Creating a configMap that should be mutated @ 07/11/24 06:28:21.22
  I0711 06:28:21.282454 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8168" for this suite. @ 07/11/24 06:28:21.286
  STEP: Destroying namespace "webhook-markers-1333" for this suite. @ 07/11/24 06:28:21.296
• [3.389 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 07/11/24 06:28:21.305
  I0711 06:28:21.305384 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename namespaces @ 07/11/24 06:28:21.305
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:21.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:21.322
  STEP: Updating Namespace "namespaces-346" @ 07/11/24 06:28:21.324
  I0711 06:28:21.332400 20 namespace.go:389] Namespace "namespaces-346" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"b5d2bce4-72e0-469e-9b87-8839b2fc22bf", "kubernetes.io/metadata.name":"namespaces-346", "namespaces-346":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0711 06:28:21.332483 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-346" for this suite. @ 07/11/24 06:28:21.335
• [0.038 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 07/11/24 06:28:21.343
  I0711 06:28:21.343136 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 06:28:21.343
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:21.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:21.359
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 07/11/24 06:28:21.361
  E0711 06:28:21.552924      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:22.553093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:23.554140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:24.554314      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:28:25.386
  I0711 06:28:25.390867 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-b8a4e019-34d7-4786-b431-9b1936a6e7e8 container test-container: <nil>
  STEP: delete the pod @ 07/11/24 06:28:25.401
  I0711 06:28:25.420452 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2896" for this suite. @ 07/11/24 06:28:25.424
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 07/11/24 06:28:25.434
  I0711 06:28:25.434452 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename aggregateddiscovery @ 07/11/24 06:28:25.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:25.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:25.451
  I0711 06:28:25.453717 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:28:25.554998      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:26.555071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:27.555188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:28.508035 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-1997" for this suite. @ 07/11/24 06:28:28.512
• [3.087 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 07/11/24 06:28:28.521
  I0711 06:28:28.521928 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replicaset @ 07/11/24 06:28:28.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:28.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:28.537
  STEP: Create a Replicaset @ 07/11/24 06:28:28.544
  STEP: Verify that the required pods have come up. @ 07/11/24 06:28:28.551
  I0711 06:28:28.554149 20 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0711 06:28:28.555240      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:29.555433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:30.555552      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:31.555702      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:32.555856      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:33.556611      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:33.558219 20 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 07/11/24 06:28:33.558
  STEP: Getting /status @ 07/11/24 06:28:33.558
  I0711 06:28:33.562268 20 replica_set.go:643] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 07/11/24 06:28:33.562
  I0711 06:28:33.572919 20 replica_set.go:663] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 07/11/24 06:28:33.572
  I0711 06:28:33.574405 20 replica_set.go:689] Observed &ReplicaSet event: ADDED
  I0711 06:28:33.574504 20 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0711 06:28:33.574638 20 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0711 06:28:33.574730 20 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0711 06:28:33.574747 20 replica_set.go:682] Found replicaset test-rs in namespace replicaset-9068 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0711 06:28:33.574764 20 replica_set.go:693] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 07/11/24 06:28:33.574
  I0711 06:28:33.574785 20 replica_set.go:697] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0711 06:28:33.581969 20 replica_set.go:701] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 07/11/24 06:28:33.582
  I0711 06:28:33.583357 20 replica_set.go:725] Observed &ReplicaSet event: ADDED
  I0711 06:28:33.583482 20 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0711 06:28:33.583599 20 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0711 06:28:33.583663 20 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0711 06:28:33.583679 20 replica_set.go:721] Observed replicaset test-rs in namespace replicaset-9068 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0711 06:28:33.583751 20 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0711 06:28:33.583767 20 replica_set.go:718] Found replicaset test-rs in namespace replicaset-9068 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0711 06:28:33.583794 20 replica_set.go:729] Replicaset test-rs has a patched status
  I0711 06:28:33.583902 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9068" for this suite. @ 07/11/24 06:28:33.587
• [5.074 seconds]
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 07/11/24 06:28:33.595
  I0711 06:28:33.595849 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename daemonsets @ 07/11/24 06:28:33.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:33.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:33.614
  STEP: Creating a simple DaemonSet "daemon-set" @ 07/11/24 06:28:33.636
  STEP: Check that daemon pods launch on every node of the cluster. @ 07/11/24 06:28:33.642
  I0711 06:28:33.648076 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:28:33.648102 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:28:33.651189 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 06:28:33.651206 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  E0711 06:28:34.556762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:34.647534 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:28:34.647599 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:28:34.651401 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0711 06:28:34.651418 20 fixtures.go:130] Node ip-172-31-17-237 is running 0 daemon pod, expected 1
  E0711 06:28:35.557087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:35.649058 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:28:35.649103 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:28:35.653394 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0711 06:28:35.653419 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 07/11/24 06:28:35.657
  I0711 06:28:35.675369 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:28:35.675402 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:28:35.681848 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0711 06:28:35.681865 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 07/11/24 06:28:35.681
  STEP: Deleting DaemonSet "daemon-set" @ 07/11/24 06:28:35.694
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1932, will wait for the garbage collector to delete the pods @ 07/11/24 06:28:35.694
  I0711 06:28:35.757225 20 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.66756ms
  I0711 06:28:35.857616 20 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.340996ms
  E0711 06:28:36.557386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:37.558130      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:37.763197 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 06:28:37.763227 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0711 06:28:37.766998 20 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22373"},"items":null}

  I0711 06:28:37.770673 20 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22373"},"items":null}

  I0711 06:28:37.783892 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1932" for this suite. @ 07/11/24 06:28:37.787
• [4.199 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 07/11/24 06:28:37.795
  I0711 06:28:37.795065 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename field-validation @ 07/11/24 06:28:37.795
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:37.808
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:37.811
  STEP: apply creating a deployment @ 07/11/24 06:28:37.813
  I0711 06:28:37.827378 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-793" for this suite. @ 07/11/24 06:28:37.83
• [0.042 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 07/11/24 06:28:37.837
  I0711 06:28:37.837283 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pod-network-test @ 07/11/24 06:28:37.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:37.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:37.854
  STEP: Performing setup for networking test in namespace pod-network-test-3650 @ 07/11/24 06:28:37.856
  STEP: creating a selector @ 07/11/24 06:28:37.856
  STEP: Creating the service pods in kubernetes @ 07/11/24 06:28:37.856
  I0711 06:28:37.856610 20 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0711 06:28:38.558276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:39.558463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:40.558777      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:41.559373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:42.559969      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:43.560094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:44.560153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:45.560254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:46.561094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:47.561394      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:48.561913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:49.562079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 07/11/24 06:28:49.944
  E0711 06:28:50.562204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:51.562338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:51.964807 20 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0711 06:28:51.964856 20 networking.go:42] Breadth first check of 192.168.122.71 on host 172.31.11.2...
  I0711 06:28:51.968592 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.37.26:9080/dial?request=hostname&protocol=udp&host=192.168.122.71&port=8081&tries=1'] Namespace:pod-network-test-3650 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:28:51.968616 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:28:51.969088 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:28:51.969155 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3650/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.37.26%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.122.71%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0711 06:28:52.014850 20 utils.go:331] Waiting for responses: map[]
  I0711 06:28:52.014881 20 utils.go:335] reached 192.168.122.71 after 0/1 tries
  I0711 06:28:52.014890 20 networking.go:42] Breadth first check of 192.168.133.102 on host 172.31.17.237...
  I0711 06:28:52.019481 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.37.26:9080/dial?request=hostname&protocol=udp&host=192.168.133.102&port=8081&tries=1'] Namespace:pod-network-test-3650 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:28:52.019501 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:28:52.019934 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:28:52.019993 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3650/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.37.26%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.133.102%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0711 06:28:52.066099 20 utils.go:331] Waiting for responses: map[]
  I0711 06:28:52.066125 20 utils.go:335] reached 192.168.133.102 after 0/1 tries
  I0711 06:28:52.066156 20 networking.go:42] Breadth first check of 192.168.37.21 on host 172.31.80.240...
  I0711 06:28:52.070373 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.37.26:9080/dial?request=hostname&protocol=udp&host=192.168.37.21&port=8081&tries=1'] Namespace:pod-network-test-3650 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:28:52.070394 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:28:52.070821 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:28:52.070903 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3650/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.37.26%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.37.21%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0711 06:28:52.121418 20 utils.go:331] Waiting for responses: map[]
  I0711 06:28:52.121453 20 utils.go:335] reached 192.168.37.21 after 0/1 tries
  I0711 06:28:52.121460 20 networking.go:53] Going to retry 0 out of 3 pods....
  I0711 06:28:52.121645 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3650" for this suite. @ 07/11/24 06:28:52.127
• [14.297 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 07/11/24 06:28:52.135
  I0711 06:28:52.135301 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename svcaccounts @ 07/11/24 06:28:52.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:52.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:52.153
  STEP: creating a ServiceAccount @ 07/11/24 06:28:52.155
  STEP: watching for the ServiceAccount to be added @ 07/11/24 06:28:52.162
  STEP: patching the ServiceAccount @ 07/11/24 06:28:52.163
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 07/11/24 06:28:52.169
  STEP: deleting the ServiceAccount @ 07/11/24 06:28:52.172
  I0711 06:28:52.189184 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5652" for this suite. @ 07/11/24 06:28:52.193
• [0.064 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 07/11/24 06:28:52.2
  I0711 06:28:52.200050 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replication-controller @ 07/11/24 06:28:52.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:52.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:52.217
  STEP: Creating replication controller my-hostname-basic-c771058c-b4c9-4890-9cf1-77aa94a9308b @ 07/11/24 06:28:52.22
  I0711 06:28:52.229570 20 resource.go:87] Pod name my-hostname-basic-c771058c-b4c9-4890-9cf1-77aa94a9308b: Found 0 pods out of 1
  E0711 06:28:52.563251      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:53.563369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:54.563461      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:55.563630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:56.564559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:28:57.233496 20 resource.go:87] Pod name my-hostname-basic-c771058c-b4c9-4890-9cf1-77aa94a9308b: Found 1 pods out of 1
  I0711 06:28:57.233528 20 rc.go:507] Ensuring all pods for ReplicationController "my-hostname-basic-c771058c-b4c9-4890-9cf1-77aa94a9308b" are running
  I0711 06:28:57.236354 20 rc.go:523] Pod "my-hostname-basic-c771058c-b4c9-4890-9cf1-77aa94a9308b-zws4x" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:28:53 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:28:52 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:28:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:28:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:28:52 +0000 UTC Reason: Message:}])
  I0711 06:28:57.236373 20 rc.go:531] Trying to dial the pod
  STEP: trying to dial each unique pod @ 07/11/24 06:28:57.236
  I0711 06:28:57.246984 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9463" for this suite. @ 07/11/24 06:28:57.249
• [5.056 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 07/11/24 06:28:57.256
  I0711 06:28:57.256224 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename dns @ 07/11/24 06:28:57.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:28:57.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:28:57.276
  STEP: Creating a test externalName service @ 07/11/24 06:28:57.279
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2667.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2667.svc.cluster.local; sleep 1; done
   @ 07/11/24 06:28:57.286
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2667.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2667.svc.cluster.local; sleep 1; done
   @ 07/11/24 06:28:57.286
  STEP: creating a pod to probe DNS @ 07/11/24 06:28:57.286
  STEP: submitting the pod to kubernetes @ 07/11/24 06:28:57.286
  E0711 06:28:57.565482      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:58.565662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:28:59.565769      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:00.565801      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:01.566010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:02.566106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:03.566620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:04.566651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:05.567475      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:06.568245      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 07/11/24 06:29:07.327
  STEP: looking for the results for each expected name from probers @ 07/11/24 06:29:07.331
  I0711 06:29:07.341331 20 dns_common.go:552] DNS probes using dns-test-262e5ba8-488c-4467-a9aa-ced2f65c7d4b succeeded

  STEP: changing the externalName to bar.example.com @ 07/11/24 06:29:07.341
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2667.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2667.svc.cluster.local; sleep 1; done
   @ 07/11/24 06:29:07.35
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2667.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2667.svc.cluster.local; sleep 1; done
   @ 07/11/24 06:29:07.35
  STEP: creating a second pod to probe DNS @ 07/11/24 06:29:07.35
  STEP: submitting the pod to kubernetes @ 07/11/24 06:29:07.351
  E0711 06:29:07.568406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:08.569037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 07/11/24 06:29:09.369
  STEP: looking for the results for each expected name from probers @ 07/11/24 06:29:09.374
  I0711 06:29:09.383936 20 dns_common.go:552] DNS probes using dns-test-a54b0ee1-8758-4ee6-ac3d-099991f12308 succeeded

  STEP: changing the service to type=ClusterIP @ 07/11/24 06:29:09.383
  W0711 06:29:09.400492      20 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2667.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2667.svc.cluster.local; sleep 1; done
   @ 07/11/24 06:29:09.4
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2667.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2667.svc.cluster.local; sleep 1; done
   @ 07/11/24 06:29:09.4
  STEP: creating a third pod to probe DNS @ 07/11/24 06:29:09.4
  STEP: submitting the pod to kubernetes @ 07/11/24 06:29:09.405
  E0711 06:29:09.569763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:10.569893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 07/11/24 06:29:11.425
  STEP: looking for the results for each expected name from probers @ 07/11/24 06:29:11.429
  I0711 06:29:11.439039 20 dns_common.go:552] DNS probes using dns-test-493594df-4dc0-4c71-8567-1cbfda6bc0d8 succeeded

  STEP: deleting the pod @ 07/11/24 06:29:11.439
  STEP: deleting the pod @ 07/11/24 06:29:11.452
  STEP: deleting the pod @ 07/11/24 06:29:11.473
  STEP: deleting the test externalName service @ 07/11/24 06:29:11.491
  I0711 06:29:11.511673 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2667" for this suite. @ 07/11/24 06:29:11.515
• [14.266 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 07/11/24 06:29:11.522
  I0711 06:29:11.522816 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename gc @ 07/11/24 06:29:11.523
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:29:11.537
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:29:11.539
  STEP: create the deployment @ 07/11/24 06:29:11.541
  W0711 06:29:11.547387      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 07/11/24 06:29:11.547
  STEP: delete the deployment @ 07/11/24 06:29:11.553
  STEP: wait for all rs to be garbage collected @ 07/11/24 06:29:11.563
  E0711 06:29:11.570694      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: expected 0 rs, got 1 rs @ 07/11/24 06:29:11.587
  STEP: expected 0 pods, got 2 pods @ 07/11/24 06:29:11.592
  STEP: Gathering metrics @ 07/11/24 06:29:12.074
  W0711 06:29:12.079176      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0711 06:29:12.079202 20 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0711 06:29:12.079345 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8301" for this suite. @ 07/11/24 06:29:12.083
• [0.570 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 07/11/24 06:29:12.092
  I0711 06:29:12.092730 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-watch @ 07/11/24 06:29:12.093
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:29:12.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:29:12.11
  I0711 06:29:12.113042 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:29:12.570861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:13.571751      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:14.572564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 07/11/24 06:29:14.647
  I0711 06:29:14.652221 20 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-07-11T06:29:14Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-07-11T06:29:14Z]] name:name1 resourceVersion:22796 uid:d9c73206-73e7-41e5-b33e-ec30028da5bb] num:map[num1:9223372036854775807 num2:1000000]]}
  E0711 06:29:15.572772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:16.572818      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:17.573087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:18.573205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:19.573473      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:20.573566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:21.573848      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:22.574801      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:23.574998      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:24.575106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 07/11/24 06:29:24.652
  I0711 06:29:24.659192 20 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-07-11T06:29:24Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-07-11T06:29:24Z]] name:name2 resourceVersion:22874 uid:f8018426-678f-4e92-91f6-d62366bec788] num:map[num1:9223372036854775807 num2:1000000]]}
  E0711 06:29:25.575325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:26.575529      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:27.575731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:28.575889      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:29.575963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:30.576032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:31.576150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:32.576254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:33.577159      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:34.577443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 07/11/24 06:29:34.659
  I0711 06:29:34.666329 20 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-07-11T06:29:14Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-07-11T06:29:34Z]] name:name1 resourceVersion:22894 uid:d9c73206-73e7-41e5-b33e-ec30028da5bb] num:map[num1:9223372036854775807 num2:1000000]]}
  E0711 06:29:35.578468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:36.579604      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:37.579857      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:38.579971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:39.580036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:40.581012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:41.581143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:42.581220      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:43.581395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:44.581618      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 07/11/24 06:29:44.666
  I0711 06:29:44.673944 20 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-07-11T06:29:24Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-07-11T06:29:44Z]] name:name2 resourceVersion:22915 uid:f8018426-678f-4e92-91f6-d62366bec788] num:map[num1:9223372036854775807 num2:1000000]]}
  E0711 06:29:45.582187      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:46.582266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:47.583239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:48.583402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:49.583507      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:50.583700      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:51.583940      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:52.584042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:53.585025      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:54.585231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 07/11/24 06:29:54.674
  I0711 06:29:54.683576 20 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-07-11T06:29:14Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-07-11T06:29:34Z]] name:name1 resourceVersion:22939 uid:d9c73206-73e7-41e5-b33e-ec30028da5bb] num:map[num1:9223372036854775807 num2:1000000]]}
  E0711 06:29:55.585552      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:56.586208      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:57.586393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:58.586616      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:29:59.586760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:00.586969      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:01.587316      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:02.587546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:03.587849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:04.587977      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 07/11/24 06:30:04.684
  I0711 06:30:04.693581 20 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-07-11T06:29:24Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-07-11T06:29:44Z]] name:name2 resourceVersion:22959 uid:f8018426-678f-4e92-91f6-d62366bec788] num:map[num1:9223372036854775807 num2:1000000]]}
  E0711 06:30:05.588064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:06.588911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:07.589126      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:08.589680      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:09.590028      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:10.590139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:11.590534      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:12.590724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:13.591000      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:14.591121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:30:15.210533 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-3558" for this suite. @ 07/11/24 06:30:15.215
• [63.131 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 07/11/24 06:30:15.223
  I0711 06:30:15.223507 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 06:30:15.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:30:15.239
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:30:15.242
  STEP: Creating resourceQuota "e2e-rq-status-cjzrz" @ 07/11/24 06:30:15.247
  I0711 06:30:15.254521 20 resource_quota.go:1051] Resource quota "e2e-rq-status-cjzrz" reports spec: hard cpu limit of 500m
  I0711 06:30:15.254543 20 resource_quota.go:1053] Resource quota "e2e-rq-status-cjzrz" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-cjzrz" /status @ 07/11/24 06:30:15.254
  STEP: Confirm /status for "e2e-rq-status-cjzrz" resourceQuota via watch @ 07/11/24 06:30:15.281
  I0711 06:30:15.282265 20 resource_quota.go:1080] observed resourceQuota "e2e-rq-status-cjzrz" in namespace "resourcequota-4905" with hard status: v1.ResourceList(nil)
  I0711 06:30:15.282319 20 resource_quota.go:1083] Found resourceQuota "e2e-rq-status-cjzrz" in namespace "resourcequota-4905" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0711 06:30:15.282335 20 resource_quota.go:1090] ResourceQuota "e2e-rq-status-cjzrz" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 07/11/24 06:30:15.285
  I0711 06:30:15.291067 20 resource_quota.go:1101] Resource quota "e2e-rq-status-cjzrz" reports spec: hard cpu limit of 1
  I0711 06:30:15.291088 20 resource_quota.go:1102] Resource quota "e2e-rq-status-cjzrz" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-cjzrz" /status @ 07/11/24 06:30:15.291
  STEP: Confirm /status for "e2e-rq-status-cjzrz" resourceQuota via watch @ 07/11/24 06:30:15.298
  I0711 06:30:15.299913 20 resource_quota.go:1124] observed resourceQuota "e2e-rq-status-cjzrz" in namespace "resourcequota-4905" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0711 06:30:15.299971 20 resource_quota.go:1127] Found resourceQuota "e2e-rq-status-cjzrz" in namespace "resourcequota-4905" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0711 06:30:15.300005 20 resource_quota.go:1134] ResourceQuota "e2e-rq-status-cjzrz" /status was patched
  STEP: Get "e2e-rq-status-cjzrz" /status @ 07/11/24 06:30:15.3
  I0711 06:30:15.303891 20 resource_quota.go:1145] Resourcequota "e2e-rq-status-cjzrz" reports status: hard cpu of 1
  I0711 06:30:15.303911 20 resource_quota.go:1147] Resourcequota "e2e-rq-status-cjzrz" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-cjzrz" /status before checking Spec is unchanged @ 07/11/24 06:30:15.307
  I0711 06:30:15.313601 20 resource_quota.go:1167] Resourcequota "e2e-rq-status-cjzrz" reports status: hard cpu of 2
  I0711 06:30:15.313622 20 resource_quota.go:1169] Resourcequota "e2e-rq-status-cjzrz" reports status: hard memory of 2Gi
  I0711 06:30:15.314722 20 resource_quota.go:1181] Found resourceQuota "e2e-rq-status-cjzrz" in namespace "resourcequota-4905" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0711 06:30:15.318229 20 resource_quota.go:1212] ResourceQuota "e2e-rq-status-cjzrz" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-cjzrz", GenerateName:"", Namespace:"resourcequota-4905", SelfLink:"", UID:"35c673f5-2f21-442f-90ce-dbccbcd4f15e", ResourceVersion:"22997", Generation:0, CreationTimestamp:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-cjzrz"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73920), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73950), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73980), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0711 06:30:15.591888      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:16.592163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:17.592254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:18.593007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:19.593108      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:30:20.318833 20 resource_quota.go:1212] ResourceQuota "e2e-rq-status-cjzrz" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-cjzrz", GenerateName:"", Namespace:"resourcequota-4905", SelfLink:"", UID:"35c673f5-2f21-442f-90ce-dbccbcd4f15e", ResourceVersion:"22997", Generation:0, CreationTimestamp:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-cjzrz"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73b00), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73b48), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73b78), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0711 06:30:20.594161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:21.594603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:22.594762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:23.595331      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:24.595428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:30:25.319945 20 resource_quota.go:1212] ResourceQuota "e2e-rq-status-cjzrz" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-cjzrz", GenerateName:"", Namespace:"resourcequota-4905", SelfLink:"", UID:"35c673f5-2f21-442f-90ce-dbccbcd4f15e", ResourceVersion:"22997", Generation:0, CreationTimestamp:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-cjzrz"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73cf8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73d28), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73d58), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0711 06:30:25.596497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:26.596559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:27.596756      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:28.597023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:29.597137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:30:30.320261 20 resource_quota.go:1212] ResourceQuota "e2e-rq-status-cjzrz" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-cjzrz", GenerateName:"", Namespace:"resourcequota-4905", SelfLink:"", UID:"35c673f5-2f21-442f-90ce-dbccbcd4f15e", ResourceVersion:"22997", Generation:0, CreationTimestamp:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-cjzrz"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00515e468), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00515e4b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00515e4f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0711 06:30:30.597594      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:31.598060      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:32.598240      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:33.598485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:34.598630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:30:35.320056 20 resource_quota.go:1212] ResourceQuota "e2e-rq-status-cjzrz" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-cjzrz", GenerateName:"", Namespace:"resourcequota-4905", SelfLink:"", UID:"35c673f5-2f21-442f-90ce-dbccbcd4f15e", ResourceVersion:"22997", Generation:0, CreationTimestamp:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-cjzrz"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f73f68), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f42060), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004f420a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0711 06:30:35.599576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:36.599777      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:37.600031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:38.600104      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:39.601074      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:30:40.319299 20 resource_quota.go:1212] ResourceQuota "e2e-rq-status-cjzrz" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-cjzrz", GenerateName:"", Namespace:"resourcequota-4905", SelfLink:"", UID:"35c673f5-2f21-442f-90ce-dbccbcd4f15e", ResourceVersion:"22997", Generation:0, CreationTimestamp:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-cjzrz"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00515e840), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00515e8a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 6, 30, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00515e8e8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0711 06:30:40.601719      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:41.601958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:42.602090      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:43.602279      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:44.602452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:30:45.319929 20 resource_quota.go:1209] ResourceQuota "e2e-rq-status-cjzrz" Spec was unchanged and /status reset
  I0711 06:30:45.320037 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4905" for this suite. @ 07/11/24 06:30:45.324
• [30.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 07/11/24 06:30:45.338
  I0711 06:30:45.338144 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-preemption @ 07/11/24 06:30:45.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:30:45.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:30:45.358
  I0711 06:30:45.375880 20 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0711 06:30:45.602997      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:46.603071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:47.603352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:48.603488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:49.603796      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:50.603958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:51.604675      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:52.605080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:53.605433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:54.605696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:55.605923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:56.606167      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:57.606828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:58.607087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:30:59.607710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:00.607973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:01.608685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:02.609011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:03.609719      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:04.610013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:05.610734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:06.610903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:07.611685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:08.611951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:09.612519      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:10.613031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:11.613973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:12.614163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:13.614592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:14.614816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:15.615353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:16.615604      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:17.615718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:18.615956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:19.616678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:20.617241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:21.617996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:22.618960      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:23.619952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:24.620052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:25.620793      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:26.621013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:27.621562      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:28.621661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:29.622414      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:30.622502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:31.623242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:32.623475      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:33.623637      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:34.623861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:35.624602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:36.625013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:37.625577      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:38.625817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:39.626852      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:40.626947      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:41.627641      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:42.628261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:43.628502      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:44.629173      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:31:45.381620 20 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 07/11/24 06:31:45.385
  I0711 06:31:45.385582 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-preemption-path @ 07/11/24 06:31:45.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:31:45.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:31:45.405
  I0711 06:31:45.426652 20 preemption.go:818] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0711 06:31:45.430189 20 preemption.go:824] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  I0711 06:31:45.508750 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-1139" for this suite. @ 07/11/24 06:31:45.512
  I0711 06:31:45.521190 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1173" for this suite. @ 07/11/24 06:31:45.524
• [60.193 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 07/11/24 06:31:45.531
  I0711 06:31:45.531092 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 06:31:45.531
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:31:45.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:31:45.549
  STEP: creating secret secrets-1619/secret-test-d3f549e2-4920-411f-86f3-964867190c85 @ 07/11/24 06:31:45.551
  STEP: Creating a pod to test consume secrets @ 07/11/24 06:31:45.56
  E0711 06:31:45.629592      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:46.629793      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:47.630121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:48.630301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:31:49.583
  I0711 06:31:49.587053 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-configmaps-48bcfab5-c69e-4120-b02b-a904da52e74e container env-test: <nil>
  STEP: delete the pod @ 07/11/24 06:31:49.601
  I0711 06:31:49.617392 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1619" for this suite. @ 07/11/24 06:31:49.62
• [4.098 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 07/11/24 06:31:49.629
  I0711 06:31:49.629486 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename watch @ 07/11/24 06:31:49.63
  E0711 06:31:49.630239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:31:49.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:31:49.646
  STEP: getting a starting resourceVersion @ 07/11/24 06:31:49.648
  STEP: starting a background goroutine to produce watch events @ 07/11/24 06:31:49.654
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 07/11/24 06:31:49.654
  E0711 06:31:50.630844      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:51.630846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:31:52.436161 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2449" for this suite. @ 07/11/24 06:31:52.485
• [2.910 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 07/11/24 06:31:52.54
  I0711 06:31:52.540590 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 06:31:52.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:31:52.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:31:52.557
  E0711 06:31:52.631854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:53.632433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:54.632514      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:55.633558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:56.634158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:57.634203      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:58.634662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:31:59.635075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:00.635379      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:01.636445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:02.637381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:03.637609      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:04.638649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:05.639630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:06.640713      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:07.640805      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:08.641030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:09.641143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:10.641314      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:11.641355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:12.642429      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:13.642785      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:14.642875      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:15.643507      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:16.643705      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:17.644035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:18.644122      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:19.644598      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:20.644693      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:21.644966      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:22.646040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:23.646346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:24.646547      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:25.647445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:26.648436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:27.648537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:28.648633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:29.648763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:30.648860      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:31.649064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:32.649174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:33.649285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:34.649398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:35.650389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:36.650508      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:37.650759      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:38.650937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:39.651832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:40.651995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:41.652076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:42.652168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:43.652293      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:44.653034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:45.653359      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:46.653821      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:47.653909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:48.654919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:49.655148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:50.655253      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:51.655720      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:32:52.574050 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5336" for this suite. @ 07/11/24 06:32:52.578
• [60.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 07/11/24 06:32:52.585
  I0711 06:32:52.586002 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename watch @ 07/11/24 06:32:52.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:32:52.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:32:52.606
  STEP: creating a watch on configmaps with label A @ 07/11/24 06:32:52.609
  STEP: creating a watch on configmaps with label B @ 07/11/24 06:32:52.61
  STEP: creating a watch on configmaps with label A or B @ 07/11/24 06:32:52.611
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 07/11/24 06:32:52.612
  I0711 06:32:52.616982 20 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9314  85b987fa-1e56-4737-acaa-5c55dba9a063 23547 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 06:32:52.617082 20 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9314  85b987fa-1e56-4737-acaa-5c55dba9a063 23547 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 07/11/24 06:32:52.617
  I0711 06:32:52.624913 20 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9314  85b987fa-1e56-4737-acaa-5c55dba9a063 23548 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 06:32:52.625044 20 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9314  85b987fa-1e56-4737-acaa-5c55dba9a063 23548 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 07/11/24 06:32:52.625
  I0711 06:32:52.633258 20 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9314  85b987fa-1e56-4737-acaa-5c55dba9a063 23549 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 06:32:52.633441 20 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9314  85b987fa-1e56-4737-acaa-5c55dba9a063 23549 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 07/11/24 06:32:52.633
  I0711 06:32:52.640178 20 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9314  85b987fa-1e56-4737-acaa-5c55dba9a063 23550 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 06:32:52.640205 20 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9314  85b987fa-1e56-4737-acaa-5c55dba9a063 23550 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 07/11/24 06:32:52.64
  I0711 06:32:52.644830 20 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9314  2772de04-7ff7-4e58-b1d7-5f1791352d6e 23551 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 06:32:52.644972 20 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9314  2772de04-7ff7-4e58-b1d7-5f1791352d6e 23551 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0711 06:32:52.655979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:53.657073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:54.657180      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:55.657411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:56.657636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:57.657784      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:58.657979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:32:59.658214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:00.658371      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:01.659239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 07/11/24 06:33:02.645
  I0711 06:33:02.654046 20 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9314  2772de04-7ff7-4e58-b1d7-5f1791352d6e 23589 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 06:33:02.654081 20 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9314  2772de04-7ff7-4e58-b1d7-5f1791352d6e 23589 0 2024-07-11 06:32:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-07-11 06:32:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0711 06:33:02.659288      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:03.659546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:04.659896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:05.660774      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:06.660833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:07.660984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:08.661082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:09.661146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:10.661347      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:11.661467      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:12.654684 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9314" for this suite. @ 07/11/24 06:33:12.66
  E0711 06:33:12.662314      20 retrywatcher.go:129] "Watch failed" err="context canceled"
• [20.082 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 07/11/24 06:33:12.668
  I0711 06:33:12.668359 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:33:12.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:33:12.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:33:12.687
  STEP: Creating configMap with name configmap-projected-all-test-volume-421c8d93-d738-4619-a346-911162ad428d @ 07/11/24 06:33:12.689
  STEP: Creating secret with name secret-projected-all-test-volume-956e03bd-710d-4bef-9f06-f5e2c0731489 @ 07/11/24 06:33:12.694
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 07/11/24 06:33:12.698
  E0711 06:33:13.662866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:14.663241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:15.663482      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:16.663569      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:33:16.73
  I0711 06:33:16.734437 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod projected-volume-0247fd5c-46fb-4cf1-b916-c44e60e344e2 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 06:33:16.741
  I0711 06:33:16.758324 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2273" for this suite. @ 07/11/24 06:33:16.762
• [4.102 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:850
  STEP: Creating a kubernetes client @ 07/11/24 06:33:16.77
  I0711 06:33:16.770513 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 06:33:16.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:33:16.785
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:33:16.787
  STEP: creating service multi-endpoint-test in namespace services-7613 @ 07/11/24 06:33:16.789
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7613 to expose endpoints map[] @ 07/11/24 06:33:16.804
  I0711 06:33:16.814667 20 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-7613 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-7613 @ 07/11/24 06:33:16.814
  E0711 06:33:17.663680      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:18.663920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7613 to expose endpoints map[pod1:[100]] @ 07/11/24 06:33:18.833
  I0711 06:33:18.845281 20 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-7613 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-7613 @ 07/11/24 06:33:18.845
  E0711 06:33:19.663996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:20.664085      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7613 to expose endpoints map[pod1:[100] pod2:[101]] @ 07/11/24 06:33:20.868
  I0711 06:33:20.883330 20 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-7613 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 07/11/24 06:33:20.883
  I0711 06:33:20.883380 20 resource.go:361] Creating new exec pod
  E0711 06:33:21.664589      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:22.665263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:23.665375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:23.908021 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-7613 exec execpodckvhp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I0711 06:33:24.002642 20 builder.go:146] stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  I0711 06:33:24.002682 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:33:24.002858 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-7613 exec execpodckvhp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.82 80'
  I0711 06:33:24.085162 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.82 80\nConnection to 10.152.183.82 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0711 06:33:24.085222 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:33:24.085395 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-7613 exec execpodckvhp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0711 06:33:24.175022 20 builder.go:146] stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  I0711 06:33:24.175077 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:33:24.175251 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-7613 exec execpodckvhp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.82 81'
  I0711 06:33:24.261780 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.82 81\n+ echo hostName\nConnection to 10.152.183.82 81 port [tcp/*] succeeded!\n"
  I0711 06:33:24.261835 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-7613 @ 07/11/24 06:33:24.261
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7613 to expose endpoints map[pod2:[101]] @ 07/11/24 06:33:24.282
  E0711 06:33:24.665496      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:25.304833 20 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-7613 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-7613 @ 07/11/24 06:33:25.304
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7613 to expose endpoints map[] @ 07/11/24 06:33:25.322
  I0711 06:33:25.330592 20 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-7613 exposes endpoints map[]
  I0711 06:33:25.348519 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7613" for this suite. @ 07/11/24 06:33:25.355
• [8.591 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 07/11/24 06:33:25.361
  I0711 06:33:25.361705 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename statefulset @ 07/11/24 06:33:25.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:33:25.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:33:25.378
  STEP: Creating service test in namespace statefulset-611 @ 07/11/24 06:33:25.38
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 07/11/24 06:33:25.384
  STEP: Creating stateful set ss in namespace statefulset-611 @ 07/11/24 06:33:25.392
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-611 @ 07/11/24 06:33:25.398
  I0711 06:33:25.403351 20 wait.go:40] Found 0 stateful pods, waiting for 1
  E0711 06:33:25.665723      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:26.666404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:27.667417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:28.667695      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:29.667836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:30.668017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:31.668077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:32.669026      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:33.669228      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:34.669438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:35.405455 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 07/11/24 06:33:35.405
  I0711 06:33:35.412099 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-611 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0711 06:33:35.509162 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 06:33:35.509225 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 06:33:35.509235 20 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0711 06:33:35.513613 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0711 06:33:35.670021      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:36.670108      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:37.670352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:38.670665      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:39.670873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:40.670990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:41.671195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:42.671417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:43.671537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:44.671642      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:45.514009 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0711 06:33:45.514051 20 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0711 06:33:45.534297 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 9.999999725s
  E0711 06:33:45.672651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:46.540201 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 8.99307502s
  E0711 06:33:46.673372      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:47.545808 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 7.987018777s
  E0711 06:33:47.674009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:48.550388 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 6.982008084s
  E0711 06:33:48.674633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:49.555533 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 5.977412501s
  E0711 06:33:49.674832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:50.561409 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 4.972162425s
  E0711 06:33:50.675681      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:51.566943 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 3.966472233s
  E0711 06:33:51.676345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:52.572350 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 2.960653793s
  E0711 06:33:52.676722      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:53.577715 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 1.955538508s
  E0711 06:33:53.676890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:54.582879 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 950.088733ms
  E0711 06:33:54.677148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-611 @ 07/11/24 06:33:55.583
  I0711 06:33:55.588707 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-611 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0711 06:33:55.677227      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:33:55.682128 20 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0711 06:33:55.682168 20 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0711 06:33:55.682178 20 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0711 06:33:55.686444 20 wait.go:40] Found 1 stateful pods, waiting for 3
  E0711 06:33:56.677392      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:57.678361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:58.678548      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:33:59.678673      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:00.678790      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:01.679002      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:02.679236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:03.679412      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:04.680306      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:05.680573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:05.688141 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0711 06:34:05.688174 20 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0711 06:34:05.688181 20 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 07/11/24 06:34:05.688
  STEP: Scale down will halt with unhealthy stateful pod @ 07/11/24 06:34:05.688
  I0711 06:34:05.695877 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-611 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0711 06:34:05.782007 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 06:34:05.782047 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 06:34:05.782056 20 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0711 06:34:05.782098 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-611 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0711 06:34:05.872388 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 06:34:05.872425 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 06:34:05.872435 20 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0711 06:34:05.872566 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-611 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0711 06:34:05.978465 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 06:34:05.978508 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 06:34:05.978517 20 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0711 06:34:05.978526 20 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0711 06:34:05.982172 20 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0711 06:34:06.681549      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:07.681767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:08.681983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:09.682061      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:10.682198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:11.683146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:12.683311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:13.683404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:14.683462      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:15.683795      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:15.987833 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0711 06:34:15.987860 20 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0711 06:34:15.987866 20 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0711 06:34:16.002118 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 9.999999806s
  E0711 06:34:16.683951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:17.007703 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 8.996408063s
  E0711 06:34:17.684046      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:18.013913 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 7.990078115s
  E0711 06:34:18.685044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:19.019301 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 6.983929218s
  E0711 06:34:19.685237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:20.025182 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 5.978983622s
  E0711 06:34:20.685847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:21.029514 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 4.973368819s
  E0711 06:34:21.686576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:22.034914 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 3.968554785s
  E0711 06:34:22.687654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:23.039483 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 2.963528212s
  E0711 06:34:23.687978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:24.045666 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 1.958089936s
  E0711 06:34:24.688055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:25.050990 20 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 951.981017ms
  E0711 06:34:25.688589      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-611 @ 07/11/24 06:34:26.051
  I0711 06:34:26.056115 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-611 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0711 06:34:26.153539 20 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0711 06:34:26.153595 20 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0711 06:34:26.153607 20 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0711 06:34:26.153651 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-611 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0711 06:34:26.273729 20 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0711 06:34:26.273775 20 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0711 06:34:26.273785 20 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0711 06:34:26.273830 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-611 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0711 06:34:26.392537 20 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0711 06:34:26.392615 20 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0711 06:34:26.392629 20 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0711 06:34:26.392639 20 rest.go:150] Scaling statefulset ss to 0
  E0711 06:34:26.689524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:27.689700      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:28.690513      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:29.690570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:30.690670      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:31.691115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:32.691259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:33.691451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:34.691608      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:35.692508      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 07/11/24 06:34:36.403
  I0711 06:34:36.403638 20 statefulset.go:135] Deleting all statefulset in ns statefulset-611
  I0711 06:34:36.407026 20 rest.go:150] Scaling statefulset ss to 0
  I0711 06:34:36.413226 20 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0711 06:34:36.417573 20 rest.go:88] Deleting statefulset ss
  I0711 06:34:36.431400 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-611" for this suite. @ 07/11/24 06:34:36.435
• [71.082 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 07/11/24 06:34:36.443
  I0711 06:34:36.443412 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 06:34:36.443
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:34:36.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:34:36.459
  STEP: creating the pod @ 07/11/24 06:34:36.462
  STEP: submitting the pod to kubernetes @ 07/11/24 06:34:36.462
  W0711 06:34:36.472067      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0711 06:34:36.693237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:37.693284      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 07/11/24 06:34:38.485
  STEP: updating the pod @ 07/11/24 06:34:38.489
  E0711 06:34:38.694131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:39.003580 20 pod_client.go:141] Successfully updated pod "pod-update-activedeadlineseconds-edb15578-d01d-4556-90e4-f2e47146f6f8"
  E0711 06:34:39.694837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:40.694939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:41.695893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:42.696149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:43.019388 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2731" for this suite. @ 07/11/24 06:34:43.023
• [6.587 seconds]
------------------------------
SS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:697
  STEP: Creating a kubernetes client @ 07/11/24 06:34:43.03
  I0711 06:34:43.030379 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename job @ 07/11/24 06:34:43.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:34:43.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:34:43.045
  STEP: Creating a job @ 07/11/24 06:34:43.048
  STEP: Ensuring active pods == parallelism @ 07/11/24 06:34:43.055
  E0711 06:34:43.696249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:44.697024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 07/11/24 06:34:45.061
  I0711 06:34:45.579780 20 pod_client.go:141] Successfully updated pod "adopt-release-fr9c9"
  STEP: Checking that the Job readopts the Pod @ 07/11/24 06:34:45.579
  E0711 06:34:45.697355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:46.697431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 07/11/24 06:34:47.589
  E0711 06:34:47.697827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:48.103763 20 pod_client.go:141] Successfully updated pod "adopt-release-fr9c9"
  STEP: Checking that the Job releases the Pod @ 07/11/24 06:34:48.103
  E0711 06:34:48.698195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:49.698536      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:34:50.113834 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8781" for this suite. @ 07/11/24 06:34:50.118
• [7.096 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 07/11/24 06:34:50.126
  I0711 06:34:50.126474 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 06:34:50.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:34:50.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:34:50.145
  STEP: Counting existing ResourceQuota @ 07/11/24 06:34:50.147
  E0711 06:34:50.699519      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:51.699650      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:52.699775      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:53.700180      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:54.700303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 07/11/24 06:34:55.166
  STEP: Ensuring resource quota status is calculated @ 07/11/24 06:34:55.179
  E0711 06:34:55.700806      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:56.700925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 07/11/24 06:34:57.183
  STEP: Ensuring resource quota status captures replicaset creation @ 07/11/24 06:34:57.196
  E0711 06:34:57.701679      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:34:58.701941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 07/11/24 06:34:59.201
  STEP: Ensuring resource quota status released usage @ 07/11/24 06:34:59.209
  E0711 06:34:59.702053      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:00.702261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:35:01.214606 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7670" for this suite. @ 07/11/24 06:35:01.218
• [11.100 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 07/11/24 06:35:01.226
  I0711 06:35:01.226526 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename containers @ 07/11/24 06:35:01.227
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:01.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:01.248
  STEP: Creating a pod to test override all @ 07/11/24 06:35:01.254
  E0711 06:35:01.702362      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:02.702469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:03.702676      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:04.703342      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:35:05.285
  I0711 06:35:05.290145 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod client-containers-1d79ff44-b2ae-4607-9e3f-6423793b8006 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:35:05.3
  I0711 06:35:05.315384 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-1131" for this suite. @ 07/11/24 06:35:05.319
• [4.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 07/11/24 06:35:05.328
  I0711 06:35:05.328656 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename csiinlinevolumes @ 07/11/24 06:35:05.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:05.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:05.346
  STEP: Creating two CSIDrivers @ 07/11/24 06:35:05.349
  STEP: Getting "inline-driver-ce98b49d-f318-4818-89a1-9221d54a71a5" & "inline-driver-d11f0a77-4106-497d-9669-de5a43e283fb" @ 07/11/24 06:35:05.367
  STEP: Patching the CSIDriver "inline-driver-d11f0a77-4106-497d-9669-de5a43e283fb" @ 07/11/24 06:35:05.373
  STEP: Updating the CSIDriver "inline-driver-d11f0a77-4106-497d-9669-de5a43e283fb" @ 07/11/24 06:35:05.38
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-5438" @ 07/11/24 06:35:05.388
  STEP: Deleting CSIDriver "inline-driver-ce98b49d-f318-4818-89a1-9221d54a71a5" @ 07/11/24 06:35:05.392
  STEP: Confirm deletion of CSIDriver "inline-driver-ce98b49d-f318-4818-89a1-9221d54a71a5" @ 07/11/24 06:35:05.398
  STEP: Deleting CSIDriver "inline-driver-d11f0a77-4106-497d-9669-de5a43e283fb" via DeleteCollection @ 07/11/24 06:35:05.401
  STEP: Confirm deletion of CSIDriver "inline-driver-d11f0a77-4106-497d-9669-de5a43e283fb" @ 07/11/24 06:35:05.409
  I0711 06:35:05.413541 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5438" for this suite. @ 07/11/24 06:35:05.416
• [0.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 07/11/24 06:35:05.425
  I0711 06:35:05.425497 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:35:05.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:05.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:05.441
  STEP: Setting up server cert @ 07/11/24 06:35:05.467
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:35:05.563
  STEP: Deploying the webhook pod @ 07/11/24 06:35:05.573
  STEP: Wait for the deployment to be ready @ 07/11/24 06:35:05.587
  I0711 06:35:05.595975 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:35:05.704148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:06.704312      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:35:07.609
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:35:07.622
  E0711 06:35:07.704497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:35:08.622443 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 07/11/24 06:35:08.63
  STEP: create a pod @ 07/11/24 06:35:08.643
  E0711 06:35:08.705028      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:09.705670      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 07/11/24 06:35:10.659
  I0711 06:35:10.659875 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=webhook-5209 attach --namespace=webhook-5209 to-be-attached-pod -i -c=container1'
  E0711 06:35:10.706260      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:35:10.711717 20 builder.go:135] rc: 1
  I0711 06:35:10.770225 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5209" for this suite. @ 07/11/24 06:35:10.776
  STEP: Destroying namespace "webhook-markers-7892" for this suite. @ 07/11/24 06:35:10.783
• [5.365 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 07/11/24 06:35:10.79
  I0711 06:35:10.790788 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 06:35:10.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:10.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:10.808
  E0711 06:35:11.706542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:12.706771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:13.706849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:14.707059      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:15.707442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:16.709967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:17.710138      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:18.710847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:19.710961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:20.711117      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:21.711211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:22.711326      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:23.711545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:24.711609      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:25.712595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:26.713354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:27.713441      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 07/11/24 06:35:27.815
  E0711 06:35:28.714065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:29.714817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:30.715150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:31.715363      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:32.715952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 07/11/24 06:35:32.82
  STEP: Ensuring resource quota status is calculated @ 07/11/24 06:35:32.826
  E0711 06:35:33.716081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:34.716182      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 07/11/24 06:35:34.831
  STEP: Ensuring resource quota status captures configMap creation @ 07/11/24 06:35:34.841
  E0711 06:35:35.716313      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:36.717063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 07/11/24 06:35:36.846
  STEP: Ensuring resource quota status released usage @ 07/11/24 06:35:36.854
  E0711 06:35:37.717546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:38.717745      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:35:38.859547 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2131" for this suite. @ 07/11/24 06:35:38.864
• [28.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 07/11/24 06:35:38.872
  I0711 06:35:38.872978 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 07/11/24 06:35:38.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:38.887
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:38.89
  STEP: create the container to handle the HTTPGet hook request. @ 07/11/24 06:35:38.896
  E0711 06:35:39.718081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:40.718291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 07/11/24 06:35:40.92
  E0711 06:35:41.718332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:42.718542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 07/11/24 06:35:42.939
  STEP: delete the pod with lifecycle hook @ 07/11/24 06:35:42.947
  E0711 06:35:43.718749      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:44.718881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:35:44.965856 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-426" for this suite. @ 07/11/24 06:35:44.969
• [6.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 07/11/24 06:35:44.977
  I0711 06:35:44.977355 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-webhook @ 07/11/24 06:35:44.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:44.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:45.001
  STEP: Setting up server cert @ 07/11/24 06:35:45.003
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 07/11/24 06:35:45.156
  STEP: Deploying the custom resource conversion webhook pod @ 07/11/24 06:35:45.167
  STEP: Wait for the deployment to be ready @ 07/11/24 06:35:45.18
  I0711 06:35:45.187986 20 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0711 06:35:45.719456      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:46.719568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:35:47.201
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:35:47.213
  E0711 06:35:47.719743      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:35:48.214114 20 util.go:427] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0711 06:35:48.224041 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:35:48.719970      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:49.720493      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:50.721109      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 07/11/24 06:35:50.773
  STEP: v2 custom resource should be converted @ 07/11/24 06:35:50.779
  I0711 06:35:51.349429 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-5886" for this suite. @ 07/11/24 06:35:51.353
• [6.383 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 07/11/24 06:35:51.36
  I0711 06:35:51.360343 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 06:35:51.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:51.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:51.377
  STEP: Creating configMap with name configmap-test-volume-22c21009-6ef5-46ce-806f-51c66cab2312 @ 07/11/24 06:35:51.379
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:35:51.384
  E0711 06:35:51.721744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:52.722040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:53.722552      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:54.722626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:35:55.411
  I0711 06:35:55.415058 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-configmaps-b4926a3c-bd98-43e2-b729-24778634998c container configmap-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 06:35:55.422
  I0711 06:35:55.439021 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9689" for this suite. @ 07/11/24 06:35:55.442
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 07/11/24 06:35:55.45
  I0711 06:35:55.450565 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 06:35:55.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:55.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:55.469
  STEP: Creating configMap with name configmap-test-upd-894b0782-d541-4c2f-b917-7824f58af97a @ 07/11/24 06:35:55.476
  STEP: Creating the pod @ 07/11/24 06:35:55.48
  E0711 06:35:55.722726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:56.722809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 07/11/24 06:35:57.501
  STEP: Waiting for pod with binary data @ 07/11/24 06:35:57.508
  I0711 06:35:57.515001 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7314" for this suite. @ 07/11/24 06:35:57.519
• [2.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 07/11/24 06:35:57.529
  I0711 06:35:57.529824 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename endpointslice @ 07/11/24 06:35:57.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:57.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:57.547
  I0711 06:35:57.594733 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7236" for this suite. @ 07/11/24 06:35:57.598
• [0.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 07/11/24 06:35:57.606
  I0711 06:35:57.606326 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-pred @ 07/11/24 06:35:57.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:35:57.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:35:57.624
  I0711 06:35:57.626662 20 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0711 06:35:57.634526 20 util.go:400] Waiting for terminating namespaces to be deleted...
  I0711 06:35:57.637690 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-11-2 before test
  I0711 06:35:57.643079 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-vst4d from ingress-nginx-kubernetes-worker started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.643093 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 06:35:57.643101 20 predicates.go:887] calico-node-9r7js from kube-system started at 2024-07-11 05:31:26 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.643107 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 06:35:57.643112 20 predicates.go:887] coredns-5c6d979c47-sb7z6 from kube-system started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.643185 20 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0711 06:35:57.643244 20 predicates.go:887] kube-state-metrics-77cc559b76-46cmg from kube-system started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.643304 20 predicates.go:889] 	Container kube-state-metrics ready: true, restart count 1
  I0711 06:35:57.643343 20 predicates.go:887] metrics-server-v0.7.0-7995f698bf-5zlw4 from kube-system started at 2024-07-11 05:25:49 +0000 UTC (2 container statuses recorded)
  I0711 06:35:57.643399 20 predicates.go:889] 	Container metrics-server ready: true, restart count 0
  I0711 06:35:57.643430 20 predicates.go:889] 	Container metrics-server-nanny ready: true, restart count 0
  I0711 06:35:57.643497 20 predicates.go:887] dashboard-metrics-scraper-55584b484c-j4mdq from kubernetes-dashboard started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.643527 20 predicates.go:889] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I0711 06:35:57.643579 20 predicates.go:887] kubernetes-dashboard-6fd7bf4447-4xclp from kubernetes-dashboard started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.643622 20 predicates.go:889] 	Container kubernetes-dashboard ready: true, restart count 1
  I0711 06:35:57.643631 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-fccgk from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 06:35:57.643636 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 06:35:57.643642 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0711 06:35:57.643648 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-17-237 before test
  I0711 06:35:57.648770 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-7fjdd from ingress-nginx-kubernetes-worker started at 2024-07-11 05:31:54 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.648788 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 06:35:57.648795 20 predicates.go:887] calico-node-795zl from kube-system started at 2024-07-11 05:31:35 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.648800 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 06:35:57.648806 20 predicates.go:887] sonobuoy-e2e-job-46eff94557cb4446 from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 06:35:57.648810 20 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0711 06:35:57.648814 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 06:35:57.648820 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-ll2lq from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 06:35:57.648824 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 06:35:57.648830 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0711 06:35:57.648835 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-80-240 before test
  I0711 06:35:57.653585 20 predicates.go:887] pod-configmaps-3cbaa94c-5622-426a-b612-ae56760783a7 from configmap-7314 started at 2024-07-11 06:35:55 +0000 UTC (2 container statuses recorded)
  I0711 06:35:57.653599 20 predicates.go:889] 	Container agnhost-container ready: true, restart count 0
  I0711 06:35:57.653605 20 predicates.go:889] 	Container configmap-volume-binary-test ready: false, restart count 0
  I0711 06:35:57.653611 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-w7fxm from ingress-nginx-kubernetes-worker started at 2024-07-11 06:25:51 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.653617 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 06:35:57.653622 20 predicates.go:887] calico-node-fcrzw from kube-system started at 2024-07-11 05:32:46 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.653629 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 06:35:57.653634 20 predicates.go:887] sonobuoy from sonobuoy started at 2024-07-11 05:34:19 +0000 UTC (1 container statuses recorded)
  I0711 06:35:57.653639 20 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0711 06:35:57.653645 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-9fdzf from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 06:35:57.653650 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 06:35:57.653654 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 07/11/24 06:35:57.653
  E0711 06:35:57.723640      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:35:58.723882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 07/11/24 06:35:59.681
  STEP: Trying to apply a random label on the found node. @ 07/11/24 06:35:59.702
  STEP: verifying the node has the label kubernetes.io/e2e-3ec6f502-80fe-4ca6-9565-517b11f2fb92 95 @ 07/11/24 06:35:59.71
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 07/11/24 06:35:59.715
  E0711 06:35:59.723925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:00.725038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:01.725355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.17.237 on the node which pod4 resides and expect not scheduled @ 07/11/24 06:36:01.736
  E0711 06:36:02.726188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:03.726334      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:04.726468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:05.726750      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:06.726847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:07.726938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:08.727240      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:09.727375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:10.727482      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:11.727585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:12.727983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:13.728125      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:14.729113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:15.729566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:16.730648      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:17.730862      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:18.731500      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:19.731596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:20.732012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:21.732077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:22.732206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:23.732377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:24.732466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:25.733464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:26.734224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:27.734324      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:28.734510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:29.734738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:30.734872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:31.735065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:32.735261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:33.735424      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:34.735508      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:35.735694      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:36.735866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:37.736034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:38.736130      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:39.736233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:40.736325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:41.737089      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:42.737233      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:43.737345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:44.737421      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:45.737718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:46.737894      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:47.738155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:48.738339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:49.738560      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:50.738711      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:51.739128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:52.740127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:53.741033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:54.741143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:55.741890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:56.741997      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:57.742837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:58.742927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:36:59.743013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:00.743301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:01.743626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:02.743968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:03.744077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:04.744168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:05.744635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:06.745281      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:07.745394      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:08.745434      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:09.745543      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:10.746595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:11.746744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:12.746987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:13.747250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:14.747511      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:15.747547      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:16.747999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:17.748072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:18.748155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:19.748249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:20.749225      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:21.749308      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:22.749432      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:23.749547      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:24.749637      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:25.750491      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:26.750602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:27.750809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:28.750997      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:29.751204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:30.751323      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:31.751474      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:32.751965      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:33.752050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:34.752030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:35.752308      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:36.752362      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:37.753023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:38.753855      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:39.754031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:40.754191      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:41.754709      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:42.755787      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:43.755949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:44.757008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:45.757485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:46.758332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:47.758490      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:48.759482      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:49.759705      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:50.759734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:51.759943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:52.760017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:53.761013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:54.761106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:55.761623      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:56.761867      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:57.762064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:58.762173      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:37:59.763080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:00.763178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:01.763681      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:02.763949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:03.765001      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:04.765697      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:05.766627      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:06.766816      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:07.767075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:08.767980      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:09.768087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:10.768187      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:11.768288      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:12.768353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:13.769113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:14.769206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:15.769521      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:16.770441      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:17.770718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:18.770948      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:19.771071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:20.771259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:21.771737      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:22.771942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:23.772048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:24.772997      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:25.773404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:26.773472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:27.773659      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:28.774277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:29.774495      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:30.774629      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:31.774729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:32.775232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:33.775510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:34.776301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:35.776760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:36.777283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:37.777484      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:38.778477      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:39.778676      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:40.779410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:41.779494      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:42.779981      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:43.780027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:44.780836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:45.781303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:46.782305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:47.782446      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:48.783217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:49.783395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:50.783913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:51.783949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:52.784836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:53.785188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:54.785283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:55.785907      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:56.786276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:57.786477      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:58.786971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:38:59.787186      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:00.787465      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:01.787733      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:02.787959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:03.788128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:04.788228      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:05.788774      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:06.789573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:07.789710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:08.789918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:09.790236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:10.790303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:11.790420      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:12.791471      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:13.791672      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:14.791941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:15.792542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:16.793006      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:17.793291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:18.793714      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:19.794772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:20.795097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:21.795412      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:22.795706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:23.795941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:24.796016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:25.796667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:26.797141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:27.797219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:28.797410      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:29.798350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:30.798478      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:31.798600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:32.799690      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:33.799951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:34.800039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:35.800374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:36.801150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:37.801458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:38.801693      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:39.801986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:40.802785      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:41.802878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:42.803436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:43.803734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:44.803938      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:45.804272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:46.805009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:47.805113      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:48.805205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:49.805484      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:50.806450      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:51.806601      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:52.806909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:53.807029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:54.807239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:55.807700      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:56.808729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:57.809334      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:58.810370      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:39:59.810501      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:00.810559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:01.811168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:02.811953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:03.812005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:04.812964      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:05.813450      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:06.814226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:07.814409      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:08.814992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:09.815312      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:10.815918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:11.816091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:12.817024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:13.817143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:14.817179      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:15.817742      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:16.817967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:17.818071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:18.819120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:19.819259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:20.819828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:21.820110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:22.820990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:23.821254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:24.821368      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:25.821596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:26.821640      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:27.822363      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:28.822833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:29.822929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:30.823311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:31.823602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:32.823689      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:33.823893      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:34.824986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:35.825495      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:36.826373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:37.826794      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:38.826913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:39.827035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:40.827759      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:41.827971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:42.828041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:43.828143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:44.828250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:45.828953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:46.829939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:47.830164      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:48.831141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:49.831273      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:50.831710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:51.831964      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:52.833148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:53.833236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:54.833329      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:55.833761      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:56.834541      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:57.834768      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:58.835259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:40:59.835679      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:00.836297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-3ec6f502-80fe-4ca6-9565-517b11f2fb92 off the node ip-172-31-17-237 @ 07/11/24 06:41:01.745
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-3ec6f502-80fe-4ca6-9565-517b11f2fb92 @ 07/11/24 06:41:01.76
  I0711 06:41:01.764014 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5104" for this suite. @ 07/11/24 06:41:01.769
• [304.171 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1833
  STEP: Creating a kubernetes client @ 07/11/24 06:41:01.777
  I0711 06:41:01.777452 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 06:41:01.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:01.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:01.796
  STEP: starting the proxy server @ 07/11/24 06:41:01.805
  I0711 06:41:01.806043 20 util.go:592] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-9543 proxy -p 0 --disable-filter'
  E0711 06:41:01.836360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: curling proxy /api/ output @ 07/11/24 06:41:01.847
  I0711 06:41:01.851758 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0711 06:41:01.852872 20 kubectl.go:2223] kubectl proxy stdout: Starting to serve on 127.0.0.1:42619

  I0711 06:41:01.852880 20 kubectl.go:2228] kubectl proxy stderr: W0711 06:41:01.846733     400 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-9543" for this suite. @ 07/11/24 06:41:01.856
• [0.087 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 07/11/24 06:41:01.864
  I0711 06:41:01.864643 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 06:41:01.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:01.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:01.883
  STEP: Creating secret with name secret-test-map-58dc1242-6a33-4675-a2fc-1bbb5d399884 @ 07/11/24 06:41:01.885
  STEP: Creating a pod to test consume secrets @ 07/11/24 06:41:01.891
  E0711 06:41:02.837169      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:03.837263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:04.837378      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:05.837621      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:41:05.916
  I0711 06:41:05.920497 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-secrets-dbb8b169-c8bb-438b-8af4-64f40457e8b2 container secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 06:41:05.934
  I0711 06:41:05.950618 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7624" for this suite. @ 07/11/24 06:41:05.954
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:70
  STEP: Creating a kubernetes client @ 07/11/24 06:41:05.963
  I0711 06:41:05.963039 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-publish-openapi @ 07/11/24 06:41:05.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:05.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:05.981
  I0711 06:41:05.983921 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:41:06.838020      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 07/11/24 06:41:07.267
  I0711 06:41:07.267104 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 --namespace=crd-publish-openapi-904 create -f -'
  I0711 06:41:07.318260 20 builder.go:146] stderr: ""
  I0711 06:41:07.318301 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-824-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0711 06:41:07.318404 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 --namespace=crd-publish-openapi-904 delete e2e-test-crd-publish-openapi-824-crds test-foo'
  I0711 06:41:07.364045 20 builder.go:146] stderr: ""
  I0711 06:41:07.364106 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-824-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I0711 06:41:07.364200 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 --namespace=crd-publish-openapi-904 apply -f -'
  I0711 06:41:07.428667 20 builder.go:146] stderr: ""
  I0711 06:41:07.428711 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-824-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0711 06:41:07.428753 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 --namespace=crd-publish-openapi-904 delete e2e-test-crd-publish-openapi-824-crds test-foo'
  I0711 06:41:07.478393 20 builder.go:146] stderr: ""
  I0711 06:41:07.478444 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-824-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 07/11/24 06:41:07.478
  I0711 06:41:07.478644 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 --namespace=crd-publish-openapi-904 create -f -'
  I0711 06:41:07.519363 20 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 07/11/24 06:41:07.519
  I0711 06:41:07.519481 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 --namespace=crd-publish-openapi-904 create -f -'
  I0711 06:41:07.559996 20 builder.go:135] rc: 1
  I0711 06:41:07.560094 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 --namespace=crd-publish-openapi-904 apply -f -'
  I0711 06:41:07.607571 20 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 07/11/24 06:41:07.607
  I0711 06:41:07.607827 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 --namespace=crd-publish-openapi-904 create -f -'
  I0711 06:41:07.647960 20 builder.go:135] rc: 1
  I0711 06:41:07.648041 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 --namespace=crd-publish-openapi-904 apply -f -'
  I0711 06:41:07.697024 20 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 07/11/24 06:41:07.697
  I0711 06:41:07.697152 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 explain e2e-test-crd-publish-openapi-824-crds'
  I0711 06:41:07.737371 20 builder.go:146] stderr: ""
  I0711 06:41:07.737422 20 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-824-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 07/11/24 06:41:07.737
  I0711 06:41:07.737650 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 explain e2e-test-crd-publish-openapi-824-crds.metadata'
  I0711 06:41:07.777270 20 builder.go:146] stderr: ""
  I0711 06:41:07.777443 20 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-824-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0711 06:41:07.777714 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 explain e2e-test-crd-publish-openapi-824-crds.spec'
  I0711 06:41:07.817303 20 builder.go:146] stderr: ""
  I0711 06:41:07.817345 20 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-824-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0711 06:41:07.817447 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 explain e2e-test-crd-publish-openapi-824-crds.spec.bars'
  E0711 06:41:07.838810      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:07.856186 20 builder.go:146] stderr: ""
  I0711 06:41:07.856245 20 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-824-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 07/11/24 06:41:07.856
  I0711 06:41:07.856479 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-904 explain e2e-test-crd-publish-openapi-824-crds.spec.bars2'
  I0711 06:41:07.895130 20 builder.go:135] rc: 1
  E0711 06:41:08.838910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:09.195268 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-904" for this suite. @ 07/11/24 06:41:09.204
• [3.256 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:237
  STEP: Creating a kubernetes client @ 07/11/24 06:41:09.219
  I0711 06:41:09.219092 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-publish-openapi @ 07/11/24 06:41:09.219
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:09.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:09.235
  I0711 06:41:09.238106 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:41:09.839919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 07/11/24 06:41:10.436
  I0711 06:41:10.436206 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-2357 --namespace=crd-publish-openapi-2357 create -f -'
  E0711 06:41:10.840042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:11.840104      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:12.502070 20 builder.go:146] stderr: ""
  I0711 06:41:12.502107 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-3680-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0711 06:41:12.502169 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-2357 --namespace=crd-publish-openapi-2357 delete e2e-test-crd-publish-openapi-3680-crds test-cr'
  I0711 06:41:12.559703 20 builder.go:146] stderr: ""
  I0711 06:41:12.559745 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-3680-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I0711 06:41:12.559787 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-2357 --namespace=crd-publish-openapi-2357 apply -f -'
  I0711 06:41:12.616022 20 builder.go:146] stderr: ""
  I0711 06:41:12.616063 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-3680-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0711 06:41:12.616102 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-2357 --namespace=crd-publish-openapi-2357 delete e2e-test-crd-publish-openapi-3680-crds test-cr'
  I0711 06:41:12.664203 20 builder.go:146] stderr: ""
  I0711 06:41:12.664261 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-3680-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 07/11/24 06:41:12.664
  I0711 06:41:12.664336 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-2357 explain e2e-test-crd-publish-openapi-3680-crds'
  I0711 06:41:12.703010 20 builder.go:146] stderr: ""
  I0711 06:41:12.703060 20 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-3680-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0711 06:41:12.840897      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:13.840906      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:13.911411 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2357" for this suite. @ 07/11/24 06:41:13.918
• [4.709 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 07/11/24 06:41:13.928
  I0711 06:41:13.928606 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 06:41:13.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:13.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:13.948
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 07/11/24 06:41:13.95
  E0711 06:41:14.841229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:15.841316      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:16.841395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:17.841460      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:41:17.978
  I0711 06:41:17.981807 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-9f35cd68-f5bc-44fb-959c-28cb7b52bd9d container test-container: <nil>
  STEP: delete the pod @ 07/11/24 06:41:17.994
  I0711 06:41:18.010606 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-897" for this suite. @ 07/11/24 06:41:18.014
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 07/11/24 06:41:18.022
  I0711 06:41:18.022752 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename daemonsets @ 07/11/24 06:41:18.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:18.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:18.04
  I0711 06:41:18.061595 20 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 07/11/24 06:41:18.066
  I0711 06:41:18.069706 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 06:41:18.069724 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 07/11/24 06:41:18.069
  I0711 06:41:18.090498 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 06:41:18.090629 20 fixtures.go:130] Node ip-172-31-17-237 is running 0 daemon pod, expected 1
  E0711 06:41:18.842512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:19.089538 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0711 06:41:19.089569 20 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 07/11/24 06:41:19.093
  I0711 06:41:19.109937 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0711 06:41:19.110088 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0711 06:41:19.842601      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:20.112265 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 06:41:20.112316 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 07/11/24 06:41:20.112
  I0711 06:41:20.123571 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 06:41:20.123697 20 fixtures.go:130] Node ip-172-31-17-237 is running 0 daemon pod, expected 1
  E0711 06:41:20.842654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:21.125623 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0711 06:41:21.125656 20 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 07/11/24 06:41:21.132
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6334, will wait for the garbage collector to delete the pods @ 07/11/24 06:41:21.132
  I0711 06:41:21.194664 20 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.939036ms
  I0711 06:41:21.295490 20 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.82046ms
  E0711 06:41:21.843094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:22.844139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:23.000412 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 06:41:23.000446 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0711 06:41:23.003524 20 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25779"},"items":null}

  I0711 06:41:23.007328 20 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25779"},"items":null}

  I0711 06:41:23.052185 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6334" for this suite. @ 07/11/24 06:41:23.056
• [5.041 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 07/11/24 06:41:23.063
  I0711 06:41:23.063946 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 06:41:23.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:23.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:23.086
  STEP: Create set of pods @ 07/11/24 06:41:23.089
  I0711 06:41:23.099165 20 pods.go:871] created test-pod-1
  I0711 06:41:23.105786 20 pods.go:871] created test-pod-2
  I0711 06:41:23.113287 20 pods.go:871] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 07/11/24 06:41:23.113
  E0711 06:41:23.844264      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:24.844351      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 07/11/24 06:41:25.169
  I0711 06:41:25.173187 20 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  E0711 06:41:25.845020      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:26.174773 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3715" for this suite. @ 07/11/24 06:41:26.178
• [3.123 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:531
  STEP: Creating a kubernetes client @ 07/11/24 06:41:26.186
  I0711 06:41:26.186812 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename security-context-test @ 07/11/24 06:41:26.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:26.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:26.207
  E0711 06:41:26.845152      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:27.845247      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:28.234399 20 security_context.go:538] Got logs for pod "busybox-privileged-false-6ec3a03f-10a8-4a1e-9ecd-9222032d2231": "ip: RTNETLINK answers: Operation not permitted\n"
  I0711 06:41:28.234500 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9123" for this suite. @ 07/11/24 06:41:28.239
• [2.060 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 07/11/24 06:41:28.247
  I0711 06:41:28.247297 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename proxy @ 07/11/24 06:41:28.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:28.265
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:28.268
  I0711 06:41:28.270766 20 proxy.go:293] Creating pod...
  E0711 06:41:28.845362      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:29.845712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:30.292131 20 proxy.go:317] Creating service...
  I0711 06:41:30.304345 20 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/pods/agnhost/proxy/some/path/with/DELETE
  I0711 06:41:30.310836 20 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0711 06:41:30.310866 20 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/pods/agnhost/proxy/some/path/with/GET
  I0711 06:41:30.314949 20 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0711 06:41:30.314975 20 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/pods/agnhost/proxy/some/path/with/HEAD
  I0711 06:41:30.318659 20 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0711 06:41:30.318674 20 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/pods/agnhost/proxy/some/path/with/OPTIONS
  I0711 06:41:30.322873 20 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0711 06:41:30.322894 20 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/pods/agnhost/proxy/some/path/with/PATCH
  I0711 06:41:30.327955 20 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0711 06:41:30.328030 20 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/pods/agnhost/proxy/some/path/with/POST
  I0711 06:41:30.332096 20 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0711 06:41:30.332142 20 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/pods/agnhost/proxy/some/path/with/PUT
  I0711 06:41:30.336997 20 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0711 06:41:30.337011 20 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/services/test-service/proxy/some/path/with/DELETE
  I0711 06:41:30.342593 20 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0711 06:41:30.342611 20 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/services/test-service/proxy/some/path/with/GET
  I0711 06:41:30.348177 20 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0711 06:41:30.348200 20 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/services/test-service/proxy/some/path/with/HEAD
  I0711 06:41:30.355454 20 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0711 06:41:30.355476 20 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/services/test-service/proxy/some/path/with/OPTIONS
  I0711 06:41:30.362399 20 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0711 06:41:30.362448 20 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/services/test-service/proxy/some/path/with/PATCH
  I0711 06:41:30.368413 20 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0711 06:41:30.368437 20 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/services/test-service/proxy/some/path/with/POST
  I0711 06:41:30.375545 20 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0711 06:41:30.375600 20 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7929/services/test-service/proxy/some/path/with/PUT
  I0711 06:41:30.380991 20 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0711 06:41:30.381082 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7929" for this suite. @ 07/11/24 06:41:30.385
• [2.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 07/11/24 06:41:30.394
  I0711 06:41:30.394202 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename var-expansion @ 07/11/24 06:41:30.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:41:30.415
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:41:30.418
  STEP: creating the pod @ 07/11/24 06:41:30.42
  STEP: waiting for pod running @ 07/11/24 06:41:30.43
  E0711 06:41:30.846449      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:31.846587      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 07/11/24 06:41:32.443
  I0711 06:41:32.448070 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4962 PodName:var-expansion-6acb866f-5093-4f11-ac05-cb42140854a8 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:41:32.448094 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:41:32.448548 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:41:32.448589 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-4962/pods/var-expansion-6acb866f-5093-4f11-ac05-cb42140854a8/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 07/11/24 06:41:32.509
  I0711 06:41:32.513176 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4962 PodName:var-expansion-6acb866f-5093-4f11-ac05-cb42140854a8 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:41:32.513199 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:41:32.513587 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:41:32.513628 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-4962/pods/var-expansion-6acb866f-5093-4f11-ac05-cb42140854a8/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 07/11/24 06:41:32.559
  E0711 06:41:32.847381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:41:33.074725 20 pod_client.go:141] Successfully updated pod "var-expansion-6acb866f-5093-4f11-ac05-cb42140854a8"
  STEP: waiting for annotated pod running @ 07/11/24 06:41:33.075
  STEP: deleting the pod gracefully @ 07/11/24 06:41:33.078
  I0711 06:41:33.078606 20 delete.go:62] Deleting pod "var-expansion-6acb866f-5093-4f11-ac05-cb42140854a8" in namespace "var-expansion-4962"
  I0711 06:41:33.087139 20 delete.go:70] Wait up to 5m0s for pod "var-expansion-6acb866f-5093-4f11-ac05-cb42140854a8" to be fully deleted
  E0711 06:41:33.847725      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:34.848138      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:35.848357      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:36.848873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:37.848981      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:38.849207      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:39.849308      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:40.850035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:41.850276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:42.850466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:43.850804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:44.850859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:45.851506      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:46.851621      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:47.851716      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:48.851947      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:49.851980      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:50.852074      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:51.853020      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:52.853110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:53.853699      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:54.853892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:55.854522      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:56.854775      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:57.855846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:58.855963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:41:59.856094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:00.856187      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:01.857004      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:02.858055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:03.858888      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:04.859218      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:05.859738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:06.859947      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:07.181563 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4962" for this suite. @ 07/11/24 06:42:07.186
• [36.799 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 07/11/24 06:42:07.193
  I0711 06:42:07.193957 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 06:42:07.194
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:07.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:07.216
  STEP: Creating configMap with name configmap-test-volume-d5fde001-77f2-43e4-9507-2e4293be2c70 @ 07/11/24 06:42:07.218
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:42:07.222
  E0711 06:42:07.860617      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:08.861142      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:42:09.24
  I0711 06:42:09.244672 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-configmaps-23923a93-e1eb-4b92-b0ab-e2e53c04c3cb container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:42:09.252
  I0711 06:42:09.270309 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3058" for this suite. @ 07/11/24 06:42:09.273
• [2.088 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 07/11/24 06:42:09.282
  I0711 06:42:09.282229 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename namespaces @ 07/11/24 06:42:09.282
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:09.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:09.299
  STEP: creating a Namespace @ 07/11/24 06:42:09.302
  STEP: patching the Namespace @ 07/11/24 06:42:09.32
  STEP: get the Namespace and ensuring it has the label @ 07/11/24 06:42:09.325
  I0711 06:42:09.329388 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7973" for this suite. @ 07/11/24 06:42:09.334
  STEP: Destroying namespace "nspatchtest-6f6ebfb0-abf8-47d9-97e3-bddca49b35cb-2443" for this suite. @ 07/11/24 06:42:09.341
• [0.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1394
  STEP: Creating a kubernetes client @ 07/11/24 06:42:09.349
  I0711 06:42:09.349899 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 06:42:09.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:09.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:09.372
  I0711 06:42:09.375323 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-9082 create -f -'
  I0711 06:42:09.449850 20 builder.go:146] stderr: ""
  I0711 06:42:09.449902 20 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I0711 06:42:09.449947 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-9082 create -f -'
  I0711 06:42:09.531737 20 builder.go:146] stderr: ""
  I0711 06:42:09.531793 20 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 07/11/24 06:42:09.531
  E0711 06:42:09.862189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:10.537285 20 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0711 06:42:10.537320 20 framework.go:733] Found 1 / 1
  I0711 06:42:10.537335 20 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0711 06:42:10.541571 20 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0711 06:42:10.541588 20 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0711 06:42:10.541670 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-9082 describe pod agnhost-primary-6mvbn'
  I0711 06:42:10.592701 20 builder.go:146] stderr: ""
  I0711 06:42:10.592764 20 builder.go:147] stdout: "Name:             agnhost-primary-6mvbn\nNamespace:        kubectl-9082\nPriority:         0\nService Account:  default\nNode:             ip-172-31-80-240/172.31.80.240\nStart Time:       Thu, 11 Jul 2024 06:42:09 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.37.48\nIPs:\n  IP:           192.168.37.48\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://651ce7ae4f5ca0e551a3f29054686189bfa96ec7c1cafe50b244e9f6375abc5b\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 11 Jul 2024 06:42:10 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-vtv8h (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-vtv8h:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-9082/agnhost-primary-6mvbn to ip-172-31-80-240\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
  I0711 06:42:10.592826 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-9082 describe rc agnhost-primary'
  I0711 06:42:10.644553 20 builder.go:146] stderr: ""
  I0711 06:42:10.644599 20 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9082\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-6mvbn\n"
  I0711 06:42:10.644651 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-9082 describe service agnhost-primary'
  I0711 06:42:10.695541 20 builder.go:146] stderr: ""
  I0711 06:42:10.695581 20 builder.go:147] stdout: "Name:              agnhost-primary\nNamespace:         kubectl-9082\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.34\nIPs:               10.152.183.34\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.37.48:6379\nSession Affinity:  None\nEvents:            <none>\n"
  I0711 06:42:10.699608 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-9082 describe node ip-172-31-11-2'
  I0711 06:42:10.764099 20 builder.go:146] stderr: ""
  I0711 06:42:10.764178 20 builder.go:147] stdout: "Name:               ip-172-31-11-2\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    juju.io/cloud=ec2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-11-2\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 11 Jul 2024 05:21:12 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-11-2\n  AcquireTime:     <unset>\n  RenewTime:       Thu, 11 Jul 2024 06:42:05 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 11 Jul 2024 05:31:28 +0000   Thu, 11 Jul 2024 05:31:28 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Thu, 11 Jul 2024 06:37:48 +0000   Thu, 11 Jul 2024 05:21:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Thu, 11 Jul 2024 06:37:48 +0000   Thu, 11 Jul 2024 05:21:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Thu, 11 Jul 2024 06:37:48 +0000   Thu, 11 Jul 2024 05:21:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Thu, 11 Jul 2024 06:37:48 +0000   Thu, 11 Jul 2024 05:22:41 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.31.11.2\n  Hostname:    ip-172-31-11-2\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7958136Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7855736Ki\n  pods:               110\nSystem Info:\n  Machine ID:                      ec2cb77db8a0aff106345813463d4942\n  System UUID:                     ec2cb77d-b8a0-aff1-0634-5813463d4942\n  Boot ID:                         6ecfc41b-59d5-44da-97c7-a8c3132471aa\n  Kernel Version:                  6.5.0-1022-aws\n  OS Image:                        Ubuntu 22.04.4 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.6.8\n  Kubelet Version:                 v1.30.2\n  Kube-Proxy Version:              v1.30.2\nNon-terminated Pods:               (8 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-vst4d           0 (0%)        0 (0%)      0 (0%)           0 (0%)         76m\n  kube-system                      calico-node-9r7js                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                      coredns-5c6d979c47-sb7z6                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     81m\n  kube-system                      kube-state-metrics-77cc559b76-46cmg                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                      metrics-server-v0.7.0-7995f698bf-5zlw4                     5m (0%)       100m (5%)   50Mi (0%)        300Mi (3%)     81m\n  kubernetes-dashboard             dashboard-metrics-scraper-55584b484c-j4mdq                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kubernetes-dashboard             kubernetes-dashboard-6fd7bf4447-4xclp                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-fccgk    0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                355m (17%)  100m (5%)\n  memory             120Mi (1%)  470Mi (6%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
  I0711 06:42:10.764230 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-9082 describe namespace kubectl-9082'
  I0711 06:42:10.814208 20 builder.go:146] stderr: ""
  I0711 06:42:10.814261 20 builder.go:147] stdout: "Name:         kubectl-9082\nLabels:       e2e-framework=kubectl\n              e2e-run=b5d2bce4-72e0-469e-9b87-8839b2fc22bf\n              kubernetes.io/metadata.name=kubectl-9082\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0711 06:42:10.814350 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9082" for this suite. @ 07/11/24 06:42:10.819
• [1.477 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 07/11/24 06:42:10.827
  I0711 06:42:10.827583 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 06:42:10.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:10.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:10.849
  STEP: Creating configMap with name configmap-test-volume-map-66c10de2-8540-434c-ba45-ea8533e55aad @ 07/11/24 06:42:10.852
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:42:10.857
  E0711 06:42:10.863134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:11.863297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:12.863384      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:13.863953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:14.864062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:42:14.881
  I0711 06:42:14.885141 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-configmaps-191f9107-608c-4538-ab44-d338ceb6f190 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:42:14.902
  I0711 06:42:14.920216 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3543" for this suite. @ 07/11/24 06:42:14.923
• [4.106 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 07/11/24 06:42:14.933
  I0711 06:42:14.933796 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 06:42:14.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:14.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:14.96
  STEP: Counting existing ResourceQuota @ 07/11/24 06:42:14.963
  E0711 06:42:15.864433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:16.864542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:17.864631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:18.865226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:19.865344      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 07/11/24 06:42:19.967
  STEP: Ensuring resource quota status is calculated @ 07/11/24 06:42:19.972
  E0711 06:42:20.865418      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:21.865686      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 07/11/24 06:42:21.977
  STEP: Ensuring resource quota status captures replication controller creation @ 07/11/24 06:42:21.989
  E0711 06:42:22.866339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:23.866537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 07/11/24 06:42:23.995
  STEP: Ensuring resource quota status released usage @ 07/11/24 06:42:24.002
  E0711 06:42:24.866760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:25.866822      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:26.007593 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4786" for this suite. @ 07/11/24 06:42:26.011
• [11.086 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 07/11/24 06:42:26.02
  I0711 06:42:26.020426 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename deployment @ 07/11/24 06:42:26.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:26.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:26.045
  I0711 06:42:26.047672 20 deployment.go:1196] Creating deployment "webserver-deployment"
  I0711 06:42:26.051967 20 deployment.go:1200] Waiting for observed generation 1
  E0711 06:42:26.867865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:27.868209      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:28.060765 20 deployment.go:1205] Waiting for all required pods to come up
  I0711 06:42:28.064809 20 resource.go:87] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 07/11/24 06:42:28.064
  I0711 06:42:28.064931 20 deployment.go:1209] Waiting for deployment "webserver-deployment" to complete
  I0711 06:42:28.071760 20 deployment.go:1218] Updating deployment "webserver-deployment" with a non-existent image
  I0711 06:42:28.082546 20 deployment.go:313] Updating deployment webserver-deployment
  I0711 06:42:28.082568 20 deployment.go:1224] Waiting for observed generation 2
  E0711 06:42:28.869045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:29.869313      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:30.090688 20 deployment.go:1234] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I0711 06:42:30.095156 20 deployment.go:1239] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0711 06:42:30.098841 20 deployment.go:1244] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0711 06:42:30.109896 20 deployment.go:1258] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0711 06:42:30.110029 20 deployment.go:1263] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0711 06:42:30.113325 20 deployment.go:1268] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0711 06:42:30.120423 20 deployment.go:1275] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0711 06:42:30.120525 20 deployment.go:1283] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0711 06:42:30.130921 20 deployment.go:313] Updating deployment webserver-deployment
  I0711 06:42:30.130968 20 deployment.go:1289] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0711 06:42:30.139488 20 deployment.go:1297] Verifying that first rollout's replicaset has .spec.replicas = 20
  I0711 06:42:30.143468 20 deployment.go:1303] Verifying that second rollout's replicaset has .spec.replicas = 13
  I0711 06:42:30.151917 20 deployment.go:633] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "92cde5f7-3f82-4441-86c1-a96641a673ad",
      ResourceVersion: (string) (len=5) "26563",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-67c89d485c\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0711 06:42:30.166350 20 deployment.go:39] New ReplicaSet "webserver-deployment-67c89d485c" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-67c89d485c",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "db2592bc-c173-4e5c-8c11-ae6280f96cd7",
      ResourceVersion: (string) (len=5) "26567",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "92cde5f7-3f82-4441-86c1-a96641a673ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 32 63 64 65 35  66 37 2d 33 66 38 32 2d  |\"92cde5f7-3f82-|
              00000120  34 34 34 31 2d 38 36 63  31 2d 61 39 36 36 34 31  |4441-86c1-a96641|
              00000130  61 36 37 33 61 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a673ad\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 06:42:30.166812 20 deployment.go:44] All old ReplicaSets of Deployment "webserver-deployment":
  I0711 06:42:30.167022 20 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-77db57d8df",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
      ResourceVersion: (string) (len=5) "26564",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "92cde5f7-3f82-4441-86c1-a96641a673ad",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 32 63 64 65 35  66 37 2d 33 66 38 32 2d  |\"92cde5f7-3f82-|
              00000120  34 34 34 31 2d 38 36 63  31 2d 61 39 36 36 34 31  |4441-86c1-a96641|
              00000130  61 36 37 33 61 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a673ad\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 06:42:30.174684 20 deployment.go:67] Pod "webserver-deployment-67c89d485c-6dmpj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-6dmpj",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "91c0da94-f046-474a-b624-edba174eebe5",
      ResourceVersion: (string) (len=5) "26558",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "db2592bc-c173-4e5c-8c11-ae6280f96cd7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 62  32 35 39 32 62 63 2d 63  |d\":\"db2592bc-c|
              00000090  31 37 33 2d 34 65 35 63  2d 38 63 31 31 2d 61 65  |173-4e5c-8c11-ae|
              000000a0  36 32 38 30 66 39 36 63  64 37 5c 22 7d 22 3a 7b  |6280f96cd7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276949,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 33 33 2e 31  31 35 5c 22 7d 22 3a 7b  |68.133.115\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-25q8t",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-25q8t",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-237",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276949,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.237",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.237"
        }
      },
      PodIP: (string) (len=15) "192.168.133.115",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.133.115"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.177731 20 deployment.go:67] Pod "webserver-deployment-67c89d485c-6pzcd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-6pzcd",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "87a3a359-787b-4a6d-9784-f9bb325e77ba",
      ResourceVersion: (string) (len=5) "26559",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "db2592bc-c173-4e5c-8c11-ae6280f96cd7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 62  32 35 39 32 62 63 2d 63  |d\":\"db2592bc-c|
              00000090  31 37 33 2d 34 65 35 63  2d 38 63 31 31 2d 61 65  |173-4e5c-8c11-ae|
              000000a0  36 32 38 30 66 39 36 63  64 37 5c 22 7d 22 3a 7b  |6280f96cd7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276949,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=707) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 33 37 2e 35 33  5c 22 7d 22 3a 7b 22 2e  |68.37.53\"}":{".|
              000002a0  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              000002b0  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              000002c0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qstfn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qstfn",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276949,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) (len=13) "192.168.37.53",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.37.53"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.178972 20 deployment.go:67] Pod "webserver-deployment-67c89d485c-fcrhr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-fcrhr",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "72ab28d4-ae3f-43c0-bf53-23f8c592b22f",
      ResourceVersion: (string) (len=5) "26539",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "db2592bc-c173-4e5c-8c11-ae6280f96cd7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 62  32 35 39 32 62 63 2d 63  |d\":\"db2592bc-c|
              00000090  31 37 33 2d 34 65 35 63  2d 38 63 31 31 2d 61 65  |173-4e5c-8c11-ae|
              000000a0  36 32 38 30 66 39 36 63  64 37 5c 22 7d 22 3a 7b  |6280f96cd7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 32 32 2e 37  37 5c 22 7d 22 3a 7b 22  |68.122.77\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xr2rf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xr2rf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-11-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.11.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "172.31.11.2"
        }
      },
      PodIP: (string) (len=14) "192.168.122.77",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.122.77"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.180252 20 deployment.go:67] Pod "webserver-deployment-67c89d485c-q8p7j" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-q8p7j",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "005d933f-1efb-4d16-8866-57e7d5c973d9",
      ResourceVersion: (string) (len=5) "26554",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "db2592bc-c173-4e5c-8c11-ae6280f96cd7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 62  32 35 39 32 62 63 2d 63  |d\":\"db2592bc-c|
              00000090  31 37 33 2d 34 65 35 63  2d 38 63 31 31 2d 61 65  |173-4e5c-8c11-ae|
              000000a0  36 32 38 30 66 39 36 63  64 37 5c 22 7d 22 3a 7b  |6280f96cd7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276949,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=707) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 33 37 2e 35 35  5c 22 7d 22 3a 7b 22 2e  |68.37.55\"}":{".|
              000002a0  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              000002b0  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              000002c0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zccd7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zccd7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276949,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) (len=13) "192.168.37.55",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.37.55"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.181385 20 deployment.go:67] Pod "webserver-deployment-67c89d485c-rx956" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-rx956",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "23c6867c-bcae-47dd-8766-4371a0bfa3df",
      ResourceVersion: (string) (len=5) "26571",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "db2592bc-c173-4e5c-8c11-ae6280f96cd7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 62  32 35 39 32 62 63 2d 63  |d\":\"db2592bc-c|
              00000090  31 37 33 2d 34 65 35 63  2d 38 63 31 31 2d 61 65  |173-4e5c-8c11-ae|
              000000a0  36 32 38 30 66 39 36 63  64 37 5c 22 7d 22 3a 7b  |6280f96cd7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rvvz5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rvvz5",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.182218 20 deployment.go:67] Pod "webserver-deployment-67c89d485c-wbw4c" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-wbw4c",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2e63e02a-c6f1-41ff-8721-ddd990b19749",
      ResourceVersion: (string) (len=5) "26552",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "db2592bc-c173-4e5c-8c11-ae6280f96cd7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 62  32 35 39 32 62 63 2d 63  |d\":\"db2592bc-c|
              00000090  31 37 33 2d 34 65 35 63  2d 38 63 31 31 2d 61 65  |173-4e5c-8c11-ae|
              000000a0  36 32 38 30 66 39 36 63  64 37 5c 22 7d 22 3a 7b  |6280f96cd7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276949,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 33 33 2e 31  31 34 5c 22 7d 22 3a 7b  |68.133.114\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6bqdq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6bqdq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-237",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276949,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276948,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.237",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.237"
        }
      },
      PodIP: (string) (len=15) "192.168.133.114",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.133.114"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276948,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.183518 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-5p8vg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-5p8vg",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2030740a-aa77-4a38-83eb-54a99f8c4d71",
      ResourceVersion: (string) (len=5) "26431",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 37  2e 34 39 5c 22 7d 22 3a  |2.168.37.49\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-m9nzw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-m9nzw",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) (len=13) "192.168.37.49",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.37.49"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856276947,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://5a1f5180f124e17e04ba2e20a502dc914dbad312b4afc11461ad85c460ca1f0a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.188940 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-9r8n6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-9r8n6",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7b8151bd-796d-4ca1-bebf-b2e26dedb59b",
      ResourceVersion: (string) (len=5) "26451",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  32 2e 38 32 5c 22 7d 22  |2.168.122.82\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4lgsp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4lgsp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-11-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.11.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "172.31.11.2"
        }
      },
      PodIP: (string) (len=14) "192.168.122.82",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.122.82"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856276946,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d7bce0aedc99b04cb12ada9929276ba4086473f57acf49f2a0b02182172fdc01",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.190126 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-dwcbz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-dwcbz",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "072145f9-d7b3-4f1d-8b17-819db0d4b2f5",
      ResourceVersion: (string) (len=5) "26569",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dkp6x",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dkp6x",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.190985 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-gnqdl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-gnqdl",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "85795107-d585-4e74-b57f-89ed5bf923c3",
      ResourceVersion: (string) (len=5) "26425",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 37  2e 35 32 5c 22 7d 22 3a  |2.168.37.52\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qpgk2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qpgk2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) (len=13) "192.168.37.52",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.37.52"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856276946,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://2c84afb3cf4e3b55b2c314f8456ae0b96d1ac809bc7be3248038767376a5606c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.199976 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-hm9bb" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-hm9bb",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aef6014e-f935-4b99-8eda-99554e93821f",
      ResourceVersion: (string) (len=5) "26454",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  32 2e 39 32 5c 22 7d 22  |2.168.122.92\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-76g72",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-76g72",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-11-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.11.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "172.31.11.2"
        }
      },
      PodIP: (string) (len=14) "192.168.122.92",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.122.92"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856276946,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f8c16fb8707df233478f1ad297ecbb19ee772eb11337e85f53fb9c962d65bf8c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.204913 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-lkw6s" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-lkw6s",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9fb9752c-ff08-4fdb-886c-e06819aad65e",
      ResourceVersion: (string) (len=5) "26448",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 32  32 2e 39 34 5c 22 7d 22  |2.168.122.94\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-x2mp9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-x2mp9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-11-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.11.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=11) "172.31.11.2"
        }
      },
      PodIP: (string) (len=14) "192.168.122.94",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.122.94"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856276946,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://c77f6f570cc69f42b31711621914bc2061822f0f8370e582782bbd5c0775076b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.209561 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-lp9hg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-lp9hg",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7ebb8932-366e-42bc-8e4e-61483629585e",
      ResourceVersion: (string) (len=5) "26433",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 33  33 2e 31 31 32 5c 22 7d  |2.168.133.112\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6qbcq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6qbcq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-237",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.237",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.237"
        }
      },
      PodIP: (string) (len=15) "192.168.133.112",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.133.112"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856276947,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f9fb9fb6255b62eb0eb3ccf24fd72d631e12aac5a7a91edc318600f2d5078816",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.213362 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-mb8nq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-mb8nq",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6bb1a744-7ad1-440a-afa3-e3190ca48b71",
      ResourceVersion: (string) (len=5) "26439",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 33  33 2e 31 31 30 5c 22 7d  |2.168.133.110\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lcnsm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lcnsm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-237",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.237",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.237"
        }
      },
      PodIP: (string) (len=15) "192.168.133.110",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.133.110"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856276946,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f29481a5b3a0a4b4e68dc7489c9d682f4c575453b8f4bd1c636ad194d5fa3461",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.214161 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-mz6rq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-mz6rq",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d02446ed-1ab9-42ff-a262-66455c0b3be0",
      ResourceVersion: (string) (len=5) "26572",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mc654",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mc654",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.214638 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-nk57t" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-nk57t",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "92ea5fd0-7c9d-4248-9acc-24a724e947f5",
      ResourceVersion: (string) (len=5) "26427",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 33  33 2e 31 31 33 5c 22 7d  |2.168.133.113\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-cvbrh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-cvbrh",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-237",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276947,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276946,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.237",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.237"
        }
      },
      PodIP: (string) (len=15) "192.168.133.113",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.133.113"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276946,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856276946,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://176afd92fa80bacbe59c5b400107cb2f14d51549cbf0700e949766e061da6594",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.222226 20 deployment.go:67] Pod "webserver-deployment-77db57d8df-nn6ml" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-nn6ml",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-6113",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "51c57465-e963-4c15-960e-ce7cd9aff916",
      ResourceVersion: (string) (len=5) "26573",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856276950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "b01af1ca-69cc-4b28-9f3d-c34291dc0fb9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856276950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 30  31 61 66 31 63 61 2d 36  |d\":\"b01af1ca-6|
              00000090  39 63 63 2d 34 62 32 38  2d 39 66 33 64 2d 63 33  |9cc-4b28-9f3d-c3|
              000000a0  34 32 39 31 64 63 30 66  62 39 5c 22 7d 22 3a 7b  |4291dc0fb9\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p94nv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p94nv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 06:42:30.222763 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6113" for this suite. @ 07/11/24 06:42:30.229
• [4.220 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 07/11/24 06:42:30.24
  I0711 06:42:30.240738 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename server-version @ 07/11/24 06:42:30.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:30.326
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:30.329
  STEP: Request ServerVersion @ 07/11/24 06:42:30.332
  STEP: Confirm major version @ 07/11/24 06:42:30.333
  I0711 06:42:30.333543 20 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 07/11/24 06:42:30.333
  I0711 06:42:30.333607 20 server_version.go:58] cleanMinorVersion: 30
  I0711 06:42:30.333629 20 server_version.go:62] Minor version: 30
  I0711 06:42:30.333735 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-7968" for this suite. @ 07/11/24 06:42:30.34
• [0.113 seconds]
------------------------------
SSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 07/11/24 06:42:30.354
  I0711 06:42:30.354199 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename runtimeclass @ 07/11/24 06:42:30.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:30.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:30.378
  STEP: getting /apis @ 07/11/24 06:42:30.38
  STEP: getting /apis/node.k8s.io @ 07/11/24 06:42:30.384
  STEP: getting /apis/node.k8s.io/v1 @ 07/11/24 06:42:30.385
  STEP: creating @ 07/11/24 06:42:30.386
  STEP: watching @ 07/11/24 06:42:30.402
  I0711 06:42:30.402875 20 runtimeclass.go:275] starting watch
  STEP: getting @ 07/11/24 06:42:30.409
  STEP: listing @ 07/11/24 06:42:30.412
  STEP: patching @ 07/11/24 06:42:30.415
  STEP: updating @ 07/11/24 06:42:30.421
  I0711 06:42:30.426075 20 runtimeclass.go:305] waiting for watch events with expected annotations
  STEP: deleting @ 07/11/24 06:42:30.426
  STEP: deleting a collection @ 07/11/24 06:42:30.44
  I0711 06:42:30.457715 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2467" for this suite. @ 07/11/24 06:42:30.461
• [0.114 seconds]
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 07/11/24 06:42:30.468
  I0711 06:42:30.468257 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename svc-latency @ 07/11/24 06:42:30.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:30.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:30.49
  I0711 06:42:30.492699 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-9772 @ 07/11/24 06:42:30.493
  I0711 06:42:30.498922      20 runners.go:198] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9772, replica count: 1
  E0711 06:42:30.870163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:31.550380      20 runners.go:198] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0711 06:42:31.870987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:32.551320      20 runners.go:198] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0711 06:42:32.664508 20 service_latency.go:356] Created: latency-svc-nvxs7
  I0711 06:42:32.671132 20 service_latency.go:363] Got endpoints: latency-svc-nvxs7 [18.438462ms]
  I0711 06:42:32.683202 20 service_latency.go:356] Created: latency-svc-z8wc7
  I0711 06:42:32.687723 20 service_latency.go:363] Got endpoints: latency-svc-z8wc7 [16.427419ms]
  I0711 06:42:32.693165 20 service_latency.go:356] Created: latency-svc-x6rtd
  I0711 06:42:32.697916 20 service_latency.go:363] Got endpoints: latency-svc-x6rtd [25.826868ms]
  I0711 06:42:32.702853 20 service_latency.go:356] Created: latency-svc-hkd54
  I0711 06:42:32.707101 20 service_latency.go:363] Got endpoints: latency-svc-hkd54 [34.900774ms]
  I0711 06:42:32.710399 20 service_latency.go:356] Created: latency-svc-nj4c6
  I0711 06:42:32.715790 20 service_latency.go:363] Got endpoints: latency-svc-nj4c6 [43.576845ms]
  I0711 06:42:32.720485 20 service_latency.go:356] Created: latency-svc-clrw5
  I0711 06:42:32.727918 20 service_latency.go:363] Got endpoints: latency-svc-clrw5 [55.771513ms]
  I0711 06:42:32.729661 20 service_latency.go:356] Created: latency-svc-f2mjl
  I0711 06:42:32.734662 20 service_latency.go:356] Created: latency-svc-5zzk2
  I0711 06:42:32.737411 20 service_latency.go:363] Got endpoints: latency-svc-f2mjl [65.122062ms]
  I0711 06:42:32.739791 20 service_latency.go:363] Got endpoints: latency-svc-5zzk2 [67.549681ms]
  I0711 06:42:32.746859 20 service_latency.go:356] Created: latency-svc-7cpfk
  I0711 06:42:32.752248 20 service_latency.go:363] Got endpoints: latency-svc-7cpfk [79.921005ms]
  I0711 06:42:32.755835 20 service_latency.go:356] Created: latency-svc-fpcjt
  I0711 06:42:32.760642 20 service_latency.go:363] Got endpoints: latency-svc-fpcjt [88.341669ms]
  I0711 06:42:32.761610 20 service_latency.go:356] Created: latency-svc-2zm7r
  I0711 06:42:32.766049 20 service_latency.go:363] Got endpoints: latency-svc-2zm7r [93.689548ms]
  I0711 06:42:32.772863 20 service_latency.go:356] Created: latency-svc-bx7ms
  I0711 06:42:32.777289 20 service_latency.go:356] Created: latency-svc-m4xm2
  I0711 06:42:32.777975 20 service_latency.go:363] Got endpoints: latency-svc-bx7ms [105.586771ms]
  I0711 06:42:32.781558 20 service_latency.go:363] Got endpoints: latency-svc-m4xm2 [109.141966ms]
  I0711 06:42:32.784989 20 service_latency.go:356] Created: latency-svc-bmqcz
  I0711 06:42:32.791317 20 service_latency.go:363] Got endpoints: latency-svc-bmqcz [119.422548ms]
  I0711 06:42:32.795615 20 service_latency.go:356] Created: latency-svc-cn29k
  I0711 06:42:32.801391 20 service_latency.go:363] Got endpoints: latency-svc-cn29k [128.943031ms]
  I0711 06:42:32.802386 20 service_latency.go:356] Created: latency-svc-ws6g4
  I0711 06:42:32.806692 20 service_latency.go:363] Got endpoints: latency-svc-ws6g4 [134.21457ms]
  I0711 06:42:32.812460 20 service_latency.go:356] Created: latency-svc-cshsn
  I0711 06:42:32.817582 20 service_latency.go:363] Got endpoints: latency-svc-cshsn [129.660008ms]
  I0711 06:42:32.823846 20 service_latency.go:356] Created: latency-svc-q9sd9
  I0711 06:42:32.829739 20 service_latency.go:363] Got endpoints: latency-svc-q9sd9 [131.709101ms]
  I0711 06:42:32.833140 20 service_latency.go:356] Created: latency-svc-rw25t
  I0711 06:42:32.836293 20 service_latency.go:363] Got endpoints: latency-svc-rw25t [129.065032ms]
  I0711 06:42:32.844594 20 service_latency.go:356] Created: latency-svc-7lbr7
  I0711 06:42:32.851706 20 service_latency.go:363] Got endpoints: latency-svc-7lbr7 [135.819726ms]
  I0711 06:42:32.855736 20 service_latency.go:356] Created: latency-svc-srfkz
  I0711 06:42:32.860233 20 service_latency.go:363] Got endpoints: latency-svc-srfkz [132.022503ms]
  I0711 06:42:32.867366 20 service_latency.go:356] Created: latency-svc-ktfbx
  E0711 06:42:32.871562      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:32.872379 20 service_latency.go:363] Got endpoints: latency-svc-ktfbx [134.937255ms]
  I0711 06:42:32.878217 20 service_latency.go:356] Created: latency-svc-psxsz
  I0711 06:42:32.879687 20 service_latency.go:363] Got endpoints: latency-svc-psxsz [139.855584ms]
  I0711 06:42:32.887460 20 service_latency.go:356] Created: latency-svc-bkln5
  I0711 06:42:32.891337 20 service_latency.go:363] Got endpoints: latency-svc-bkln5 [139.066477ms]
  I0711 06:42:32.893476 20 service_latency.go:356] Created: latency-svc-hm64k
  I0711 06:42:32.908283 20 service_latency.go:363] Got endpoints: latency-svc-hm64k [147.611612ms]
  I0711 06:42:32.910449 20 service_latency.go:356] Created: latency-svc-vpww8
  I0711 06:42:32.914492 20 service_latency.go:363] Got endpoints: latency-svc-vpww8 [148.347408ms]
  I0711 06:42:32.922035 20 service_latency.go:356] Created: latency-svc-lswdh
  I0711 06:42:32.926468 20 service_latency.go:363] Got endpoints: latency-svc-lswdh [148.414695ms]
  I0711 06:42:32.929173 20 service_latency.go:356] Created: latency-svc-w2whv
  I0711 06:42:32.936186 20 service_latency.go:363] Got endpoints: latency-svc-w2whv [154.343597ms]
  I0711 06:42:32.937949 20 service_latency.go:356] Created: latency-svc-fcf8t
  I0711 06:42:32.944648 20 service_latency.go:363] Got endpoints: latency-svc-fcf8t [153.22744ms]
  I0711 06:42:32.951630 20 service_latency.go:356] Created: latency-svc-54n4h
  I0711 06:42:32.955712 20 service_latency.go:363] Got endpoints: latency-svc-54n4h [154.184705ms]
  I0711 06:42:32.960284 20 service_latency.go:356] Created: latency-svc-t6zdj
  I0711 06:42:32.964654 20 service_latency.go:363] Got endpoints: latency-svc-t6zdj [157.790994ms]
  I0711 06:42:32.968791 20 service_latency.go:356] Created: latency-svc-xgtdq
  I0711 06:42:32.973328 20 service_latency.go:363] Got endpoints: latency-svc-xgtdq [155.712472ms]
  I0711 06:42:32.975502 20 service_latency.go:356] Created: latency-svc-dkh4q
  I0711 06:42:32.979497 20 service_latency.go:363] Got endpoints: latency-svc-dkh4q [149.729195ms]
  I0711 06:42:32.982794 20 service_latency.go:356] Created: latency-svc-nvlt2
  I0711 06:42:32.988651 20 service_latency.go:363] Got endpoints: latency-svc-nvlt2 [152.336826ms]
  I0711 06:42:32.989554 20 service_latency.go:356] Created: latency-svc-lsr76
  I0711 06:42:32.994851 20 service_latency.go:363] Got endpoints: latency-svc-lsr76 [143.121767ms]
  I0711 06:42:33.000245 20 service_latency.go:356] Created: latency-svc-vcjgw
  I0711 06:42:33.005147 20 service_latency.go:363] Got endpoints: latency-svc-vcjgw [144.887363ms]
  I0711 06:42:33.010491 20 service_latency.go:356] Created: latency-svc-lzcpv
  I0711 06:42:33.016217 20 service_latency.go:356] Created: latency-svc-pcl2m
  I0711 06:42:33.018315 20 service_latency.go:363] Got endpoints: latency-svc-lzcpv [145.908408ms]
  I0711 06:42:33.026576 20 service_latency.go:356] Created: latency-svc-xd72t
  I0711 06:42:33.030519 20 service_latency.go:356] Created: latency-svc-mgkkg
  I0711 06:42:33.036802 20 service_latency.go:356] Created: latency-svc-jtn7b
  I0711 06:42:33.044196 20 service_latency.go:356] Created: latency-svc-kfrc7
  I0711 06:42:33.052857 20 service_latency.go:356] Created: latency-svc-spgzh
  I0711 06:42:33.059039 20 service_latency.go:356] Created: latency-svc-pn9f5
  I0711 06:42:33.066749 20 service_latency.go:356] Created: latency-svc-9gpms
  I0711 06:42:33.072034 20 service_latency.go:363] Got endpoints: latency-svc-pcl2m [192.327978ms]
  I0711 06:42:33.075150 20 service_latency.go:356] Created: latency-svc-qwqts
  I0711 06:42:33.080960 20 service_latency.go:356] Created: latency-svc-qh8ll
  I0711 06:42:33.089791 20 service_latency.go:356] Created: latency-svc-5jq4d
  I0711 06:42:33.094718 20 service_latency.go:356] Created: latency-svc-pt8j5
  I0711 06:42:33.100965 20 service_latency.go:356] Created: latency-svc-nz4g6
  I0711 06:42:33.110941 20 service_latency.go:356] Created: latency-svc-5m6bg
  I0711 06:42:33.115853 20 service_latency.go:356] Created: latency-svc-9tqcv
  I0711 06:42:33.120811 20 service_latency.go:363] Got endpoints: latency-svc-xd72t [229.391158ms]
  I0711 06:42:33.121757 20 service_latency.go:356] Created: latency-svc-mtqqw
  I0711 06:42:33.131819 20 service_latency.go:356] Created: latency-svc-qrxtd
  I0711 06:42:33.170724 20 service_latency.go:363] Got endpoints: latency-svc-mgkkg [262.402858ms]
  I0711 06:42:33.182823 20 service_latency.go:356] Created: latency-svc-9847b
  I0711 06:42:33.220262 20 service_latency.go:363] Got endpoints: latency-svc-jtn7b [305.644141ms]
  I0711 06:42:33.231727 20 service_latency.go:356] Created: latency-svc-nwwjn
  I0711 06:42:33.273307 20 service_latency.go:363] Got endpoints: latency-svc-kfrc7 [346.814907ms]
  I0711 06:42:33.286221 20 service_latency.go:356] Created: latency-svc-9q5mn
  I0711 06:42:33.319873 20 service_latency.go:363] Got endpoints: latency-svc-spgzh [383.636861ms]
  I0711 06:42:33.330631 20 service_latency.go:356] Created: latency-svc-pd952
  I0711 06:42:33.372278 20 service_latency.go:363] Got endpoints: latency-svc-pn9f5 [427.597241ms]
  I0711 06:42:33.382989 20 service_latency.go:356] Created: latency-svc-xjfmw
  I0711 06:42:33.421778 20 service_latency.go:363] Got endpoints: latency-svc-9gpms [466.041402ms]
  I0711 06:42:33.434715 20 service_latency.go:356] Created: latency-svc-6f7r4
  I0711 06:42:33.469702 20 service_latency.go:363] Got endpoints: latency-svc-qwqts [505.020704ms]
  I0711 06:42:33.481316 20 service_latency.go:356] Created: latency-svc-fj94x
  I0711 06:42:33.519737 20 service_latency.go:363] Got endpoints: latency-svc-qh8ll [546.338859ms]
  I0711 06:42:33.531116 20 service_latency.go:356] Created: latency-svc-x6bwq
  I0711 06:42:33.571171 20 service_latency.go:363] Got endpoints: latency-svc-5jq4d [591.589319ms]
  I0711 06:42:33.585372 20 service_latency.go:356] Created: latency-svc-p8df6
  I0711 06:42:33.622319 20 service_latency.go:363] Got endpoints: latency-svc-pt8j5 [633.640514ms]
  I0711 06:42:33.632342 20 service_latency.go:356] Created: latency-svc-gn5js
  I0711 06:42:33.670838 20 service_latency.go:363] Got endpoints: latency-svc-nz4g6 [675.956546ms]
  I0711 06:42:33.682212 20 service_latency.go:356] Created: latency-svc-sscx4
  I0711 06:42:33.721802 20 service_latency.go:363] Got endpoints: latency-svc-5m6bg [716.622905ms]
  I0711 06:42:33.733708 20 service_latency.go:356] Created: latency-svc-b4psn
  I0711 06:42:33.769362 20 service_latency.go:363] Got endpoints: latency-svc-9tqcv [750.836518ms]
  I0711 06:42:33.781072 20 service_latency.go:356] Created: latency-svc-cgqkf
  I0711 06:42:33.819667 20 service_latency.go:363] Got endpoints: latency-svc-mtqqw [747.329635ms]
  I0711 06:42:33.829587 20 service_latency.go:356] Created: latency-svc-2rzz2
  E0711 06:42:33.871688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:33.872054 20 service_latency.go:363] Got endpoints: latency-svc-qrxtd [751.190226ms]
  I0711 06:42:33.884225 20 service_latency.go:356] Created: latency-svc-g8n6b
  I0711 06:42:33.922369 20 service_latency.go:363] Got endpoints: latency-svc-9847b [751.601409ms]
  I0711 06:42:33.933353 20 service_latency.go:356] Created: latency-svc-mvkm2
  I0711 06:42:33.970701 20 service_latency.go:363] Got endpoints: latency-svc-nwwjn [750.388114ms]
  I0711 06:42:33.981997 20 service_latency.go:356] Created: latency-svc-hvfzl
  I0711 06:42:34.021342 20 service_latency.go:363] Got endpoints: latency-svc-9q5mn [747.853493ms]
  I0711 06:42:34.033059 20 service_latency.go:356] Created: latency-svc-7nfqj
  I0711 06:42:34.069944 20 service_latency.go:363] Got endpoints: latency-svc-pd952 [749.832536ms]
  I0711 06:42:34.082290 20 service_latency.go:356] Created: latency-svc-gvqm7
  I0711 06:42:34.119369 20 service_latency.go:363] Got endpoints: latency-svc-xjfmw [746.870713ms]
  I0711 06:42:34.129359 20 service_latency.go:356] Created: latency-svc-2w2zw
  I0711 06:42:34.171552 20 service_latency.go:363] Got endpoints: latency-svc-6f7r4 [749.691218ms]
  I0711 06:42:34.184049 20 service_latency.go:356] Created: latency-svc-p9xm6
  I0711 06:42:34.221094 20 service_latency.go:363] Got endpoints: latency-svc-fj94x [751.346465ms]
  I0711 06:42:34.234169 20 service_latency.go:356] Created: latency-svc-fp88l
  I0711 06:42:34.271699 20 service_latency.go:363] Got endpoints: latency-svc-x6bwq [751.913274ms]
  I0711 06:42:34.282561 20 service_latency.go:356] Created: latency-svc-j9bqx
  I0711 06:42:34.319702 20 service_latency.go:363] Got endpoints: latency-svc-p8df6 [748.488479ms]
  I0711 06:42:34.330589 20 service_latency.go:356] Created: latency-svc-6gnsg
  I0711 06:42:34.370408 20 service_latency.go:363] Got endpoints: latency-svc-gn5js [748.052653ms]
  I0711 06:42:34.382488 20 service_latency.go:356] Created: latency-svc-wlpjk
  I0711 06:42:34.421100 20 service_latency.go:363] Got endpoints: latency-svc-sscx4 [750.212538ms]
  I0711 06:42:34.431394 20 service_latency.go:356] Created: latency-svc-f6fz9
  I0711 06:42:34.470971 20 service_latency.go:363] Got endpoints: latency-svc-b4psn [749.035202ms]
  I0711 06:42:34.482592 20 service_latency.go:356] Created: latency-svc-g9d4f
  I0711 06:42:34.519839 20 service_latency.go:363] Got endpoints: latency-svc-cgqkf [750.312655ms]
  I0711 06:42:34.531112 20 service_latency.go:356] Created: latency-svc-56mhj
  I0711 06:42:34.570483 20 service_latency.go:363] Got endpoints: latency-svc-2rzz2 [750.61834ms]
  I0711 06:42:34.596791 20 service_latency.go:356] Created: latency-svc-g5kgx
  I0711 06:42:34.619344 20 service_latency.go:363] Got endpoints: latency-svc-g8n6b [747.262551ms]
  I0711 06:42:34.665795 20 service_latency.go:356] Created: latency-svc-dpczs
  I0711 06:42:34.673176 20 service_latency.go:363] Got endpoints: latency-svc-mvkm2 [750.741538ms]
  I0711 06:42:34.684617 20 service_latency.go:356] Created: latency-svc-cphbv
  I0711 06:42:34.721299 20 service_latency.go:363] Got endpoints: latency-svc-hvfzl [750.532808ms]
  I0711 06:42:34.731216 20 service_latency.go:356] Created: latency-svc-gp527
  I0711 06:42:34.769450 20 service_latency.go:363] Got endpoints: latency-svc-7nfqj [748.012763ms]
  I0711 06:42:34.780677 20 service_latency.go:356] Created: latency-svc-8mqfh
  I0711 06:42:34.820349 20 service_latency.go:363] Got endpoints: latency-svc-gvqm7 [750.350556ms]
  I0711 06:42:34.830556 20 service_latency.go:356] Created: latency-svc-kx5gs
  E0711 06:42:34.871896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:34.872430 20 service_latency.go:363] Got endpoints: latency-svc-2w2zw [752.994978ms]
  I0711 06:42:34.882687 20 service_latency.go:356] Created: latency-svc-m9gmr
  I0711 06:42:34.921132 20 service_latency.go:363] Got endpoints: latency-svc-p9xm6 [749.357906ms]
  I0711 06:42:34.932355 20 service_latency.go:356] Created: latency-svc-n5nll
  I0711 06:42:34.971558 20 service_latency.go:363] Got endpoints: latency-svc-fp88l [750.384718ms]
  I0711 06:42:34.984125 20 service_latency.go:356] Created: latency-svc-qvh42
  I0711 06:42:35.019750 20 service_latency.go:363] Got endpoints: latency-svc-j9bqx [748.006912ms]
  I0711 06:42:35.030575 20 service_latency.go:356] Created: latency-svc-4zbrp
  I0711 06:42:35.069924 20 service_latency.go:363] Got endpoints: latency-svc-6gnsg [750.170032ms]
  I0711 06:42:35.085487 20 service_latency.go:356] Created: latency-svc-6tfw4
  I0711 06:42:35.120511 20 service_latency.go:363] Got endpoints: latency-svc-wlpjk [750.066246ms]
  I0711 06:42:35.132841 20 service_latency.go:356] Created: latency-svc-m7ds8
  I0711 06:42:35.171018 20 service_latency.go:363] Got endpoints: latency-svc-f6fz9 [749.860455ms]
  I0711 06:42:35.182186 20 service_latency.go:356] Created: latency-svc-xzqbq
  I0711 06:42:35.220772 20 service_latency.go:363] Got endpoints: latency-svc-g9d4f [749.758865ms]
  I0711 06:42:35.233290 20 service_latency.go:356] Created: latency-svc-nhhd4
  I0711 06:42:35.269305 20 service_latency.go:363] Got endpoints: latency-svc-56mhj [749.407589ms]
  I0711 06:42:35.280249 20 service_latency.go:356] Created: latency-svc-kgwkn
  I0711 06:42:35.321031 20 service_latency.go:363] Got endpoints: latency-svc-g5kgx [750.460391ms]
  I0711 06:42:35.330979 20 service_latency.go:356] Created: latency-svc-vvhqj
  I0711 06:42:35.371579 20 service_latency.go:363] Got endpoints: latency-svc-dpczs [752.155613ms]
  I0711 06:42:35.384216 20 service_latency.go:356] Created: latency-svc-dzlbg
  I0711 06:42:35.420259 20 service_latency.go:363] Got endpoints: latency-svc-cphbv [746.738996ms]
  I0711 06:42:35.431546 20 service_latency.go:356] Created: latency-svc-kp7q4
  I0711 06:42:35.471670 20 service_latency.go:363] Got endpoints: latency-svc-gp527 [750.238507ms]
  I0711 06:42:35.481463 20 service_latency.go:356] Created: latency-svc-cpv7g
  I0711 06:42:35.521585 20 service_latency.go:363] Got endpoints: latency-svc-8mqfh [752.095401ms]
  I0711 06:42:35.534789 20 service_latency.go:356] Created: latency-svc-n846q
  I0711 06:42:35.572406 20 service_latency.go:363] Got endpoints: latency-svc-kx5gs [751.856944ms]
  I0711 06:42:35.583190 20 service_latency.go:356] Created: latency-svc-hhjtw
  I0711 06:42:35.620209 20 service_latency.go:363] Got endpoints: latency-svc-m9gmr [747.693827ms]
  I0711 06:42:35.630977 20 service_latency.go:356] Created: latency-svc-jlkgm
  I0711 06:42:35.670467 20 service_latency.go:363] Got endpoints: latency-svc-n5nll [748.904776ms]
  I0711 06:42:35.683258 20 service_latency.go:356] Created: latency-svc-4v6w5
  I0711 06:42:35.719856 20 service_latency.go:363] Got endpoints: latency-svc-qvh42 [748.087233ms]
  I0711 06:42:35.731420 20 service_latency.go:356] Created: latency-svc-v2br8
  I0711 06:42:35.770438 20 service_latency.go:363] Got endpoints: latency-svc-4zbrp [750.640639ms]
  I0711 06:42:35.780426 20 service_latency.go:356] Created: latency-svc-qwzsz
  I0711 06:42:35.819428 20 service_latency.go:363] Got endpoints: latency-svc-6tfw4 [749.435017ms]
  I0711 06:42:35.831391 20 service_latency.go:356] Created: latency-svc-grhln
  I0711 06:42:35.871250 20 service_latency.go:363] Got endpoints: latency-svc-m7ds8 [750.694877ms]
  E0711 06:42:35.871801      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:35.882952 20 service_latency.go:356] Created: latency-svc-plvfk
  I0711 06:42:35.919375 20 service_latency.go:363] Got endpoints: latency-svc-xzqbq [748.081531ms]
  I0711 06:42:35.931934 20 service_latency.go:356] Created: latency-svc-hdv7x
  I0711 06:42:35.971450 20 service_latency.go:363] Got endpoints: latency-svc-nhhd4 [750.059907ms]
  I0711 06:42:35.983147 20 service_latency.go:356] Created: latency-svc-pzsmz
  I0711 06:42:36.020637 20 service_latency.go:363] Got endpoints: latency-svc-kgwkn [751.28285ms]
  I0711 06:42:36.031587 20 service_latency.go:356] Created: latency-svc-8fsq9
  I0711 06:42:36.069657 20 service_latency.go:363] Got endpoints: latency-svc-vvhqj [748.574253ms]
  I0711 06:42:36.080660 20 service_latency.go:356] Created: latency-svc-xrw7q
  I0711 06:42:36.121069 20 service_latency.go:363] Got endpoints: latency-svc-dzlbg [749.199642ms]
  I0711 06:42:36.133872 20 service_latency.go:356] Created: latency-svc-cknft
  I0711 06:42:36.171618 20 service_latency.go:363] Got endpoints: latency-svc-kp7q4 [751.317091ms]
  I0711 06:42:36.188105 20 service_latency.go:356] Created: latency-svc-kdts9
  I0711 06:42:36.223179 20 service_latency.go:363] Got endpoints: latency-svc-cpv7g [751.472175ms]
  I0711 06:42:36.240967 20 service_latency.go:356] Created: latency-svc-srsbn
  I0711 06:42:36.274758 20 service_latency.go:363] Got endpoints: latency-svc-n846q [752.958929ms]
  I0711 06:42:36.294420 20 service_latency.go:356] Created: latency-svc-p95gh
  I0711 06:42:36.320790 20 service_latency.go:363] Got endpoints: latency-svc-hhjtw [748.34924ms]
  I0711 06:42:36.335228 20 service_latency.go:356] Created: latency-svc-7hf7v
  I0711 06:42:36.373062 20 service_latency.go:363] Got endpoints: latency-svc-jlkgm [752.577919ms]
  I0711 06:42:36.390514 20 service_latency.go:356] Created: latency-svc-54kdc
  I0711 06:42:36.421798 20 service_latency.go:363] Got endpoints: latency-svc-4v6w5 [750.947827ms]
  I0711 06:42:36.439146 20 service_latency.go:356] Created: latency-svc-7n9r4
  I0711 06:42:36.474022 20 service_latency.go:363] Got endpoints: latency-svc-v2br8 [754.122945ms]
  I0711 06:42:36.491982 20 service_latency.go:356] Created: latency-svc-css49
  I0711 06:42:36.528296 20 service_latency.go:363] Got endpoints: latency-svc-qwzsz [757.762745ms]
  I0711 06:42:36.546629 20 service_latency.go:356] Created: latency-svc-twg6z
  I0711 06:42:36.570745 20 service_latency.go:363] Got endpoints: latency-svc-grhln [751.236698ms]
  I0711 06:42:36.592886 20 service_latency.go:356] Created: latency-svc-md7t2
  I0711 06:42:36.619497 20 service_latency.go:363] Got endpoints: latency-svc-plvfk [748.028971ms]
  I0711 06:42:36.637345 20 service_latency.go:356] Created: latency-svc-cq4j5
  I0711 06:42:36.669429 20 service_latency.go:363] Got endpoints: latency-svc-hdv7x [749.870354ms]
  I0711 06:42:36.697241 20 service_latency.go:356] Created: latency-svc-5sfwq
  I0711 06:42:36.720851 20 service_latency.go:363] Got endpoints: latency-svc-pzsmz [749.062044ms]
  I0711 06:42:36.734389 20 service_latency.go:356] Created: latency-svc-4bg96
  I0711 06:42:36.770057 20 service_latency.go:363] Got endpoints: latency-svc-8fsq9 [749.246475ms]
  I0711 06:42:36.780780 20 service_latency.go:356] Created: latency-svc-slpkn
  I0711 06:42:36.830334 20 service_latency.go:363] Got endpoints: latency-svc-xrw7q [760.626478ms]
  I0711 06:42:36.847301 20 service_latency.go:356] Created: latency-svc-88zcx
  I0711 06:42:36.874732 20 service_latency.go:363] Got endpoints: latency-svc-cknft [753.481335ms]
  E0711 06:42:36.874898      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:36.888147 20 service_latency.go:356] Created: latency-svc-kgsrt
  I0711 06:42:36.921716 20 service_latency.go:363] Got endpoints: latency-svc-kdts9 [750.044346ms]
  I0711 06:42:36.941777 20 service_latency.go:356] Created: latency-svc-ff8xs
  I0711 06:42:36.980014 20 service_latency.go:363] Got endpoints: latency-svc-srsbn [756.792404ms]
  I0711 06:42:36.992566 20 service_latency.go:356] Created: latency-svc-bsgr9
  I0711 06:42:37.020337 20 service_latency.go:363] Got endpoints: latency-svc-p95gh [745.364869ms]
  I0711 06:42:37.033222 20 service_latency.go:356] Created: latency-svc-2x9jv
  I0711 06:42:37.071882 20 service_latency.go:363] Got endpoints: latency-svc-7hf7v [751.055554ms]
  I0711 06:42:37.084388 20 service_latency.go:356] Created: latency-svc-s5vsz
  I0711 06:42:37.122827 20 service_latency.go:363] Got endpoints: latency-svc-54kdc [749.623843ms]
  I0711 06:42:37.133627 20 service_latency.go:356] Created: latency-svc-88n8h
  I0711 06:42:37.169273 20 service_latency.go:363] Got endpoints: latency-svc-7n9r4 [747.417168ms]
  I0711 06:42:37.180814 20 service_latency.go:356] Created: latency-svc-vnvvc
  I0711 06:42:37.221937 20 service_latency.go:363] Got endpoints: latency-svc-css49 [747.789191ms]
  I0711 06:42:37.232522 20 service_latency.go:356] Created: latency-svc-5xh6c
  I0711 06:42:37.270984 20 service_latency.go:363] Got endpoints: latency-svc-twg6z [742.645686ms]
  I0711 06:42:37.281047 20 service_latency.go:356] Created: latency-svc-g7t9r
  I0711 06:42:37.320958 20 service_latency.go:363] Got endpoints: latency-svc-md7t2 [750.165738ms]
  I0711 06:42:37.334414 20 service_latency.go:356] Created: latency-svc-cqz8z
  I0711 06:42:37.370075 20 service_latency.go:363] Got endpoints: latency-svc-cq4j5 [750.537664ms]
  I0711 06:42:37.382258 20 service_latency.go:356] Created: latency-svc-gr998
  I0711 06:42:37.421901 20 service_latency.go:363] Got endpoints: latency-svc-5sfwq [752.425199ms]
  I0711 06:42:37.431353 20 service_latency.go:356] Created: latency-svc-zj9w9
  I0711 06:42:37.472039 20 service_latency.go:363] Got endpoints: latency-svc-4bg96 [749.657808ms]
  I0711 06:42:37.483039 20 service_latency.go:356] Created: latency-svc-ccrk9
  I0711 06:42:37.520963 20 service_latency.go:363] Got endpoints: latency-svc-slpkn [750.765948ms]
  I0711 06:42:37.530902 20 service_latency.go:356] Created: latency-svc-99xhd
  I0711 06:42:37.570208 20 service_latency.go:363] Got endpoints: latency-svc-88zcx [739.52499ms]
  I0711 06:42:37.580024 20 service_latency.go:356] Created: latency-svc-ck99g
  I0711 06:42:37.621872 20 service_latency.go:363] Got endpoints: latency-svc-kgsrt [746.8883ms]
  I0711 06:42:37.634149 20 service_latency.go:356] Created: latency-svc-gh5sh
  I0711 06:42:37.670528 20 service_latency.go:363] Got endpoints: latency-svc-ff8xs [747.815489ms]
  I0711 06:42:37.683362 20 service_latency.go:356] Created: latency-svc-kh6sq
  I0711 06:42:37.719393 20 service_latency.go:363] Got endpoints: latency-svc-bsgr9 [739.332238ms]
  I0711 06:42:37.730083 20 service_latency.go:356] Created: latency-svc-rlv26
  I0711 06:42:37.770649 20 service_latency.go:363] Got endpoints: latency-svc-2x9jv [750.243016ms]
  I0711 06:42:37.782875 20 service_latency.go:356] Created: latency-svc-jcj57
  I0711 06:42:37.821571 20 service_latency.go:363] Got endpoints: latency-svc-s5vsz [749.592488ms]
  I0711 06:42:37.833847 20 service_latency.go:356] Created: latency-svc-b4zqx
  I0711 06:42:37.871531 20 service_latency.go:363] Got endpoints: latency-svc-88n8h [748.659635ms]
  E0711 06:42:37.875250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:37.881284 20 service_latency.go:356] Created: latency-svc-95c2c
  I0711 06:42:37.919957 20 service_latency.go:363] Got endpoints: latency-svc-vnvvc [750.555014ms]
  I0711 06:42:37.975476 20 service_latency.go:363] Got endpoints: latency-svc-5xh6c [753.421007ms]
  I0711 06:42:38.020110 20 service_latency.go:363] Got endpoints: latency-svc-g7t9r [749.090071ms]
  I0711 06:42:38.085603 20 service_latency.go:363] Got endpoints: latency-svc-cqz8z [764.495421ms]
  I0711 06:42:38.089226 20 service_latency.go:356] Created: latency-svc-l45ds
  I0711 06:42:38.100045 20 service_latency.go:356] Created: latency-svc-g2kwh
  I0711 06:42:38.101313 20 service_latency.go:356] Created: latency-svc-zk68g
  I0711 06:42:38.109824 20 service_latency.go:356] Created: latency-svc-vfd7g
  I0711 06:42:38.119744 20 service_latency.go:363] Got endpoints: latency-svc-gr998 [749.582414ms]
  I0711 06:42:38.131119 20 service_latency.go:356] Created: latency-svc-fk7d2
  I0711 06:42:38.170054 20 service_latency.go:363] Got endpoints: latency-svc-zj9w9 [748.008809ms]
  I0711 06:42:38.181125 20 service_latency.go:356] Created: latency-svc-kvxmf
  I0711 06:42:38.218547 20 service_latency.go:363] Got endpoints: latency-svc-ccrk9 [746.466691ms]
  I0711 06:42:38.229416 20 service_latency.go:356] Created: latency-svc-qpfc6
  I0711 06:42:38.269843 20 service_latency.go:363] Got endpoints: latency-svc-99xhd [748.831383ms]
  I0711 06:42:38.279933 20 service_latency.go:356] Created: latency-svc-m8qn6
  I0711 06:42:38.320626 20 service_latency.go:363] Got endpoints: latency-svc-ck99g [750.35547ms]
  I0711 06:42:38.332313 20 service_latency.go:356] Created: latency-svc-jg8tv
  I0711 06:42:38.370198 20 service_latency.go:363] Got endpoints: latency-svc-gh5sh [748.281171ms]
  I0711 06:42:38.382204 20 service_latency.go:356] Created: latency-svc-rzr7b
  I0711 06:42:38.420291 20 service_latency.go:363] Got endpoints: latency-svc-kh6sq [749.727716ms]
  I0711 06:42:38.431606 20 service_latency.go:356] Created: latency-svc-5qjwj
  I0711 06:42:38.469590 20 service_latency.go:363] Got endpoints: latency-svc-rlv26 [750.151546ms]
  I0711 06:42:38.479261 20 service_latency.go:356] Created: latency-svc-2g8sl
  I0711 06:42:38.520095 20 service_latency.go:363] Got endpoints: latency-svc-jcj57 [749.408824ms]
  I0711 06:42:38.531325 20 service_latency.go:356] Created: latency-svc-5tjmj
  I0711 06:42:38.573277 20 service_latency.go:363] Got endpoints: latency-svc-b4zqx [751.656033ms]
  I0711 06:42:38.583944 20 service_latency.go:356] Created: latency-svc-dpzkr
  I0711 06:42:38.621704 20 service_latency.go:363] Got endpoints: latency-svc-95c2c [750.059085ms]
  I0711 06:42:38.632297 20 service_latency.go:356] Created: latency-svc-h85xf
  I0711 06:42:38.670477 20 service_latency.go:363] Got endpoints: latency-svc-l45ds [750.44399ms]
  I0711 06:42:38.684302 20 service_latency.go:356] Created: latency-svc-gxqjm
  I0711 06:42:38.720419 20 service_latency.go:363] Got endpoints: latency-svc-g2kwh [744.868599ms]
  I0711 06:42:38.734554 20 service_latency.go:356] Created: latency-svc-dfmz4
  I0711 06:42:38.770675 20 service_latency.go:363] Got endpoints: latency-svc-zk68g [750.493508ms]
  I0711 06:42:38.783251 20 service_latency.go:356] Created: latency-svc-stf76
  I0711 06:42:38.821243 20 service_latency.go:363] Got endpoints: latency-svc-vfd7g [735.570297ms]
  I0711 06:42:38.832296 20 service_latency.go:356] Created: latency-svc-b6k55
  I0711 06:42:38.870099 20 service_latency.go:363] Got endpoints: latency-svc-fk7d2 [750.324127ms]
  E0711 06:42:38.876329      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:38.882152 20 service_latency.go:356] Created: latency-svc-lgwjt
  I0711 06:42:38.920743 20 service_latency.go:363] Got endpoints: latency-svc-kvxmf [750.654676ms]
  I0711 06:42:38.936067 20 service_latency.go:356] Created: latency-svc-xrtkb
  I0711 06:42:38.970971 20 service_latency.go:363] Got endpoints: latency-svc-qpfc6 [752.265848ms]
  I0711 06:42:38.981870 20 service_latency.go:356] Created: latency-svc-tqrnf
  I0711 06:42:39.022612 20 service_latency.go:363] Got endpoints: latency-svc-m8qn6 [752.595705ms]
  I0711 06:42:39.032728 20 service_latency.go:356] Created: latency-svc-rqkq9
  I0711 06:42:39.070848 20 service_latency.go:363] Got endpoints: latency-svc-jg8tv [749.832096ms]
  I0711 06:42:39.080885 20 service_latency.go:356] Created: latency-svc-hpnvz
  I0711 06:42:39.122556 20 service_latency.go:363] Got endpoints: latency-svc-rzr7b [752.321689ms]
  I0711 06:42:39.134727 20 service_latency.go:356] Created: latency-svc-57z4x
  I0711 06:42:39.169878 20 service_latency.go:363] Got endpoints: latency-svc-5qjwj [749.439417ms]
  I0711 06:42:39.180978 20 service_latency.go:356] Created: latency-svc-vfck5
  I0711 06:42:39.220282 20 service_latency.go:363] Got endpoints: latency-svc-2g8sl [750.644413ms]
  I0711 06:42:39.230713 20 service_latency.go:356] Created: latency-svc-vxcpr
  I0711 06:42:39.272194 20 service_latency.go:363] Got endpoints: latency-svc-5tjmj [751.954368ms]
  I0711 06:42:39.283857 20 service_latency.go:356] Created: latency-svc-g6q6c
  I0711 06:42:39.320186 20 service_latency.go:363] Got endpoints: latency-svc-dpzkr [746.669045ms]
  I0711 06:42:39.332006 20 service_latency.go:356] Created: latency-svc-vnrzj
  I0711 06:42:39.370589 20 service_latency.go:363] Got endpoints: latency-svc-h85xf [748.769749ms]
  I0711 06:42:39.382445 20 service_latency.go:356] Created: latency-svc-zk9px
  I0711 06:42:39.419989 20 service_latency.go:363] Got endpoints: latency-svc-gxqjm [749.26295ms]
  I0711 06:42:39.432097 20 service_latency.go:356] Created: latency-svc-sgmn5
  I0711 06:42:39.470913 20 service_latency.go:363] Got endpoints: latency-svc-dfmz4 [750.428301ms]
  I0711 06:42:39.483441 20 service_latency.go:356] Created: latency-svc-r7qnn
  I0711 06:42:39.523550 20 service_latency.go:363] Got endpoints: latency-svc-stf76 [752.741583ms]
  I0711 06:42:39.533670 20 service_latency.go:356] Created: latency-svc-gn86f
  I0711 06:42:39.570386 20 service_latency.go:363] Got endpoints: latency-svc-b6k55 [749.066752ms]
  I0711 06:42:39.582115 20 service_latency.go:356] Created: latency-svc-kpgnv
  I0711 06:42:39.621640 20 service_latency.go:363] Got endpoints: latency-svc-lgwjt [751.497466ms]
  I0711 06:42:39.632944 20 service_latency.go:356] Created: latency-svc-5bwv4
  I0711 06:42:39.670771 20 service_latency.go:363] Got endpoints: latency-svc-xrtkb [749.942425ms]
  I0711 06:42:39.685742 20 service_latency.go:356] Created: latency-svc-p9qnb
  I0711 06:42:39.720076 20 service_latency.go:363] Got endpoints: latency-svc-tqrnf [748.68913ms]
  I0711 06:42:39.730356 20 service_latency.go:356] Created: latency-svc-9cshn
  I0711 06:42:39.772585 20 service_latency.go:363] Got endpoints: latency-svc-rqkq9 [749.833403ms]
  I0711 06:42:39.784120 20 service_latency.go:356] Created: latency-svc-2vbc4
  I0711 06:42:39.820908 20 service_latency.go:363] Got endpoints: latency-svc-hpnvz [749.933397ms]
  I0711 06:42:39.831322 20 service_latency.go:356] Created: latency-svc-n8gpw
  I0711 06:42:39.870601 20 service_latency.go:363] Got endpoints: latency-svc-57z4x [747.946172ms]
  E0711 06:42:39.876860      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:39.882200 20 service_latency.go:356] Created: latency-svc-z8dhs
  I0711 06:42:39.920538 20 service_latency.go:363] Got endpoints: latency-svc-vfck5 [750.621891ms]
  I0711 06:42:39.931793 20 service_latency.go:356] Created: latency-svc-7rt47
  I0711 06:42:39.970503 20 service_latency.go:363] Got endpoints: latency-svc-vxcpr [749.912521ms]
  I0711 06:42:39.981368 20 service_latency.go:356] Created: latency-svc-8kdkx
  I0711 06:42:40.022841 20 service_latency.go:363] Got endpoints: latency-svc-g6q6c [750.468394ms]
  I0711 06:42:40.035062 20 service_latency.go:356] Created: latency-svc-mgv45
  I0711 06:42:40.071537 20 service_latency.go:363] Got endpoints: latency-svc-vnrzj [751.306623ms]
  I0711 06:42:40.082461 20 service_latency.go:356] Created: latency-svc-jf75x
  I0711 06:42:40.121009 20 service_latency.go:363] Got endpoints: latency-svc-zk9px [750.367006ms]
  I0711 06:42:40.132715 20 service_latency.go:356] Created: latency-svc-4dvh9
  I0711 06:42:40.171317 20 service_latency.go:363] Got endpoints: latency-svc-sgmn5 [751.238593ms]
  I0711 06:42:40.183150 20 service_latency.go:356] Created: latency-svc-m775s
  I0711 06:42:40.219914 20 service_latency.go:363] Got endpoints: latency-svc-r7qnn [748.787962ms]
  I0711 06:42:40.230906 20 service_latency.go:356] Created: latency-svc-fhh6b
  I0711 06:42:40.270450 20 service_latency.go:363] Got endpoints: latency-svc-gn86f [746.760034ms]
  I0711 06:42:40.280911 20 service_latency.go:356] Created: latency-svc-rww7m
  I0711 06:42:40.321860 20 service_latency.go:363] Got endpoints: latency-svc-kpgnv [751.339673ms]
  I0711 06:42:40.335123 20 service_latency.go:356] Created: latency-svc-5scnl
  I0711 06:42:40.371136 20 service_latency.go:363] Got endpoints: latency-svc-5bwv4 [749.22751ms]
  I0711 06:42:40.382470 20 service_latency.go:356] Created: latency-svc-kxslq
  I0711 06:42:40.420962 20 service_latency.go:363] Got endpoints: latency-svc-p9qnb [750.054849ms]
  I0711 06:42:40.432811 20 service_latency.go:356] Created: latency-svc-s22v9
  I0711 06:42:40.470774 20 service_latency.go:363] Got endpoints: latency-svc-9cshn [750.520612ms]
  I0711 06:42:40.481204 20 service_latency.go:356] Created: latency-svc-wgvbm
  I0711 06:42:40.521898 20 service_latency.go:363] Got endpoints: latency-svc-2vbc4 [749.262857ms]
  I0711 06:42:40.570362 20 service_latency.go:363] Got endpoints: latency-svc-n8gpw [749.065503ms]
  I0711 06:42:40.620505 20 service_latency.go:363] Got endpoints: latency-svc-z8dhs [749.821939ms]
  I0711 06:42:40.670269 20 service_latency.go:363] Got endpoints: latency-svc-7rt47 [749.685025ms]
  I0711 06:42:40.721044 20 service_latency.go:363] Got endpoints: latency-svc-8kdkx [750.487367ms]
  I0711 06:42:40.771055 20 service_latency.go:363] Got endpoints: latency-svc-mgv45 [748.136385ms]
  I0711 06:42:40.823909 20 service_latency.go:363] Got endpoints: latency-svc-jf75x [752.074064ms]
  I0711 06:42:40.871421 20 service_latency.go:363] Got endpoints: latency-svc-4dvh9 [750.180792ms]
  E0711 06:42:40.877474      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:40.921953 20 service_latency.go:363] Got endpoints: latency-svc-m775s [750.580327ms]
  I0711 06:42:40.970998 20 service_latency.go:363] Got endpoints: latency-svc-fhh6b [751.037567ms]
  I0711 06:42:41.020887 20 service_latency.go:363] Got endpoints: latency-svc-rww7m [750.380271ms]
  I0711 06:42:41.069940 20 service_latency.go:363] Got endpoints: latency-svc-5scnl [747.444423ms]
  I0711 06:42:41.120210 20 service_latency.go:363] Got endpoints: latency-svc-kxslq [748.86804ms]
  I0711 06:42:41.170628 20 service_latency.go:363] Got endpoints: latency-svc-s22v9 [749.605518ms]
  I0711 06:42:41.223442 20 service_latency.go:363] Got endpoints: latency-svc-wgvbm [752.61685ms]
  I0711 06:42:41.223769 20 service_latency.go:114] Latencies: [16.427419ms 25.826868ms 34.900774ms 43.576845ms 55.771513ms 65.122062ms 67.549681ms 79.921005ms 88.341669ms 93.689548ms 105.586771ms 109.141966ms 119.422548ms 128.943031ms 129.065032ms 129.660008ms 131.709101ms 132.022503ms 134.21457ms 134.937255ms 135.819726ms 139.066477ms 139.855584ms 143.121767ms 144.887363ms 145.908408ms 147.611612ms 148.347408ms 148.414695ms 149.729195ms 152.336826ms 153.22744ms 154.184705ms 154.343597ms 155.712472ms 157.790994ms 192.327978ms 229.391158ms 262.402858ms 305.644141ms 346.814907ms 383.636861ms 427.597241ms 466.041402ms 505.020704ms 546.338859ms 591.589319ms 633.640514ms 675.956546ms 716.622905ms 735.570297ms 739.332238ms 739.52499ms 742.645686ms 744.868599ms 745.364869ms 746.466691ms 746.669045ms 746.738996ms 746.760034ms 746.870713ms 746.8883ms 747.262551ms 747.329635ms 747.417168ms 747.444423ms 747.693827ms 747.789191ms 747.815489ms 747.853493ms 747.946172ms 748.006912ms 748.008809ms 748.012763ms 748.028971ms 748.052653ms 748.081531ms 748.087233ms 748.136385ms 748.281171ms 748.34924ms 748.488479ms 748.574253ms 748.659635ms 748.68913ms 748.769749ms 748.787962ms 748.831383ms 748.86804ms 748.904776ms 749.035202ms 749.062044ms 749.065503ms 749.066752ms 749.090071ms 749.199642ms 749.22751ms 749.246475ms 749.262857ms 749.26295ms 749.357906ms 749.407589ms 749.408824ms 749.435017ms 749.439417ms 749.582414ms 749.592488ms 749.605518ms 749.623843ms 749.657808ms 749.685025ms 749.691218ms 749.727716ms 749.758865ms 749.821939ms 749.832096ms 749.832536ms 749.833403ms 749.860455ms 749.870354ms 749.912521ms 749.933397ms 749.942425ms 750.044346ms 750.054849ms 750.059085ms 750.059907ms 750.066246ms 750.151546ms 750.165738ms 750.170032ms 750.180792ms 750.212538ms 750.238507ms 750.243016ms 750.312655ms 750.324127ms 750.350556ms 750.35547ms 750.367006ms 750.380271ms 750.384718ms 750.388114ms 750.428301ms 750.44399ms 750.460391ms 750.468394ms 750.487367ms 750.493508ms 750.520612ms 750.532808ms 750.537664ms 750.555014ms 750.580327ms 750.61834ms 750.621891ms 750.640639ms 750.644413ms 750.654676ms 750.694877ms 750.741538ms 750.765948ms 750.836518ms 750.947827ms 751.037567ms 751.055554ms 751.190226ms 751.236698ms 751.238593ms 751.28285ms 751.306623ms 751.317091ms 751.339673ms 751.346465ms 751.472175ms 751.497466ms 751.601409ms 751.656033ms 751.856944ms 751.913274ms 751.954368ms 752.074064ms 752.095401ms 752.155613ms 752.265848ms 752.321689ms 752.425199ms 752.577919ms 752.595705ms 752.61685ms 752.741583ms 752.958929ms 752.994978ms 753.421007ms 753.481335ms 754.122945ms 756.792404ms 757.762745ms 760.626478ms 764.495421ms]
  I0711 06:42:41.223841 20 service_latency.go:118] 50 %ile: 749.357906ms
  I0711 06:42:41.223852 20 service_latency.go:119] 90 %ile: 751.954368ms
  I0711 06:42:41.223859 20 service_latency.go:120] 99 %ile: 760.626478ms
  I0711 06:42:41.223865 20 service_latency.go:121] Total sample count: 200
  I0711 06:42:41.223943 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-9772" for this suite. @ 07/11/24 06:42:41.229
• [10.768 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1793
  STEP: Creating a kubernetes client @ 07/11/24 06:42:41.237
  I0711 06:42:41.237722 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 06:42:41.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:41.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:41.258
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 07/11/24 06:42:41.261
  I0711 06:42:41.261814 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3295 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0711 06:42:41.312468 20 builder.go:146] stderr: ""
  I0711 06:42:41.312504 20 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 07/11/24 06:42:41.312
  E0711 06:42:41.878436      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:42.878991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:43.879146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:44.879226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:45.879321      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 07/11/24 06:42:46.363
  I0711 06:42:46.363982 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3295 get pod e2e-test-httpd-pod -o json'
  I0711 06:42:46.435747 20 builder.go:146] stderr: ""
  I0711 06:42:46.435866 20 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-07-11T06:42:41Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3295\",\n        \"resourceVersion\": \"27843\",\n        \"uid\": \"4e429546-da7b-4149-ad52-f5741e4bfb65\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-64rfc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-17-237\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-64rfc\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-07-11T06:42:42Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-07-11T06:42:41Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-07-11T06:42:42Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-07-11T06:42:42Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-07-11T06:42:41Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://e60c6ed5e099149705eaea7810a654889a6b667641366932d9cb75d94efb9504\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-07-11T06:42:41Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.17.237\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"172.31.17.237\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.133.118\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.133.118\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-07-11T06:42:41Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 07/11/24 06:42:46.435
  I0711 06:42:46.436008 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3295 replace -f -'
  I0711 06:42:46.523424 20 builder.go:146] stderr: ""
  I0711 06:42:46.523476 20 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 07/11/24 06:42:46.523
  I0711 06:42:46.528034 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3295 delete pods e2e-test-httpd-pod'
  E0711 06:42:46.879423      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:47.879520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:42:48.152785 20 builder.go:146] stderr: ""
  I0711 06:42:48.152823 20 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0711 06:42:48.153040 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3295" for this suite. @ 07/11/24 06:42:48.157
• [6.927 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 07/11/24 06:42:48.164
  I0711 06:42:48.164848 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 06:42:48.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:42:48.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:42:48.188
  STEP: Creating a ResourceQuota with terminating scope @ 07/11/24 06:42:48.19
  STEP: Ensuring ResourceQuota status is calculated @ 07/11/24 06:42:48.196
  E0711 06:42:48.880106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:49.880240      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 07/11/24 06:42:50.201
  STEP: Ensuring ResourceQuota status is calculated @ 07/11/24 06:42:50.206
  E0711 06:42:50.881133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:51.881226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 07/11/24 06:42:52.212
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 07/11/24 06:42:52.227
  E0711 06:42:52.881501      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:53.881740      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 07/11/24 06:42:54.232
  E0711 06:42:54.882575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:55.882654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 07/11/24 06:42:56.238
  STEP: Ensuring resource quota status released the pod usage @ 07/11/24 06:42:56.255
  E0711 06:42:56.883026      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:57.883576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 07/11/24 06:42:58.26
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 07/11/24 06:42:58.272
  E0711 06:42:58.883858      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:42:59.883995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 07/11/24 06:43:00.277
  E0711 06:43:00.885040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:01.885250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 07/11/24 06:43:02.281
  STEP: Ensuring resource quota status released the pod usage @ 07/11/24 06:43:02.302
  E0711 06:43:02.885430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:03.885542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:04.307596 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1236" for this suite. @ 07/11/24 06:43:04.312
• [16.155 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 07/11/24 06:43:04.32
  I0711 06:43:04.320130 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename certificates @ 07/11/24 06:43:04.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:04.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:04.344
  STEP: getting /apis @ 07/11/24 06:43:04.557
  STEP: getting /apis/certificates.k8s.io @ 07/11/24 06:43:04.56
  STEP: getting /apis/certificates.k8s.io/v1 @ 07/11/24 06:43:04.562
  STEP: creating @ 07/11/24 06:43:04.563
  STEP: getting @ 07/11/24 06:43:04.581
  STEP: listing @ 07/11/24 06:43:04.584
  STEP: watching @ 07/11/24 06:43:04.588
  I0711 06:43:04.588712 20 certificates.go:316] starting watch
  STEP: patching @ 07/11/24 06:43:04.59
  STEP: updating @ 07/11/24 06:43:04.596
  I0711 06:43:04.602455 20 certificates.go:332] waiting for watch events with expected annotations
  I0711 06:43:04.602503 20 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 07/11/24 06:43:04.602
  STEP: patching /approval @ 07/11/24 06:43:04.606
  STEP: updating /approval @ 07/11/24 06:43:04.613
  STEP: getting /status @ 07/11/24 06:43:04.618
  STEP: patching /status @ 07/11/24 06:43:04.622
  STEP: updating /status @ 07/11/24 06:43:04.629
  STEP: deleting @ 07/11/24 06:43:04.636
  STEP: deleting a collection @ 07/11/24 06:43:04.649
  I0711 06:43:04.669447 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-7630" for this suite. @ 07/11/24 06:43:04.673
• [0.361 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 07/11/24 06:43:04.681
  I0711 06:43:04.681074 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:43:04.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:04.7
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:04.702
  STEP: Setting up server cert @ 07/11/24 06:43:04.73
  E0711 06:43:04.885909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:43:04.955
  STEP: Deploying the webhook pod @ 07/11/24 06:43:04.966
  STEP: Wait for the deployment to be ready @ 07/11/24 06:43:04.979
  I0711 06:43:04.986700 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:43:05.886001      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:06.886108      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:43:07.004
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:43:07.015
  E0711 06:43:07.886342      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:08.016616 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 07/11/24 06:43:08.024
  STEP: Creating a custom resource definition that should be denied by the webhook @ 07/11/24 06:43:08.038
  I0711 06:43:08.038759 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:43:08.095040 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2642" for this suite. @ 07/11/24 06:43:08.099
  STEP: Destroying namespace "webhook-markers-6346" for this suite. @ 07/11/24 06:43:08.106
• [3.433 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 07/11/24 06:43:08.114
  I0711 06:43:08.114212 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename events @ 07/11/24 06:43:08.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:08.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:08.133
  STEP: creating a test event @ 07/11/24 06:43:08.136
  STEP: listing all events in all namespaces @ 07/11/24 06:43:08.144
  STEP: patching the test event @ 07/11/24 06:43:08.148
  STEP: fetching the test event @ 07/11/24 06:43:08.155
  STEP: updating the test event @ 07/11/24 06:43:08.158
  STEP: getting the test event @ 07/11/24 06:43:08.169
  STEP: deleting the test event @ 07/11/24 06:43:08.173
  STEP: listing all events in all namespaces @ 07/11/24 06:43:08.18
  I0711 06:43:08.185253 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8150" for this suite. @ 07/11/24 06:43:08.189
• [0.083 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:715
  STEP: Creating a kubernetes client @ 07/11/24 06:43:08.197
  I0711 06:43:08.197281 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:43:08.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:08.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:08.218
  STEP: Setting up server cert @ 07/11/24 06:43:08.246
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:43:08.554
  STEP: Deploying the webhook pod @ 07/11/24 06:43:08.561
  STEP: Wait for the deployment to be ready @ 07/11/24 06:43:08.574
  I0711 06:43:08.581422 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:43:08.886882      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:09.887039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:43:10.595
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:43:10.607
  E0711 06:43:10.887973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:11.607868 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 07/11/24 06:43:11.616
  STEP: verifying the validating webhook match conditions @ 07/11/24 06:43:11.634
  STEP: updating the validating webhook match conditions @ 07/11/24 06:43:11.638
  STEP: verifying the validating webhook match conditions @ 07/11/24 06:43:11.646
  I0711 06:43:11.693278 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-798" for this suite. @ 07/11/24 06:43:11.696
  STEP: Destroying namespace "webhook-markers-4430" for this suite. @ 07/11/24 06:43:11.705
• [3.517 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 07/11/24 06:43:11.713
  I0711 06:43:11.713928 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:43:11.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:11.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:11.732
  STEP: Setting up server cert @ 07/11/24 06:43:11.759
  E0711 06:43:11.888076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:43:11.913
  STEP: Deploying the webhook pod @ 07/11/24 06:43:11.92
  STEP: Wait for the deployment to be ready @ 07/11/24 06:43:11.934
  I0711 06:43:11.943680 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:43:12.888923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:13.889149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:43:13.957
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:43:13.97
  E0711 06:43:14.889256      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:14.971497 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0711 06:43:14.980395 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-622-crds.webhook.example.com via the AdmissionRegistration API @ 07/11/24 06:43:15.492
  STEP: Creating a custom resource that should be mutated by the webhook @ 07/11/24 06:43:15.508
  E0711 06:43:15.890105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:16.890178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:17.891051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:18.098208 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-857" for this suite. @ 07/11/24 06:43:18.103
  STEP: Destroying namespace "webhook-markers-7592" for this suite. @ 07/11/24 06:43:18.111
• [6.406 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:355
  STEP: Creating a kubernetes client @ 07/11/24 06:43:18.119
  I0711 06:43:18.119832 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 06:43:18.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:18.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:18.145
  STEP: creating a replication controller @ 07/11/24 06:43:18.148
  I0711 06:43:18.148758 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 create -f -'
  I0711 06:43:18.224679 20 builder.go:146] stderr: ""
  I0711 06:43:18.224727 20 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 07/11/24 06:43:18.224
  I0711 06:43:18.224805 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0711 06:43:18.266788 20 builder.go:146] stderr: ""
  I0711 06:43:18.266829 20 builder.go:147] stdout: "update-demo-nautilus-5jcrd update-demo-nautilus-n28c5 "
  I0711 06:43:18.266874 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-5jcrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 06:43:18.307317 20 builder.go:146] stderr: ""
  I0711 06:43:18.307361 20 builder.go:147] stdout: ""
  I0711 06:43:18.307369 20 kubectl.go:2501] update-demo-nautilus-5jcrd is created but not running
  E0711 06:43:18.892066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:19.893011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:20.893135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:21.893222      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:22.893401      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:23.308132 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0711 06:43:23.349281 20 builder.go:146] stderr: ""
  I0711 06:43:23.349331 20 builder.go:147] stdout: "update-demo-nautilus-5jcrd update-demo-nautilus-n28c5 "
  I0711 06:43:23.349375 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-5jcrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 06:43:23.390418 20 builder.go:146] stderr: ""
  I0711 06:43:23.390459 20 builder.go:147] stdout: "true"
  I0711 06:43:23.390504 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-5jcrd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0711 06:43:23.431123 20 builder.go:146] stderr: ""
  I0711 06:43:23.431165 20 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0711 06:43:23.431175 20 kubectl.go:2392] validating pod update-demo-nautilus-5jcrd
  I0711 06:43:23.438290 20 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0711 06:43:23.438333 20 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0711 06:43:23.438344 20 kubectl.go:2519] update-demo-nautilus-5jcrd is verified up and running
  I0711 06:43:23.438375 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-n28c5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 06:43:23.478105 20 builder.go:146] stderr: ""
  I0711 06:43:23.478139 20 builder.go:147] stdout: "true"
  I0711 06:43:23.478180 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-n28c5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0711 06:43:23.519480 20 builder.go:146] stderr: ""
  I0711 06:43:23.519525 20 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0711 06:43:23.519538 20 kubectl.go:2392] validating pod update-demo-nautilus-n28c5
  I0711 06:43:23.525528 20 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0711 06:43:23.525578 20 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0711 06:43:23.525588 20 kubectl.go:2519] update-demo-nautilus-n28c5 is verified up and running
  STEP: scaling down the replication controller @ 07/11/24 06:43:23.525
  I0711 06:43:23.526339 20 kubectl.go:324] scanned /root for discovery docs: <nil>
  I0711 06:43:23.526365 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0711 06:43:23.894012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:24.583002 20 builder.go:146] stderr: ""
  I0711 06:43:24.583042 20 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 07/11/24 06:43:24.583
  I0711 06:43:24.583128 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0711 06:43:24.624632 20 builder.go:146] stderr: ""
  I0711 06:43:24.624669 20 builder.go:147] stdout: "update-demo-nautilus-5jcrd "
  I0711 06:43:24.624711 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-5jcrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 06:43:24.663961 20 builder.go:146] stderr: ""
  I0711 06:43:24.663995 20 builder.go:147] stdout: "true"
  I0711 06:43:24.664037 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-5jcrd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0711 06:43:24.704784 20 builder.go:146] stderr: ""
  I0711 06:43:24.704825 20 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0711 06:43:24.704838 20 kubectl.go:2392] validating pod update-demo-nautilus-5jcrd
  I0711 06:43:24.710006 20 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0711 06:43:24.710101 20 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0711 06:43:24.710120 20 kubectl.go:2519] update-demo-nautilus-5jcrd is verified up and running
  STEP: scaling up the replication controller @ 07/11/24 06:43:24.71
  I0711 06:43:24.710893 20 kubectl.go:324] scanned /root for discovery docs: <nil>
  I0711 06:43:24.710921 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0711 06:43:24.894433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:25.772528 20 builder.go:146] stderr: ""
  I0711 06:43:25.772570 20 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 07/11/24 06:43:25.772
  I0711 06:43:25.772769 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0711 06:43:25.814232 20 builder.go:146] stderr: ""
  I0711 06:43:25.814283 20 builder.go:147] stdout: "update-demo-nautilus-5jcrd update-demo-nautilus-sqnc5 "
  I0711 06:43:25.814326 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-5jcrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 06:43:25.855559 20 builder.go:146] stderr: ""
  I0711 06:43:25.855608 20 builder.go:147] stdout: "true"
  I0711 06:43:25.855648 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-5jcrd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0711 06:43:25.895013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:25.896403 20 builder.go:146] stderr: ""
  I0711 06:43:25.896434 20 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0711 06:43:25.896445 20 kubectl.go:2392] validating pod update-demo-nautilus-5jcrd
  I0711 06:43:25.901307 20 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0711 06:43:25.901345 20 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0711 06:43:25.901360 20 kubectl.go:2519] update-demo-nautilus-5jcrd is verified up and running
  I0711 06:43:25.901405 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-sqnc5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 06:43:25.941038 20 builder.go:146] stderr: ""
  I0711 06:43:25.941080 20 builder.go:147] stdout: ""
  I0711 06:43:25.941090 20 kubectl.go:2501] update-demo-nautilus-sqnc5 is created but not running
  E0711 06:43:26.895188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:27.895370      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:28.895571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:29.895697      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:30.895968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:30.942180 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0711 06:43:30.985223 20 builder.go:146] stderr: ""
  I0711 06:43:30.985263 20 builder.go:147] stdout: "update-demo-nautilus-5jcrd update-demo-nautilus-sqnc5 "
  I0711 06:43:30.985308 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-5jcrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 06:43:31.029020 20 builder.go:146] stderr: ""
  I0711 06:43:31.029068 20 builder.go:147] stdout: "true"
  I0711 06:43:31.029112 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-5jcrd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0711 06:43:31.070018 20 builder.go:146] stderr: ""
  I0711 06:43:31.070059 20 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0711 06:43:31.070071 20 kubectl.go:2392] validating pod update-demo-nautilus-5jcrd
  I0711 06:43:31.074703 20 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0711 06:43:31.074806 20 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0711 06:43:31.074823 20 kubectl.go:2519] update-demo-nautilus-5jcrd is verified up and running
  I0711 06:43:31.074876 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-sqnc5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0711 06:43:31.115256 20 builder.go:146] stderr: ""
  I0711 06:43:31.115292 20 builder.go:147] stdout: "true"
  I0711 06:43:31.115337 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods update-demo-nautilus-sqnc5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0711 06:43:31.155116 20 builder.go:146] stderr: ""
  I0711 06:43:31.155163 20 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0711 06:43:31.155174 20 kubectl.go:2392] validating pod update-demo-nautilus-sqnc5
  I0711 06:43:31.161611 20 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0711 06:43:31.161689 20 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0711 06:43:31.161707 20 kubectl.go:2519] update-demo-nautilus-sqnc5 is verified up and running
  STEP: using delete to clean up resources @ 07/11/24 06:43:31.161
  I0711 06:43:31.161787 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 delete --grace-period=0 --force -f -'
  I0711 06:43:31.208046 20 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0711 06:43:31.208090 20 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0711 06:43:31.208125 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get rc,svc -l name=update-demo --no-headers'
  I0711 06:43:31.294632 20 builder.go:146] stderr: "No resources found in kubectl-2384 namespace.\n"
  I0711 06:43:31.294680 20 builder.go:147] stdout: ""
  I0711 06:43:31.294721 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2384 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0711 06:43:31.363087 20 builder.go:146] stderr: ""
  I0711 06:43:31.363134 20 builder.go:147] stdout: ""
  I0711 06:43:31.363233 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2384" for this suite. @ 07/11/24 06:43:31.367
• [13.256 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 07/11/24 06:43:31.375
  I0711 06:43:31.375954 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename dns @ 07/11/24 06:43:31.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:31.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:31.405
  STEP: Creating a test headless service @ 07/11/24 06:43:31.411
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5212.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5212.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5212.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5212.svc.cluster.local;sleep 1; done
   @ 07/11/24 06:43:31.416
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5212.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5212.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5212.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5212.svc.cluster.local;sleep 1; done
   @ 07/11/24 06:43:31.416
  STEP: creating a pod to probe DNS @ 07/11/24 06:43:31.416
  STEP: submitting the pod to kubernetes @ 07/11/24 06:43:31.416
  E0711 06:43:31.896660      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:32.896775      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 07/11/24 06:43:33.443
  STEP: looking for the results for each expected name from probers @ 07/11/24 06:43:33.447
  I0711 06:43:33.453097 20 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local from pod dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36: the server could not find the requested resource (get pods dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36)
  I0711 06:43:33.457082 20 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local from pod dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36: the server could not find the requested resource (get pods dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36)
  I0711 06:43:33.461173 20 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-5212.svc.cluster.local from pod dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36: the server could not find the requested resource (get pods dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36)
  I0711 06:43:33.465981 20 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-5212.svc.cluster.local from pod dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36: the server could not find the requested resource (get pods dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36)
  I0711 06:43:33.470084 20 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local from pod dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36: the server could not find the requested resource (get pods dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36)
  I0711 06:43:33.474362 20 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local from pod dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36: the server could not find the requested resource (get pods dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36)
  I0711 06:43:33.479186 20 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-5212.svc.cluster.local from pod dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36: the server could not find the requested resource (get pods dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36)
  I0711 06:43:33.483165 20 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-5212.svc.cluster.local from pod dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36: the server could not find the requested resource (get pods dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36)
  I0711 06:43:33.483191 20 dns_common.go:489] Lookups using dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5212.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5212.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5212.svc.cluster.local jessie_udp@dns-test-service-2.dns-5212.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5212.svc.cluster.local]

  I0711 06:43:33.489905 20 dns_common.go:495] Pod client logs for webserver: 
  I0711 06:43:33.496965 20 dns_common.go:495] Pod client logs for querier: 
  I0711 06:43:33.504507 20 dns_common.go:495] Pod client logs for jessie-querier: 
  E0711 06:43:33.896943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:34.897052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:35.897600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:36.898062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:37.898254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:38.484572 20 dns_common.go:527] DNS probes using dns-5212/dns-test-25fab9be-8e6c-4e17-b533-37ba3dfedb36 succeeded

  STEP: deleting the pod @ 07/11/24 06:43:38.484
  STEP: deleting the test headless service @ 07/11/24 06:43:38.503
  I0711 06:43:38.518283 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5212" for this suite. @ 07/11/24 06:43:38.523
• [7.155 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 07/11/24 06:43:38.531
  I0711 06:43:38.531121 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:43:38.531
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:38.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:38.552
  STEP: Creating configMap with name projected-configmap-test-volume-deb4012f-0be0-4d5f-b050-144c14421e44 @ 07/11/24 06:43:38.555
  STEP: Creating a pod to test consume configMaps @ 07/11/24 06:43:38.559
  E0711 06:43:38.899264      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:39.900183      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:43:40.578
  I0711 06:43:40.583106 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-configmaps-2f14c90e-34a0-4ed4-8809-fbd8d927d1c7 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 06:43:40.591
  I0711 06:43:40.611764 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6649" for this suite. @ 07/11/24 06:43:40.616
• [2.092 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 07/11/24 06:43:40.623
  I0711 06:43:40.623415 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename podtemplate @ 07/11/24 06:43:40.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:40.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:40.644
  STEP: Create a pod template @ 07/11/24 06:43:40.646
  STEP: Replace a pod template @ 07/11/24 06:43:40.651
  I0711 06:43:40.666749 20 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I0711 06:43:40.666847 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-4716" for this suite. @ 07/11/24 06:43:40.67
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 07/11/24 06:43:40.676
  I0711 06:43:40.676796 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:43:40.677
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:40.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:40.694
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 06:43:40.697
  E0711 06:43:40.900804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:41.901372      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:42.901862      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:43.901923      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:43:44.725
  I0711 06:43:44.728916 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-f8f70026-4b20-475d-89c5-e3fb3d9493cd container client-container: <nil>
  STEP: delete the pod @ 07/11/24 06:43:44.735
  I0711 06:43:44.749951 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7466" for this suite. @ 07/11/24 06:43:44.754
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:358
  STEP: Creating a kubernetes client @ 07/11/24 06:43:44.761
  I0711 06:43:44.761179 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-publish-openapi @ 07/11/24 06:43:44.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:44.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:44.783
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 07/11/24 06:43:44.788
  I0711 06:43:44.790106 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:43:44.902520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:45.903197      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:46.010149 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:43:46.903568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:47.903883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:48.904755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:49.905536      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:50.906110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:50.952504 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-566" for this suite. @ 07/11/24 06:43:50.962
• [6.208 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2203
  STEP: Creating a kubernetes client @ 07/11/24 06:43:50.969
  I0711 06:43:50.969532 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 06:43:50.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:43:50.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:43:50.99
  STEP: creating service in namespace services-8782 @ 07/11/24 06:43:50.992
  STEP: creating service affinity-clusterip-transition in namespace services-8782 @ 07/11/24 06:43:50.992
  STEP: creating replication controller affinity-clusterip-transition in namespace services-8782 @ 07/11/24 06:43:51.002
  I0711 06:43:51.010239      20 runners.go:198] Created replication controller with name: affinity-clusterip-transition, namespace: services-8782, replica count: 3
  E0711 06:43:51.907144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:52.907174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:53.907278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:54.061654      20 runners.go:198] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0711 06:43:54.070545 20 resource.go:361] Creating new exec pod
  E0711 06:43:54.907833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:55.908713      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:56.908821      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:43:57.088379 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8782 exec execpod-affinityttrn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I0711 06:43:57.206023 20 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  I0711 06:43:57.206063 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:43:57.206244 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8782 exec execpod-affinityttrn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.89 80'
  I0711 06:43:57.289921 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.89 80\n+ echo hostName\nConnection to 10.152.183.89 80 port [tcp/http] succeeded!\n"
  I0711 06:43:57.289962 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 06:43:57.299786 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8782 exec execpod-affinityttrn4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.89:80/ ; done'
  I0711 06:43:57.428722 20 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n"
  I0711 06:43:57.428771 20 builder.go:147] stdout: "\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-jqlzh\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-jqlzh\naffinity-clusterip-transition-jqlzh\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-jqlzh\naffinity-clusterip-transition-jqlzh\naffinity-clusterip-transition-g4dcr\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-jqlzh\naffinity-clusterip-transition-g4dcr\naffinity-clusterip-transition-g4dcr"
  I0711 06:43:57.428785 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.428792 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.428798 20 service.go:242] Received response from host: affinity-clusterip-transition-jqlzh
  I0711 06:43:57.428803 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.428809 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.428879 20 service.go:242] Received response from host: affinity-clusterip-transition-jqlzh
  I0711 06:43:57.428945 20 service.go:242] Received response from host: affinity-clusterip-transition-jqlzh
  I0711 06:43:57.428952 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.428963 20 service.go:242] Received response from host: affinity-clusterip-transition-jqlzh
  I0711 06:43:57.428973 20 service.go:242] Received response from host: affinity-clusterip-transition-jqlzh
  I0711 06:43:57.428980 20 service.go:242] Received response from host: affinity-clusterip-transition-g4dcr
  I0711 06:43:57.429003 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.429010 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.429078 20 service.go:242] Received response from host: affinity-clusterip-transition-jqlzh
  I0711 06:43:57.429086 20 service.go:242] Received response from host: affinity-clusterip-transition-g4dcr
  I0711 06:43:57.429093 20 service.go:242] Received response from host: affinity-clusterip-transition-g4dcr
  I0711 06:43:57.440571 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8782 exec execpod-affinityttrn4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.89:80/ ; done'
  I0711 06:43:57.570145 20 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.89:80/\n"
  I0711 06:43:57.570199 20 builder.go:147] stdout: "\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5\naffinity-clusterip-transition-nktm5"
  I0711 06:43:57.570212 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570220 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570227 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570232 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570238 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570243 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570355 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570365 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570372 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570379 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570386 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570393 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570399 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570413 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570422 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570428 20 service.go:242] Received response from host: affinity-clusterip-transition-nktm5
  I0711 06:43:57.570498 20 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-8782, will wait for the garbage collector to delete the pods @ 07/11/24 06:43:57.583
  I0711 06:43:57.648431 20 resources.go:139] Deleting ReplicationController affinity-clusterip-transition took: 8.360242ms
  I0711 06:43:57.748885 20 resources.go:163] Terminating ReplicationController affinity-clusterip-transition pods took: 100.44931ms
  E0711 06:43:57.909479      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:58.910141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:43:59.910959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:44:00.374435 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8782" for this suite. @ 07/11/24 06:44:00.378
• [9.418 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 07/11/24 06:44:00.387
  I0711 06:44:00.387586 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:44:00.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:00.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:00.404
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 06:44:00.407
  E0711 06:44:00.911979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:01.912061      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:02.912754      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:03.912839      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:44:04.431
  I0711 06:44:04.435147 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-fe5b35e5-22a5-4eb8-b8bf-9d7a2233e30e container client-container: <nil>
  STEP: delete the pod @ 07/11/24 06:44:04.446
  I0711 06:44:04.465083 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7626" for this suite. @ 07/11/24 06:44:04.468
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:57
  STEP: Creating a kubernetes client @ 07/11/24 06:44:04.475
  I0711 06:44:04.475342 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename volumeattachment @ 07/11/24 06:44:04.476
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:04.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:04.494
  STEP: Create VolumeAttachment "va-e2e-jcfz6" on node "ip-172-31-80-240" @ 07/11/24 06:44:04.499
  STEP: Get VolumeAttachment "va-e2e-jcfz6" on node "ip-172-31-80-240" @ 07/11/24 06:44:04.504
  STEP: Patch VolumeAttachment "va-e2e-jcfz6" on node "ip-172-31-80-240" @ 07/11/24 06:44:04.507
  STEP: List VolumeAttachments with "va-e2e-jcfz6=patched" label @ 07/11/24 06:44:04.512
  STEP: Delete VolumeAttachment "va-e2e-jcfz6" on node "ip-172-31-80-240" @ 07/11/24 06:44:04.515
  STEP: Confirm deletion of VolumeAttachment "va-e2e-jcfz6" on node "ip-172-31-80-240" @ 07/11/24 06:44:04.522
  STEP: Create VolumeAttachment "va-e2e-mvkz5" on node "ip-172-31-72-118" @ 07/11/24 06:44:04.533
  STEP: Update the VolumeAttachment "va-e2e-mvkz5" on node "ip-172-31-72-118" with label "va-e2e=updated" @ 07/11/24 06:44:04.542
  STEP: Create VolumeAttachment "va-e2e-6sxfj" on node "ip-172-31-92-117" @ 07/11/24 06:44:04.558
  STEP: Update the VolumeAttachment "va-e2e-6sxfj" on node "ip-172-31-92-117" with label "va-e2e=updated" @ 07/11/24 06:44:04.566
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 07/11/24 06:44:04.58
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 07/11/24 06:44:04.605
  I0711 06:44:04.608989 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-5636" for this suite. @ 07/11/24 06:44:04.613
• [0.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:673
  STEP: Creating a kubernetes client @ 07/11/24 06:44:04.619
  I0711 06:44:04.619839 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename validating-admission-policy @ 07/11/24 06:44:04.62
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:04.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:04.637
  STEP: getting /apis @ 07/11/24 06:44:04.644
  STEP: getting /apis/admissionregistration.k8s.io @ 07/11/24 06:44:04.646
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 07/11/24 06:44:04.647
  STEP: creating @ 07/11/24 06:44:04.648
  STEP: getting @ 07/11/24 06:44:04.666
  STEP: listing @ 07/11/24 06:44:04.669
  STEP: watching @ 07/11/24 06:44:04.673
  I0711 06:44:04.673290 20 validatingadmissionpolicy.go:768] starting watch
  STEP: patching @ 07/11/24 06:44:04.674
  STEP: updating @ 07/11/24 06:44:04.68
  I0711 06:44:04.689112 20 validatingadmissionpolicy.go:796] waiting for watch events with expected annotations
  STEP: deleting @ 07/11/24 06:44:04.689
  STEP: deleting a collection @ 07/11/24 06:44:04.703
  I0711 06:44:04.725082 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-5196" for this suite. @ 07/11/24 06:44:04.729
• [0.116 seconds]
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 07/11/24 06:44:04.736
  I0711 06:44:04.736233 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename custom-resource-definition @ 07/11/24 06:44:04.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:04.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:04.755
  I0711 06:44:04.758338 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 06:44:04.913007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:05.913281      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:06.914031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:07.914358      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:08.915375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:09.915789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:10.916686      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:44:10.968679 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6887" for this suite. @ 07/11/24 06:44:10.973
• [6.245 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 07/11/24 06:44:10.981
  I0711 06:44:10.981878 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pod-network-test @ 07/11/24 06:44:10.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:10.996
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:10.998
  STEP: Performing setup for networking test in namespace pod-network-test-6813 @ 07/11/24 06:44:11.001
  STEP: creating a selector @ 07/11/24 06:44:11.001
  STEP: Creating the service pods in kubernetes @ 07/11/24 06:44:11.001
  I0711 06:44:11.001500 20 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0711 06:44:11.917229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:12.917328      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:13.918341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:14.918544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:15.918873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:16.919381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:17.920075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:18.920685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:19.921189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:20.921520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:21.921619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:22.921918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 07/11/24 06:44:23.09
  E0711 06:44:23.922056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:24.922140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:44:25.128122 20 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0711 06:44:25.128155 20 utils.go:472] Going to poll 192.168.122.86 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0711 06:44:25.131153 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.122.86 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6813 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:44:25.131168 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:44:25.131624 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:44:25.131708 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6813/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.122.86+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0711 06:44:25.922858      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:44:26.185738 20 utils.go:489] Found all 1 expected endpoints: [netserver-0]
  I0711 06:44:26.185775 20 utils.go:472] Going to poll 192.168.133.119 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0711 06:44:26.191026 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.133.119 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6813 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:44:26.191050 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:44:26.191490 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:44:26.191615 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6813/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.133.119+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0711 06:44:26.923543      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:44:27.237435 20 utils.go:489] Found all 1 expected endpoints: [netserver-1]
  I0711 06:44:27.237474 20 utils.go:472] Going to poll 192.168.37.3 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I0711 06:44:27.241820 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.37.3 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6813 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:44:27.241840 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:44:27.242222 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:44:27.242263 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6813/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.37.3+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0711 06:44:27.923799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:44:28.289350 20 utils.go:489] Found all 1 expected endpoints: [netserver-2]
  I0711 06:44:28.289623 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6813" for this suite. @ 07/11/24 06:44:28.294
• [17.322 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 07/11/24 06:44:28.304
  I0711 06:44:28.304356 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 06:44:28.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:28.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:28.327
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 07/11/24 06:44:28.329
  E0711 06:44:28.924888      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:29.925067      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:30.925944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:31.926022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:44:32.357
  I0711 06:44:32.361533 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-41e26623-3118-4a1f-96d5-25c5c96a0ff1 container test-container: <nil>
  STEP: delete the pod @ 07/11/24 06:44:32.372
  I0711 06:44:32.387575 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2134" for this suite. @ 07/11/24 06:44:32.39
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 07/11/24 06:44:32.399
  I0711 06:44:32.399012 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 06:44:32.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:32.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:32.417
  STEP: Creating secret with name secret-test-b2f894b9-0021-4354-8856-889a7c3d8464 @ 07/11/24 06:44:32.419
  STEP: Creating a pod to test consume secrets @ 07/11/24 06:44:32.424
  E0711 06:44:32.926149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:33.926264      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:34.926491      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:35.926677      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:44:36.452
  I0711 06:44:36.456435 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-secrets-e84f1c06-263a-4cf5-9846-1509acb3a0bf container secret-env-test: <nil>
  STEP: delete the pod @ 07/11/24 06:44:36.463
  I0711 06:44:36.480576 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2675" for this suite. @ 07/11/24 06:44:36.485
• [4.093 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 07/11/24 06:44:36.492
  I0711 06:44:36.492290 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename daemonsets @ 07/11/24 06:44:36.492
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:36.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:36.513
  STEP: Creating simple DaemonSet "daemon-set" @ 07/11/24 06:44:36.533
  STEP: Check that daemon pods launch on every node of the cluster. @ 07/11/24 06:44:36.54
  I0711 06:44:36.546075 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:44:36.546112 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:44:36.549321 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 06:44:36.549344 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  E0711 06:44:36.926853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:44:37.544331 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:44:37.544377 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:44:37.547542 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0711 06:44:37.547560 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  E0711 06:44:37.926891      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:44:38.544731 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:44:38.544775 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 06:44:38.548679 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0711 06:44:38.548702 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 07/11/24 06:44:38.552
  STEP: DeleteCollection of the DaemonSets @ 07/11/24 06:44:38.556
  STEP: Verify that ReplicaSets have been deleted @ 07/11/24 06:44:38.565
  I0711 06:44:38.581452 20 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30068"},"items":null}

  I0711 06:44:38.588010 20 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30070"},"items":[{"metadata":{"name":"daemon-set-h9f26","generateName":"daemon-set-","namespace":"daemonsets-7597","uid":"ca35dd1c-a44b-42c0-b7f3-83e94b544292","resourceVersion":"30050","creationTimestamp":"2024-07-11T06:44:36Z","labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"379acc20-d3d0-4848-b6d8-a127b039ac60","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-07-11T06:44:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"379acc20-d3d0-4848-b6d8-a127b039ac60\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-07-11T06:44:37Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.37.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hbg2s","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hbg2s","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-80-240","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-80-240"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:37Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:37Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:37Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:36Z"}],"hostIP":"172.31.80.240","hostIPs":[{"ip":"172.31.80.240"}],"podIP":"192.168.37.6","podIPs":[{"ip":"192.168.37.6"}],"startTime":"2024-07-11T06:44:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-07-11T06:44:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://021c42f1f3d1af7e38711ea17c0f86945a7a55d6dae7fe413196b97f243cbb4d","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-hv5cv","generateName":"daemon-set-","namespace":"daemonsets-7597","uid":"74ee6d1e-17de-409f-add6-00b7b517758e","resourceVersion":"30068","creationTimestamp":"2024-07-11T06:44:36Z","deletionTimestamp":"2024-07-11T06:45:08Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"379acc20-d3d0-4848-b6d8-a127b039ac60","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-07-11T06:44:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"379acc20-d3d0-4848-b6d8-a127b039ac60\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-07-11T06:44:37Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.133.122\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-kzfv6","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-kzfv6","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-17-237","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-17-237"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:37Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:37Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:37Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:36Z"}],"hostIP":"172.31.17.237","hostIPs":[{"ip":"172.31.17.237"}],"podIP":"192.168.133.122","podIPs":[{"ip":"192.168.133.122"}],"startTime":"2024-07-11T06:44:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-07-11T06:44:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://330b3ba0537a3327836fbaa5332224ab32475ca28e70cbde1121b6e62902e81f","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-lrdfn","generateName":"daemon-set-","namespace":"daemonsets-7597","uid":"bafd5db8-63b6-4ebf-b8ec-9238faa3a7c8","resourceVersion":"30070","creationTimestamp":"2024-07-11T06:44:36Z","deletionTimestamp":"2024-07-11T06:45:08Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"379acc20-d3d0-4848-b6d8-a127b039ac60","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-07-11T06:44:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"379acc20-d3d0-4848-b6d8-a127b039ac60\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-07-11T06:44:38Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.122.99\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-7tmxb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-7tmxb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-11-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-11-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:38Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:38Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:38Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-07-11T06:44:36Z"}],"hostIP":"172.31.11.2","hostIPs":[{"ip":"172.31.11.2"}],"podIP":"192.168.122.99","podIPs":[{"ip":"192.168.122.99"}],"startTime":"2024-07-11T06:44:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-07-11T06:44:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://dcfdf707bc745b2410cdc47cc8582e9e15d3ba97e8f90a11a8ac3368443e2db0","started":true}],"qosClass":"BestEffort"}}]}

  I0711 06:44:38.605434 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7597" for this suite. @ 07/11/24 06:44:38.608
• [2.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 07/11/24 06:44:38.617
  I0711 06:44:38.617548 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename proxy @ 07/11/24 06:44:38.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:38.634
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:38.637
  I0711 06:44:38.639620 20 proxy.go:387] Creating pod...
  E0711 06:44:38.927877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:39.927962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:44:40.658261 20 proxy.go:411] Creating service...
  I0711 06:44:40.671862 20 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/pods/agnhost/proxy?method=DELETE
  I0711 06:44:40.681972 20 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0711 06:44:40.682000 20 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/pods/agnhost/proxy?method=OPTIONS
  I0711 06:44:40.685708 20 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0711 06:44:40.685731 20 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/pods/agnhost/proxy?method=PATCH
  I0711 06:44:40.689903 20 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0711 06:44:40.689918 20 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/pods/agnhost/proxy?method=POST
  I0711 06:44:40.694111 20 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0711 06:44:40.694197 20 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/pods/agnhost/proxy?method=PUT
  I0711 06:44:40.699393 20 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0711 06:44:40.699414 20 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/services/e2e-proxy-test-service/proxy?method=DELETE
  I0711 06:44:40.705765 20 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0711 06:44:40.705804 20 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0711 06:44:40.711186 20 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0711 06:44:40.711220 20 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/services/e2e-proxy-test-service/proxy?method=PATCH
  I0711 06:44:40.716644 20 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0711 06:44:40.716701 20 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/services/e2e-proxy-test-service/proxy?method=POST
  I0711 06:44:40.722541 20 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0711 06:44:40.722558 20 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/services/e2e-proxy-test-service/proxy?method=PUT
  I0711 06:44:40.728182 20 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0711 06:44:40.728349 20 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/pods/agnhost/proxy?method=GET
  I0711 06:44:40.731437 20 proxy.go:487] http.Client request:GET StatusCode:301
  I0711 06:44:40.731461 20 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/services/e2e-proxy-test-service/proxy?method=GET
  I0711 06:44:40.736624 20 proxy.go:487] http.Client request:GET StatusCode:301
  I0711 06:44:40.736698 20 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/pods/agnhost/proxy?method=HEAD
  I0711 06:44:40.739756 20 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0711 06:44:40.739770 20 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1264/services/e2e-proxy-test-service/proxy?method=HEAD
  I0711 06:44:40.745131 20 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0711 06:44:40.745283 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-1264" for this suite. @ 07/11/24 06:44:40.749
• [2.139 seconds]
------------------------------
SS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 07/11/24 06:44:40.756
  I0711 06:44:40.756633 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename hostport @ 07/11/24 06:44:40.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:44:40.776
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:44:40.778
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 07/11/24 06:44:40.784
  E0711 06:44:40.928801      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:41.929231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.11.2 on the node which pod1 resides and expect scheduled @ 07/11/24 06:44:42.804
  E0711 06:44:42.929895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:43.930084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:44.931014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:45.931215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:46.931495      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:47.931542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:48.931602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:49.931956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:50.932538      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:51.932635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:52.933244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:53.933413      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.11.2 but use UDP protocol on the node which pod2 resides @ 07/11/24 06:44:54.845
  E0711 06:44:54.934101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:55.934737      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:56.935712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:44:57.935900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 07/11/24 06:44:58.88
  I0711 06:44:58.880935 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.11.2 http://127.0.0.1:54323/hostname] Namespace:hostport-3898 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:44:58.881015 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:44:58.881468 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:44:58.881539 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-3898/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.11.2+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0711 06:44:58.936114      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.11.2, port: 54323 @ 07/11/24 06:44:58.937
  I0711 06:44:58.937667 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.11.2:54323/hostname] Namespace:hostport-3898 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:44:58.937690 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:44:58.938145 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:44:58.938226 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-3898/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.11.2%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.11.2, port: 54323 UDP @ 07/11/24 06:44:58.984
  I0711 06:44:58.984790 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.11.2 54323] Namespace:hostport-3898 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 06:44:58.984907 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 06:44:58.985362 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 06:44:58.985421 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-3898/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.11.2+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0711 06:44:59.937077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:00.937196      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:01.937320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:02.937408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:03.937613      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:45:04.043535 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-3898" for this suite. @ 07/11/24 06:45:04.048
• [23.299 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 07/11/24 06:45:04.056
  I0711 06:45:04.056032 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 06:45:04.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:45:04.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:45:04.075
  STEP: Creating projection with secret that has name secret-emptykey-test-91407891-0cab-4168-8eaa-b926fb027b14 @ 07/11/24 06:45:04.078
  I0711 06:45:04.079912 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4208" for this suite. @ 07/11/24 06:45:04.083
• [0.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:348
  STEP: Creating a kubernetes client @ 07/11/24 06:45:04.094
  I0711 06:45:04.094898 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename disruption @ 07/11/24 06:45:04.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:45:04.111
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:45:04.113
  STEP: Creating a pdb that targets all three pods in a test replica set @ 07/11/24 06:45:04.115
  STEP: Waiting for the pdb to be processed @ 07/11/24 06:45:04.12
  E0711 06:45:04.937785      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:05.937799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 07/11/24 06:45:06.131
  STEP: Waiting for all pods to be running @ 07/11/24 06:45:06.131
  I0711 06:45:06.135893 20 disruption.go:567] pods: 0 < 3
  E0711 06:45:06.938638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:07.938808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 07/11/24 06:45:08.136
  STEP: Updating the pdb to allow a pod to be evicted @ 07/11/24 06:45:08.148
  STEP: Waiting for the pdb to be processed @ 07/11/24 06:45:08.157
  E0711 06:45:08.938952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:09.939170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 07/11/24 06:45:10.161
  STEP: Waiting for all pods to be running @ 07/11/24 06:45:10.161
  STEP: Waiting for the pdb to observed all healthy pods @ 07/11/24 06:45:10.165
  STEP: Patching the pdb to disallow a pod to be evicted @ 07/11/24 06:45:10.197
  STEP: Waiting for the pdb to be processed @ 07/11/24 06:45:10.244
  E0711 06:45:10.939266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:11.939391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 07/11/24 06:45:12.249
  STEP: locating a running pod @ 07/11/24 06:45:12.252
  STEP: Deleting the pdb to allow a pod to be evicted @ 07/11/24 06:45:12.263
  STEP: Waiting for the pdb to be deleted @ 07/11/24 06:45:12.27
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 07/11/24 06:45:12.273
  STEP: Waiting for all pods to be running @ 07/11/24 06:45:12.273
  I0711 06:45:12.298155 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1615" for this suite. @ 07/11/24 06:45:12.304
• [8.226 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 07/11/24 06:45:12.321
  I0711 06:45:12.321779 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sysctl @ 07/11/24 06:45:12.322
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:45:12.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:45:12.344
  STEP: Creating a pod with one valid and two invalid sysctls @ 07/11/24 06:45:12.346
  I0711 06:45:12.351014 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-8956" for this suite. @ 07/11/24 06:45:12.355
• [0.041 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 07/11/24 06:45:12.362
  I0711 06:45:12.362642 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 06:45:12.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:45:12.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:45:12.382
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 06:45:12.384
  E0711 06:45:12.940323      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:13.940438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:14.941468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:15.941758      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:45:16.411
  I0711 06:45:16.414696 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-3897c6e7-858d-4c68-8852-685fcc03e4d2 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 06:45:16.421
  I0711 06:45:16.446797 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6244" for this suite. @ 07/11/24 06:45:16.45
• [4.095 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 07/11/24 06:45:16.457
  I0711 06:45:16.457636 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename statefulset @ 07/11/24 06:45:16.458
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:45:16.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:45:16.475
  STEP: Creating service test in namespace statefulset-9031 @ 07/11/24 06:45:16.477
  STEP: Looking for a node to schedule stateful set and pod @ 07/11/24 06:45:16.483
  STEP: Creating pod with conflicting port in namespace statefulset-9031 @ 07/11/24 06:45:16.487
  STEP: Waiting until pod test-pod will start running in namespace statefulset-9031 @ 07/11/24 06:45:16.496
  E0711 06:45:16.941961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:17.942059      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-9031 @ 07/11/24 06:45:18.504
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9031 @ 07/11/24 06:45:18.511
  I0711 06:45:18.523421 20 statefulset.go:866] Observed stateful pod in namespace: statefulset-9031, name: ss-0, uid: 31f7559d-ffd1-4bfd-9a90-f1a5c368ae80, status phase: Pending. Waiting for statefulset controller to delete.
  I0711 06:45:18.541211 20 statefulset.go:866] Observed stateful pod in namespace: statefulset-9031, name: ss-0, uid: 31f7559d-ffd1-4bfd-9a90-f1a5c368ae80, status phase: Failed. Waiting for statefulset controller to delete.
  I0711 06:45:18.549830 20 statefulset.go:866] Observed stateful pod in namespace: statefulset-9031, name: ss-0, uid: 31f7559d-ffd1-4bfd-9a90-f1a5c368ae80, status phase: Failed. Waiting for statefulset controller to delete.
  I0711 06:45:18.555567 20 statefulset.go:860] Observed delete event for stateful pod ss-0 in namespace statefulset-9031
  STEP: Removing pod with conflicting port in namespace statefulset-9031 @ 07/11/24 06:45:18.555
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9031 and will be in running state @ 07/11/24 06:45:18.574
  E0711 06:45:18.942911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:19.943008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:45:20.589770 20 statefulset.go:135] Deleting all statefulset in ns statefulset-9031
  I0711 06:45:20.593269 20 rest.go:150] Scaling statefulset ss to 0
  E0711 06:45:20.943092      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:21.943205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:22.943702      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:23.944687      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:24.944799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:25.945640      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:26.945771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:27.945921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:28.946325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:29.947099      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:45:30.610081 20 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0711 06:45:30.614293 20 rest.go:88] Deleting statefulset ss
  I0711 06:45:30.629998 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9031" for this suite. @ 07/11/24 06:45:30.633
• [14.183 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 07/11/24 06:45:30.64
  I0711 06:45:30.640625 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename validating-admission-policy @ 07/11/24 06:45:30.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:45:30.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:45:30.658
  STEP: creating a policy with variables @ 07/11/24 06:45:30.666
  STEP: waiting until the marker is denied @ 07/11/24 06:45:30.683
  E0711 06:45:30.947791      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 07/11/24 06:45:31.089
  STEP: testing a non-replicated ReplicaSet not to be denied @ 07/11/24 06:45:31.104
  I0711 06:45:31.157877 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-5723" for this suite. @ 07/11/24 06:45:31.169
• [0.535 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 07/11/24 06:45:31.176
  I0711 06:45:31.176108 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replicaset @ 07/11/24 06:45:31.176
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:45:31.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:45:31.195
  I0711 06:45:31.197631 20 replica_set.go:191] Creating ReplicaSet my-hostname-basic-f49a096a-e45b-43a0-87ac-a3ef08abfa17
  I0711 06:45:31.206380 20 resource.go:87] Pod name my-hostname-basic-f49a096a-e45b-43a0-87ac-a3ef08abfa17: Found 0 pods out of 1
  E0711 06:45:31.947988      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:32.949031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:33.949114      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:34.949303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:35.949605      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:45:36.210777 20 resource.go:87] Pod name my-hostname-basic-f49a096a-e45b-43a0-87ac-a3ef08abfa17: Found 1 pods out of 1
  I0711 06:45:36.210812 20 replica_set.go:204] Ensuring a pod for ReplicaSet "my-hostname-basic-f49a096a-e45b-43a0-87ac-a3ef08abfa17" is running
  I0711 06:45:36.214365 20 replica_set.go:220] Pod "my-hostname-basic-f49a096a-e45b-43a0-87ac-a3ef08abfa17-lkfps" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:45:32 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:45:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:45:32 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:45:32 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-07-11 06:45:31 +0000 UTC Reason: Message:}])
  I0711 06:45:36.214388 20 replica_set.go:228] Trying to dial the pod
  STEP: trying to dial each unique pod @ 07/11/24 06:45:36.214
  I0711 06:45:36.225911 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-252" for this suite. @ 07/11/24 06:45:36.229
• [5.060 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 07/11/24 06:45:36.238
  I0711 06:45:36.238322 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 06:45:36.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:45:36.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:45:36.256
  STEP: creating a secret @ 07/11/24 06:45:36.258
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 07/11/24 06:45:36.263
  STEP: patching the secret @ 07/11/24 06:45:36.268
  STEP: deleting the secret using a LabelSelector @ 07/11/24 06:45:36.277
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 07/11/24 06:45:36.286
  I0711 06:45:36.290661 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3493" for this suite. @ 07/11/24 06:45:36.294
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 07/11/24 06:45:36.3
  I0711 06:45:36.300829 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename var-expansion @ 07/11/24 06:45:36.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:45:36.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:45:36.319
  STEP: creating the pod with failed condition @ 07/11/24 06:45:36.322
  E0711 06:45:36.949783      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:37.950009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:38.950994      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:39.951112      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:40.951215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:41.951365      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:42.951510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:43.951580      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:44.951710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:45.951959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:46.952083      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:47.953024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:48.953133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:49.953224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:50.953334      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:51.953709      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:52.954607      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:53.954746      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:54.954927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:55.955060      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:56.955144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:57.955326      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:58.955442      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:45:59.955545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:00.955990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:01.956589      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:02.956704      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:03.957159      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:04.957271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:05.957368      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:06.957423      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:07.957624      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:08.957784      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:09.958031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:10.958290      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:11.958709      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:12.959755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:13.959976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:14.960864      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:15.961781      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:16.962223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:17.962420      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:18.962537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:19.962829      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:20.963337      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:21.963734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:22.963827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:23.963955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:24.964998      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:25.965527      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:26.966520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:27.966696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:28.966823      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:29.967151      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:30.967239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:31.967677      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:32.968664      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:33.969075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:34.969154      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:35.969614      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:36.969744      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:37.969936      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:38.970453      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:39.970559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:40.971505      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:41.971958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:42.972192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:43.972302      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:44.972940      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:45.973871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:46.973939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:47.974137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:48.975196      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:49.975377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:50.975514      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:51.975872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:52.976906      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:53.977195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:54.978210      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:55.978588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:56.979601      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:57.979844      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:58.979942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:46:59.980054      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:00.980670      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:01.981180      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:02.981287      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:03.981504      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:04.982190      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:05.982497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:06.983141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:07.983236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:08.983355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:09.983520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:10.984001      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:11.984141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:12.985027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:13.985131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:14.985905      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:15.986961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:16.987481      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:17.987600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:18.987652      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:19.987973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:20.989089      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:21.989178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:22.989775      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:23.989870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:24.990093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:25.990491      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:26.991078      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:27.991259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:28.991943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:29.992031      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:30.993006      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:31.993158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:32.993498      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:33.993667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:34.993862      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:35.994125      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 07/11/24 06:47:36.336
  I0711 06:47:36.850254 20 pod_client.go:141] Successfully updated pod "var-expansion-25ed2a86-5114-4a58-8a4a-5ce3c8599a16"
  STEP: waiting for pod running @ 07/11/24 06:47:36.85
  E0711 06:47:36.994276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:37.994432      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 07/11/24 06:47:38.86
  I0711 06:47:38.860324 20 delete.go:62] Deleting pod "var-expansion-25ed2a86-5114-4a58-8a4a-5ce3c8599a16" in namespace "var-expansion-5698"
  I0711 06:47:38.870460 20 delete.go:70] Wait up to 5m0s for pod "var-expansion-25ed2a86-5114-4a58-8a4a-5ce3c8599a16" to be fully deleted
  E0711 06:47:38.994916      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:39.995119      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:40.995237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:41.995355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:42.996116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:43.997038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:44.998110      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:45.998696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:46.999590      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:47.999710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:49.000513      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:50.001094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:51.002032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:52.002139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:53.003055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:54.003260      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:55.003791      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:56.003966      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:57.004847      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:58.005720      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:47:59.006271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:00.006378      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:01.006550      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:02.007033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:03.007826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:04.007976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:05.008002      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:06.008111      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:07.008664      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:08.008936      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:09.008957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:10.009176      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:48:10.957893 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5698" for this suite. @ 07/11/24 06:48:10.961
• [154.668 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 07/11/24 06:48:10.969
  I0711 06:48:10.969354 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename deployment @ 07/11/24 06:48:10.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:48:10.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:48:10.987
  STEP: creating a Deployment @ 07/11/24 06:48:10.996
  STEP: waiting for Deployment to be created @ 07/11/24 06:48:11.002
  STEP: waiting for all Replicas to be Ready @ 07/11/24 06:48:11.004
  I0711 06:48:11.005309 20 deployment.go:246] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0711 06:48:11.005330 20 deployment.go:248] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0711 06:48:11.009403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:48:11.015516 20 deployment.go:246] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0711 06:48:11.015538 20 deployment.go:248] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0711 06:48:11.030882 20 deployment.go:246] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0711 06:48:11.030907 20 deployment.go:248] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0711 06:48:11.056807 20 deployment.go:246] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0711 06:48:11.056837 20 deployment.go:248] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0711 06:48:11.665291 20 deployment.go:246] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0711 06:48:11.665323 20 deployment.go:248] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0711 06:48:11.691402 20 deployment.go:248] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 07/11/24 06:48:11.691
  I0711 06:48:11.700830 20 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 07/11/24 06:48:11.7
  I0711 06:48:11.702118 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0
  I0711 06:48:11.702167 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0
  I0711 06:48:11.702179 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0
  I0711 06:48:11.702184 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0
  I0711 06:48:11.702193 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0
  I0711 06:48:11.702199 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0
  I0711 06:48:11.702268 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0
  I0711 06:48:11.702274 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 0
  I0711 06:48:11.702281 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:11.702287 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:11.702293 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:11.702300 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:11.702333 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:11.702339 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:11.710527 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:11.710558 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:11.728237 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:11.728262 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:11.743051 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:11.743078 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:11.751878 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:11.751904 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  E0711 06:48:12.010387      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:48:12.707306 20 deployment.go:309] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:12.707356 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:12.728770 20 deployment.go:311] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  STEP: listing Deployments @ 07/11/24 06:48:12.728
  I0711 06:48:12.732533 20 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 07/11/24 06:48:12.732
  I0711 06:48:12.744775 20 deployment.go:360] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 07/11/24 06:48:12.744
  I0711 06:48:12.753138 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0711 06:48:12.760091 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0711 06:48:12.777706 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0711 06:48:12.794904 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0711 06:48:12.813286 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0711 06:48:13.010710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:48:13.720319 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0711 06:48:13.753512 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  I0711 06:48:13.765601 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  I0711 06:48:13.781987 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0711 06:48:14.011326      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:48:14.688044 20 deployment.go:389] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 07/11/24 06:48:14.726
  STEP: fetching the DeploymentStatus @ 07/11/24 06:48:14.735
  I0711 06:48:14.742232 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:14.742281 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:14.742290 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:14.742363 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:14.742374 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 1
  I0711 06:48:14.742381 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:14.742421 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 3
  I0711 06:48:14.742430 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 3
  I0711 06:48:14.742438 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 2
  I0711 06:48:14.742493 20 deployment.go:449] observed Deployment test-deployment in namespace deployment-3288 with ReadyReplicas 3
  STEP: deleting the Deployment @ 07/11/24 06:48:14.742
  I0711 06:48:14.752092 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752212 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752243 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752409 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752468 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752536 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752606 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752723 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752795 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752842 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752921 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.752960 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.753030 20 deployment.go:475] observed event type MODIFIED
  I0711 06:48:14.758980 20 deployment.go:650] Log out all the ReplicaSets if there is no deployment created
  I0711 06:48:14.767285 20 deployment.go:657] ReplicaSet "test-deployment-5bf4984755":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-5bf4984755",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6a29240b-7aca-4c8f-86a1-c2ce16b88ee0",
      ResourceVersion: (string) (len=5) "31319",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856277291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5bf4984755",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "b7187154-55f6-4f65-af1d-780a7217754c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 62 37 31 38  37 31 35 34 2d 35 35 66  |":\"b7187154-55f|
              00000130  36 2d 34 66 36 35 2d 61  66 31 64 2d 37 38 30 61  |6-4f65-af1d-780a|
              00000140  37 32 31 37 37 35 34 63  5c 22 7d 22 3a 7b 7d 7d  |7217754c\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "5bf4984755",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "5bf4984755",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0711 06:48:14.771394 20 deployment.go:657] ReplicaSet "test-deployment-6b9f8f4d48":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-6b9f8f4d48",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d121b8d8-f4ea-4406-bb04-a56d6fbd74ef",
      ResourceVersion: (string) (len=5) "31408",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856277292,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "b7187154-55f6-4f65-af1d-780a7217754c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277293,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 62 37 31 38  37 31 35 34 2d 35 35 66  |":\"b7187154-55f|
              00000130  36 2d 34 66 36 35 2d 61  66 31 64 2d 37 38 30 61  |6-4f65-af1d-780a|
              00000140  37 32 31 37 37 35 34 63  5c 22 7d 22 3a 7b 7d 7d  |7217754c\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277294,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0711 06:48:14.781531 20 deployment.go:669] pod: "test-deployment-6b9f8f4d48-pzp9w":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6b9f8f4d48-pzp9w",
      GenerateName: (string) (len=27) "test-deployment-6b9f8f4d48-",
      Namespace: (string) (len=15) "deployment-3288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e8dc80f2-6f32-43ec-9399-b249955ee1c1",
      ResourceVersion: (string) (len=5) "31429",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856277292,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856277295,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(1),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6b9f8f4d48",
          UID: (types.UID) (len=36) "d121b8d8-f4ea-4406-bb04-a56d6fbd74ef",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 31 32 31 62 38 64 38  |uid\":\"d121b8d8|
              000000a0  2d 66 34 65 61 2d 34 34  30 36 2d 62 62 30 34 2d  |-f4ea-4406-bb04-|
              000000b0  61 35 36 64 36 66 62 64  37 34 65 66 5c 22 7d 22  |a56d6fbd74ef\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277293,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 37  2e 32 33 5c 22 7d 22 3a  |2.168.37.23\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dnc7n",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dnc7n",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277293,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277293,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277293,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) (len=13) "192.168.37.23",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.37.23"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856277292,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856277293,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://bc848091ceb5d93cfb9e925d4215d0f1b208325d04fdd1e8c086bbd0b6c6d1b1",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0711 06:48:14.782820 20 deployment.go:669] pod: "test-deployment-6b9f8f4d48-tq79c":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6b9f8f4d48-tq79c",
      GenerateName: (string) (len=27) "test-deployment-6b9f8f4d48-",
      Namespace: (string) (len=15) "deployment-3288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "892fffb2-f4ac-4e93-9ef4-056b65d5da1f",
      ResourceVersion: (string) (len=5) "31430",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856277293,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856277295,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(1),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6b9f8f4d48",
          UID: (types.UID) (len=36) "d121b8d8-f4ea-4406-bb04-a56d6fbd74ef",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277293,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 31 32 31 62 38 64 38  |uid\":\"d121b8d8|
              000000a0  2d 66 34 65 61 2d 34 34  30 36 2d 62 62 30 34 2d  |-f4ea-4406-bb04-|
              000000b0  61 35 36 64 36 66 62 64  37 34 65 66 5c 22 7d 22  |a56d6fbd74ef\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277294,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 33  33 2e 36 38 5c 22 7d 22  |2.168.133.68\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-m2k8n",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-m2k8n",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-237",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277294,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277293,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277294,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277294,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856277293,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.237",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.237"
        }
      },
      PodIP: (string) (len=14) "192.168.133.68",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.133.68"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856277293,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856277294,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0db3cec7608fe1497422e51aed5028e5f8682e0939c1f5e9578d95224b7c8d92",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0711 06:48:14.783856 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3288" for this suite. @ 07/11/24 06:48:14.789
• [3.826 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1420
  STEP: Creating a kubernetes client @ 07/11/24 06:48:14.796
  I0711 06:48:14.796058 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 06:48:14.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:48:14.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:48:14.817
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-2993 @ 07/11/24 06:48:14.819
  STEP: changing the ExternalName service to type=ClusterIP @ 07/11/24 06:48:14.825
  STEP: creating replication controller externalname-service in namespace services-2993 @ 07/11/24 06:48:14.846
  I0711 06:48:14.853032      20 runners.go:198] Created replication controller with name: externalname-service, namespace: services-2993, replica count: 2
  E0711 06:48:15.011991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:16.012775      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:17.013271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:48:17.903888      20 runners.go:198] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0711 06:48:17.903931 20 resource.go:361] Creating new exec pod
  E0711 06:48:18.013688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:19.013887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:20.014223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:48:20.921091 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-2993 exec execpod4pqtw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0711 06:48:21.014539      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:48:21.014931 20 builder.go:146] stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0711 06:48:21.014971 20 builder.go:147] stdout: "externalname-service-nwrl5"
  I0711 06:48:21.015085 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-2993 exec execpod4pqtw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.149 80'
  I0711 06:48:21.101223 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.149 80\nConnection to 10.152.183.149 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0711 06:48:21.101265 20 builder.go:147] stdout: "externalname-service-nwrl5"
  I0711 06:48:21.101412 20 service.go:1429] Cleaning up the ExternalName to ClusterIP test service
  I0711 06:48:21.122034 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2993" for this suite. @ 07/11/24 06:48:21.126
• [6.338 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 07/11/24 06:48:21.134
  I0711 06:48:21.134449 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename dns @ 07/11/24 06:48:21.134
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:48:21.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:48:21.153
  STEP: Creating a test headless service @ 07/11/24 06:48:21.155
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-648.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-648.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 07/11/24 06:48:21.163
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-648.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-648.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 07/11/24 06:48:21.163
  STEP: creating a pod to probe DNS @ 07/11/24 06:48:21.163
  STEP: submitting the pod to kubernetes @ 07/11/24 06:48:21.163
  E0711 06:48:22.014630      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:23.014736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 07/11/24 06:48:23.186
  STEP: looking for the results for each expected name from probers @ 07/11/24 06:48:23.19
  I0711 06:48:23.207192 20 dns_common.go:527] DNS probes using dns-648/dns-test-e78d0539-1286-42a1-826e-31ccf26ffb96 succeeded

  STEP: deleting the pod @ 07/11/24 06:48:23.207
  STEP: deleting the test headless service @ 07/11/24 06:48:23.219
  I0711 06:48:23.235893 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-648" for this suite. @ 07/11/24 06:48:23.239
• [2.111 seconds]
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 07/11/24 06:48:23.245
  I0711 06:48:23.245550 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename security-context @ 07/11/24 06:48:23.246
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:48:23.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:48:23.262
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 07/11/24 06:48:23.264
  E0711 06:48:24.015012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:25.015261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:26.015347      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:27.015458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:48:27.286
  I0711 06:48:27.289836 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod security-context-ffc5e7f5-6f15-4e1e-8c2a-20e0e793f9be container test-container: <nil>
  STEP: delete the pod @ 07/11/24 06:48:27.305
  I0711 06:48:27.321647 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-759" for this suite. @ 07/11/24 06:48:27.325
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 07/11/24 06:48:27.332
  I0711 06:48:27.332749 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename cronjob @ 07/11/24 06:48:27.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:48:27.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:48:27.353
  STEP: Creating a suspended cronjob @ 07/11/24 06:48:27.355
  STEP: Ensuring no jobs are scheduled @ 07/11/24 06:48:27.36
  E0711 06:48:28.016235      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:29.017047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:30.017873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:31.018137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:32.018363      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:33.018451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:34.018555      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:35.018615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:36.019663      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:37.019973      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:38.020066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:39.020959      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:40.021065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:41.021539      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:42.022295      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:43.022559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:44.022649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:45.022738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:46.022791      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:47.022877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:48.023963      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:49.024071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:50.024173      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:51.024270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:52.025035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:53.025263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:54.025359      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:55.025458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:56.026230      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:57.026455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:58.026638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:48:59.026796      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:00.026966      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:01.027417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:02.028331      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:03.028416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:04.028527      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:05.029175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:06.030010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:07.030454      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:08.030742      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:09.030940      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:10.031914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:11.031986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:12.032158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:13.032609      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:14.033018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:15.033083      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:16.033729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:17.034023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:18.034057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:19.034152      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:20.035190      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:21.035435      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:22.036282      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:23.037091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:24.037332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:25.037525      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:26.037701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:27.037977      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:28.038083      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:29.038340      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:30.039175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:31.039278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:32.039524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:33.039749      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:34.040708      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:35.040945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:36.041698      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:37.042179      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:38.042299      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:39.042546      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:40.042622      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:41.042843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:42.042958      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:43.043563      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:44.043982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:45.044043      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:46.044918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:47.045028      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:48.045131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:49.045455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:50.045638      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:51.045748      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:52.046522      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:53.046618      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:54.046730      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:55.047168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:56.047955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:57.048565      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:58.049148      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:49:59.049242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:00.049747      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:01.049971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:02.050226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:03.050400      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:04.050619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:05.050872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:06.051038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:07.051269      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:08.051982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:09.052060      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:10.052721      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:11.052807      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:12.052903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:13.053237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:14.054248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:15.054431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:16.055264      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:17.055646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:18.055778      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:19.056386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:20.056696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:21.056907      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:22.057537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:23.057655      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:24.057736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:25.057943      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:26.058918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:27.059229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:28.059932      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:29.060100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:30.060986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:31.061245      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:32.062055      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:33.062143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:34.062876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:35.063050      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:36.063178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:37.063765      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:38.064369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:39.065129      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:40.066170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:41.066369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:42.067327      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:43.067547      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:44.068438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:45.068543      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:46.068643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:47.068736      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:48.068925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:49.069105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:50.070039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:51.071131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:52.072168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:53.073058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:54.073154      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:55.073353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:56.073566      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:57.073664      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:58.074417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:50:59.074621      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:00.075145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:01.075178      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:02.075303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:03.075417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:04.075529      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:05.075755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:06.075853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:07.076096      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:08.076211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:09.077147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:10.077623      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:11.078096      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:12.078385      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:13.078580      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:14.079526      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:15.079787      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:16.079929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:17.080202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:18.081077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:19.081280      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:20.081343      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:21.082172      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:22.082701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:23.082799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:24.083090      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:25.083254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:26.083937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:27.085007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:28.085093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:29.085289      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:30.085645      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:31.086086      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:32.086202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:33.086393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:34.086952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:35.087223      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:36.087786      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:37.087935      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:38.088049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:39.088152      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:40.088559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:41.089163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:42.090069      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:43.090258      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:44.090481      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:45.090807      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:46.091710      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:47.091986      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:48.093191      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:49.093535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:50.094219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:51.095188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:52.095568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:53.095693      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:54.096540      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:55.097103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:56.097626      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:57.097829      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:58.098106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:51:59.098389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:00.099392      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:01.099399      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:02.100082      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:03.100196      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:04.100953      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:05.101304      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:06.102332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:07.102447      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:08.102984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:09.103173      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:10.104150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:11.105137      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:12.105232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:13.105480      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:14.106136      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:15.106492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:16.106560      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:17.106772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:18.106872      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:19.107103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:20.107460      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:21.107472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:22.108429      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:23.109062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:24.109232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:25.109346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:26.110176      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:27.110283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:28.110841      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:29.111049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:30.111408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:31.112196      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:32.112331      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:33.113008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:34.114052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:35.114341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:36.115017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:37.115271      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:38.115687      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:39.115942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:40.116876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:41.117118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:42.117209      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:43.117423      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:44.118026      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:45.118309      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:46.118332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:47.118604      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:48.119265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:49.119362      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:50.120236      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:51.120320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:52.120817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:53.121014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:54.121139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:55.121354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:56.121455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:57.121734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:58.122017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:52:59.122126      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:00.122172      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:01.123093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:02.123835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:03.123946      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:04.124354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:05.125069      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:06.125545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:07.125762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:08.125956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:09.126182      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:10.126352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:11.127144      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:12.127373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:13.127558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:14.128319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:15.128440      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:16.129322      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:17.129565      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:18.130086      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:19.130535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:20.130933      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:21.131140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:22.131311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:23.131940      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:24.132036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:25.132378      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:26.132841      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:27.132931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 07/11/24 06:53:27.361
  STEP: Removing cronjob @ 07/11/24 06:53:27.365
  I0711 06:53:27.373468 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3547" for this suite. @ 07/11/24 06:53:27.377
• [300.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 07/11/24 06:53:27.386
  I0711 06:53:27.386547 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir-wrapper @ 07/11/24 06:53:27.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:53:27.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:53:27.405
  E0711 06:53:28.133702      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:29.134005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 07/11/24 06:53:29.438
  STEP: Cleaning up the configmap @ 07/11/24 06:53:29.445
  STEP: Cleaning up the pod @ 07/11/24 06:53:29.453
  I0711 06:53:29.464740 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-1569" for this suite. @ 07/11/24 06:53:29.468
• [2.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 07/11/24 06:53:29.479
  I0711 06:53:29.479051 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename subpath @ 07/11/24 06:53:29.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:53:29.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:53:29.5
  STEP: Setting up data @ 07/11/24 06:53:29.502
  STEP: Creating pod pod-subpath-test-projected-hrc8 @ 07/11/24 06:53:29.511
  STEP: Creating a pod to test atomic-volume-subpath @ 07/11/24 06:53:29.511
  E0711 06:53:30.134097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:31.135147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:32.135831      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:33.136106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:34.136900      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:35.137195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:36.137966      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:37.138153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:38.138270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:39.138483      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:40.138595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:41.139065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:42.139239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:43.139361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:44.139484      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:45.139659      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:46.140167      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:47.140260      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:48.141259      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:49.141334      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:50.142199      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:51.143195      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:53:51.584
  I0711 06:53:51.589086 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-subpath-test-projected-hrc8 container test-container-subpath-projected-hrc8: <nil>
  STEP: delete the pod @ 07/11/24 06:53:51.607
  STEP: Deleting pod pod-subpath-test-projected-hrc8 @ 07/11/24 06:53:51.622
  I0711 06:53:51.622641 20 delete.go:62] Deleting pod "pod-subpath-test-projected-hrc8" in namespace "subpath-7940"
  I0711 06:53:51.626114 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7940" for this suite. @ 07/11/24 06:53:51.629
• [22.157 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:882
  STEP: Creating a kubernetes client @ 07/11/24 06:53:51.636
  I0711 06:53:51.636692 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 06:53:51.637
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:53:51.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:53:51.654
  STEP: validating api versions @ 07/11/24 06:53:51.657
  I0711 06:53:51.657083 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-3610 api-versions'
  I0711 06:53:51.696341 20 builder.go:146] stderr: ""
  I0711 06:53:51.696388 20 builder.go:147] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I0711 06:53:51.696469 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3610" for this suite. @ 07/11/24 06:53:51.7
• [0.070 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 07/11/24 06:53:51.707
  I0711 06:53:51.707232 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 06:53:51.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:53:51.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:53:51.724
  STEP: Creating a pod to test downward api env vars @ 07/11/24 06:53:51.727
  E0711 06:53:52.143846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:53.143984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:54.145026      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:55.145224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:53:55.751
  I0711 06:53:55.754793 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downward-api-ca13edc9-cc07-4514-82cb-293f468422e3 container dapi-container: <nil>
  STEP: delete the pod @ 07/11/24 06:53:55.761
  I0711 06:53:55.779853 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4696" for this suite. @ 07/11/24 06:53:55.783
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:927
  STEP: Creating a kubernetes client @ 07/11/24 06:53:55.791
  I0711 06:53:55.791126 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename job @ 07/11/24 06:53:55.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:53:55.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:53:55.809
  STEP: Creating a suspended job @ 07/11/24 06:53:55.814
  STEP: Patching the Job @ 07/11/24 06:53:55.82
  STEP: Watching for Job to be patched @ 07/11/24 06:53:55.835
  I0711 06:53:55.836569 20 job.go:1109] Event ADDED observed for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-job-label:e2e-5dlsd] and annotations: map[]
  I0711 06:53:55.836595 20 job.go:1109] Event MODIFIED observed for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-job-label:e2e-5dlsd] and annotations: map[]
  I0711 06:53:55.836616 20 job.go:1112] Event MODIFIED found for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[]
  STEP: Updating the job @ 07/11/24 06:53:55.836
  STEP: Watching for Job to be updated @ 07/11/24 06:53:55.848
  I0711 06:53:55.849952 20 job.go:1112] Event MODIFIED found for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[updated:true]
  I0711 06:53:55.849984 20 job.go:1005] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 07/11/24 06:53:55.849
  I0711 06:53:55.853216 20 job.go:1012] Job: e2e-5dlsd as labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd]
  STEP: Waiting for job to complete @ 07/11/24 06:53:55.853
  E0711 06:53:56.145878      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:57.146071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:58.146225      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:53:59.146422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:00.146515      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:01.147224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:02.148280      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:03.148366      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 07/11/24 06:54:03.858
  STEP: Watching for Job to be deleted @ 07/11/24 06:54:03.867
  I0711 06:54:03.870200 20 job.go:1109] Event MODIFIED observed for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[updated:true]
  I0711 06:54:03.870229 20 job.go:1109] Event MODIFIED observed for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[updated:true]
  I0711 06:54:03.870326 20 job.go:1109] Event MODIFIED observed for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[updated:true]
  I0711 06:54:03.870377 20 job.go:1109] Event MODIFIED observed for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[updated:true]
  I0711 06:54:03.870388 20 job.go:1109] Event MODIFIED observed for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[updated:true]
  I0711 06:54:03.870511 20 job.go:1109] Event MODIFIED observed for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[updated:true]
  I0711 06:54:03.870520 20 job.go:1109] Event MODIFIED observed for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[updated:true]
  I0711 06:54:03.870529 20 job.go:1112] Event DELETED found for Job e2e-5dlsd in namespace job-9736 with labels: map[e2e-5dlsd:patched e2e-job-label:e2e-5dlsd] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 07/11/24 06:54:03.87
  I0711 06:54:03.874728 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9736" for this suite. @ 07/11/24 06:54:03.881
• [8.108 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 07/11/24 06:54:03.899
  I0711 06:54:03.899505 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename security-context @ 07/11/24 06:54:03.9
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:54:03.915
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:54:03.917
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 07/11/24 06:54:03.919
  E0711 06:54:04.149448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:05.149535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:06.150407      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:07.150615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:54:07.951
  I0711 06:54:07.955443 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod security-context-91db5fbf-14ec-44ae-975b-81b04729f9bf container test-container: <nil>
  STEP: delete the pod @ 07/11/24 06:54:07.963
  I0711 06:54:07.981972 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-3527" for this suite. @ 07/11/24 06:54:07.986
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 07/11/24 06:54:07.993
  I0711 06:54:07.993545 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-runtime @ 07/11/24 06:54:07.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:54:08.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:54:08.01
  STEP: create the container @ 07/11/24 06:54:08.012
  W0711 06:54:08.021639      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 07/11/24 06:54:08.021
  E0711 06:54:08.150685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:09.150797      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:10.151270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 07/11/24 06:54:11.039
  STEP: the container should be terminated @ 07/11/24 06:54:11.043
  STEP: the termination message should be set @ 07/11/24 06:54:11.043
  I0711 06:54:11.043841 20 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 07/11/24 06:54:11.043
  I0711 06:54:11.058862 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9200" for this suite. @ 07/11/24 06:54:11.062
• [3.077 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 07/11/24 06:54:11.07
  I0711 06:54:11.070723 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename gc @ 07/11/24 06:54:11.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:54:11.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:54:11.087
  STEP: create the rc1 @ 07/11/24 06:54:11.093
  STEP: create the rc2 @ 07/11/24 06:54:11.099
  E0711 06:54:11.152257      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:12.152256      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:13.160072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:14.160157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:15.162466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:16.163140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 07/11/24 06:54:17.108
  E0711 06:54:17.164134      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 07/11/24 06:54:17.525
  STEP: wait for the rc to be deleted @ 07/11/24 06:54:17.534
  E0711 06:54:18.164281      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:19.164348      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:20.164835      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:21.165159      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:22.165237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:22.549643 20 garbage_collector.go:762] 72 pods remaining
  I0711 06:54:22.549674 20 garbage_collector.go:769] 72 pods has nil DeletionTimestamp
  I0711 06:54:22.549680 20 garbage_collector.go:770] 
  E0711 06:54:23.166537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:24.166741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:25.167117      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:26.168025      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:27.169010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 07/11/24 06:54:27.545
  W0711 06:54:27.551270      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0711 06:54:27.551303 20 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0711 06:54:27.551397 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2s2rc" in namespace "gc-6788"
  I0711 06:54:27.565227 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2xsqt" in namespace "gc-6788"
  I0711 06:54:27.649091 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2zmgh" in namespace "gc-6788"
  I0711 06:54:27.662567 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4446d" in namespace "gc-6788"
  I0711 06:54:27.679862 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-47ckn" in namespace "gc-6788"
  I0711 06:54:27.692458 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-56947" in namespace "gc-6788"
  I0711 06:54:27.705603 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5hcp2" in namespace "gc-6788"
  I0711 06:54:27.717947 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5wgtx" in namespace "gc-6788"
  I0711 06:54:27.731783 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-69gk7" in namespace "gc-6788"
  I0711 06:54:27.745481 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6gw85" in namespace "gc-6788"
  I0711 06:54:27.757316 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-75q92" in namespace "gc-6788"
  I0711 06:54:27.775356 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7rncv" in namespace "gc-6788"
  I0711 06:54:27.790729 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7t9mz" in namespace "gc-6788"
  I0711 06:54:27.803321 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7tjth" in namespace "gc-6788"
  I0711 06:54:27.815091 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-82nwn" in namespace "gc-6788"
  I0711 06:54:27.829975 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8jd4s" in namespace "gc-6788"
  I0711 06:54:27.842951 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8l7v2" in namespace "gc-6788"
  I0711 06:54:27.863401 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8z2w4" in namespace "gc-6788"
  I0711 06:54:27.879110 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8zvzg" in namespace "gc-6788"
  I0711 06:54:27.896850 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-99ptl" in namespace "gc-6788"
  I0711 06:54:27.907643 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9f6h7" in namespace "gc-6788"
  I0711 06:54:27.921150 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9r9g2" in namespace "gc-6788"
  I0711 06:54:27.936523 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9tvxk" in namespace "gc-6788"
  I0711 06:54:27.949149 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-b464h" in namespace "gc-6788"
  I0711 06:54:27.966615 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-b5gnr" in namespace "gc-6788"
  I0711 06:54:27.978527 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bkssg" in namespace "gc-6788"
  I0711 06:54:27.997463 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bvgg8" in namespace "gc-6788"
  I0711 06:54:28.012262 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-c2hdd" in namespace "gc-6788"
  I0711 06:54:28.027677 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-c69xw" in namespace "gc-6788"
  I0711 06:54:28.040722 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cdpbz" in namespace "gc-6788"
  I0711 06:54:28.051740 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-chqft" in namespace "gc-6788"
  I0711 06:54:28.075456 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-ckrr9" in namespace "gc-6788"
  I0711 06:54:28.092110 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-ckxgb" in namespace "gc-6788"
  I0711 06:54:28.114270 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cw4mm" in namespace "gc-6788"
  I0711 06:54:28.126840 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cwjjc" in namespace "gc-6788"
  I0711 06:54:28.159191 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dm85l" in namespace "gc-6788"
  I0711 06:54:28.180125 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-drqz7" in namespace "gc-6788"
  E0711 06:54:28.180408      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:28.196056 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dxzlq" in namespace "gc-6788"
  I0711 06:54:28.214164 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-f7fhb" in namespace "gc-6788"
  I0711 06:54:28.245482 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-ffkfl" in namespace "gc-6788"
  I0711 06:54:28.257258 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-g8mg4" in namespace "gc-6788"
  I0711 06:54:28.269542 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-g9nr8" in namespace "gc-6788"
  I0711 06:54:28.285650 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gk4hn" in namespace "gc-6788"
  I0711 06:54:28.298371 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gp6zm" in namespace "gc-6788"
  I0711 06:54:28.313649 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-h4lm5" in namespace "gc-6788"
  I0711 06:54:28.325041 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hng2g" in namespace "gc-6788"
  I0711 06:54:28.339935 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hnr6m" in namespace "gc-6788"
  I0711 06:54:28.354163 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hsr4h" in namespace "gc-6788"
  I0711 06:54:28.369994 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hxpzz" in namespace "gc-6788"
  I0711 06:54:28.384245 20 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j7k6p" in namespace "gc-6788"
  I0711 06:54:28.405281 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6788" for this suite. @ 07/11/24 06:54:28.409
• [17.358 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 07/11/24 06:54:28.43
  I0711 06:54:28.430668 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replication-controller @ 07/11/24 06:54:28.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:54:28.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:54:28.46
  STEP: Given a ReplicationController is created @ 07/11/24 06:54:28.463
  STEP: When the matched label of one of its pods change @ 07/11/24 06:54:28.469
  I0711 06:54:28.478591 20 resource.go:87] Pod name pod-release: Found 0 pods out of 1
  E0711 06:54:29.180367      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:30.180480      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:31.181235      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:32.181453      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:33.181542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:33.482481 20 resource.go:87] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 07/11/24 06:54:33.493
  E0711 06:54:34.181669      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:34.502375 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4935" for this suite. @ 07/11/24 06:54:34.506
• [6.088 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 07/11/24 06:54:34.519
  I0711 06:54:34.519309 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 06:54:34.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:54:34.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:54:34.552
  STEP: Creating pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682 @ 07/11/24 06:54:34.554
  E0711 06:54:35.181758      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:36.182184      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 07/11/24 06:54:36.595
  I0711 06:54:36.602130 20 container_probe.go:1749] Initial restart count of pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f is 0
  I0711 06:54:36.605204 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:37.182979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:38.183177      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:38.611088 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:39.183747      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:40.183983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:40.615478 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:41.184053      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:42.185052      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:42.621781 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:43.185141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:44.185239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:44.627320 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:45.186044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:46.186623      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:46.632858 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:47.186654      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:48.186745      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:48.637908 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:49.187582      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:50.187653      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:50.642832 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:51.188165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:52.188288      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:52.648955 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:53.188395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:54.189185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:54.655033 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:55.189284      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:56.190157      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:56.660080 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:57.190684      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:54:58.190836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:54:58.665673 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:54:59.191251      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:00.191344      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:00.670296 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:01.191891      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:02.191990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:02.675079 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:03.192750      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:04.192810      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:04.679278 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:05.193573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:06.194074      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:06.684106 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:07.194965      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:08.195080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:08.689267 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:09.195162      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:10.195396      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:10.695302 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:11.196047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:12.196154      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:12.700146 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:13.196661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:14.197048      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:14.706043 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:15.197231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:16.197798      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:16.710814 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:17.198731      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:18.198956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:18.716405 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:19.199000      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:20.199106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:20.721947 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:21.199918      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:22.199991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:22.726892 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:23.200128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:24.200232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:24.732973 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:25.201165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:26.201699      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:26.737824 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:27.202124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:28.202205      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:28.742916 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:29.202285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:30.202385      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:30.748637 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:31.203243      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:32.203337      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:32.754077 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:33.203647      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:34.203887      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:34.759473 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:35.204007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:36.204274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:36.765142 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:37.204386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:38.204485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:38.769620 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:39.205131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:40.205351      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:40.775272 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:41.205879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:42.206346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:42.781188 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:43.206661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:44.206886      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:44.786132 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:45.207861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:46.208332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:46.792139 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:47.208602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:48.208705      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:48.797156 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:49.209646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:50.209898      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:50.802565 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:51.210014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:52.210174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:52.807306 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:53.210870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:54.210967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:54.813341 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:55.211019      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:56.211648      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:56.819422 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:57.211741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:55:58.211853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:55:58.824563 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:55:59.211991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:00.213065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:00.828936 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:01.213585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:02.214070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:02.834884 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:03.214332      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:04.214539      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:04.839498 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:05.214968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:06.215224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:06.844351 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:07.215846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:08.216024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:08.848554 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:09.217100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:10.217198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:10.854163 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:11.217789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:12.217814      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:12.859148 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:13.218754      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:14.218968      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:14.864829 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:15.219267      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:16.219894      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:16.869708 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:17.220034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:18.220140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:18.874500 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:19.221073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:20.221454      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:20.880415 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:21.222402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:22.222446      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:22.885806 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:23.223197      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:24.223292      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:24.891507 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:25.223906      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:26.223951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:26.897572 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:27.225001      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:28.225106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:28.902514 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:29.225890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:30.226084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:30.907993 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:31.226498      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:32.226667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:32.914314 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:33.227759      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:34.228041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:34.919244 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:35.228813      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:36.229117      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:36.923893 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:37.229270      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:38.229612      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:38.929526 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:39.229820      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:40.229939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:40.934361 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:41.230075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:42.230338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:42.939482 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:43.231115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:44.231374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:44.944877 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:45.232328      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:46.232884      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:46.951092 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:47.233521      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:48.233624      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:48.957849 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:49.234341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:50.234456      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:50.962664 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:51.235118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:52.235672      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:52.968713 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:53.236266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:54.236379      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:54.973930 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:55.237160      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:56.237732      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:56.979574 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:57.237840      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:56:58.238121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:56:58.984670 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:56:59.239165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:00.239406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:00.990106 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:01.239542      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:02.239861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:02.995013 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:03.240426      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:04.240532      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:05.000603 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:05.240883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:06.241294      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:07.006725 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:07.242029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:08.242118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:09.011887 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:09.243062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:10.243256      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:11.016928 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:11.243373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:12.243489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:13.023018 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:13.244300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:14.244407      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:15.029072 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:15.245450      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:16.246139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:17.034357 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:17.246629      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:18.246827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:19.038917 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:19.247444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:20.247662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:21.044423 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:21.248047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:22.248127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:23.049786 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:23.249128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:24.249333      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:25.055567 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:25.249830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:26.250226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:27.060263 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:27.250737      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:28.250996      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:29.066056 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:29.251415      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:30.251518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:31.071893 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:31.252152      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:32.253016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:33.078098 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:33.253543      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:34.253834      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:35.083212 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:35.254451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:36.254934      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:37.089428 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:37.255722      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:38.255952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:39.094030 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:39.256357      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:40.256455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:41.101032 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:41.257356      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:42.257786      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:43.106966 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:43.258250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:44.258524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:45.111451 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:45.258676      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:46.259405      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:47.117777 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:47.260008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:48.261029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:49.123033 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:49.261245      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:50.262140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:51.129236 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:51.262539      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:52.262609      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:53.134275 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:53.263499      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:54.263600      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:55.139538 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:55.263741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:56.264224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:57.145425 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:57.264693      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:57:58.265042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:57:59.151509 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:57:59.265741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:00.265961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:01.156606 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:01.266787      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:02.266881      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:03.161818 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:03.267063      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:04.267189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:05.166728 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:05.267925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:06.268978      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:07.171638 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:07.269824      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:08.269995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:09.176591 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:09.270920      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:10.271051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:11.182154 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:11.271278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:12.271449      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:13.187721 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:13.271935      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:14.271987      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:15.192924 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:15.272033      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:16.272772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:17.197661 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:17.272804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:18.272991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:19.202421 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:19.273559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:20.273890      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:21.209131 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:21.274334      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:22.275220      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:23.214170 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:23.275369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:24.275588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:25.219899 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:25.276213      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:26.277242      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:27.224322 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:27.277472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:28.277939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:29.230046 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:29.278153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:30.278427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:31.234810 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:31.278967      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:32.279293      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:33.241106 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:33.280283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:34.280395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:35.245905 20 container_probe.go:1759] Get pod test-grpc-ae77dc6f-9614-45ab-bae6-1f085bbc0c4f in namespace container-probe-4682
  E0711 06:58:35.281091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:36.281219      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 07/11/24 06:58:37.246
  I0711 06:58:37.259060 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4682" for this suite. @ 07/11/24 06:58:37.262
• [242.753 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 07/11/24 06:58:37.272
  I0711 06:58:37.272102 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:58:37.272
  E0711 06:58:37.281237      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:58:37.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:58:37.288
  STEP: Setting up server cert @ 07/11/24 06:58:37.317
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:58:37.539
  STEP: Deploying the webhook pod @ 07/11/24 06:58:37.548
  STEP: Wait for the deployment to be ready @ 07/11/24 06:58:37.563
  I0711 06:58:37.570688 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:58:38.281453      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:39.281518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 06:58:39.584
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 06:58:39.6
  E0711 06:58:40.281803      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:40.601231 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0711 06:58:40.609968 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7935-crds.webhook.example.com via the AdmissionRegistration API @ 07/11/24 06:58:41.121
  STEP: Creating a custom resource while v1 is storage version @ 07/11/24 06:58:41.134
  E0711 06:58:41.282649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:42.282880      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 07/11/24 06:58:43.161
  STEP: Patching the custom resource while v2 is storage version @ 07/11/24 06:58:43.223
  E0711 06:58:43.282962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:43.840135 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7595" for this suite. @ 07/11/24 06:58:43.845
  STEP: Destroying namespace "webhook-markers-6269" for this suite. @ 07/11/24 06:58:43.854
• [6.590 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 07/11/24 06:58:43.861
  I0711 06:58:43.861904 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 06:58:43.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:58:43.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:58:43.879
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 06:58:43.882
  E0711 06:58:44.283029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:45.283114      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:46.283746      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:47.283937      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 06:58:47.906
  I0711 06:58:47.910327 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-b7b53e69-d06a-49e1-8813-6ab14eb85390 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 06:58:47.92
  I0711 06:58:47.936871 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3182" for this suite. @ 07/11/24 06:58:47.94
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 07/11/24 06:58:47.948
  I0711 06:58:47.948240 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename statefulset @ 07/11/24 06:58:47.948
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:58:47.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:58:47.965
  STEP: Creating service test in namespace statefulset-1833 @ 07/11/24 06:58:47.968
  STEP: Creating a new StatefulSet @ 07/11/24 06:58:47.974
  I0711 06:58:47.989914 20 wait.go:40] Found 0 stateful pods, waiting for 3
  E0711 06:58:48.284438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:49.284537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:50.285153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:51.285274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:52.285734      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:53.285837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:54.286010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:55.286129      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:56.286823      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:57.286981      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:58:57.989704 20 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0711 06:58:57.989740 20 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0711 06:58:57.989749 20 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 07/11/24 06:58:58.001
  I0711 06:58:58.022794 20 statefulset.go:2241] Updating stateful set ss2
  STEP: Creating a new revision @ 07/11/24 06:58:58.022
  E0711 06:58:58.287553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:58:59.287652      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:00.287909      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:01.288445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:02.288555      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:03.289038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:04.289326      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:05.289526      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:06.290123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:07.290404      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 07/11/24 06:59:08.031
  STEP: Performing a canary update @ 07/11/24 06:59:08.031
  I0711 06:59:08.052889 20 statefulset.go:2241] Updating stateful set ss2
  I0711 06:59:08.060239 20 wait.go:74] Waiting for Pod statefulset-1833/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0711 06:59:08.290686      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:09.290828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:10.291087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:11.291220      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:12.291339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:13.291597      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:14.292352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:15.292443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:16.293017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:17.293228      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 07/11/24 06:59:18.062
  I0711 06:59:18.109679 20 wait.go:40] Found 2 stateful pods, waiting for 3
  E0711 06:59:18.293928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:19.294026      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:20.294239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:21.295290      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:22.295411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:23.295537      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:24.295718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:25.295971      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:26.296400      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:27.296460      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:59:28.104327 20 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0711 06:59:28.104355 20 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0711 06:59:28.104363 20 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 07/11/24 06:59:28.111
  I0711 06:59:28.133427 20 statefulset.go:2241] Updating stateful set ss2
  I0711 06:59:28.143435 20 wait.go:74] Waiting for Pod statefulset-1833/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0711 06:59:28.300928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:29.301039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:30.301346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:31.302545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:32.303214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:33.303250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:34.303353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:35.303486      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:36.303902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:37.303946      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:59:38.163690 20 statefulset.go:2241] Updating stateful set ss2
  I0711 06:59:38.175459 20 wait.go:56] Waiting for StatefulSet statefulset-1833/ss2 to complete update
  I0711 06:59:38.175499 20 wait.go:63] Waiting for Pod statefulset-1833/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0711 06:59:38.304741      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:39.304817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:40.305150      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:41.305262      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:42.305394      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:43.305608      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:44.305721      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:45.305839      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:46.306234      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:47.306431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:59:48.172847 20 statefulset.go:135] Deleting all statefulset in ns statefulset-1833
  I0711 06:59:48.176816 20 rest.go:150] Scaling statefulset ss2 to 0
  E0711 06:59:48.306548      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:49.306746      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:50.306942      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:51.307414      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:52.307550      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:53.307615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:54.307931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:55.308170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:56.308784      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 06:59:57.309054      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 06:59:58.191494 20 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0711 06:59:58.195736 20 rest.go:88] Deleting statefulset ss2
  I0711 06:59:58.210793 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1833" for this suite. @ 07/11/24 06:59:58.214
• [70.273 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 07/11/24 06:59:58.221
  I0711 06:59:58.221550 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 06:59:58.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 06:59:58.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 06:59:58.238
  STEP: Setting up server cert @ 07/11/24 06:59:58.26
  E0711 06:59:58.309761      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 06:59:58.523
  STEP: Deploying the webhook pod @ 07/11/24 06:59:58.532
  STEP: Wait for the deployment to be ready @ 07/11/24 06:59:58.545
  I0711 06:59:58.555882 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 06:59:59.310598      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:00.310805      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 07:00:00.569
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 07:00:00.581
  E0711 07:00:01.311179      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:00:01.581634 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 07/11/24 07:00:01.59
  STEP: create a configmap that should be updated by the webhook @ 07/11/24 07:00:01.602
  I0711 07:00:01.752269 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2946" for this suite. @ 07/11/24 07:00:01.755
  STEP: Destroying namespace "webhook-markers-7441" for this suite. @ 07/11/24 07:00:01.762
• [3.548 seconds]
------------------------------
S
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 07/11/24 07:00:01.77
  I0711 07:00:01.770077 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename disruption @ 07/11/24 07:00:01.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:01.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:01.785
  STEP: Waiting for the pdb to be processed @ 07/11/24 07:00:01.792
  STEP: Updating PodDisruptionBudget status @ 07/11/24 07:00:01.797
  STEP: Waiting for all pods to be running @ 07/11/24 07:00:01.806
  I0711 07:00:01.812392 20 disruption.go:578] running pods: 0 < 1
  E0711 07:00:02.312212      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:03.312427      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 07/11/24 07:00:03.81
  STEP: Waiting for the pdb to be processed @ 07/11/24 07:00:03.822
  STEP: Patching PodDisruptionBudget status @ 07/11/24 07:00:03.83
  STEP: Waiting for the pdb to be processed @ 07/11/24 07:00:03.842
  I0711 07:00:03.846749 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5496" for this suite. @ 07/11/24 07:00:03.851
• [2.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 07/11/24 07:00:03.859
  I0711 07:00:03.859238 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 07:00:03.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:03.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:03.881
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 07/11/24 07:00:03.885
  E0711 07:00:04.313051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:05.313135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:06.313824      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:07.314011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:00:07.912
  I0711 07:00:07.916438 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-11059355-0408-47a3-9ab4-7c645381770d container test-container: <nil>
  STEP: delete the pod @ 07/11/24 07:00:07.935
  I0711 07:00:07.950738 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3089" for this suite. @ 07/11/24 07:00:07.954
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 07/11/24 07:00:07.962
  I0711 07:00:07.962328 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 07:00:07.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:07.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:07.98
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 07:00:07.982
  E0711 07:00:08.314175      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:09.314445      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:10.314904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:11.315075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:00:12.008
  I0711 07:00:12.012892 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod downwardapi-volume-1d56f198-9bfc-47a2-ad72-9b9088d3b7f5 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 07:00:12.02
  I0711 07:00:12.038576 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4181" for this suite. @ 07/11/24 07:00:12.041
• [4.087 seconds]
------------------------------
SSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 07/11/24 07:00:12.049
  I0711 07:00:12.049584 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 07/11/24 07:00:12.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:12.068
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:12.07
  STEP: Setting up the test @ 07/11/24 07:00:12.072
  STEP: Creating hostNetwork=false pod @ 07/11/24 07:00:12.072
  E0711 07:00:12.315799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:13.315995      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 07/11/24 07:00:14.119
  E0711 07:00:14.316101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:15.317140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:16.318135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:17.318297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 07/11/24 07:00:18.147
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 07/11/24 07:00:18.147
  I0711 07:00:18.147613 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.147631 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.148073 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.148110 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0711 07:00:18.195565 20 exec_util.go:106] Exec stderr: ""
  I0711 07:00:18.195621 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.195632 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.196191 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.196261 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0711 07:00:18.239298 20 exec_util.go:106] Exec stderr: ""
  I0711 07:00:18.239354 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.239362 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.239991 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.240073 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0711 07:00:18.287624 20 exec_util.go:106] Exec stderr: ""
  I0711 07:00:18.287858 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.287926 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.288415 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.288517 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  E0711 07:00:18.318902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:00:18.335258 20 exec_util.go:106] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 07/11/24 07:00:18.335
  I0711 07:00:18.335456 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.335526 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.336022 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.336077 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0711 07:00:18.387209 20 exec_util.go:106] Exec stderr: ""
  I0711 07:00:18.387263 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.387271 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.387843 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.387902 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0711 07:00:18.439119 20 exec_util.go:106] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 07/11/24 07:00:18.439
  I0711 07:00:18.439333 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.439421 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.439854 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.439917 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0711 07:00:18.487995 20 exec_util.go:106] Exec stderr: ""
  I0711 07:00:18.488092 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.488100 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.488502 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.488548 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0711 07:00:18.532041 20 exec_util.go:106] Exec stderr: ""
  I0711 07:00:18.532102 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.532111 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.532521 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.532567 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0711 07:00:18.580499 20 exec_util.go:106] Exec stderr: ""
  I0711 07:00:18.580716 20 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4843 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:00:18.580744 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:00:18.581230 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:00:18.581308 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4843/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0711 07:00:18.628158 20 exec_util.go:106] Exec stderr: ""
  I0711 07:00:18.628312 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-4843" for this suite. @ 07/11/24 07:00:18.633
• [6.591 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 07/11/24 07:00:18.64
  I0711 07:00:18.640610 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 07:00:18.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:18.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:18.659
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 07:00:18.661
  E0711 07:00:19.319118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:20.319540      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:21.320249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:22.321083      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:00:22.687
  I0711 07:00:22.690750 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-b689d7a0-a5d5-44f4-b76f-0e9ea3ae72e5 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 07:00:22.705
  I0711 07:00:22.727002 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5861" for this suite. @ 07/11/24 07:00:22.73
• [4.096 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1368
  STEP: Creating a kubernetes client @ 07/11/24 07:00:22.736
  I0711 07:00:22.736979 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 07:00:22.737
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:22.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:22.755
  STEP: validating cluster-info @ 07/11/24 07:00:22.758
  I0711 07:00:22.758978 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-9721 cluster-info'
  I0711 07:00:22.799787 20 builder.go:146] stderr: ""
  I0711 07:00:22.799846 20 builder.go:147] stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0711 07:00:22.800017 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9721" for this suite. @ 07/11/24 07:00:22.805
• [0.076 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1459
  STEP: Creating a kubernetes client @ 07/11/24 07:00:22.813
  I0711 07:00:22.813631 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 07:00:22.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:22.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:22.83
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1701 @ 07/11/24 07:00:22.833
  STEP: changing the ExternalName service to type=NodePort @ 07/11/24 07:00:22.839
  STEP: creating replication controller externalname-service in namespace services-1701 @ 07/11/24 07:00:22.859
  I0711 07:00:22.868940      20 runners.go:198] Created replication controller with name: externalname-service, namespace: services-1701, replica count: 2
  E0711 07:00:23.321992      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:24.322845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:25.323227      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:00:25.920246      20 runners.go:198] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0711 07:00:25.920294 20 resource.go:361] Creating new exec pod
  E0711 07:00:26.323474      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:27.323571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:28.324388      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:00:28.942920 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1701 exec execpodrbpvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0711 07:00:29.027124 20 builder.go:146] stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0711 07:00:29.027162 20 builder.go:147] stdout: "externalname-service-j7tm9"
  I0711 07:00:29.027269 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1701 exec execpodrbpvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.57 80'
  I0711 07:00:29.109704 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.57 80\nConnection to 10.152.183.57 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0711 07:00:29.109747 20 builder.go:147] stdout: ""
  E0711 07:00:29.325013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:00:30.027876 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1701 exec execpodrbpvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.57 80'
  I0711 07:00:30.114307 20 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.57 80\nConnection to 10.152.183.57 80 port [tcp/http] succeeded!\n"
  I0711 07:00:30.114353 20 builder.go:147] stdout: "externalname-service-j7tm9"
  I0711 07:00:30.114458 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1701 exec execpodrbpvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.11.2 30334'
  I0711 07:00:30.202776 20 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.11.2 30334\n+ echo hostName\nConnection to 172.31.11.2 30334 port [tcp/*] succeeded!\n"
  I0711 07:00:30.202823 20 builder.go:147] stdout: ""
  E0711 07:00:30.326006      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:00:31.115215 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1701 exec execpodrbpvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.11.2 30334'
  I0711 07:00:31.203517 20 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.11.2 30334\n+ echo hostName\nConnection to 172.31.11.2 30334 port [tcp/*] succeeded!\n"
  I0711 07:00:31.203556 20 builder.go:147] stdout: "externalname-service-j7tm9"
  I0711 07:00:31.203647 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1701 exec execpodrbpvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.17.237 30334'
  I0711 07:00:31.310176 20 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.17.237 30334\n+ echo hostName\nConnection to 172.31.17.237 30334 port [tcp/*] succeeded!\n"
  I0711 07:00:31.310215 20 builder.go:147] stdout: ""
  E0711 07:00:31.326400      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:00:32.203912 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-1701 exec execpodrbpvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.17.237 30334'
  I0711 07:00:32.290304 20 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.17.237 30334\n+ echo hostName\nConnection to 172.31.17.237 30334 port [tcp/*] succeeded!\n"
  I0711 07:00:32.290345 20 builder.go:147] stdout: "externalname-service-j7tm9"
  I0711 07:00:32.290492 20 service.go:1468] Cleaning up the ExternalName to NodePort test service
  I0711 07:00:32.318066 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1701" for this suite. @ 07/11/24 07:00:32.322
  E0711 07:00:32.327325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
• [9.517 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 07/11/24 07:00:32.33
  I0711 07:00:32.330789 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename subpath @ 07/11/24 07:00:32.331
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:32.343
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:32.345
  STEP: Setting up data @ 07/11/24 07:00:32.348
  STEP: Creating pod pod-subpath-test-downwardapi-dp28 @ 07/11/24 07:00:32.359
  STEP: Creating a pod to test atomic-volume-subpath @ 07/11/24 07:00:32.359
  E0711 07:00:33.327512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:34.327716      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:35.327972      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:36.328429      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:37.328561      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:38.328666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:39.328771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:40.329248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:41.329870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:42.330177      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:43.330519      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:44.330651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:45.330945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:46.331535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:47.331573      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:48.332042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:49.332376      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:50.332474      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:51.333303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:52.333471      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:53.334557      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:54.334865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:55.335121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:56.335902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:00:56.439
  I0711 07:00:56.443444 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-subpath-test-downwardapi-dp28 container test-container-subpath-downwardapi-dp28: <nil>
  STEP: delete the pod @ 07/11/24 07:00:56.449
  STEP: Deleting pod pod-subpath-test-downwardapi-dp28 @ 07/11/24 07:00:56.465
  I0711 07:00:56.465712 20 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-dp28" in namespace "subpath-4973"
  I0711 07:00:56.470223 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4973" for this suite. @ 07/11/24 07:00:56.474
• [24.150 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 07/11/24 07:00:56.48
  I0711 07:00:56.480794 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename field-validation @ 07/11/24 07:00:56.481
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:56.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:56.501
  I0711 07:00:56.503140 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:00:57.335991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:58.336024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:00:59.336651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:00:59.585001 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5644" for this suite. @ 07/11/24 07:00:59.589
• [3.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 07/11/24 07:00:59.599
  I0711 07:00:59.599989 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 07:00:59.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:00:59.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:00:59.618
  STEP: creating the pod @ 07/11/24 07:00:59.62
  STEP: submitting the pod to kubernetes @ 07/11/24 07:00:59.62
  E0711 07:01:00.337264      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:01.337303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 07/11/24 07:01:01.644
  STEP: updating the pod @ 07/11/24 07:01:01.648
  I0711 07:01:02.163028 20 pod_client.go:141] Successfully updated pod "pod-update-9bbfa79c-c7c4-4432-8a18-7009c810ca65"
  STEP: verifying the updated pod is in kubernetes @ 07/11/24 07:01:02.166
  I0711 07:01:02.170256 20 pods.go:391] Pod update OK
  I0711 07:01:02.170396 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6692" for this suite. @ 07/11/24 07:01:02.173
• [2.583 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 07/11/24 07:01:02.183
  I0711 07:01:02.183474 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 07:01:02.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:02.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:02.199
  STEP: Creating configMap with name projected-configmap-test-volume-map-b5fc0e4e-bcf0-4a3d-ab77-053764e1131e @ 07/11/24 07:01:02.202
  STEP: Creating a pod to test consume configMaps @ 07/11/24 07:01:02.208
  E0711 07:01:02.338165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:03.338300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:04.339009      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:05.339127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:01:06.232
  I0711 07:01:06.235924 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-configmaps-8528f27b-fd6f-4f20-a0a6-68b025d9bda9 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 07:01:06.243
  I0711 07:01:06.267830 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7892" for this suite. @ 07/11/24 07:01:06.271
• [4.097 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:443
  STEP: Creating a kubernetes client @ 07/11/24 07:01:06.28
  I0711 07:01:06.280830 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-publish-openapi @ 07/11/24 07:01:06.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:06.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:06.296
  STEP: set up a multi version CRD @ 07/11/24 07:01:06.298
  I0711 07:01:06.299241 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:01:06.339901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:07.340249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:08.340584      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:09.340620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 07/11/24 07:01:09.407
  STEP: check the unserved version gets removed @ 07/11/24 07:01:09.424
  STEP: check the other version is not changed @ 07/11/24 07:01:10.174
  E0711 07:01:10.341056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:11.341261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:12.341951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:12.606944 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1237" for this suite. @ 07/11/24 07:01:12.612
• [6.340 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 07/11/24 07:01:12.62
  I0711 07:01:12.620934 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 07:01:12.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:12.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:12.638
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 07:01:12.64
  E0711 07:01:13.342124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:14.342398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:15.342481      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:16.343024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:01:16.665
  I0711 07:01:16.668690 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-906756f8-2ec5-4cc0-b66d-9747b4cf3553 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 07:01:16.676
  I0711 07:01:16.695510 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5649" for this suite. @ 07/11/24 07:01:16.7
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 07/11/24 07:01:16.707
  I0711 07:01:16.707695 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename endpointslice @ 07/11/24 07:01:16.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:16.723
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:16.726
  E0711 07:01:17.343115      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:18.343386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 07/11/24 07:01:18.803
  STEP: referencing matching pods with named port @ 07/11/24 07:01:18.81
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 07/11/24 07:01:18.817
  STEP: recreating EndpointSlices after they've been deleted @ 07/11/24 07:01:18.824
  I0711 07:01:18.847492 20 endpointslice.go:938] EndpointSlice for Service endpointslice-9055/example-named-port not found
  E0711 07:01:19.344206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:20.344274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:20.853123 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9055" for this suite. @ 07/11/24 07:01:20.857
• [4.158 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 07/11/24 07:01:20.868
  I0711 07:01:20.868266 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename custom-resource-definition @ 07/11/24 07:01:20.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:20.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:20.893
  I0711 07:01:20.895954 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:01:21.344944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:22.345808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:23.345880      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:23.979175 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1661" for this suite. @ 07/11/24 07:01:23.984
• [3.125 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 07/11/24 07:01:23.993
  I0711 07:01:23.993287 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 07:01:23.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:24.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:24.01
  STEP: Creating secret with name secret-test-53176622-08af-4a2f-85a2-b9ebc8721bca @ 07/11/24 07:01:24.013
  STEP: Creating a pod to test consume secrets @ 07/11/24 07:01:24.017
  E0711 07:01:24.346102      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:25.346228      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:26.347029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:27.347224      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:01:28.044
  I0711 07:01:28.048038 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-secrets-af7c47a0-8935-45dd-8567-8ce73ce59cd6 container secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 07:01:28.055
  I0711 07:01:28.072307 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2219" for this suite. @ 07/11/24 07:01:28.075
• [4.090 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 07/11/24 07:01:28.083
  I0711 07:01:28.083506 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 07/11/24 07:01:28.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:28.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:28.103
  STEP: creating a target pod @ 07/11/24 07:01:28.105
  E0711 07:01:28.347859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:29.347925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 07/11/24 07:01:30.128
  E0711 07:01:30.348798      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:31.349123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 07/11/24 07:01:32.149
  I0711 07:01:32.149356 20 exec_util.go:55] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-7584 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:01:32.149374 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:01:32.149878 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:01:32.149911 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-7584/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0711 07:01:32.191669 20 exec_util.go:106] Exec stderr: ""
  I0711 07:01:32.200147 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-7584" for this suite. @ 07/11/24 07:01:32.203
• [4.127 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 07/11/24 07:01:32.211
  I0711 07:01:32.211089 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 07:01:32.211
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:32.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:32.229
  STEP: Setting up server cert @ 07/11/24 07:01:32.253
  E0711 07:01:32.349376      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 07:01:32.456
  STEP: Deploying the webhook pod @ 07/11/24 07:01:32.465
  STEP: Wait for the deployment to be ready @ 07/11/24 07:01:32.48
  I0711 07:01:32.493627 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 07:01:33.349500      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:34.349726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 07:01:34.507
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 07:01:34.518
  E0711 07:01:35.350254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:35.518641 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0711 07:01:35.525838 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8260-crds.webhook.example.com via the AdmissionRegistration API @ 07/11/24 07:01:36.037
  STEP: Creating a custom resource that should be mutated by the webhook @ 07/11/24 07:01:36.05
  E0711 07:01:36.350327      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:37.350507      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:38.351512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:38.652486 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9262" for this suite. @ 07/11/24 07:01:38.656
  STEP: Destroying namespace "webhook-markers-6284" for this suite. @ 07/11/24 07:01:38.663
• [6.461 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 07/11/24 07:01:38.672
  I0711 07:01:38.672257 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 07:01:38.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:38.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:38.691
  STEP: Creating secret with name projected-secret-test-9736c075-39f8-4a3a-b0c0-b3528c8268be @ 07/11/24 07:01:38.694
  STEP: Creating a pod to test consume secrets @ 07/11/24 07:01:38.699
  E0711 07:01:39.351991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:40.352409      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:41.353002      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:42.353792      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:01:42.725
  I0711 07:01:42.730339 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-secrets-a091e014-fb42-411d-b27e-cdadd4a02236 container secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 07:01:42.736
  I0711 07:01:42.752331 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9457" for this suite. @ 07/11/24 07:01:42.756
• [4.092 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 07/11/24 07:01:42.764
  I0711 07:01:42.764154 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 07:01:42.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:42.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:42.781
  STEP: creating a Pod with a static label @ 07/11/24 07:01:42.79
  STEP: watching for Pod to be ready @ 07/11/24 07:01:42.798
  I0711 07:01:42.799446 20 pods.go:945] observed Pod pod-test in namespace pods-3634 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0711 07:01:42.803279 20 pods.go:945] observed Pod pod-test in namespace pods-3634 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:42 +0000 UTC  }]
  I0711 07:01:42.823577 20 pods.go:945] observed Pod pod-test in namespace pods-3634 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:42 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:42 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:42 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:42 +0000 UTC  }]
  E0711 07:01:43.354171      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:43.756157 20 pods.go:948] Found Pod pod-test in namespace pods-3634 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:43 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-07-11 07:01:42 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 07/11/24 07:01:43.76
  STEP: getting the Pod and ensuring that it's patched @ 07/11/24 07:01:43.769
  STEP: replacing the Pod's status Ready condition to False @ 07/11/24 07:01:43.776
  STEP: check the Pod again to ensure its Ready conditions are False @ 07/11/24 07:01:43.785
  STEP: deleting the Pod via a Collection with a LabelSelector @ 07/11/24 07:01:43.785
  STEP: watching for the Pod to be deleted @ 07/11/24 07:01:43.799
  I0711 07:01:43.801237 20 pods.go:1058] observed event type MODIFIED
  E0711 07:01:44.354833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:45.281545 20 pods.go:1058] observed event type MODIFIED
  E0711 07:01:45.355859      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:45.765988 20 pods.go:1058] observed event type MODIFIED
  I0711 07:01:45.928217 20 pods.go:1058] observed event type MODIFIED
  E0711 07:01:46.355931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:46.763395 20 pods.go:1058] observed event type MODIFIED
  I0711 07:01:46.788265 20 pods.go:1058] observed event type MODIFIED
  I0711 07:01:46.800756 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3634" for this suite. @ 07/11/24 07:01:46.804
• [4.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 07/11/24 07:01:46.813
  I0711 07:01:46.813984 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 07:01:46.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:46.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:46.831
  STEP: Creating configMap that has name configmap-test-emptyKey-0b87b46d-834d-4a91-8b7a-94afac16f4a4 @ 07/11/24 07:01:46.833
  I0711 07:01:46.835307 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1045" for this suite. @ 07/11/24 07:01:46.838
• [0.032 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 07/11/24 07:01:46.846
  I0711 07:01:46.846242 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 07:01:46.846
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:01:46.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:01:46.863
  STEP: Setting up server cert @ 07/11/24 07:01:46.887
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 07:01:47.063
  STEP: Deploying the webhook pod @ 07/11/24 07:01:47.069
  STEP: Wait for the deployment to be ready @ 07/11/24 07:01:47.083
  I0711 07:01:47.094525 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 07:01:47.356979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:48.357615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 07:01:49.108
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 07:01:49.118
  E0711 07:01:49.358276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:01:50.119057 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 07/11/24 07:01:50.128
  STEP: Registering slow webhook via the AdmissionRegistration API @ 07/11/24 07:01:50.128
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 07/11/24 07:01:50.14
  E0711 07:01:50.358370      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 07/11/24 07:01:51.151
  STEP: Registering slow webhook via the AdmissionRegistration API @ 07/11/24 07:01:51.151
  E0711 07:01:51.358598      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 07/11/24 07:01:52.184
  STEP: Registering slow webhook via the AdmissionRegistration API @ 07/11/24 07:01:52.184
  E0711 07:01:52.358976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:53.359246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:54.359316      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:55.359521      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:56.360121      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 07/11/24 07:01:57.22
  STEP: Registering slow webhook via the AdmissionRegistration API @ 07/11/24 07:01:57.22
  E0711 07:01:57.360217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:58.360315      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:01:59.360373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:00.360481      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:01.361035      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:02:02.314828 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8667" for this suite. @ 07/11/24 07:02:02.318
  STEP: Destroying namespace "webhook-markers-8042" for this suite. @ 07/11/24 07:02:02.326
• [15.487 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 07/11/24 07:02:02.333
  I0711 07:02:02.333264 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 07:02:02.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:02:02.348
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:02:02.351
  STEP: Creating Pod @ 07/11/24 07:02:02.353
  E0711 07:02:02.362075      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:03.362254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:04.362308      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 07/11/24 07:02:04.372
  I0711 07:02:04.372330 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6515 PodName:pod-sharedvolume-a92c336a-8991-4070-b876-40c4792f64f7 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:02:04.372349 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:02:04.372789 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:02:04.372833 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-6515/pods/pod-sharedvolume-a92c336a-8991-4070-b876-40c4792f64f7/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  I0711 07:02:04.424696 20 exec_util.go:106] Exec stderr: ""
  I0711 07:02:04.424810 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6515" for this suite. @ 07/11/24 07:02:04.429
• [2.104 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 07/11/24 07:02:04.437
  I0711 07:02:04.437066 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl-logs @ 07/11/24 07:02:04.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:02:04.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:02:04.454
  STEP: creating an pod @ 07/11/24 07:02:04.457
  I0711 07:02:04.457292 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-logs-5461 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I0711 07:02:04.507013 20 builder.go:146] stderr: ""
  I0711 07:02:04.507057 20 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 07/11/24 07:02:04.507
  I0711 07:02:04.507148 20 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0711 07:02:05.363260      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:06.364042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:02:06.517235 20 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 07/11/24 07:02:06.517
  I0711 07:02:06.517597 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-logs-5461 logs logs-generator logs-generator'
  I0711 07:02:06.570814 20 builder.go:146] stderr: ""
  I0711 07:02:06.570857 20 builder.go:147] stdout: "I0711 07:02:05.057448       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/x8ns 317\nI0711 07:02:05.257534       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/z7m8 243\nI0711 07:02:05.458094       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/s4t 269\nI0711 07:02:05.658404       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/rhxj 268\nI0711 07:02:05.857528       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/b6d 557\nI0711 07:02:06.057837       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/68tq 200\nI0711 07:02:06.258149       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/9rd9 462\nI0711 07:02:06.458510       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/xsn 393\n"
  STEP: limiting log lines @ 07/11/24 07:02:06.57
  I0711 07:02:06.571011 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-logs-5461 logs logs-generator logs-generator --tail=1'
  I0711 07:02:06.618860 20 builder.go:146] stderr: ""
  I0711 07:02:06.618908 20 builder.go:147] stdout: "I0711 07:02:06.458510       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/xsn 393\n"
  I0711 07:02:06.618918 20 logs.go:127] got output "I0711 07:02:06.458510       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/xsn 393\n"
  STEP: limiting log bytes @ 07/11/24 07:02:06.618
  I0711 07:02:06.618993 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-logs-5461 logs logs-generator logs-generator --limit-bytes=1'
  I0711 07:02:06.669243 20 builder.go:146] stderr: ""
  I0711 07:02:06.669290 20 builder.go:147] stdout: "I"
  I0711 07:02:06.669299 20 logs.go:133] got output "I"
  STEP: exposing timestamps @ 07/11/24 07:02:06.669
  I0711 07:02:06.669546 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-logs-5461 logs logs-generator logs-generator --tail=1 --timestamps'
  I0711 07:02:06.742731 20 builder.go:146] stderr: ""
  I0711 07:02:06.742775 20 builder.go:147] stdout: "2024-07-11T07:02:06.657958048Z I0711 07:02:06.657843       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/4mvd 445\n"
  I0711 07:02:06.742785 20 logs.go:139] got output "2024-07-11T07:02:06.657958048Z I0711 07:02:06.657843       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/4mvd 445\n"
  STEP: restricting to a time range @ 07/11/24 07:02:06.742
  E0711 07:02:07.365044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:08.365120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:02:09.242988 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-logs-5461 logs logs-generator logs-generator --since=1s'
  I0711 07:02:09.293008 20 builder.go:146] stderr: ""
  I0711 07:02:09.293063 20 builder.go:147] stdout: "I0711 07:02:08.457672       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/cg55 580\nI0711 07:02:08.658014       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/dnpb 460\nI0711 07:02:08.858355       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/tvf 258\nI0711 07:02:09.057715       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/zht 220\nI0711 07:02:09.258118       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/6ptx 344\n"
  I0711 07:02:09.293116 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-logs-5461 logs logs-generator logs-generator --since=24h'
  I0711 07:02:09.342710 20 builder.go:146] stderr: ""
  I0711 07:02:09.342765 20 builder.go:147] stdout: "I0711 07:02:05.057448       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/x8ns 317\nI0711 07:02:05.257534       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/z7m8 243\nI0711 07:02:05.458094       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/s4t 269\nI0711 07:02:05.658404       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/rhxj 268\nI0711 07:02:05.857528       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/b6d 557\nI0711 07:02:06.057837       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/68tq 200\nI0711 07:02:06.258149       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/9rd9 462\nI0711 07:02:06.458510       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/xsn 393\nI0711 07:02:06.657843       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/4mvd 445\nI0711 07:02:06.858130       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/sk6 260\nI0711 07:02:07.058444       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/x8x 589\nI0711 07:02:07.257747       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/tpq 450\nI0711 07:02:07.458057       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/mp2x 347\nI0711 07:02:07.658352       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/8lh 572\nI0711 07:02:07.857746       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/k2k 412\nI0711 07:02:08.058056       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/t4kh 268\nI0711 07:02:08.258361       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/jr47 398\nI0711 07:02:08.457672       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/cg55 580\nI0711 07:02:08.658014       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/dnpb 460\nI0711 07:02:08.858355       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/tvf 258\nI0711 07:02:09.057715       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/zht 220\nI0711 07:02:09.258118       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/6ptx 344\n"
  I0711 07:02:09.342918 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-logs-5461 delete pod logs-generator'
  E0711 07:02:09.365936      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:02:09.951047 20 builder.go:146] stderr: ""
  I0711 07:02:09.951091 20 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I0711 07:02:09.951258 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-5461" for this suite. @ 07/11/24 07:02:09.954
• [5.526 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 07/11/24 07:02:09.964
  I0711 07:02:09.964029 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 07:02:09.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:02:09.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:02:09.982
  STEP: Creating a ResourceQuota @ 07/11/24 07:02:09.984
  STEP: Getting a ResourceQuota @ 07/11/24 07:02:09.989
  STEP: Listing all ResourceQuotas with LabelSelector @ 07/11/24 07:02:09.994
  STEP: Patching the ResourceQuota @ 07/11/24 07:02:09.998
  STEP: Deleting a Collection of ResourceQuotas @ 07/11/24 07:02:10.004
  STEP: Verifying the deleted ResourceQuota @ 07/11/24 07:02:10.014
  I0711 07:02:10.018198 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2848" for this suite. @ 07/11/24 07:02:10.021
• [0.065 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 07/11/24 07:02:10.029
  I0711 07:02:10.029510 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 07:02:10.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:02:10.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:02:10.053
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 07/11/24 07:02:10.055
  E0711 07:02:10.366468      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:11.367535      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:12.367884      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:13.367982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:02:14.079
  I0711 07:02:14.084124 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-1118273a-3085-42c3-81bf-576a2743fbff container test-container: <nil>
  STEP: delete the pod @ 07/11/24 07:02:14.092
  I0711 07:02:14.108319 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8712" for this suite. @ 07/11/24 07:02:14.113
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 07/11/24 07:02:14.12
  I0711 07:02:14.120888 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 07:02:14.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:02:14.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:02:14.138
  STEP: Creating configMap with name configmap-test-upd-58f9d0cd-dda8-4f19-9615-cd539c2db976 @ 07/11/24 07:02:14.144
  STEP: Creating the pod @ 07/11/24 07:02:14.149
  E0711 07:02:14.369046      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:15.369346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-58f9d0cd-dda8-4f19-9615-cd539c2db976 @ 07/11/24 07:02:16.18
  STEP: waiting to observe update in volume @ 07/11/24 07:02:16.185
  E0711 07:02:16.369360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:17.369578      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:18.369666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:19.370297      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:20.370644      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:21.371165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:22.371753      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:23.372631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:24.373363      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:25.373520      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:26.374559      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:27.374724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:28.375189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:29.375443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:30.376202      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:31.376399      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:32.377188      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:33.377402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:34.378027      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:35.378688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:36.379667      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:37.379865      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:38.380577      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:39.381069      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:40.381372      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:41.382406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:42.382984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:43.383133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:44.383516      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:45.383635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:46.384153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:47.384260      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:48.384955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:49.385174      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:50.385515      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:51.386503      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:52.387037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:53.387398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:54.387976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:55.388099      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:56.389138      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:57.389375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:58.389776      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:02:59.389949      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:00.390556      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:01.391591      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:02.391877      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:03.391983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:04.392087      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:05.392422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:06.392929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:07.393047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:08.393443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:09.394032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:10.394325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:11.394548      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:12.394862      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:13.395072      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:14.395168      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:15.395448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:16.396128      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:17.397058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:18.397154      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:19.397277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:20.397576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:21.398347      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:22.398561      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:23.398837      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:24.399212      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:25.399278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:26.399873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:27.400088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:28.401066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:29.401511      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:30.401612      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:31.401708      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:32.401809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:33.401993      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:34.402064      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:35.402944      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:36.403422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:37.403976      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:38.405022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:39.405742      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:40.406306      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:41.406921      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:42.407017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:43.407111      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:44.408070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:03:44.595458 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8171" for this suite. @ 07/11/24 07:03:44.6
• [90.487 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 07/11/24 07:03:44.608
  I0711 07:03:44.608237 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-pred @ 07/11/24 07:03:44.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:03:44.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:03:44.624
  I0711 07:03:44.627282 20 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0711 07:03:44.634115 20 util.go:400] Waiting for terminating namespaces to be deleted...
  I0711 07:03:44.637488 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-11-2 before test
  I0711 07:03:44.643691 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-vst4d from ingress-nginx-kubernetes-worker started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.643706 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 07:03:44.643712 20 predicates.go:887] calico-node-9r7js from kube-system started at 2024-07-11 05:31:26 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.643717 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 07:03:44.643723 20 predicates.go:887] coredns-5c6d979c47-sb7z6 from kube-system started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.643727 20 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0711 07:03:44.643743 20 predicates.go:887] kube-state-metrics-77cc559b76-46cmg from kube-system started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.643747 20 predicates.go:889] 	Container kube-state-metrics ready: true, restart count 1
  I0711 07:03:44.643752 20 predicates.go:887] metrics-server-v0.7.0-7995f698bf-5zlw4 from kube-system started at 2024-07-11 05:25:49 +0000 UTC (2 container statuses recorded)
  I0711 07:03:44.643756 20 predicates.go:889] 	Container metrics-server ready: true, restart count 0
  I0711 07:03:44.643769 20 predicates.go:889] 	Container metrics-server-nanny ready: true, restart count 0
  I0711 07:03:44.643781 20 predicates.go:887] dashboard-metrics-scraper-55584b484c-j4mdq from kubernetes-dashboard started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.643785 20 predicates.go:889] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I0711 07:03:44.643792 20 predicates.go:887] kubernetes-dashboard-6fd7bf4447-4xclp from kubernetes-dashboard started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.643797 20 predicates.go:889] 	Container kubernetes-dashboard ready: true, restart count 1
  I0711 07:03:44.643850 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-fccgk from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 07:03:44.643854 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 07:03:44.643859 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0711 07:03:44.643863 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-17-237 before test
  I0711 07:03:44.651425 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-7fjdd from ingress-nginx-kubernetes-worker started at 2024-07-11 05:31:54 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.651441 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 07:03:44.651448 20 predicates.go:887] calico-node-795zl from kube-system started at 2024-07-11 05:31:35 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.651577 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 07:03:44.651586 20 predicates.go:887] sonobuoy-e2e-job-46eff94557cb4446 from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 07:03:44.651630 20 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0711 07:03:44.651659 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 07:03:44.651672 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-ll2lq from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 07:03:44.651677 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 07:03:44.651682 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0711 07:03:44.651688 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-80-240 before test
  I0711 07:03:44.657588 20 predicates.go:887] pod-configmaps-8ca34762-f4ba-4f5b-80d4-7ea3acfee95b from configmap-8171 started at 2024-07-11 07:02:14 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.657605 20 predicates.go:889] 	Container agnhost-container ready: true, restart count 0
  I0711 07:03:44.657613 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-w7fxm from ingress-nginx-kubernetes-worker started at 2024-07-11 06:25:51 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.657620 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 07:03:44.657626 20 predicates.go:887] calico-node-fcrzw from kube-system started at 2024-07-11 05:32:46 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.657631 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 07:03:44.657637 20 predicates.go:887] sonobuoy from sonobuoy started at 2024-07-11 05:34:19 +0000 UTC (1 container statuses recorded)
  I0711 07:03:44.657658 20 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0711 07:03:44.657663 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-9fdzf from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 07:03:44.657676 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 07:03:44.657683 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 07/11/24 07:03:44.657
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17e116a3a1c0453f], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] @ 07/11/24 07:03:44.694
  E0711 07:03:45.409044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:03:45.686478 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-324" for this suite. @ 07/11/24 07:03:45.691
• [1.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 07/11/24 07:03:45.698
  I0711 07:03:45.698663 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename svcaccounts @ 07/11/24 07:03:45.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:03:45.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:03:45.717
  E0711 07:03:46.409147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:47.409527      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 07/11/24 07:03:47.742
  I0711 07:03:47.742353 20 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4825 pod-service-account-cc853281-49fa-4900-99c5-5138e53f86d2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 07/11/24 07:03:47.829
  I0711 07:03:47.830037 20 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4825 pod-service-account-cc853281-49fa-4900-99c5-5138e53f86d2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 07/11/24 07:03:47.917
  I0711 07:03:47.917647 20 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4825 pod-service-account-cc853281-49fa-4900-99c5-5138e53f86d2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I0711 07:03:48.010706 20 service_accounts.go:114] Got root ca configmap in namespace "svcaccounts-4825"
  I0711 07:03:48.012529 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4825" for this suite. @ 07/11/24 07:03:48.016
• [2.325 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 07/11/24 07:03:48.024
  I0711 07:03:48.024425 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename svcaccounts @ 07/11/24 07:03:48.024
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:03:48.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:03:48.044
  I0711 07:03:48.062318 20 service_accounts.go:618] created pod
  E0711 07:03:48.410345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:49.410444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:50.410523      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:51.411428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:03:52.079
  E0711 07:03:52.412209      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:53.412375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:54.413349      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:55.413558      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:56.414246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:57.414524      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:58.414781      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:03:59.414981      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:00.415217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:01.415374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:02.415475      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:03.415577      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:04.415767      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:05.416021      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:06.416383      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:07.417025      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:08.417239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:09.417374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:10.417486      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:11.418185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:12.418451      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:13.418655      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:14.418842      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:15.419095      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:16.419952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:17.420032      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:18.421023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:19.421116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:20.421327      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:21.421421      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:22.079991 20 service_accounts.go:624] polling logs
  I0711 07:04:22.087707 20 service_accounts.go:634] Pod logs: 
  I0711 07:03:48.619270       1 log.go:245] OK: Got token
  I0711 07:03:48.619311       1 log.go:245] validating with in-cluster discovery
  I0711 07:03:48.619507       1 log.go:245] OK: got issuer https://kubernetes.default.svc
  I0711 07:03:48.619528       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1833:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0002a5900), NotBefore:(*jwt.NumericDate)(0xc0002a59f0), IssuedAt:(*jwt.NumericDate)(0xc0002a5910), ID:"f4f2898a-8df5-437f-8ed2-6e964e98c026"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1833", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"71970d87-ae44-4889-b4d4-f4ed53e80bb5"}}}
  I0711 07:03:48.625787       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I0711 07:03:48.628586       1 log.go:245] OK: Validated signature on JWT
  I0711 07:03:48.628641       1 log.go:245] OK: Got valid claims from token!
  I0711 07:03:48.628664       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1833:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000012bb0), NotBefore:(*jwt.NumericDate)(0xc000012c18), IssuedAt:(*jwt.NumericDate)(0xc000012bb8), ID:"f4f2898a-8df5-437f-8ed2-6e964e98c026"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1833", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"71970d87-ae44-4889-b4d4-f4ed53e80bb5"}}}

  I0711 07:04:22.087761 20 service_accounts.go:638] completed pod
  I0711 07:04:22.094537 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1833" for this suite. @ 07/11/24 07:04:22.098
• [34.082 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:154
  STEP: Creating a kubernetes client @ 07/11/24 07:04:22.106
  I0711 07:04:22.106716 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-publish-openapi @ 07/11/24 07:04:22.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:22.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:22.125
  I0711 07:04:22.128063 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:04:22.422338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 07/11/24 07:04:23.383
  I0711 07:04:23.383538 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-5228 --namespace=crd-publish-openapi-5228 create -f -'
  E0711 07:04:23.423065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:24.423438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:25.423683      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:25.445897 20 builder.go:146] stderr: ""
  I0711 07:04:25.445934 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2215-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0711 07:04:25.446021 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-5228 --namespace=crd-publish-openapi-5228 delete e2e-test-crd-publish-openapi-2215-crds test-cr'
  I0711 07:04:25.495192 20 builder.go:146] stderr: ""
  I0711 07:04:25.495228 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2215-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I0711 07:04:25.495269 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-5228 --namespace=crd-publish-openapi-5228 apply -f -'
  I0711 07:04:25.559097 20 builder.go:146] stderr: ""
  I0711 07:04:25.559141 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2215-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0711 07:04:25.559186 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-5228 --namespace=crd-publish-openapi-5228 delete e2e-test-crd-publish-openapi-2215-crds test-cr'
  I0711 07:04:25.607525 20 builder.go:146] stderr: ""
  I0711 07:04:25.607572 20 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2215-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 07/11/24 07:04:25.607
  I0711 07:04:25.607654 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=crd-publish-openapi-5228 explain e2e-test-crd-publish-openapi-2215-crds'
  I0711 07:04:25.647561 20 builder.go:146] stderr: ""
  I0711 07:04:25.647606 20 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-2215-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0711 07:04:26.424646      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:26.948484 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5228" for this suite. @ 07/11/24 07:04:26.962
• [4.865 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1079
  STEP: Creating a kubernetes client @ 07/11/24 07:04:26.971
  I0711 07:04:26.971471 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 07:04:26.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:26.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:26.995
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 07/11/24 07:04:26.998
  I0711 07:04:26.998936 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-6061 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0711 07:04:27.047195 20 builder.go:146] stderr: ""
  I0711 07:04:27.047241 20 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 07/11/24 07:04:27.047
  I0711 07:04:27.047312 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-6061 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I0711 07:04:27.092115 20 builder.go:146] stderr: ""
  I0711 07:04:27.092159 20 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 07/11/24 07:04:27.092
  I0711 07:04:27.096664 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-6061 delete pods e2e-test-httpd-pod'
  E0711 07:04:27.424694      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:28.424950      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:29.070212 20 builder.go:146] stderr: ""
  I0711 07:04:29.070249 20 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0711 07:04:29.070339 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6061" for this suite. @ 07/11/24 07:04:29.074
• [2.109 seconds]
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 07/11/24 07:04:29.08
  I0711 07:04:29.080663 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 07:04:29.081
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:29.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:29.103
  STEP: creating the pod @ 07/11/24 07:04:29.105
  STEP: setting up watch @ 07/11/24 07:04:29.105
  STEP: submitting the pod to kubernetes @ 07/11/24 07:04:29.209
  STEP: verifying the pod is in kubernetes @ 07/11/24 07:04:29.22
  STEP: verifying pod creation was observed @ 07/11/24 07:04:29.225
  E0711 07:04:29.426014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:30.426991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 07/11/24 07:04:31.24
  STEP: verifying pod deletion was observed @ 07/11/24 07:04:31.25
  E0711 07:04:31.427145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:32.083086 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1940" for this suite. @ 07/11/24 07:04:32.086
• [3.013 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
  STEP: Creating a kubernetes client @ 07/11/24 07:04:32.093
  I0711 07:04:32.093592 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 07:04:32.094
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:32.113
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:32.115
  I0711 07:04:32.118477 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-817 version'
  I0711 07:04:32.154074 20 builder.go:146] stderr: ""
  I0711 07:04:32.154109 20 builder.go:147] stdout: "Client Version: v1.30.2\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.30.2\n"
  I0711 07:04:32.154345 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-817" for this suite. @ 07/11/24 07:04:32.158
• [0.072 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 07/11/24 07:04:32.165
  I0711 07:04:32.165468 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 07:04:32.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:32.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:32.187
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 07/11/24 07:04:32.19
  E0711 07:04:32.428119      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:33.428198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:04:34.21
  I0711 07:04:34.213430 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-20b8a82d-1aa2-41aa-b401-4f1523bdef70 container test-container: <nil>
  STEP: delete the pod @ 07/11/24 07:04:34.223
  I0711 07:04:34.242354 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5071" for this suite. @ 07/11/24 07:04:34.245
• [2.088 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 07/11/24 07:04:34.253
  I0711 07:04:34.253605 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename init-container @ 07/11/24 07:04:34.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:34.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:34.276
  STEP: creating the pod @ 07/11/24 07:04:34.278
  I0711 07:04:34.279080 20 init_container.go:294] PodSpec: initContainers in spec.initContainers
  E0711 07:04:34.428651      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:35.429531      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:36.429648      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:37.070756 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-462" for this suite. @ 07/11/24 07:04:37.076
• [2.829 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 07/11/24 07:04:37.083
  I0711 07:04:37.083256 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 07:04:37.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:37.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:37.108
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 07/11/24 07:04:37.11
  E0711 07:04:37.433381      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:38.433489      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:04:39.129
  I0711 07:04:39.132721 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-56c4d5b2-f72c-4145-a5cf-9fb1beab463c container test-container: <nil>
  STEP: delete the pod @ 07/11/24 07:04:39.144
  I0711 07:04:39.162838 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8450" for this suite. @ 07/11/24 07:04:39.166
• [2.092 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 07/11/24 07:04:39.175
  I0711 07:04:39.175466 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 07:04:39.176
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:39.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:39.195
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 07:04:39.198
  E0711 07:04:39.433622      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:40.433853      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:04:41.218
  I0711 07:04:41.223070 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod downwardapi-volume-35979cd6-a971-45bc-93df-7c60f9bde08a container client-container: <nil>
  STEP: delete the pod @ 07/11/24 07:04:41.23
  I0711 07:04:41.248690 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5513" for this suite. @ 07/11/24 07:04:41.252
• [2.085 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 07/11/24 07:04:41.26
  I0711 07:04:41.260205 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 07:04:41.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:41.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:41.278
  STEP: Creating projection with secret that has name projected-secret-test-map-168e85c9-6b4d-4575-89b5-e88ed9cd03a3 @ 07/11/24 07:04:41.281
  STEP: Creating a pod to test consume secrets @ 07/11/24 07:04:41.285
  E0711 07:04:41.434447      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:42.434596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:43.434886      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:44.434984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:04:45.31
  I0711 07:04:45.314768 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-projected-secrets-c4de9963-1614-4f65-a7af-51ea10af56df container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 07:04:45.321
  I0711 07:04:45.336467 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-132" for this suite. @ 07/11/24 07:04:45.34
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 07/11/24 07:04:45.347
  I0711 07:04:45.347346 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 07:04:45.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:45.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:45.37
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 07/11/24 07:04:45.373
  E0711 07:04:45.435490      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:46.436041      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:04:47.391
  I0711 07:04:47.395092 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-cdd99a5e-ba43-4dc6-98d3-3947962885d3 container test-container: <nil>
  STEP: delete the pod @ 07/11/24 07:04:47.401
  I0711 07:04:47.419949 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5648" for this suite. @ 07/11/24 07:04:47.423
• [2.083 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 07/11/24 07:04:47.43
  I0711 07:04:47.430194 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename daemonsets @ 07/11/24 07:04:47.43
  E0711 07:04:47.436062      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:47.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:47.451
  STEP: Creating simple DaemonSet "daemon-set" @ 07/11/24 07:04:47.473
  STEP: Check that daemon pods launch on every node of the cluster. @ 07/11/24 07:04:47.478
  I0711 07:04:47.481100 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:47.481138 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:47.484633 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 07:04:47.484654 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  E0711 07:04:48.436222      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:48.483781 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:48.483856 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:48.488613 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0711 07:04:48.488638 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  E0711 07:04:49.437158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:49.483313 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:49.483361 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:49.487923 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0711 07:04:49.487944 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 07/11/24 07:04:49.491
  I0711 07:04:49.509037 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:49.509073 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:49.512435 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0711 07:04:49.512454 20 fixtures.go:130] Node ip-172-31-80-240 is running 0 daemon pod, expected 1
  E0711 07:04:50.437265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:50.509891 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:50.509934 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:50.513270 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0711 07:04:50.513300 20 fixtures.go:130] Node ip-172-31-80-240 is running 0 daemon pod, expected 1
  E0711 07:04:51.437469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:51.510510 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:51.517374 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:04:51.521169 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0711 07:04:51.521192 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 07/11/24 07:04:51.525
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2007, will wait for the garbage collector to delete the pods @ 07/11/24 07:04:51.525
  I0711 07:04:51.587979 20 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.017839ms
  I0711 07:04:51.689095 20 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.111179ms
  E0711 07:04:52.437983      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:04:53.194637 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 07:04:53.194671 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0711 07:04:53.197746 20 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38775"},"items":null}

  I0711 07:04:53.201796 20 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38775"},"items":null}

  I0711 07:04:53.217530 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2007" for this suite. @ 07/11/24 07:04:53.221
• [5.800 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 07/11/24 07:04:53.23
  I0711 07:04:53.230428 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 07:04:53.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:53.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:53.25
  STEP: Creating configMap with name configmap-test-volume-1011c5f4-9e3e-42db-9167-253a293d12d2 @ 07/11/24 07:04:53.253
  STEP: Creating a pod to test consume configMaps @ 07/11/24 07:04:53.258
  E0711 07:04:53.439156      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:54.439229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:04:55.275
  I0711 07:04:55.279168 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-configmaps-ec2e415a-3e05-4e87-ba9b-627643e56423 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 07:04:55.287
  I0711 07:04:55.302689 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-695" for this suite. @ 07/11/24 07:04:55.306
• [2.086 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 07/11/24 07:04:55.316
  I0711 07:04:55.316243 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 07:04:55.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:55.338
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:55.341
  STEP: Create a pod @ 07/11/24 07:04:55.352
  E0711 07:04:55.439901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:56.439982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 07/11/24 07:04:57.372
  I0711 07:04:57.380020 20 pods.go:1124] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0711 07:04:57.380216 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8969" for this suite. @ 07/11/24 07:04:57.384
• [2.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1537
  STEP: Creating a kubernetes client @ 07/11/24 07:04:57.402
  I0711 07:04:57.402271 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 07:04:57.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:04:57.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:04:57.425
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-6875 @ 07/11/24 07:04:57.428
  E0711 07:04:57.440690      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 07/11/24 07:04:57.449
  STEP: creating service externalsvc in namespace services-6875 @ 07/11/24 07:04:57.449
  STEP: creating replication controller externalsvc in namespace services-6875 @ 07/11/24 07:04:57.462
  I0711 07:04:57.471187      20 runners.go:198] Created replication controller with name: externalsvc, namespace: services-6875, replica count: 2
  E0711 07:04:58.440832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:04:59.440940      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:00.441261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:05:00.522509      20 runners.go:198] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 07/11/24 07:05:00.526
  I0711 07:05:00.544563 20 resource.go:361] Creating new exec pod
  E0711 07:05:01.441390      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:02.441492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:05:02.565707 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-6875 exec execpodsdkkn -- /bin/sh -x -c nslookup nodeport-service.services-6875.svc.cluster.local'
  I0711 07:05:02.673148 20 builder.go:146] stderr: "+ nslookup nodeport-service.services-6875.svc.cluster.local\n"
  I0711 07:05:02.673206 20 builder.go:147] stdout: "Server:\t\t10.152.183.195\nAddress:\t10.152.183.195#53\n\nnodeport-service.services-6875.svc.cluster.local\tcanonical name = externalsvc.services-6875.svc.cluster.local.\nName:\texternalsvc.services-6875.svc.cluster.local\nAddress: 10.152.183.21\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-6875, will wait for the garbage collector to delete the pods @ 07/11/24 07:05:02.673
  I0711 07:05:02.735164 20 resources.go:139] Deleting ReplicationController externalsvc took: 6.688644ms
  I0711 07:05:02.836218 20 resources.go:163] Terminating ReplicationController externalsvc pods took: 101.043496ms
  E0711 07:05:03.441901      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:04.442258      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:05.442730      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:05:06.057936 20 service.go:1548] Cleaning up the NodePort to ExternalName test service
  I0711 07:05:06.068407 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6875" for this suite. @ 07/11/24 07:05:06.073
• [8.679 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 07/11/24 07:05:06.08
  I0711 07:05:06.080991 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename controllerrevisions @ 07/11/24 07:05:06.081
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:06.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:06.1
  STEP: Creating DaemonSet "e2e-qxlgk-daemon-set" @ 07/11/24 07:05:06.123
  STEP: Check that daemon pods launch on every node of the cluster. @ 07/11/24 07:05:06.128
  I0711 07:05:06.135165 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:05:06.135272 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:05:06.142528 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-qxlgk-daemon-set: 0
  I0711 07:05:06.142551 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  E0711 07:05:06.442989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:05:07.133798 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:05:07.133845 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:05:07.138153 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-qxlgk-daemon-set: 2
  I0711 07:05:07.138170 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  E0711 07:05:07.443554      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:05:08.133525 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:05:08.133564 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:05:08.137022 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-qxlgk-daemon-set: 3
  I0711 07:05:08.137038 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset e2e-qxlgk-daemon-set
  STEP: Confirm DaemonSet "e2e-qxlgk-daemon-set" successfully created with "daemonset-name=e2e-qxlgk-daemon-set" label @ 07/11/24 07:05:08.141
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-qxlgk-daemon-set" @ 07/11/24 07:05:08.148
  I0711 07:05:08.152482 20 controller_revision.go:162] Located ControllerRevision: "e2e-qxlgk-daemon-set-ffd7b5894"
  STEP: Patching ControllerRevision "e2e-qxlgk-daemon-set-ffd7b5894" @ 07/11/24 07:05:08.157
  I0711 07:05:08.162875 20 controller_revision.go:173] e2e-qxlgk-daemon-set-ffd7b5894 has been patched
  STEP: Create a new ControllerRevision @ 07/11/24 07:05:08.162
  I0711 07:05:08.168756 20 controller_revision.go:191] Created ControllerRevision: e2e-qxlgk-daemon-set-6bc959ff8b
  STEP: Confirm that there are two ControllerRevisions @ 07/11/24 07:05:08.168
  I0711 07:05:08.168801 20 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0711 07:05:08.172602 20 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-qxlgk-daemon-set-ffd7b5894" @ 07/11/24 07:05:08.172
  STEP: Confirm that there is only one ControllerRevision @ 07/11/24 07:05:08.18
  I0711 07:05:08.180915 20 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0711 07:05:08.184871 20 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-qxlgk-daemon-set-6bc959ff8b" @ 07/11/24 07:05:08.187
  I0711 07:05:08.196435 20 controller_revision.go:220] e2e-qxlgk-daemon-set-6bc959ff8b has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 07/11/24 07:05:08.196
  W0711 07:05:08.204394      20 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 07/11/24 07:05:08.204
  I0711 07:05:08.204483 20 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  E0711 07:05:08.443993      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:05:09.204961 20 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0711 07:05:09.209129 20 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-qxlgk-daemon-set-6bc959ff8b=updated" @ 07/11/24 07:05:09.209
  STEP: Confirm that there is only one ControllerRevision @ 07/11/24 07:05:09.219
  I0711 07:05:09.219360 20 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0711 07:05:09.223184 20 controller_revision.go:265] Found 1 ControllerRevisions
  I0711 07:05:09.226313 20 controller_revision.go:246] ControllerRevision "e2e-qxlgk-daemon-set-c4b6fdbc" has revision 3
  STEP: Deleting DaemonSet "e2e-qxlgk-daemon-set" @ 07/11/24 07:05:09.229
  STEP: deleting DaemonSet.extensions e2e-qxlgk-daemon-set in namespace controllerrevisions-3926, will wait for the garbage collector to delete the pods @ 07/11/24 07:05:09.229
  I0711 07:05:09.291305 20 resources.go:139] Deleting DaemonSet.extensions e2e-qxlgk-daemon-set took: 8.200207ms
  I0711 07:05:09.391594 20 resources.go:163] Terminating DaemonSet.extensions e2e-qxlgk-daemon-set pods took: 100.266256ms
  E0711 07:05:09.444833      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:10.445255      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:05:10.996442 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-qxlgk-daemon-set: 0
  I0711 07:05:10.996476 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-qxlgk-daemon-set
  I0711 07:05:11.000071 20 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39116"},"items":null}

  I0711 07:05:11.003027 20 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39116"},"items":null}

  I0711 07:05:11.016831 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-3926" for this suite. @ 07/11/24 07:05:11.02
• [4.947 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 07/11/24 07:05:11.028
  I0711 07:05:11.028195 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename gc @ 07/11/24 07:05:11.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:11.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:11.05
  STEP: create the deployment @ 07/11/24 07:05:11.053
  W0711 07:05:11.060545      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 07/11/24 07:05:11.06
  STEP: delete the deployment @ 07/11/24 07:05:11.168
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 07/11/24 07:05:11.176
  E0711 07:05:11.445876      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 07/11/24 07:05:11.696
  W0711 07:05:11.701485      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0711 07:05:11.701511 20 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0711 07:05:11.701950 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-467" for this suite. @ 07/11/24 07:05:11.705
• [0.684 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 07/11/24 07:05:11.712
  I0711 07:05:11.712490 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename containers @ 07/11/24 07:05:11.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:11.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:11.735
  STEP: Creating a pod to test override arguments @ 07/11/24 07:05:11.737
  E0711 07:05:12.446092      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:13.446391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:14.447470      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:15.447553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:05:15.764
  I0711 07:05:15.768632 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod client-containers-c93e189a-41c2-4fcb-a2e1-e7667a5d1356 container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 07:05:15.775
  I0711 07:05:15.794515 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8126" for this suite. @ 07/11/24 07:05:15.798
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 07/11/24 07:05:15.807
  I0711 07:05:15.807064 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename namespaces @ 07/11/24 07:05:15.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:15.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:15.83
  STEP: Creating a test namespace @ 07/11/24 07:05:15.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:15.85
  STEP: Creating a service in the namespace @ 07/11/24 07:05:15.853
  STEP: Deleting the namespace @ 07/11/24 07:05:15.867
  STEP: Waiting for the namespace to be removed. @ 07/11/24 07:05:15.879
  E0711 07:05:16.448571      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:17.448674      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:18.449699      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:19.449810      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:20.450839      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:21.450941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 07/11/24 07:05:21.885
  STEP: Verifying there is no service in the namespace @ 07/11/24 07:05:21.902
  I0711 07:05:21.909326 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4960" for this suite. @ 07/11/24 07:05:21.912
  STEP: Destroying namespace "nsdeletetest-8640" for this suite. @ 07/11/24 07:05:21.92
  I0711 07:05:21.923570 20 framework.go:370] Namespace nsdeletetest-8640 was already deleted
  STEP: Destroying namespace "nsdeletetest-7398" for this suite. @ 07/11/24 07:05:21.923
• [6.123 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 07/11/24 07:05:21.93
  I0711 07:05:21.930176 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename validating-admission-policy @ 07/11/24 07:05:21.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:21.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:21.948
  STEP: creating the policy @ 07/11/24 07:05:21.956
  STEP: waiting until the marker is denied @ 07/11/24 07:05:21.969
  E0711 07:05:22.451230      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 07/11/24 07:05:22.781
  STEP: testing a non-replicated ReplicaSet not to be denied @ 07/11/24 07:05:22.796
  I0711 07:05:22.840777 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-5330" for this suite. @ 07/11/24 07:05:22.846
• [0.926 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 07/11/24 07:05:22.857
  I0711 07:05:22.857279 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 07:05:22.857
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:22.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:22.876
  STEP: Creating projection with secret that has name projected-secret-test-map-5e937fb2-f799-405f-88d9-e2a6f5219b4f @ 07/11/24 07:05:22.878
  STEP: Creating a pod to test consume secrets @ 07/11/24 07:05:22.883
  E0711 07:05:23.451951      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:24.451989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:25.452070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:26.452868      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:05:26.907
  I0711 07:05:26.910820 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-projected-secrets-fd726d27-29ed-4abb-a5bb-afc62e00e04d container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 07:05:26.927
  I0711 07:05:26.946689 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4592" for this suite. @ 07/11/24 07:05:26.95
• [4.099 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 07/11/24 07:05:26.956
  I0711 07:05:26.956721 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename gc @ 07/11/24 07:05:26.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:26.974
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:26.977
  I0711 07:05:27.013155 20 garbage_collector.go:840] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f5639ee2-cebc-4c50-aab4-5898d0a7ec0c", Controller:(*bool)(0xc0026bad16), BlockOwnerDeletion:(*bool)(0xc0026bad17)}}
  I0711 07:05:27.021129 20 garbage_collector.go:844] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ba0df2f0-37b0-4c2b-8d68-07a30b277e9a", Controller:(*bool)(0xc0026bb036), BlockOwnerDeletion:(*bool)(0xc0026bb037)}}
  I0711 07:05:27.028924 20 garbage_collector.go:848] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a1cca1ab-431c-46de-96f7-d437878a5c84", Controller:(*bool)(0xc0026bb276), BlockOwnerDeletion:(*bool)(0xc0026bb277)}}
  E0711 07:05:27.453620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:28.453809      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:29.453911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:30.454011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:31.454239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:05:32.043751 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8117" for this suite. @ 07/11/24 07:05:32.051
• [5.105 seconds]
------------------------------
SS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 07/11/24 07:05:32.061
  I0711 07:05:32.061965 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename podtemplate @ 07/11/24 07:05:32.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:32.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:32.086
  STEP: Create set of pod templates @ 07/11/24 07:05:32.089
  I0711 07:05:32.096580 20 podtemplates.go:143] created test-podtemplate-1
  I0711 07:05:32.103572 20 podtemplates.go:143] created test-podtemplate-2
  I0711 07:05:32.108655 20 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 07/11/24 07:05:32.108
  STEP: delete collection of pod templates @ 07/11/24 07:05:32.112
  I0711 07:05:32.112085 20 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 07/11/24 07:05:32.134
  I0711 07:05:32.134110 20 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I0711 07:05:32.137454 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-2558" for this suite. @ 07/11/24 07:05:32.14
• [0.086 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 07/11/24 07:05:32.147
  I0711 07:05:32.147794 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 07:05:32.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:32.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:32.17
  STEP: Discovering how many secrets are in namespace by default @ 07/11/24 07:05:32.174
  E0711 07:05:32.454553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:33.455305      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:34.455773      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:35.456465      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:36.456658      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 07/11/24 07:05:37.18
  E0711 07:05:37.457185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:38.457843      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:39.458510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:40.459216      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:41.459762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 07/11/24 07:05:42.191
  STEP: Ensuring resource quota status is calculated @ 07/11/24 07:05:42.197
  E0711 07:05:42.460536      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:43.460661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 07/11/24 07:05:44.203
  STEP: Ensuring resource quota status captures secret creation @ 07/11/24 07:05:44.215
  E0711 07:05:44.461159      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:45.461389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 07/11/24 07:05:46.221
  STEP: Ensuring resource quota status released usage @ 07/11/24 07:05:46.229
  E0711 07:05:46.462217      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:47.462314      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:05:48.234966 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9051" for this suite. @ 07/11/24 07:05:48.239
• [16.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 07/11/24 07:05:48.248
  I0711 07:05:48.248213 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 07:05:48.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:05:48.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:05:48.269
  STEP: Counting existing ResourceQuota @ 07/11/24 07:05:48.272
  E0711 07:05:48.462391      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:49.462998      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:50.463232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:51.463544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:52.463688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 07/11/24 07:05:53.276
  STEP: Ensuring resource quota status is calculated @ 07/11/24 07:05:53.282
  E0711 07:05:53.464633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:54.465234      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 07/11/24 07:05:55.287
  STEP: Ensuring ResourceQuota status captures the pod usage @ 07/11/24 07:05:55.302
  E0711 07:05:55.465544      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:56.465780      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 07/11/24 07:05:57.307
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 07/11/24 07:05:57.31
  STEP: Ensuring a pod cannot update its resource requirements @ 07/11/24 07:05:57.312
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 07/11/24 07:05:57.316
  E0711 07:05:57.466866      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:05:58.467094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 07/11/24 07:05:59.321
  STEP: Ensuring resource quota status released the pod usage @ 07/11/24 07:05:59.337
  E0711 07:05:59.468010      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:00.469034      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:06:01.342249 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7584" for this suite. @ 07/11/24 07:06:01.347
• [13.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 07/11/24 07:06:01.355
  I0711 07:06:01.355144 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replicaset @ 07/11/24 07:06:01.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:01.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:01.375
  STEP: Create a ReplicaSet @ 07/11/24 07:06:01.378
  STEP: Verify that the required pods have come up @ 07/11/24 07:06:01.383
  I0711 07:06:01.386520 20 resource.go:87] Pod name sample-pod: Found 0 pods out of 3
  E0711 07:06:01.469743      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:02.470214      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:03.470354      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:04.470595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:05.470693      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:06:06.391776 20 resource.go:87] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 07/11/24 07:06:06.391
  I0711 07:06:06.396041 20 replica_set.go:583] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 07/11/24 07:06:06.396
  STEP: DeleteCollection of the ReplicaSets @ 07/11/24 07:06:06.4
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 07/11/24 07:06:06.411
  I0711 07:06:06.414513 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6890" for this suite. @ 07/11/24 07:06:06.417
• [5.071 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 07/11/24 07:06:06.425
  I0711 07:06:06.425914 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 07:06:06.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:06.453
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:06.456
  STEP: Creating a pod to test downward api env vars @ 07/11/24 07:06:06.459
  E0711 07:06:06.471058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:07.471979      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:08.473016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:06:08.477
  I0711 07:06:08.481256 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downward-api-937c1155-39d2-4d72-a4b2-f8ea5a9fa7b4 container dapi-container: <nil>
  STEP: delete the pod @ 07/11/24 07:06:08.49
  I0711 07:06:08.508908 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4259" for this suite. @ 07/11/24 07:06:08.513
• [2.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 07/11/24 07:06:08.521
  I0711 07:06:08.521862 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename apf @ 07/11/24 07:06:08.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:08.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:08.541
  STEP: getting /apis @ 07/11/24 07:06:08.543
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 07/11/24 07:06:08.546
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 07/11/24 07:06:08.547
  STEP: creating @ 07/11/24 07:06:08.548
  STEP: getting @ 07/11/24 07:06:08.569
  STEP: listing @ 07/11/24 07:06:08.575
  STEP: watching @ 07/11/24 07:06:08.578
  I0711 07:06:08.578983 20 flowcontrol.go:394] starting watch
  STEP: patching @ 07/11/24 07:06:08.58
  STEP: updating @ 07/11/24 07:06:08.585
  I0711 07:06:08.594763 20 flowcontrol.go:422] waiting for watch events with expected annotations
  STEP: getting /status @ 07/11/24 07:06:08.594
  STEP: patching /status @ 07/11/24 07:06:08.598
  STEP: updating /status @ 07/11/24 07:06:08.605
  STEP: deleting @ 07/11/24 07:06:08.618
  STEP: deleting a collection @ 07/11/24 07:06:08.63
  I0711 07:06:08.651610 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-4387" for this suite. @ 07/11/24 07:06:08.655
• [0.140 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1284
  STEP: Creating a kubernetes client @ 07/11/24 07:06:08.661
  I0711 07:06:08.661655 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 07:06:08.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:08.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:08.684
  STEP: creating service nodeport-test with type=NodePort in namespace services-8158 @ 07/11/24 07:06:08.687
  STEP: creating replication controller nodeport-test in namespace services-8158 @ 07/11/24 07:06:08.701
  I0711 07:06:08.709170      20 runners.go:198] Created replication controller with name: nodeport-test, namespace: services-8158, replica count: 2
  E0711 07:06:09.473889      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:10.474712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:11.474964      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:06:11.760560      20 runners.go:198] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0711 07:06:11.760598 20 resource.go:361] Creating new exec pod
  E0711 07:06:12.475089      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:13.475432      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:14.476424      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:06:14.888959 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8158 exec execpodnllb7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0711 07:06:14.987277 20 builder.go:146] stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I0711 07:06:14.987320 20 builder.go:147] stdout: ""
  E0711 07:06:15.476883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:06:15.889717 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8158 exec execpodnllb7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0711 07:06:15.979131 20 builder.go:146] stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I0711 07:06:15.979173 20 builder.go:147] stdout: "nodeport-test-kfwg2"
  I0711 07:06:15.979284 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8158 exec execpodnllb7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.50 80'
  I0711 07:06:16.069907 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.50 80\nConnection to 10.152.183.50 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0711 07:06:16.069944 20 builder.go:147] stdout: ""
  E0711 07:06:16.477720      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:06:16.979597 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8158 exec execpodnllb7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.50 80'
  I0711 07:06:17.066022 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.50 80\n+ echo hostName\nConnection to 10.152.183.50 80 port [tcp/http] succeeded!\n"
  I0711 07:06:17.066062 20 builder.go:147] stdout: "nodeport-test-kfwg2"
  I0711 07:06:17.066231 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8158 exec execpodnllb7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.11.2 31451'
  I0711 07:06:17.187364 20 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.11.2 31451\nConnection to 172.31.11.2 31451 port [tcp/*] succeeded!\n"
  I0711 07:06:17.187405 20 builder.go:147] stdout: ""
  E0711 07:06:17.477892      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:06:18.066643 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8158 exec execpodnllb7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.11.2 31451'
  I0711 07:06:18.155135 20 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.11.2 31451\nConnection to 172.31.11.2 31451 port [tcp/*] succeeded!\n"
  I0711 07:06:18.155174 20 builder.go:147] stdout: "nodeport-test-kfwg2"
  I0711 07:06:18.155315 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-8158 exec execpodnllb7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.80.240 31451'
  I0711 07:06:18.245992 20 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.80.240 31451\nConnection to 172.31.80.240 31451 port [tcp/*] succeeded!\n+ echo hostName\n"
  I0711 07:06:18.246051 20 builder.go:147] stdout: "nodeport-test-8h7xd"
  I0711 07:06:18.246150 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8158" for this suite. @ 07/11/24 07:06:18.25
• [9.597 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 07/11/24 07:06:18.259
  I0711 07:06:18.259072 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename deployment @ 07/11/24 07:06:18.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:18.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:18.279
  STEP: creating a Deployment @ 07/11/24 07:06:18.285
  I0711 07:06:18.286005 20 deployment.go:507] Creating simple deployment test-deployment-m22n7
  I0711 07:06:18.306113 20 deployment.go:222] deployment "test-deployment-m22n7" doesn't have the required revision set
  E0711 07:06:18.478360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:19.478486      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 07/11/24 07:06:20.321
  I0711 07:06:20.325199 20 deployment.go:532] Deployment test-deployment-m22n7 has Conditions: [{Available True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-m22n7-c8586b885" has successfully progressed.}]
  STEP: updating Deployment Status @ 07/11/24 07:06:20.325
  I0711 07:06:20.335833 20 deployment.go:552] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 6, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 6, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 6, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 6, 18, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-m22n7-c8586b885\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 07/11/24 07:06:20.335
  I0711 07:06:20.337514 20 deployment.go:579] Observed &Deployment event: ADDED
  I0711 07:06:20.337536 20 deployment.go:575] Observed Deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-m22n7-c8586b885"}
  I0711 07:06:20.337663 20 deployment.go:579] Observed &Deployment event: MODIFIED
  I0711 07:06:20.337697 20 deployment.go:575] Observed Deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-m22n7-c8586b885"}
  I0711 07:06:20.337709 20 deployment.go:575] Observed Deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0711 07:06:20.337846 20 deployment.go:579] Observed &Deployment event: MODIFIED
  I0711 07:06:20.337872 20 deployment.go:575] Observed Deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0711 07:06:20.337881 20 deployment.go:575] Observed Deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-m22n7-c8586b885" is progressing.}
  I0711 07:06:20.337989 20 deployment.go:579] Observed &Deployment event: MODIFIED
  I0711 07:06:20.338003 20 deployment.go:575] Observed Deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0711 07:06:20.338080 20 deployment.go:575] Observed Deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-m22n7-c8586b885" has successfully progressed.}
  I0711 07:06:20.338186 20 deployment.go:579] Observed &Deployment event: MODIFIED
  I0711 07:06:20.338201 20 deployment.go:575] Observed Deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0711 07:06:20.338210 20 deployment.go:575] Observed Deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-m22n7-c8586b885" has successfully progressed.}
  I0711 07:06:20.338220 20 deployment.go:572] Found Deployment test-deployment-m22n7 in namespace deployment-6528 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0711 07:06:20.338227 20 deployment.go:583] Deployment test-deployment-m22n7 has an updated status
  STEP: patching the Statefulset Status @ 07/11/24 07:06:20.338
  I0711 07:06:20.338251 20 deployment.go:587] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0711 07:06:20.345341 20 deployment.go:591] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 07/11/24 07:06:20.345
  I0711 07:06:20.347050 20 deployment.go:616] Observed &Deployment event: ADDED
  I0711 07:06:20.347071 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-m22n7-c8586b885"}
  I0711 07:06:20.347143 20 deployment.go:616] Observed &Deployment event: MODIFIED
  I0711 07:06:20.347170 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-m22n7-c8586b885"}
  I0711 07:06:20.347179 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0711 07:06:20.347255 20 deployment.go:616] Observed &Deployment event: MODIFIED
  I0711 07:06:20.347385 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0711 07:06:20.347399 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:18 +0000 UTC 2024-07-11 07:06:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-m22n7-c8586b885" is progressing.}
  I0711 07:06:20.347513 20 deployment.go:616] Observed &Deployment event: MODIFIED
  I0711 07:06:20.347527 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0711 07:06:20.347535 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-m22n7-c8586b885" has successfully progressed.}
  I0711 07:06:20.347591 20 deployment.go:616] Observed &Deployment event: MODIFIED
  I0711 07:06:20.347603 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0711 07:06:20.347611 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-07-11 07:06:19 +0000 UTC 2024-07-11 07:06:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-m22n7-c8586b885" has successfully progressed.}
  I0711 07:06:20.347619 20 deployment.go:612] Observed deployment test-deployment-m22n7 in namespace deployment-6528 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0711 07:06:20.347683 20 deployment.go:616] Observed &Deployment event: MODIFIED
  I0711 07:06:20.347794 20 deployment.go:609] Found deployment test-deployment-m22n7 in namespace deployment-6528 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0711 07:06:20.347845 20 deployment.go:620] Deployment test-deployment-m22n7 has a patched status
  I0711 07:06:20.351732 20 deployment.go:633] Deployment "test-deployment-m22n7":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-m22n7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6528",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3193a9b4-5c81-4828-8257-0e9e912428be",
      ResourceVersion: (string) (len=5) "40027",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856278378,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278378,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278380,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278380,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278380,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278380,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=55) "Found new replica set \"test-deployment-m22n7-c8586b885\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0711 07:06:20.355893 20 deployment.go:39] New ReplicaSet "test-deployment-m22n7-c8586b885" of Deployment "test-deployment-m22n7":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-m22n7-c8586b885",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6528",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4b5efb09-4125-4448-8ed9-211c60c7c707",
      ResourceVersion: (string) (len=5) "40022",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856278378,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-m22n7",
          UID: (types.UID) (len=36) "3193a9b4-5c81-4828-8257-0e9e912428be",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278378,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 33 31 39  |k:{\"uid\":\"319|
              00000120  33 61 39 62 34 2d 35 63  38 31 2d 34 38 32 38 2d  |3a9b4-5c81-4828-|
              00000130  38 32 35 37 2d 30 65 39  65 39 31 32 34 32 38 62  |8257-0e9e912428b|
              00000140  65 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |e\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278379,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 07:06:20.362380 20 deployment.go:67] Pod "test-deployment-m22n7-c8586b885-m25ph" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "test-deployment-m22n7-c8586b885-m25ph",
      GenerateName: (string) (len=32) "test-deployment-m22n7-c8586b885-",
      Namespace: (string) (len=15) "deployment-6528",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a7688cef-b079-4fe7-a8ad-1636a99eef16",
      ResourceVersion: (string) (len=5) "40021",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856278378,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "test-deployment-m22n7-c8586b885",
          UID: (types.UID) (len=36) "4b5efb09-4125-4448-8ed9-211c60c7c707",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278378,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 34 62 35 65 66 62 30  39 2d 34 31 32 35 2d 34  |"4b5efb09-4125-4|
              000000a0  34 34 38 2d 38 65 64 39  2d 32 31 31 63 36 30 63  |448-8ed9-211c60c|
              000000b0  37 63 37 30 37 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |7c707\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278379,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 33  33 2e 36 36 5c 22 7d 22  |2.168.133.66\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9wkgw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9wkgw",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-237",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278379,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278378,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278379,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278379,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856278378,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.237",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.237"
        }
      },
      PodIP: (string) (len=14) "192.168.133.66",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.133.66"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856278378,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856278378,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://4416f9db38501581b8824a74922a2873470cc868a1ec9f7cbfacaa6e99661b97",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 07:06:20.363579 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6528" for this suite. @ 07/11/24 07:06:20.367
• [2.114 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 07/11/24 07:06:20.373
  I0711 07:06:20.373541 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename tables @ 07/11/24 07:06:20.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:20.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:20.397
  I0711 07:06:20.402259 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-7223" for this suite. @ 07/11/24 07:06:20.406
• [0.042 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 07/11/24 07:06:20.415
  I0711 07:06:20.415970 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename namespaces @ 07/11/24 07:06:20.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:20.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:20.436
  STEP: Read namespace status @ 07/11/24 07:06:20.438
  I0711 07:06:20.441838 20 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 07/11/24 07:06:20.441
  I0711 07:06:20.447271 20 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 07/11/24 07:06:20.447
  I0711 07:06:20.458039 20 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0711 07:06:20.458134 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2672" for this suite. @ 07/11/24 07:06:20.461
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 07/11/24 07:06:20.469
  I0711 07:06:20.469834 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename endpointslice @ 07/11/24 07:06:20.47
  E0711 07:06:20.478464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:20.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:20.489
  I0711 07:06:20.502577 20 endpointslice.go:1045] Endpoints addresses: [172.31.72.118 172.31.92.117] , ports: [6443]
  I0711 07:06:20.502603 20 endpointslice.go:1075] EndpointSlices addresses: [172.31.72.118 172.31.92.117] , ports: [6443]
  I0711 07:06:20.502723 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9933" for this suite. @ 07/11/24 07:06:20.506
• [0.046 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3161
  STEP: Creating a kubernetes client @ 07/11/24 07:06:20.515
  I0711 07:06:20.515876 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 07:06:20.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:20.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:20.537
  STEP: creating an Endpoint @ 07/11/24 07:06:20.543
  STEP: waiting for available Endpoint @ 07/11/24 07:06:20.548
  STEP: listing all Endpoints @ 07/11/24 07:06:20.549
  STEP: updating the Endpoint @ 07/11/24 07:06:20.553
  STEP: fetching the Endpoint @ 07/11/24 07:06:20.559
  STEP: patching the Endpoint @ 07/11/24 07:06:20.562
  STEP: fetching the Endpoint @ 07/11/24 07:06:20.569
  STEP: deleting the Endpoint by Collection @ 07/11/24 07:06:20.573
  STEP: waiting for Endpoint deletion @ 07/11/24 07:06:20.582
  STEP: fetching the Endpoint @ 07/11/24 07:06:20.583
  I0711 07:06:20.586805 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-613" for this suite. @ 07/11/24 07:06:20.591
• [0.082 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 07/11/24 07:06:20.598
  I0711 07:06:20.598026 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 07:06:20.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:20.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:20.616
  STEP: Creating secret with name secret-test-69b793dc-35ca-44bc-b44e-3a0aa5c68498 @ 07/11/24 07:06:20.619
  STEP: Creating a pod to test consume secrets @ 07/11/24 07:06:20.626
  E0711 07:06:21.478623      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:22.478908      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:23.479022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:24.479277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:06:24.651
  I0711 07:06:24.655057 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-secrets-a8c78bec-f7c6-4230-b8df-8a56bdab2639 container secret-volume-test: <nil>
  STEP: delete the pod @ 07/11/24 07:06:24.662
  I0711 07:06:24.681381 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6282" for this suite. @ 07/11/24 07:06:24.685
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 07/11/24 07:06:24.692
  I0711 07:06:24.692702 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename subpath @ 07/11/24 07:06:24.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:24.708
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:24.711
  STEP: Setting up data @ 07/11/24 07:06:24.713
  STEP: Creating pod pod-subpath-test-configmap-brls @ 07/11/24 07:06:24.723
  STEP: Creating a pod to test atomic-volume-subpath @ 07/11/24 07:06:24.723
  E0711 07:06:25.479349      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:26.480360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:27.480471      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:28.480836      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:29.481004      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:30.481093      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:31.481276      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:32.481406      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:33.482421      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:34.483103      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:35.483204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:36.483291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:37.483838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:38.483962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:39.484854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:40.485049      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:41.485875      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:42.486111      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:43.486244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:44.486347      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:45.486530      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:46.487435      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:47.488241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:48.488324      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:06:48.802
  I0711 07:06:48.807240 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-subpath-test-configmap-brls container test-container-subpath-configmap-brls: <nil>
  STEP: delete the pod @ 07/11/24 07:06:48.816
  STEP: Deleting pod pod-subpath-test-configmap-brls @ 07/11/24 07:06:48.834
  I0711 07:06:48.835028 20 delete.go:62] Deleting pod "pod-subpath-test-configmap-brls" in namespace "subpath-1303"
  I0711 07:06:48.839379 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1303" for this suite. @ 07/11/24 07:06:48.844
• [24.159 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 07/11/24 07:06:48.851
  I0711 07:06:48.851752 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 07:06:48.852
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:48.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:48.875
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 07/11/24 07:06:48.877
  E0711 07:06:49.489021      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:50.489425      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:51.489603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:52.489699      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:06:52.901
  I0711 07:06:52.905885 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-ad031ef3-3f48-4562-807e-d985adc1c8fa container test-container: <nil>
  STEP: delete the pod @ 07/11/24 07:06:52.914
  I0711 07:06:52.932775 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1597" for this suite. @ 07/11/24 07:06:52.937
• [4.093 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 07/11/24 07:06:52.944
  I0711 07:06:52.944589 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename containers @ 07/11/24 07:06:52.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:52.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:52.968
  E0711 07:06:53.490572      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:54.490819      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:06:55.000518 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4906" for this suite. @ 07/11/24 07:06:55.004
• [2.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 07/11/24 07:06:55.013
  I0711 07:06:55.013394 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubelet-test @ 07/11/24 07:06:55.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:55.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:55.034
  STEP: Waiting for pod completion @ 07/11/24 07:06:55.05
  E0711 07:06:55.491213      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:56.492000      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:57.492345      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:06:58.492422      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:06:59.087054 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8502" for this suite. @ 07/11/24 07:06:59.091
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 07/11/24 07:06:59.099
  I0711 07:06:59.099137 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename dns @ 07/11/24 07:06:59.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:06:59.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:06:59.119
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 07/11/24 07:06:59.122
  I0711 07:06:59.129965 20 dns.go:419] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8268  290bbd31-d7d1-4c26-9ea6-91d64a8bd64d 40383 0 2024-07-11 07:06:59 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-07-11 07:06:59 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9t8t4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9t8t4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0711 07:06:59.492584      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:00.492590      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 07/11/24 07:07:01.14
  I0711 07:07:01.140874 20 exec_util.go:55] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8268 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:07:01.140986 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:07:01.141451 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:07:01.141532 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-8268/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 07/11/24 07:07:01.206
  I0711 07:07:01.206387 20 exec_util.go:55] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8268 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:07:01.206407 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:07:01.206876 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:07:01.206937 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-8268/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0711 07:07:01.261751 20 dns.go:421] Deleting pod test-dns-nameservers...
  I0711 07:07:01.276686 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8268" for this suite. @ 07/11/24 07:07:01.281
• [2.189 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 07/11/24 07:07:01.288
  I0711 07:07:01.288581 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename apf @ 07/11/24 07:07:01.289
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:01.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:01.31
  STEP: getting /apis @ 07/11/24 07:07:01.312
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 07/11/24 07:07:01.315
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 07/11/24 07:07:01.316
  STEP: creating @ 07/11/24 07:07:01.317
  STEP: getting @ 07/11/24 07:07:01.334
  STEP: listing @ 07/11/24 07:07:01.396
  STEP: watching @ 07/11/24 07:07:01.4
  I0711 07:07:01.400413 20 flowcontrol.go:620] starting watch
  STEP: patching @ 07/11/24 07:07:01.402
  STEP: updating @ 07/11/24 07:07:01.409
  I0711 07:07:01.418415 20 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 07/11/24 07:07:01.418
  STEP: patching /status @ 07/11/24 07:07:01.421
  STEP: updating /status @ 07/11/24 07:07:01.429
  STEP: deleting @ 07/11/24 07:07:01.441
  STEP: deleting a collection @ 07/11/24 07:07:01.458
  I0711 07:07:01.480676 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-5332" for this suite. @ 07/11/24 07:07:01.483
• [0.202 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 07/11/24 07:07:01.49
  I0711 07:07:01.490924 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename statefulset @ 07/11/24 07:07:01.491
  E0711 07:07:01.493605      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:01.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:01.51
  STEP: Creating service test in namespace statefulset-8457 @ 07/11/24 07:07:01.512
  STEP: Creating statefulset ss in namespace statefulset-8457 @ 07/11/24 07:07:01.517
  I0711 07:07:01.534555 20 wait.go:40] Found 0 stateful pods, waiting for 1
  E0711 07:07:02.494247      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:03.494549      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:04.494772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:05.495022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:06.495547      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:07.495758      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:08.496007      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:09.496105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:10.496402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:11.496462      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:11.532994 20 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 07/11/24 07:07:11.541
  STEP: updating a scale subresource @ 07/11/24 07:07:11.544
  STEP: verifying the statefulset Spec.Replicas was modified @ 07/11/24 07:07:11.55
  STEP: Patch a scale subresource @ 07/11/24 07:07:11.553
  STEP: verifying the statefulset Spec.Replicas was modified @ 07/11/24 07:07:11.559
  I0711 07:07:11.567199 20 statefulset.go:135] Deleting all statefulset in ns statefulset-8457
  I0711 07:07:11.570356 20 rest.go:150] Scaling statefulset ss to 0
  E0711 07:07:12.496588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:13.496682      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:14.497334      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:15.497596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:16.498349      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:17.498643      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:18.498829      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:19.499057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:20.499235      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:21.499433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:21.587043 20 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0711 07:07:21.590509 20 rest.go:88] Deleting statefulset ss
  I0711 07:07:21.603778 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8457" for this suite. @ 07/11/24 07:07:21.607
• [20.123 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 07/11/24 07:07:21.614
  I0711 07:07:21.614316 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 07:07:21.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:21.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:21.634
  STEP: Creating the pod @ 07/11/24 07:07:21.638
  E0711 07:07:22.499989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:23.500047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:24.185205 20 pod_client.go:141] Successfully updated pod "annotationupdatea0a632f6-d642-4714-b8de-1f27ea53266f"
  E0711 07:07:24.501044      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:25.501149      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:26.200033 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7428" for this suite. @ 07/11/24 07:07:26.205
• [4.599 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:489
  STEP: Creating a kubernetes client @ 07/11/24 07:07:26.213
  I0711 07:07:26.213293 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename security-context-test @ 07/11/24 07:07:26.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:26.228
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:26.231
  E0711 07:07:26.501269      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:27.501346      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:28.502250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:29.503065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:30.256836 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6781" for this suite. @ 07/11/24 07:07:30.26
• [4.054 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 07/11/24 07:07:30.267
  I0711 07:07:30.267601 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 07:07:30.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:30.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:30.288
  STEP: Creating a pod to test downward api env vars @ 07/11/24 07:07:30.29
  E0711 07:07:30.503957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:31.504076      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:32.504717      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:33.505185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:07:34.319
  I0711 07:07:34.324324 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downward-api-ee909b0e-2ac9-44a3-8c66-1285f0dc48bf container dapi-container: <nil>
  STEP: delete the pod @ 07/11/24 07:07:34.331
  I0711 07:07:34.347250 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-969" for this suite. @ 07/11/24 07:07:34.351
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 07/11/24 07:07:34.357
  I0711 07:07:34.357957 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-webhook @ 07/11/24 07:07:34.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:34.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:34.381
  STEP: Setting up server cert @ 07/11/24 07:07:34.384
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 07/11/24 07:07:34.485
  STEP: Deploying the custom resource conversion webhook pod @ 07/11/24 07:07:34.494
  E0711 07:07:34.505545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Wait for the deployment to be ready @ 07/11/24 07:07:34.507
  I0711 07:07:34.513417 20 deployment.go:222] new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  E0711 07:07:35.505700      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:36.506375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 07:07:36.524
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 07:07:36.537
  E0711 07:07:37.506512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:37.537775 20 util.go:427] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0711 07:07:37.545810 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:07:38.507545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:39.507838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 07/11/24 07:07:40.102
  STEP: Create a v2 custom resource @ 07/11/24 07:07:40.12
  STEP: List CRs in v1 @ 07/11/24 07:07:40.161
  STEP: List CRs in v2 @ 07/11/24 07:07:40.171
  E0711 07:07:40.508046      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:40.750643 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-8356" for this suite. @ 07/11/24 07:07:40.754
• [6.408 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 07/11/24 07:07:40.765
  I0711 07:07:40.765534 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 07:07:40.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:40.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:40.787
  STEP: Setting up server cert @ 07/11/24 07:07:40.814
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 07:07:41.124
  STEP: Deploying the webhook pod @ 07/11/24 07:07:41.13
  STEP: Wait for the deployment to be ready @ 07/11/24 07:07:41.143
  I0711 07:07:41.151329 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 07:07:41.508080      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:42.508153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 07:07:43.165
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 07:07:43.178
  E0711 07:07:43.508770      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:44.178695 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 07/11/24 07:07:44.187
  STEP: create a namespace for the webhook @ 07/11/24 07:07:44.198
  STEP: create a configmap should be unconditionally rejected by the webhook @ 07/11/24 07:07:44.217
  I0711 07:07:44.296717 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8798" for this suite. @ 07/11/24 07:07:44.301
  STEP: Destroying namespace "webhook-markers-2542" for this suite. @ 07/11/24 07:07:44.308
  STEP: Destroying namespace "fail-closed-namespace-2127" for this suite. @ 07/11/24 07:07:44.315
• [3.556 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:406
  STEP: Creating a kubernetes client @ 07/11/24 07:07:44.321
  I0711 07:07:44.321879 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename validating-admission-policy @ 07/11/24 07:07:44.322
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:44.338
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:44.34
  STEP: getting /apis @ 07/11/24 07:07:44.349
  STEP: getting /apis/admissionregistration.k8s.io @ 07/11/24 07:07:44.352
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 07/11/24 07:07:44.353
  STEP: creating @ 07/11/24 07:07:44.354
  STEP: getting @ 07/11/24 07:07:44.372
  STEP: listing @ 07/11/24 07:07:44.375
  STEP: watching @ 07/11/24 07:07:44.379
  I0711 07:07:44.379478 20 validatingadmissionpolicy.go:523] starting watch
  STEP: patching @ 07/11/24 07:07:44.38
  STEP: updating @ 07/11/24 07:07:44.386
  I0711 07:07:44.399200 20 validatingadmissionpolicy.go:552] waiting for watch events with expected annotations
  I0711 07:07:44.399242 20 validatingadmissionpolicy.go:568] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 07/11/24 07:07:44.399
  STEP: patching /status @ 07/11/24 07:07:44.402
  STEP: updating /status @ 07/11/24 07:07:44.414
  STEP: deleting @ 07/11/24 07:07:44.446
  STEP: deleting a collection @ 07/11/24 07:07:44.46
  I0711 07:07:44.481138 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-9592" for this suite. @ 07/11/24 07:07:44.485
• [0.170 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 07/11/24 07:07:44.492
  I0711 07:07:44.492231 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 07/11/24 07:07:44.492
  E0711 07:07:44.508817      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:44.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:44.516
  STEP: create the container to handle the HTTPGet hook request. @ 07/11/24 07:07:44.524
  E0711 07:07:45.509738      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:46.510501      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 07/11/24 07:07:46.55
  E0711 07:07:47.511483      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:48.511607      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 07/11/24 07:07:48.573
  E0711 07:07:49.512341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:50.512452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 07/11/24 07:07:50.591
  I0711 07:07:50.598738 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-8314" for this suite. @ 07/11/24 07:07:50.603
• [6.118 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 07/11/24 07:07:50.61
  I0711 07:07:50.610192 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename field-validation @ 07/11/24 07:07:50.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:50.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:50.637
  I0711 07:07:50.640325 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:07:51.513024      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:52.513393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0711 07:07:53.174977      20 warnings.go:70] unknown field "alpha"
  W0711 07:07:53.174996      20 warnings.go:70] unknown field "beta"
  W0711 07:07:53.175000      20 warnings.go:70] unknown field "delta"
  W0711 07:07:53.175003      20 warnings.go:70] unknown field "epsilon"
  W0711 07:07:53.175005      20 warnings.go:70] unknown field "gamma"
  E0711 07:07:53.513492      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:53.729369 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1808" for this suite. @ 07/11/24 07:07:53.733
• [3.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 07/11/24 07:07:53.741
  I0711 07:07:53.741100 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename svcaccounts @ 07/11/24 07:07:53.741
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:53.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:53.762
  STEP: Creating ServiceAccount "e2e-sa-rjmsz"  @ 07/11/24 07:07:53.766
  I0711 07:07:53.770856 20 service_accounts.go:825] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-rjmsz"  @ 07/11/24 07:07:53.77
  I0711 07:07:53.780615 20 service_accounts.go:839] AutomountServiceAccountToken: true
  I0711 07:07:53.780765 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6171" for this suite. @ 07/11/24 07:07:53.786
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 07/11/24 07:07:53.794
  I0711 07:07:53.794282 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 07:07:53.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:53.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:53.813
  STEP: Setting up server cert @ 07/11/24 07:07:53.841
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 07:07:54.024
  STEP: Deploying the webhook pod @ 07/11/24 07:07:54.029
  STEP: Wait for the deployment to be ready @ 07/11/24 07:07:54.042
  I0711 07:07:54.049414 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 07:07:54.513603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:55.514183      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 07:07:56.062
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 07:07:56.074
  E0711 07:07:56.514398      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:07:57.075078 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 07/11/24 07:07:57.084
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 07/11/24 07:07:57.085
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 07/11/24 07:07:57.085
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 07/11/24 07:07:57.085
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 07/11/24 07:07:57.086
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 07/11/24 07:07:57.086
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 07/11/24 07:07:57.087
  I0711 07:07:57.131257 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1646" for this suite. @ 07/11/24 07:07:57.135
  STEP: Destroying namespace "webhook-markers-8215" for this suite. @ 07/11/24 07:07:57.142
• [3.358 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 07/11/24 07:07:57.152
  I0711 07:07:57.152409 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename gc @ 07/11/24 07:07:57.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:07:57.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:07:57.175
  STEP: create the rc @ 07/11/24 07:07:57.181
  W0711 07:07:57.187594      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0711 07:07:57.515135      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:58.515985      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:07:59.520198      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:00.520440      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:01.525420      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:02.526497      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 07/11/24 07:08:03.195
  STEP: wait for the rc to be deleted @ 07/11/24 07:08:03.202
  E0711 07:08:03.527285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:04.215612 20 garbage_collector.go:670] 80 pods remaining
  I0711 07:08:04.215672 20 garbage_collector.go:677] 80 pods has nil DeletionTimestamp
  I0711 07:08:04.215679 20 garbage_collector.go:678] 
  E0711 07:08:04.527493      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:05.213974 20 garbage_collector.go:670] 71 pods remaining
  I0711 07:08:05.214126 20 garbage_collector.go:677] 70 pods has nil DeletionTimestamp
  I0711 07:08:05.214177 20 garbage_collector.go:678] 
  E0711 07:08:05.528130      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:06.216172 20 garbage_collector.go:670] 60 pods remaining
  I0711 07:08:06.216356 20 garbage_collector.go:677] 60 pods has nil DeletionTimestamp
  I0711 07:08:06.216401 20 garbage_collector.go:678] 
  E0711 07:08:06.528279      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:07.211865 20 garbage_collector.go:670] 40 pods remaining
  I0711 07:08:07.211899 20 garbage_collector.go:677] 40 pods has nil DeletionTimestamp
  I0711 07:08:07.211905 20 garbage_collector.go:678] 
  E0711 07:08:07.528239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:08.220679 20 garbage_collector.go:670] 31 pods remaining
  I0711 07:08:08.220710 20 garbage_collector.go:677] 31 pods has nil DeletionTimestamp
  I0711 07:08:08.220717 20 garbage_collector.go:678] 
  E0711 07:08:08.529145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:09.210339 20 garbage_collector.go:670] 20 pods remaining
  I0711 07:08:09.210374 20 garbage_collector.go:677] 20 pods has nil DeletionTimestamp
  I0711 07:08:09.210379 20 garbage_collector.go:678] 
  E0711 07:08:09.529610      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 07/11/24 07:08:10.223
  W0711 07:08:10.234653      20 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I0711 07:08:10.234728 20 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0711 07:08:10.234876 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3209" for this suite. @ 07/11/24 07:08:10.24
• [13.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 07/11/24 07:08:10.249
  I0711 07:08:10.249930 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename namespaces @ 07/11/24 07:08:10.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:10.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:10.302
  STEP: Creating namespace "e2e-ns-d6f68" @ 07/11/24 07:08:10.305
  I0711 07:08:10.323060 20 namespace.go:411] Namespace "e2e-ns-d6f68-1774" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-d6f68-1774" @ 07/11/24 07:08:10.323
  I0711 07:08:10.335600 20 namespace.go:434] Namespace "e2e-ns-d6f68-1774" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-d6f68-1774" @ 07/11/24 07:08:10.335
  I0711 07:08:10.343210 20 namespace.go:463] Namespace "e2e-ns-d6f68-1774" has []v1.FinalizerName{"kubernetes"}
  I0711 07:08:10.343296 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-624" for this suite. @ 07/11/24 07:08:10.346
  STEP: Destroying namespace "e2e-ns-d6f68-1774" for this suite. @ 07/11/24 07:08:10.356
• [0.113 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 07/11/24 07:08:10.363
  I0711 07:08:10.363749 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename limitrange @ 07/11/24 07:08:10.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:10.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:10.4
  STEP: Creating a LimitRange @ 07/11/24 07:08:10.412
  STEP: Setting up watch @ 07/11/24 07:08:10.413
  STEP: Submitting a LimitRange @ 07/11/24 07:08:10.528
  E0711 07:08:10.530411      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying LimitRange creation was observed @ 07/11/24 07:08:10.533
  STEP: Fetching the LimitRange to ensure it has proper values @ 07/11/24 07:08:10.533
  I0711 07:08:10.537319 20 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0711 07:08:10.537429 20 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 07/11/24 07:08:10.537
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 07/11/24 07:08:10.544
  I0711 07:08:10.546951 20 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0711 07:08:10.546978 20 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 07/11/24 07:08:10.546
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 07/11/24 07:08:10.556
  I0711 07:08:10.563375 20 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0711 07:08:10.563466 20 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 07/11/24 07:08:10.563
  STEP: Failing to create a Pod with more than max resources @ 07/11/24 07:08:10.566
  STEP: Updating a LimitRange @ 07/11/24 07:08:10.567
  STEP: Verifying LimitRange updating is effective @ 07/11/24 07:08:10.572
  E0711 07:08:11.530598      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:12.530672      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 07/11/24 07:08:12.577
  STEP: Failing to create a Pod with more than max resources @ 07/11/24 07:08:12.583
  STEP: Deleting a LimitRange @ 07/11/24 07:08:12.585
  STEP: Verifying the LimitRange was deleted @ 07/11/24 07:08:12.597
  E0711 07:08:13.531125      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:14.531553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:15.531756      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:16.532597      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:17.532709      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:17.603540 20 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 07/11/24 07:08:17.603
  I0711 07:08:17.612803 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-5429" for this suite. @ 07/11/24 07:08:17.616
• [7.262 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 07/11/24 07:08:17.626
  I0711 07:08:17.626616 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename aggregateddiscovery @ 07/11/24 07:08:17.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:17.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:17.649
  I0711 07:08:17.651552 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:08:18.533105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:19.533530      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:20.533686      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:20.705146 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-7023" for this suite. @ 07/11/24 07:08:20.71
• [3.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 07/11/24 07:08:20.718
  I0711 07:08:20.718589 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 07:08:20.719
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:20.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:20.741
  STEP: Creating the pod @ 07/11/24 07:08:20.743
  E0711 07:08:21.533781      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:22.533904      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:23.290358 20 pod_client.go:141] Successfully updated pod "labelsupdate62d2e94e-efbb-4101-ace3-b6c139504b74"
  E0711 07:08:23.534778      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:24.534903      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:25.535595      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:26.536321      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:27.315680 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-824" for this suite. @ 07/11/24 07:08:27.319
• [6.609 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 07/11/24 07:08:27.328
  I0711 07:08:27.328239 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 07:08:27.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:27.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:27.354
  STEP: Creating configMap configmap-3637/configmap-test-02e0a163-a667-4faf-b01e-b823d6ec8367 @ 07/11/24 07:08:27.357
  STEP: Creating a pod to test consume configMaps @ 07/11/24 07:08:27.361
  E0711 07:08:27.537169      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:28.537274      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:29.537701      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:30.538008      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:08:31.388
  I0711 07:08:31.392755 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-configmaps-3664f30e-4f73-4082-91c7-8e05b3c2a8a5 container env-test: <nil>
  STEP: delete the pod @ 07/11/24 07:08:31.401
  I0711 07:08:31.420191 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3637" for this suite. @ 07/11/24 07:08:31.423
• [4.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 07/11/24 07:08:31.434
  I0711 07:08:31.434589 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 07:08:31.435
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:31.453
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:31.456
  I0711 07:08:31.458911 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: creating the pod @ 07/11/24 07:08:31.459
  STEP: submitting the pod to kubernetes @ 07/11/24 07:08:31.459
  E0711 07:08:31.538756      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:32.539123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:33.494621 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1072" for this suite. @ 07/11/24 07:08:33.499
• [2.074 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 07/11/24 07:08:33.508
  I0711 07:08:33.508357 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename endpointslicemirroring @ 07/11/24 07:08:33.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:33.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:33.53
  E0711 07:08:33.539780      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring a new custom Endpoint @ 07/11/24 07:08:33.545
  I0711 07:08:33.553943 20 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  E0711 07:08:34.540215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:35.540318      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 07/11/24 07:08:35.558
  I0711 07:08:35.568883 20 endpointslicemirroring.go:171] Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0711 07:08:36.540400      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:37.540512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 07/11/24 07:08:37.575
  I0711 07:08:37.587097 20 endpointslicemirroring.go:194] Waiting for 0 EndpointSlices to exist, got 1
  E0711 07:08:38.541153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:39.541372      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:39.592302 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-8347" for this suite. @ 07/11/24 07:08:39.596
• [6.095 seconds]
------------------------------
S
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2218
  STEP: Creating a kubernetes client @ 07/11/24 07:08:39.603
  I0711 07:08:39.603747 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 07:08:39.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:39.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:39.623
  STEP: creating service in namespace services-7501 @ 07/11/24 07:08:39.625
  STEP: creating service affinity-nodeport in namespace services-7501 @ 07/11/24 07:08:39.625
  STEP: creating replication controller affinity-nodeport in namespace services-7501 @ 07/11/24 07:08:39.643
  I0711 07:08:39.649861      20 runners.go:198] Created replication controller with name: affinity-nodeport, namespace: services-7501, replica count: 3
  E0711 07:08:40.541846      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:41.542022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:42.542131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:42.701530      20 runners.go:198] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0711 07:08:42.714771 20 resource.go:361] Creating new exec pod
  E0711 07:08:43.542241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:44.542318      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:45.542854      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:45.738515 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-7501 exec execpod-affinitytpss6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I0711 07:08:45.827511 20 builder.go:146] stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  I0711 07:08:45.827555 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 07:08:45.827627 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-7501 exec execpod-affinitytpss6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.191 80'
  I0711 07:08:45.914678 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.191 80\nConnection to 10.152.183.191 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  I0711 07:08:45.914736 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 07:08:45.914809 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-7501 exec execpod-affinitytpss6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.80.240 31914'
  I0711 07:08:45.995627 20 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.80.240 31914\n+ echo hostName\nConnection to 172.31.80.240 31914 port [tcp/*] succeeded!\n"
  I0711 07:08:45.995673 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 07:08:45.995746 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-7501 exec execpod-affinitytpss6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.17.237 31914'
  I0711 07:08:46.082556 20 builder.go:146] stderr: "+ + echonc hostName -v\n -t -w 2 172.31.17.237 31914\nConnection to 172.31.17.237 31914 port [tcp/*] succeeded!\n"
  I0711 07:08:46.082600 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 07:08:46.082664 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-7501 exec execpod-affinitytpss6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.11.2:31914/ ; done'
  I0711 07:08:46.227340 20 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:31914/\n"
  I0711 07:08:46.227393 20 builder.go:147] stdout: "\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx\naffinity-nodeport-pmcfx"
  I0711 07:08:46.227407 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227414 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227419 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227429 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227435 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227442 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227448 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227453 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227461 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227466 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227472 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227477 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227482 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227487 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227492 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227497 20 service.go:242] Received response from host: affinity-nodeport-pmcfx
  I0711 07:08:46.227562 20 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-7501, will wait for the garbage collector to delete the pods @ 07/11/24 07:08:46.243
  I0711 07:08:46.305400 20 resources.go:139] Deleting ReplicationController affinity-nodeport took: 8.06925ms
  I0711 07:08:46.405816 20 resources.go:163] Terminating ReplicationController affinity-nodeport pods took: 100.408931ms
  E0711 07:08:46.543485      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:47.544375      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:48.544800      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:49.531198 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7501" for this suite. @ 07/11/24 07:08:49.535
• [9.939 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 07/11/24 07:08:49.543
  I0711 07:08:49.543094 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename dns @ 07/11/24 07:08:49.543
  E0711 07:08:49.545682      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:49.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:49.563
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4507.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4507.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 07/11/24 07:08:49.566
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4507.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4507.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 07/11/24 07:08:49.566
  STEP: creating a pod to probe /etc/hosts @ 07/11/24 07:08:49.566
  STEP: submitting the pod to kubernetes @ 07/11/24 07:08:49.566
  E0711 07:08:50.545777      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:51.546377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 07/11/24 07:08:51.587
  STEP: looking for the results for each expected name from probers @ 07/11/24 07:08:51.591
  I0711 07:08:51.609701 20 dns_common.go:527] DNS probes using dns-4507/dns-test-8f89b595-3cc1-4018-b352-9117140606bc succeeded

  STEP: deleting the pod @ 07/11/24 07:08:51.609
  I0711 07:08:51.621316 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4507" for this suite. @ 07/11/24 07:08:51.626
• [2.089 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3345
  STEP: Creating a kubernetes client @ 07/11/24 07:08:51.632
  I0711 07:08:51.632578 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 07:08:51.633
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:51.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:51.654
  STEP: creating a Service @ 07/11/24 07:08:51.664
  STEP: watching for the Service to be added @ 07/11/24 07:08:51.68
  I0711 07:08:51.682411 20 service.go:3397] Found Service test-service-b96fx in namespace services-5990 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 31746}]
  I0711 07:08:51.682674 20 service.go:3404] Service test-service-b96fx created
  STEP: Getting /status @ 07/11/24 07:08:51.682
  I0711 07:08:51.686800 20 service.go:3415] Service test-service-b96fx has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 07/11/24 07:08:51.686
  STEP: watching for the Service to be patched @ 07/11/24 07:08:51.693
  I0711 07:08:51.695031 20 service.go:3438] observed Service test-service-b96fx in namespace services-5990 with annotations: map[] & LoadBalancer: {[]}
  I0711 07:08:51.695063 20 service.go:3441] Found Service test-service-b96fx in namespace services-5990 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc000bf9920 []}]}
  I0711 07:08:51.695071 20 service.go:3448] Service test-service-b96fx has service status patched
  STEP: updating the ServiceStatus @ 07/11/24 07:08:51.695
  I0711 07:08:51.704005 20 service.go:3468] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 07/11/24 07:08:51.704
  I0711 07:08:51.706195 20 service.go:3479] Observed Service test-service-b96fx in namespace services-5990 with annotations: map[] & Conditions: {[]}
  I0711 07:08:51.706371 20 service.go:3494] Observed event: &Service{ObjectMeta:{test-service-b96fx  services-5990  cddbe4c5-36eb-4569-a9f6-1ed1ac25897d 43975 0 2024-07-11 07:08:51 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-07-11 07:08:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-07-11 07:08:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:31746,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.143,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.143],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,TrafficDistribution:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:*VIP,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  I0711 07:08:51.706413 20 service.go:3486] Found Service test-service-b96fx in namespace services-5990 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0711 07:08:51.706424 20 service.go:3498] Service test-service-b96fx has service status updated
  STEP: patching the service @ 07/11/24 07:08:51.706
  STEP: watching for the Service to be patched @ 07/11/24 07:08:51.715
  I0711 07:08:51.717347 20 service.go:3521] observed Service test-service-b96fx in namespace services-5990 with labels: map[test-service-static:true]
  I0711 07:08:51.717432 20 service.go:3521] observed Service test-service-b96fx in namespace services-5990 with labels: map[test-service-static:true]
  I0711 07:08:51.717448 20 service.go:3521] observed Service test-service-b96fx in namespace services-5990 with labels: map[test-service-static:true]
  I0711 07:08:51.717472 20 service.go:3524] Found Service test-service-b96fx in namespace services-5990 with labels: map[test-service:patched test-service-static:true]
  I0711 07:08:51.717508 20 service.go:3531] Service test-service-b96fx patched
  STEP: deleting the service @ 07/11/24 07:08:51.717
  STEP: watching for the Service to be deleted @ 07/11/24 07:08:51.736
  I0711 07:08:51.737532 20 service.go:3555] Observed event: ADDED
  I0711 07:08:51.737548 20 service.go:3555] Observed event: MODIFIED
  I0711 07:08:51.737571 20 service.go:3555] Observed event: MODIFIED
  I0711 07:08:51.737682 20 service.go:3555] Observed event: MODIFIED
  I0711 07:08:51.737695 20 service.go:3551] Found Service test-service-b96fx in namespace services-5990 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0711 07:08:51.737767 20 service.go:3560] Service test-service-b96fx deleted
  I0711 07:08:51.737924 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5990" for this suite. @ 07/11/24 07:08:51.741
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 07/11/24 07:08:51.748
  I0711 07:08:51.748774 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename proxy @ 07/11/24 07:08:51.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:51.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:51.769
  STEP: starting an echo server on multiple ports @ 07/11/24 07:08:51.782
  STEP: creating replication controller proxy-service-dmzcm in namespace proxy-2825 @ 07/11/24 07:08:51.782
  I0711 07:08:51.790467      20 runners.go:198] Created replication controller with name: proxy-service-dmzcm, namespace: proxy-2825, replica count: 1
  E0711 07:08:52.547300      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:52.841882      20 runners.go:198] proxy-service-dmzcm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0711 07:08:53.548005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:53.842304      20 runners.go:198] proxy-service-dmzcm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0711 07:08:53.846668 20 proxy.go:230] setup took 2.07504833s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 07/11/24 07:08:53.846
  I0711 07:08:53.852279 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.424394ms)
  I0711 07:08:53.853685 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 6.493963ms)
  I0711 07:08:53.853637 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.501228ms)
  I0711 07:08:53.856215 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 9.008135ms)
  I0711 07:08:53.856412 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 9.326758ms)
  I0711 07:08:53.856454 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 9.258485ms)
  I0711 07:08:53.856471 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 9.548939ms)
  I0711 07:08:53.857472 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 10.332187ms)
  I0711 07:08:53.857492 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 10.427088ms)
  I0711 07:08:53.857506 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 10.484354ms)
  I0711 07:08:53.857521 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 10.51616ms)
  I0711 07:08:53.857529 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 10.678724ms)
  I0711 07:08:53.857607 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 10.452467ms)
  I0711 07:08:53.857648 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 10.605809ms)
  I0711 07:08:53.858196 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 11.230418ms)
  I0711 07:08:53.858252 20 proxy.go:558] (0) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 11.289596ms)
  I0711 07:08:53.862063 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 3.422865ms)
  I0711 07:08:53.862624 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 3.922736ms)
  I0711 07:08:53.864132 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 5.133818ms)
  I0711 07:08:53.864920 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 5.904652ms)
  I0711 07:08:53.865289 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.420179ms)
  I0711 07:08:53.865476 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 6.626002ms)
  I0711 07:08:53.865494 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 6.53139ms)
  I0711 07:08:53.865504 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 6.476072ms)
  I0711 07:08:53.865955 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 6.905452ms)
  I0711 07:08:53.865975 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 7.077535ms)
  I0711 07:08:53.866111 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 7.319035ms)
  I0711 07:08:53.866279 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 7.336367ms)
  I0711 07:08:53.866392 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 7.443867ms)
  I0711 07:08:53.869208 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 10.226871ms)
  I0711 07:08:53.869722 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 10.808249ms)
  I0711 07:08:53.870220 20 proxy.go:558] (1) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 11.395785ms)
  I0711 07:08:53.873562 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 3.283589ms)
  I0711 07:08:53.876011 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.431284ms)
  I0711 07:08:53.876204 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 5.706346ms)
  I0711 07:08:53.876203 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.658851ms)
  I0711 07:08:53.876564 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 6.104029ms)
  I0711 07:08:53.876826 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 6.309228ms)
  I0711 07:08:53.877107 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 6.727523ms)
  I0711 07:08:53.877472 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 6.939067ms)
  I0711 07:08:53.877822 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 7.46235ms)
  I0711 07:08:53.878356 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 7.862922ms)
  I0711 07:08:53.878400 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 8.108932ms)
  I0711 07:08:53.878543 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 8.135772ms)
  I0711 07:08:53.878741 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 8.402303ms)
  I0711 07:08:53.878865 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 8.419442ms)
  I0711 07:08:53.879024 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 8.466867ms)
  I0711 07:08:53.879949 20 proxy.go:558] (2) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 9.51839ms)
  I0711 07:08:53.883911 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 3.92322ms)
  I0711 07:08:53.884003 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 3.989121ms)
  I0711 07:08:53.885158 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 5.071957ms)
  I0711 07:08:53.885219 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 5.112342ms)
  I0711 07:08:53.885494 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 5.194536ms)
  I0711 07:08:53.885510 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.242244ms)
  I0711 07:08:53.886636 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 6.436059ms)
  I0711 07:08:53.887047 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.761761ms)
  I0711 07:08:53.887249 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 7.014356ms)
  I0711 07:08:53.887267 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 7.127703ms)
  I0711 07:08:53.887413 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 7.237816ms)
  I0711 07:08:53.888664 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 8.447236ms)
  I0711 07:08:53.888688 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 8.346674ms)
  I0711 07:08:53.888723 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 8.476103ms)
  I0711 07:08:53.889572 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 9.253214ms)
  I0711 07:08:53.889805 20 proxy.go:558] (3) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 9.647994ms)
  I0711 07:08:53.893364 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 3.439957ms)
  I0711 07:08:53.893938 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 4.104882ms)
  I0711 07:08:53.894357 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 4.47397ms)
  I0711 07:08:53.895679 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 5.544606ms)
  I0711 07:08:53.895690 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 5.603684ms)
  I0711 07:08:53.895886 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 5.78288ms)
  I0711 07:08:53.896013 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.022436ms)
  I0711 07:08:53.896109 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 5.925461ms)
  I0711 07:08:53.896114 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 5.951059ms)
  I0711 07:08:53.896392 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 6.321545ms)
  I0711 07:08:53.897242 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 7.29169ms)
  I0711 07:08:53.897664 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 7.608887ms)
  I0711 07:08:53.897740 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 7.729428ms)
  I0711 07:08:53.897664 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 7.519769ms)
  I0711 07:08:53.898486 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 8.516061ms)
  I0711 07:08:53.898945 20 proxy.go:558] (4) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 8.908421ms)
  I0711 07:08:53.902439 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 3.389846ms)
  I0711 07:08:53.903054 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 4.074349ms)
  I0711 07:08:53.904404 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 5.116336ms)
  I0711 07:08:53.904509 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 5.352629ms)
  I0711 07:08:53.904531 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 5.35935ms)
  I0711 07:08:53.904541 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.221425ms)
  I0711 07:08:53.904813 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 5.598746ms)
  I0711 07:08:53.905918 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 6.646476ms)
  I0711 07:08:53.906060 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 6.94221ms)
  I0711 07:08:53.906060 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.980748ms)
  I0711 07:08:53.906357 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 7.167313ms)
  I0711 07:08:53.906510 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 7.256738ms)
  I0711 07:08:53.906988 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 7.889211ms)
  I0711 07:08:53.907119 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 7.816486ms)
  I0711 07:08:53.907613 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 8.458797ms)
  I0711 07:08:53.908112 20 proxy.go:558] (5) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 8.881949ms)
  I0711 07:08:53.913386 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 5.106007ms)
  I0711 07:08:53.913519 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.340773ms)
  I0711 07:08:53.913717 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 5.460883ms)
  I0711 07:08:53.914421 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 6.10852ms)
  I0711 07:08:53.915035 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 6.581415ms)
  I0711 07:08:53.915250 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.812655ms)
  I0711 07:08:53.915450 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 7.100688ms)
  I0711 07:08:53.915761 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 7.360043ms)
  I0711 07:08:53.915838 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 7.511843ms)
  I0711 07:08:53.916193 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 7.770818ms)
  I0711 07:08:53.916691 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 8.466138ms)
  I0711 07:08:53.916755 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 8.46151ms)
  I0711 07:08:53.917065 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 8.680305ms)
  I0711 07:08:53.917186 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 8.818174ms)
  I0711 07:08:53.917587 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 9.445513ms)
  I0711 07:08:53.918080 20 proxy.go:558] (6) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 9.87586ms)
  I0711 07:08:53.921699 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 3.595915ms)
  I0711 07:08:53.922002 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 3.784924ms)
  I0711 07:08:53.922070 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 3.958192ms)
  I0711 07:08:53.923661 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 5.368639ms)
  I0711 07:08:53.924112 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 5.872375ms)
  I0711 07:08:53.924121 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.848868ms)
  I0711 07:08:53.924132 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.877268ms)
  I0711 07:08:53.924149 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 5.802831ms)
  I0711 07:08:53.924835 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 6.473385ms)
  I0711 07:08:53.925515 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 7.134699ms)
  I0711 07:08:53.925618 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 7.186927ms)
  I0711 07:08:53.925881 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 7.479847ms)
  I0711 07:08:53.926034 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 7.724497ms)
  I0711 07:08:53.926928 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 8.602604ms)
  I0711 07:08:53.927032 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 8.836338ms)
  I0711 07:08:53.928395 20 proxy.go:558] (7) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 9.980131ms)
  I0711 07:08:53.932267 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 3.724564ms)
  I0711 07:08:53.933996 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.296721ms)
  I0711 07:08:53.934821 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 6.224033ms)
  I0711 07:08:53.934960 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 6.313376ms)
  I0711 07:08:53.935110 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.498161ms)
  I0711 07:08:53.935264 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.551515ms)
  I0711 07:08:53.935446 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 6.78329ms)
  I0711 07:08:53.935532 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 6.783991ms)
  I0711 07:08:53.935638 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 7.06428ms)
  I0711 07:08:53.935682 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 6.949205ms)
  I0711 07:08:53.936832 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 8.362108ms)
  I0711 07:08:53.937275 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 8.753629ms)
  I0711 07:08:53.937431 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 8.93788ms)
  I0711 07:08:53.939543 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 10.861086ms)
  I0711 07:08:53.940590 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 11.959564ms)
  I0711 07:08:53.940611 20 proxy.go:558] (8) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 11.847942ms)
  I0711 07:08:53.950336 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 9.694449ms)
  I0711 07:08:53.955921 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 14.982695ms)
  I0711 07:08:53.956434 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 15.473151ms)
  I0711 07:08:53.956843 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 15.900254ms)
  I0711 07:08:53.958811 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 17.917936ms)
  I0711 07:08:53.959524 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 18.530666ms)
  I0711 07:08:53.959981 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 19.130479ms)
  I0711 07:08:53.960047 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 19.136107ms)
  I0711 07:08:53.960088 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 19.117735ms)
  I0711 07:08:53.960346 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 19.475432ms)
  I0711 07:08:53.960618 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 19.764293ms)
  I0711 07:08:53.960679 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 19.944332ms)
  I0711 07:08:53.961131 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 20.422297ms)
  I0711 07:08:53.961155 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 20.357649ms)
  I0711 07:08:53.961203 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 20.443522ms)
  I0711 07:08:53.962529 20 proxy.go:558] (9) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 21.748515ms)
  I0711 07:08:53.970044 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 7.338759ms)
  I0711 07:08:53.971027 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 8.136004ms)
  I0711 07:08:53.971133 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 8.581902ms)
  I0711 07:08:53.971285 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 8.526248ms)
  I0711 07:08:53.972475 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 9.602355ms)
  I0711 07:08:53.972701 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 9.980568ms)
  I0711 07:08:53.975225 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 12.449544ms)
  I0711 07:08:53.975932 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 13.189546ms)
  I0711 07:08:53.976422 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 13.625414ms)
  I0711 07:08:53.976533 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 13.846201ms)
  I0711 07:08:53.976733 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 13.813129ms)
  I0711 07:08:53.976780 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 13.950267ms)
  I0711 07:08:53.976901 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 14.085362ms)
  I0711 07:08:53.976997 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 14.415507ms)
  I0711 07:08:53.977480 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 14.832557ms)
  I0711 07:08:53.979276 20 proxy.go:558] (10) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 16.419747ms)
  I0711 07:08:53.988387 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 8.95482ms)
  I0711 07:08:53.988408 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 8.793597ms)
  I0711 07:08:53.988602 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 9.304233ms)
  I0711 07:08:53.988647 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 9.165745ms)
  I0711 07:08:53.988821 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 9.253968ms)
  I0711 07:08:53.989404 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 9.954301ms)
  I0711 07:08:53.990080 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 10.565818ms)
  I0711 07:08:53.990154 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 10.656885ms)
  I0711 07:08:53.990579 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 11.211188ms)
  I0711 07:08:53.990592 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 11.127648ms)
  I0711 07:08:53.990674 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 11.129694ms)
  I0711 07:08:53.992113 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 12.527363ms)
  I0711 07:08:53.992132 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 12.495763ms)
  I0711 07:08:53.992270 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 12.671303ms)
  I0711 07:08:53.992649 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 13.24443ms)
  I0711 07:08:53.994279 20 proxy.go:558] (11) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 14.749376ms)
  I0711 07:08:54.003192 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 8.868554ms)
  I0711 07:08:54.004977 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 10.463616ms)
  I0711 07:08:54.005136 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 10.508428ms)
  I0711 07:08:54.005755 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 11.145837ms)
  I0711 07:08:54.005783 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 11.287394ms)
  I0711 07:08:54.005855 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 11.277874ms)
  I0711 07:08:54.006081 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 11.519426ms)
  I0711 07:08:54.006195 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 11.752233ms)
  I0711 07:08:54.006098 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 11.620704ms)
  I0711 07:08:54.006240 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 11.645627ms)
  I0711 07:08:54.006595 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 12.170286ms)
  I0711 07:08:54.006597 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 12.137477ms)
  I0711 07:08:54.006986 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 12.45725ms)
  I0711 07:08:54.007113 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 12.755882ms)
  I0711 07:08:54.007832 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 13.286903ms)
  I0711 07:08:54.008148 20 proxy.go:558] (12) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 13.755054ms)
  I0711 07:08:54.012940 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 4.722241ms)
  I0711 07:08:54.014740 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 6.33764ms)
  I0711 07:08:54.014740 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 6.523926ms)
  I0711 07:08:54.016542 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 8.029962ms)
  I0711 07:08:54.016542 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 8.120079ms)
  I0711 07:08:54.016574 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 8.296889ms)
  I0711 07:08:54.016642 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 8.315507ms)
  I0711 07:08:54.016643 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 8.186002ms)
  I0711 07:08:54.021505 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 13.010876ms)
  I0711 07:08:54.021921 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 13.446842ms)
  I0711 07:08:54.022579 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 14.268522ms)
  I0711 07:08:54.022979 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 14.634412ms)
  I0711 07:08:54.023686 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 15.160421ms)
  I0711 07:08:54.023926 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 15.544502ms)
  I0711 07:08:54.024113 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 15.748171ms)
  I0711 07:08:54.024340 20 proxy.go:558] (13) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 15.901938ms)
  I0711 07:08:54.030868 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 6.39931ms)
  I0711 07:08:54.031649 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 7.232643ms)
  I0711 07:08:54.032937 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 8.303148ms)
  I0711 07:08:54.034049 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 9.55438ms)
  I0711 07:08:54.034176 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 9.446188ms)
  I0711 07:08:54.034258 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 9.642458ms)
  I0711 07:08:54.034268 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 9.688977ms)
  I0711 07:08:54.034539 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 9.978494ms)
  I0711 07:08:54.034621 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 10.250909ms)
  I0711 07:08:54.034654 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 10.141437ms)
  I0711 07:08:54.034883 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 10.19345ms)
  I0711 07:08:54.035465 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 10.7927ms)
  I0711 07:08:54.035523 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 10.981625ms)
  I0711 07:08:54.036049 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 11.454994ms)
  I0711 07:08:54.036582 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 11.871238ms)
  I0711 07:08:54.036614 20 proxy.go:558] (14) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 11.947221ms)
  I0711 07:08:54.046863 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 10.229342ms)
  I0711 07:08:54.048801 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 11.813834ms)
  I0711 07:08:54.049681 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 12.830358ms)
  I0711 07:08:54.049856 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 12.956548ms)
  I0711 07:08:54.050005 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 13.123407ms)
  I0711 07:08:54.050281 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 13.436709ms)
  I0711 07:08:54.050390 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 13.453656ms)
  I0711 07:08:54.050401 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 13.678254ms)
  I0711 07:08:54.050790 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 13.756318ms)
  I0711 07:08:54.051435 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 14.517109ms)
  I0711 07:08:54.051857 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 15.071912ms)
  I0711 07:08:54.052137 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 15.087062ms)
  I0711 07:08:54.052608 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 15.640558ms)
  I0711 07:08:54.052693 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 15.692406ms)
  I0711 07:08:54.053389 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 16.437427ms)
  I0711 07:08:54.053702 20 proxy.go:558] (15) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 16.687425ms)
  I0711 07:08:54.058938 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 5.157232ms)
  I0711 07:08:54.059728 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 5.88302ms)
  I0711 07:08:54.059832 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 6.071692ms)
  I0711 07:08:54.060853 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.869817ms)
  I0711 07:08:54.061393 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 7.484959ms)
  I0711 07:08:54.061392 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 7.500042ms)
  I0711 07:08:54.062255 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 8.392987ms)
  I0711 07:08:54.062263 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 8.228907ms)
  I0711 07:08:54.062286 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 8.314563ms)
  I0711 07:08:54.062548 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 8.552182ms)
  I0711 07:08:54.062659 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 8.586994ms)
  I0711 07:08:54.063108 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 9.282499ms)
  I0711 07:08:54.063296 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 9.353343ms)
  I0711 07:08:54.063622 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 9.696688ms)
  I0711 07:08:54.064095 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 10.044534ms)
  I0711 07:08:54.065273 20 proxy.go:558] (16) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 11.256065ms)
  I0711 07:08:54.073059 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 7.646103ms)
  I0711 07:08:54.073289 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 7.921374ms)
  I0711 07:08:54.074289 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 8.758963ms)
  I0711 07:08:54.074836 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 9.289241ms)
  I0711 07:08:54.075362 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 9.799832ms)
  I0711 07:08:54.076612 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 10.992444ms)
  I0711 07:08:54.076636 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 11.155734ms)
  I0711 07:08:54.076940 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 11.647784ms)
  I0711 07:08:54.078279 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 12.849352ms)
  I0711 07:08:54.078444 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 12.997951ms)
  I0711 07:08:54.078520 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 13.039674ms)
  I0711 07:08:54.079072 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 13.576257ms)
  I0711 07:08:54.079241 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 13.606107ms)
  I0711 07:08:54.079767 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 14.184365ms)
  I0711 07:08:54.080133 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 14.533135ms)
  I0711 07:08:54.080462 20 proxy.go:558] (17) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 14.952324ms)
  I0711 07:08:54.084341 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 3.742514ms)
  I0711 07:08:54.084485 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 3.978709ms)
  I0711 07:08:54.086425 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 5.634585ms)
  I0711 07:08:54.086556 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 5.69912ms)
  I0711 07:08:54.086556 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 5.93001ms)
  I0711 07:08:54.086574 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 5.874573ms)
  I0711 07:08:54.086602 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.819628ms)
  I0711 07:08:54.087121 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 6.637457ms)
  I0711 07:08:54.087387 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 6.632331ms)
  I0711 07:08:54.087924 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 7.239873ms)
  I0711 07:08:54.088059 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 7.394501ms)
  I0711 07:08:54.088216 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 7.480428ms)
  I0711 07:08:54.088525 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 7.947989ms)
  I0711 07:08:54.088711 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 8.07119ms)
  I0711 07:08:54.089107 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 8.382471ms)
  I0711 07:08:54.089217 20 proxy.go:558] (18) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 8.413835ms)
  I0711 07:08:54.094468 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:443/proxy/tlsrewritem... (200; 5.220615ms)
  I0711 07:08:54.094681 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 5.080469ms)
  I0711 07:08:54.094704 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 5.265849ms)
  I0711 07:08:54.094779 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">test<... (200; 5.359554ms)
  I0711 07:08:54.095461 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname2/proxy/: bar (200; 6.131305ms)
  I0711 07:08:54.095551 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:462/proxy/: tls qux (200; 6.082893ms)
  I0711 07:08:54.095632 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/proxy-service-dmzcm-8rxgz/proxy/rewriteme">test</a> (200; 6.067998ms)
  I0711 07:08:54.095667 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/https:proxy-service-dmzcm-8rxgz:460/proxy/: tls baz (200; 6.119912ms)
  I0711 07:08:54.095996 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname2/proxy/: tls qux (200; 6.595964ms)
  I0711 07:08:54.096781 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname1/proxy/: foo (200; 7.295384ms)
  I0711 07:08:54.097675 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/services/https:proxy-service-dmzcm:tlsportname1/proxy/: tls baz (200; 8.168504ms)
  I0711 07:08:54.097700 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:162/proxy/: bar (200; 8.116133ms)
  I0711 07:08:54.097768 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:160/proxy/: foo (200; 8.151539ms)
  I0711 07:08:54.097811 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/: <a href="/api/v1/namespaces/proxy-2825/pods/http:proxy-service-dmzcm-8rxgz:1080/proxy/rewriteme">... (200; 8.260417ms)
  I0711 07:08:54.098537 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/services/http:proxy-service-dmzcm:portname2/proxy/: bar (200; 9.162256ms)
  I0711 07:08:54.099520 20 proxy.go:558] (19) /api/v1/namespaces/proxy-2825/services/proxy-service-dmzcm:portname1/proxy/: foo (200; 10.070496ms)
  STEP: deleting ReplicationController proxy-service-dmzcm in namespace proxy-2825, will wait for the garbage collector to delete the pods @ 07/11/24 07:08:54.099
  I0711 07:08:54.161108 20 resources.go:139] Deleting ReplicationController proxy-service-dmzcm took: 7.115378ms
  I0711 07:08:54.262111 20 resources.go:163] Terminating ReplicationController proxy-service-dmzcm pods took: 100.998285ms
  E0711 07:08:54.548849      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:08:55.549787      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:56.363182 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2825" for this suite. @ 07/11/24 07:08:56.367
• [4.626 seconds]
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 07/11/24 07:08:56.375
  I0711 07:08:56.375276 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename daemonsets @ 07/11/24 07:08:56.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:08:56.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:08:56.397
  I0711 07:08:56.419304 20 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 07/11/24 07:08:56.425
  I0711 07:08:56.428917 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:08:56.428988 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:08:56.432548 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 07:08:56.432579 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  E0711 07:08:56.550911      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:57.429677 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:08:57.429742 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:08:57.433394 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0711 07:08:57.433428 20 fixtures.go:130] Node ip-172-31-11-2 is running 0 daemon pod, expected 1
  E0711 07:08:57.551737      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:58.431195 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:08:58.431341 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:08:58.435585 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0711 07:08:58.435691 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 07/11/24 07:08:58.45
  STEP: Check that daemon pods images are updated. @ 07/11/24 07:08:58.46
  I0711 07:08:58.465591 20 daemon_set.go:1178] Wrong image for pod: daemon-set-5gq5f. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0711 07:08:58.465672 20 daemon_set.go:1178] Wrong image for pod: daemon-set-8j7jv. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0711 07:08:58.465693 20 daemon_set.go:1178] Wrong image for pod: daemon-set-jbvls. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0711 07:08:58.469435 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:08:58.469570 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0711 07:08:58.552458      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:08:59.465483 20 daemon_set.go:1178] Wrong image for pod: daemon-set-5gq5f. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0711 07:08:59.465628 20 daemon_set.go:1178] Wrong image for pod: daemon-set-8j7jv. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0711 07:08:59.465682 20 daemon_set.go:1183] Pod daemon-set-lwxl5 is not available
  I0711 07:08:59.469797 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:08:59.469921 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0711 07:08:59.552870      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:00.465854 20 daemon_set.go:1178] Wrong image for pod: daemon-set-8j7jv. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0711 07:09:00.465941 20 daemon_set.go:1183] Pod daemon-set-nqpq7 is not available
  I0711 07:09:00.469495 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:09:00.469551 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0711 07:09:00.553357      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:01.469338 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:09:01.469409 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0711 07:09:01.554506      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:02.469765 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:09:02.469806 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 07/11/24 07:09:02.469
  I0711 07:09:02.473513 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-72-118 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:09:02.473544 20 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-92-117 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I0711 07:09:02.477404 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I0711 07:09:02.477421 20 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 07/11/24 07:09:02.493
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5497, will wait for the garbage collector to delete the pods @ 07/11/24 07:09:02.493
  I0711 07:09:02.554730 20 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.81196ms
  E0711 07:09:02.554762      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:02.655298 20 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.561847ms
  E0711 07:09:03.555051      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:04.360556 20 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0711 07:09:04.360588 20 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0711 07:09:04.363513 20 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44276"},"items":null}

  I0711 07:09:04.366581 20 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44276"},"items":null}

  I0711 07:09:04.383668 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5497" for this suite. @ 07/11/24 07:09:04.388
• [8.020 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:392
  STEP: Creating a kubernetes client @ 07/11/24 07:09:04.395
  I0711 07:09:04.395528 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-publish-openapi @ 07/11/24 07:09:04.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:09:04.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:09:04.42
  STEP: set up a multi version CRD @ 07/11/24 07:09:04.422
  I0711 07:09:04.422923 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:09:04.555166      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:05.558706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:06.559303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 07/11/24 07:09:07.523
  STEP: check the new version name is served @ 07/11/24 07:09:07.539
  E0711 07:09:07.560211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 07/11/24 07:09:08.374
  E0711 07:09:08.560732      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 07/11/24 07:09:08.967
  E0711 07:09:09.561140      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:10.562056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:11.373220 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8218" for this suite. @ 07/11/24 07:09:11.38
• [6.993 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 07/11/24 07:09:11.388
  I0711 07:09:11.388780 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename aggregator @ 07/11/24 07:09:11.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:09:11.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:09:11.411
  I0711 07:09:11.414026 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Registering the sample API server. @ 07/11/24 07:09:11.414
  E0711 07:09:11.562209      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:11.719715 20 helpers.go:161] Found ClusterRoles; assuming RBAC is enabled.
  I0711 07:09:11.752210 20 deployment.go:222] deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0711 07:09:12.562517      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:13.563116      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:13.803614 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:14.563216      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:15.563303      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:15.808338 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:16.564293      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:17.564412      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:17.808700 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:18.565013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:19.565123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:19.809834 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:20.565649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:21.566289      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:21.809148 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:22.566962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:23.567070      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:23.809506 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:24.567669      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:25.567999      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:25.810218 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:26.568056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:27.568079      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:27.808510 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:28.568183      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:29.568417      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:29.808638 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:30.569100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:31.569552      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:31.809730 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:32.570560      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:33.570771      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:33.808519 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:34.571207      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:35.572139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:35.809310 20 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0711 07:09:36.572254      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:37.573073      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:09:37.931669 20 aggregator.go:749] Waited 114.380042ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 07/11/24 07:09:37.962
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 07/11/24 07:09:37.966
  STEP: List APIServices @ 07/11/24 07:09:37.972
  I0711 07:09:37.977815 20 aggregator.go:550] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 07/11/24 07:09:37.977
  I0711 07:09:37.989735 20 aggregator.go:575] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 07/11/24 07:09:37.989
  I0711 07:09:38.000358 20 aggregator.go:601] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.July, 11, 7, 9, 37, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 07/11/24 07:09:38
  I0711 07:09:38.003627 20 aggregator.go:619] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-07-11 07:09:37 +0000 UTC Passed all checks passed}
  I0711 07:09:38.003651 20 aggregator.go:615] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0711 07:09:38.003661 20 aggregator.go:625] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 07/11/24 07:09:38.003
  I0711 07:09:38.014027 20 aggregator.go:641] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-1531032610" @ 07/11/24 07:09:38.014
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 07/11/24 07:09:38.022
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 07/11/24 07:09:38.028
  STEP: Patch APIService Status @ 07/11/24 07:09:38.031
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 07/11/24 07:09:38.039
  I0711 07:09:38.044830 20 aggregator.go:719] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-07-11 07:09:37 +0000 UTC Passed all checks passed}
  I0711 07:09:38.044855 20 aggregator.go:719] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0711 07:09:38.044868 20 aggregator.go:715] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0711 07:09:38.044878 20 aggregator.go:725] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 07/11/24 07:09:38.044
  STEP: Confirm that the generated APIService has been deleted @ 07/11/24 07:09:38.056
  I0711 07:09:38.056041 20 aggregator.go:786] Requesting list of APIServices to confirm quantity
  I0711 07:09:38.059727 20 aggregator.go:796] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0711 07:09:38.059742 20 aggregator.go:738] APIService v1alpha1.wardle.example.com has been deleted.
  I0711 07:09:38.165895 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-2256" for this suite. @ 07/11/24 07:09:38.169
• [26.789 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 07/11/24 07:09:38.178
  I0711 07:09:38.178470 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-probe @ 07/11/24 07:09:38.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:09:38.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:09:38.208
  E0711 07:09:38.573789      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:39.574799      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:40.575796      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:41.576751      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:42.577735      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:43.578005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:44.578706      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:45.579556      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:46.579965      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:47.581018      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:48.581772      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:49.582056      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:50.583016      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:51.583114      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:52.584147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:53.584522      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:54.585098      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:55.585306      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:56.585403      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:57.585511      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:58.586320      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:09:59.586488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:10:00.287208 20 container_probe.go:92] Container started at 2024-07-11 07:09:41 +0000 UTC, pod became ready at 2024-07-11 07:09:58 +0000 UTC
  I0711 07:10:00.287307 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7626" for this suite. @ 07/11/24 07:10:00.293
• [22.122 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 07/11/24 07:10:00.3
  I0711 07:10:00.300949 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename statefulset @ 07/11/24 07:10:00.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:10:00.318
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:10:00.321
  STEP: Creating service test in namespace statefulset-7171 @ 07/11/24 07:10:00.324
  STEP: Creating a new StatefulSet @ 07/11/24 07:10:00.329
  I0711 07:10:00.342651 20 wait.go:40] Found 0 stateful pods, waiting for 3
  E0711 07:10:00.587319      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:01.587561      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:02.587766      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:03.587990      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:04.588133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:05.588204      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:06.588563      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:07.589101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:08.589385      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:09.589588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:10:10.344775 20 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0711 07:10:10.344826 20 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0711 07:10:10.344837 20 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0711 07:10:10.356548 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-7171 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0711 07:10:10.448716 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 07:10:10.448754 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 07:10:10.448765 20 statefulset.go:2184] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0711 07:10:10.590037      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:11.590395      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:12.590848      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:13.591015      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:14.591119      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:15.591249      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:16.591549      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:17.591685      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:18.591880      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:19.592003      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 07/11/24 07:10:20.459
  I0711 07:10:20.480622 20 statefulset.go:2241] Updating stateful set ss2
  STEP: Creating a new revision @ 07/11/24 07:10:20.48
  E0711 07:10:20.592821      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:21.592927      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:22.593015      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:23.593649      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:24.593851      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:25.594084      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:26.594359      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:27.594711      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:28.595331      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:29.595692      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 07/11/24 07:10:30.49
  I0711 07:10:30.495080 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-7171 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0711 07:10:30.585820 20 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0711 07:10:30.585861 20 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0711 07:10:30.585871 20 statefulset.go:2208] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0711 07:10:30.595725      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:31.596022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:32.596096      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:33.597120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:34.597261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:35.597373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:36.597525      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:37.597774      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:38.598042      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:39.598327      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:40.598557      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 07/11/24 07:10:40.602
  I0711 07:10:40.602726 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-7171 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0711 07:10:40.692077 20 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0711 07:10:40.692115 20 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0711 07:10:40.692125 20 statefulset.go:2184] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0711 07:10:41.598674      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:42.598915      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:43.599124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:44.599277      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:45.599752      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:46.599993      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:47.600091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:48.601023      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:49.601252      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:50.601446      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:10:50.723796 20 statefulset.go:2241] Updating stateful set ss2
  E0711 07:10:51.601568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:52.601677      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:53.601863      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:54.601962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:55.602517      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:56.602575      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:57.602666      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:58.602726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:10:59.602827      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:00.603360      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 07/11/24 07:11:00.733
  I0711 07:11:00.737952 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=statefulset-7171 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0711 07:11:00.825069 20 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0711 07:11:00.825108 20 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0711 07:11:00.825119 20 statefulset.go:2208] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0711 07:11:01.603455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:02.603563      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:03.603780      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:04.604097      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:05.604729      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:06.605447      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:07.605745      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:08.605945      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:09.606280      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:10.606564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:11:10.843055 20 statefulset.go:135] Deleting all statefulset in ns statefulset-7171
  I0711 07:11:10.846677 20 rest.go:150] Scaling statefulset ss2 to 0
  E0711 07:11:11.606956      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:12.606883      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:13.607057      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:14.607291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:15.607545      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:16.607941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:17.608038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:18.608127      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:19.609015      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:20.609118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:11:20.863537 20 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0711 07:11:20.866984 20 rest.go:88] Deleting statefulset ss2
  I0711 07:11:20.881117 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7171" for this suite. @ 07/11/24 07:11:20.884
• [80.591 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 07/11/24 07:11:20.891
  I0711 07:11:20.891831 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 07:11:20.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:11:20.908
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:11:20.911
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 07:11:21.048
  E0711 07:11:21.609681      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:22.609984      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:23.610118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:24.610329      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:11:25.076
  I0711 07:11:25.080058 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-7854f9c4-2bb8-4ef6-a0c0-341a41a18044 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 07:11:25.094
  I0711 07:11:25.116418 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1480" for this suite. @ 07/11/24 07:11:25.12
• [4.237 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:310
  STEP: Creating a kubernetes client @ 07/11/24 07:11:25.129
  I0711 07:11:25.129430 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename crd-publish-openapi @ 07/11/24 07:11:25.129
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:11:25.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:11:25.149
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 07/11/24 07:11:25.152
  I0711 07:11:25.152526 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:11:25.611358      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:26.612194      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:27.613011      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:28.613248      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:29.613368      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 07/11/24 07:11:30.109
  I0711 07:11:30.110366 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:11:30.613760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:11:31.319822 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  E0711 07:11:31.614058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:32.614452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:33.615226      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:34.615658      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:35.616091      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:11:36.335595 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1976" for this suite. @ 07/11/24 07:11:36.341
• [11.219 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 07/11/24 07:11:36.348
  I0711 07:11:36.348562 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename aggregateddiscovery @ 07/11/24 07:11:36.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:11:36.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:11:36.366
  I0711 07:11:36.371671 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-3374" for this suite. @ 07/11/24 07:11:36.375
• [0.034 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:420
  STEP: Creating a kubernetes client @ 07/11/24 07:11:36.382
  I0711 07:11:36.382599 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename job @ 07/11/24 07:11:36.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:11:36.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:11:36.401
  STEP: Creating Indexed job @ 07/11/24 07:11:36.403
  STEP: Ensuring job reaches completions @ 07/11/24 07:11:36.409
  E0711 07:11:36.616642      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:37.616725      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:38.617576      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:39.617764      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:40.618065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:41.618146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:42.618283      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:43.618438      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 07/11/24 07:11:44.413
  I0711 07:11:44.418312 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-106" for this suite. @ 07/11/24 07:11:44.421
• [8.047 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 07/11/24 07:11:44.429
  I0711 07:11:44.429651 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename runtimeclass @ 07/11/24 07:11:44.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:11:44.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:11:44.445
  STEP: Deleting RuntimeClass runtimeclass-7622-delete-me @ 07/11/24 07:11:44.452
  STEP: Waiting for the RuntimeClass to disappear @ 07/11/24 07:11:44.458
  I0711 07:11:44.468158 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7622" for this suite. @ 07/11/24 07:11:44.471
• [0.050 seconds]
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 07/11/24 07:11:44.48
  I0711 07:11:44.480231 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename secrets @ 07/11/24 07:11:44.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:11:44.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:11:44.499
  STEP: Creating secret with name s-test-opt-del-89366432-c112-4bbe-ad97-0852ff5e9325 @ 07/11/24 07:11:44.504
  STEP: Creating secret with name s-test-opt-upd-dee4e349-50c5-41f9-9bb7-c637aed84c11 @ 07/11/24 07:11:44.509
  STEP: Creating the pod @ 07/11/24 07:11:44.513
  E0711 07:11:44.618788      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:45.619415      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-89366432-c112-4bbe-ad97-0852ff5e9325 @ 07/11/24 07:11:46.565
  STEP: Updating secret s-test-opt-upd-dee4e349-50c5-41f9-9bb7-c637aed84c11 @ 07/11/24 07:11:46.572
  STEP: Creating secret with name s-test-opt-create-64f164a8-4a49-43c7-94cd-7deb58f01bff @ 07/11/24 07:11:46.577
  STEP: waiting to observe update in volume @ 07/11/24 07:11:46.581
  E0711 07:11:46.620133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:47.620222      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:48.621058      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:49.621278      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:50.621720      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:51.622177      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:52.623231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:53.623342      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:54.624131      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:55.624402      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:56.625389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:57.626106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:58.627053      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:11:59.627910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:00.628868      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:01.629857      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:02.630401      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:03.630525      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:04.630724      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:05.631539      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:06.632054      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:07.632161      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:08.632266      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:09.632350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:10.632464      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:11.632919      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:12.633014      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:13.633112      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:14.633301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:15.633350      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:16.633587      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:17.633803      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:18.633896      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:19.634624      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:20.634806      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:21.635568      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:22.635929      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:23.635961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:24.637005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:25.637678      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:26.638074      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:27.638580      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:28.638675      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:29.638855      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:30.639108      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:31.639419      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:32.639602      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:33.639723      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:34.639941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:35.640428      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:36.641146      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:37.641954      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:38.642463      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:39.642830      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:40.643047      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:41.644039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:42.645030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:43.645130      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:44.645443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:45.646430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:46.646910      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:47.647212      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:48.647327      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:49.647691      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:50.647845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:51.647957      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:52.648071      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:53.649036      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:54.649206      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:55.649543      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:56.650038      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:57.650506      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:58.650780      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:12:59.650902      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:00.651201      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:01.652239      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:02.652343      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:03.653012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:04.653176      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:05.653286      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:06.653611      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:07.653714      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:08.653803      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:13:08.977883 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6929" for this suite. @ 07/11/24 07:13:08.986
• [84.518 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 07/11/24 07:13:08.998
  I0711 07:13:08.998805 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename runtimeclass @ 07/11/24 07:13:08.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:13:09.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:13:09.032
  I0711 07:13:09.046241 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5683" for this suite. @ 07/11/24 07:13:09.05
• [0.059 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 07/11/24 07:13:09.057
  I0711 07:13:09.057761 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-runtime @ 07/11/24 07:13:09.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:13:09.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:13:09.074
  STEP: create the container @ 07/11/24 07:13:09.076
  W0711 07:13:09.086114      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 07/11/24 07:13:09.086
  E0711 07:13:09.654726      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:10.655570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 07/11/24 07:13:11.105
  STEP: the container should be terminated @ 07/11/24 07:13:11.109
  STEP: the termination message should be set @ 07/11/24 07:13:11.109
  I0711 07:13:11.109975 20 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 07/11/24 07:13:11.109
  I0711 07:13:11.126140 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-666" for this suite. @ 07/11/24 07:13:11.129
• [2.079 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:817
  STEP: Creating a kubernetes client @ 07/11/24 07:13:11.137
  I0711 07:13:11.137155 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 07:13:11.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:13:11.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:13:11.156
  STEP: Setting up server cert @ 07/11/24 07:13:11.179
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 07:13:11.449
  STEP: Deploying the webhook pod @ 07/11/24 07:13:11.461
  STEP: Wait for the deployment to be ready @ 07/11/24 07:13:11.474
  I0711 07:13:11.481561 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 07:13:11.655828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:12.656013      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 07:13:13.494
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 07:13:13.51
  E0711 07:13:13.656955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:13:14.511923 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 07/11/24 07:13:14.518
  I0711 07:13:14.570985 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-496" for this suite. @ 07/11/24 07:13:14.575
  STEP: Destroying namespace "webhook-markers-2420" for this suite. @ 07/11/24 07:13:14.583
• [3.454 seconds]
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 07/11/24 07:13:14.59
  I0711 07:13:14.590939 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename init-container @ 07/11/24 07:13:14.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:13:14.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:13:14.607
  STEP: creating the pod @ 07/11/24 07:13:14.61
  I0711 07:13:14.610274 20 init_container.go:374] PodSpec: initContainers in spec.initContainers
  E0711 07:13:14.657473      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:15.657622      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:16.657828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:17.657917      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:18.658162      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:19.658393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:20.658653      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:21.658861      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:22.659077      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:23.659373      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:24.659531      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:25.659603      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:26.659939      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:27.660518      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:28.660619      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:29.660941      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:30.661045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:31.661279      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:32.661341      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:33.661620      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:34.661709      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:35.662378      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:36.662766      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:37.662671      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:38.662633      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:39.663662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:40.663850      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:41.663955      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:42.665017      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:43.665145      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:44.665364      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:45.666386      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:46.666659      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:47.666781      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:48.666895      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:49.667139      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:50.667241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:51.667469      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:52.667636      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:53.667873      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:54.667961      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:55.668412      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:56.668512      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:57.669124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:13:58.669325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:13:58.864288 20 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d5bcebf0-b290-486f-ba8b-3a272dc27f94", GenerateName:"", Namespace:"init-container-2980", SelfLink:"", UID:"8515bc0d-18c8-41bc-9b99-0697614196b5", ResourceVersion:"45956", Generation:0, CreationTimestamp:time.Date(2024, time.July, 11, 7, 13, 14, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"610265874"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 7, 13, 14, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bca330), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.July, 11, 7, 13, 58, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000bca360), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-s9pgv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc001757b00), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-s9pgv", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-s9pgv", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-s9pgv", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001347f80), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-80-240", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0030fe700), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004f0c070)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004f0c090)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004f0c098), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004f0c09c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc005bd5630), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.July, 11, 7, 13, 15, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.July, 11, 7, 13, 14, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.July, 11, 7, 13, 14, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.July, 11, 7, 13, 14, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.July, 11, 7, 13, 14, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.80.240", HostIPs:[]v1.HostIP{v1.HostIP{IP:"172.31.80.240"}}, PodIP:"192.168.37.38", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.37.38"}}, StartTime:time.Date(2024, time.July, 11, 7, 13, 14, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000250230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000250380)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://d424b650f56321f3d89f94ce08c060a4e57d5f2f7a04bab68b75a6ae1026f89b", Started:(*bool)(0xc004f0c13f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001757b80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc004f0c145), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001757b60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc004f0c114), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I0711 07:13:58.864412 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2980" for this suite. @ 07/11/24 07:13:58.869
• [44.286 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 07/11/24 07:13:58.876
  I0711 07:13:58.876966 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename configmap @ 07/11/24 07:13:58.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:13:58.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:13:58.896
  STEP: Creating configMap with name cm-test-opt-del-b3970a2e-7899-48f0-834b-0566dca89b26 @ 07/11/24 07:13:58.901
  STEP: Creating configMap with name cm-test-opt-upd-0d1489b4-0f40-406c-914b-cac52cbec038 @ 07/11/24 07:13:58.907
  STEP: Creating the pod @ 07/11/24 07:13:58.911
  E0711 07:13:59.669433      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:00.669564      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-b3970a2e-7899-48f0-834b-0566dca89b26 @ 07/11/24 07:14:00.964
  STEP: Updating configmap cm-test-opt-upd-0d1489b4-0f40-406c-914b-cac52cbec038 @ 07/11/24 07:14:00.971
  STEP: Creating configMap with name cm-test-opt-create-fc4cf733-4364-47f5-8378-baefb27b94d1 @ 07/11/24 07:14:00.977
  STEP: waiting to observe update in volume @ 07/11/24 07:14:00.981
  E0711 07:14:01.669688      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:02.669913      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:03.670094      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:04.670291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:05.670494      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:06.670635      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:07.671615      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:08.671839      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:09.672778      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:10.672889      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:11.673808      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:12.673998      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:13.674586      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:14.674832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:15.675409      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:16.675488      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:17.676605      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:18.677197      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:19.677227      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:20.677669      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:21.677782      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:22.677928      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:23.678136      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:24.678671      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:25.679443      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:26.680124      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:27.680250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:28.680361      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:29.680467      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:30.680552      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:31.681100      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:32.681200      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:33.681310      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:34.681526      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:35.682235      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:36.682327      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:37.682586      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:38.683359      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:39.683933      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:40.684133      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:41.685225      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:42.685325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:43.686158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:44.686409      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:45.687040      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:46.687118      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:47.687272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:48.687374      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:49.687628      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:50.687828      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:51.688515      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:52.688627      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:53.688856      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:54.689106      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:55.690067      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:56.690141      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:57.690871      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:58.691096      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:14:59.692030      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:00.692108      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:01.692211      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:02.693232      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:03.694250      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:04.694393      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:05.694769      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:06.695510      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:07.696296      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:08.696416      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:09.696486      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:10.696593      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:11.697663      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:12.697864      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:13.697925      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:14.698142      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:15:15.347922 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5198" for this suite. @ 07/11/24 07:15:15.351
• [76.482 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1533
  STEP: Creating a kubernetes client @ 07/11/24 07:15:15.358
  I0711 07:15:15.358847 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 07:15:15.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:15:15.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:15:15.378
  STEP: creating Agnhost RC @ 07/11/24 07:15:15.38
  I0711 07:15:15.380372 20 kubectl.go:1540] namespace kubectl-2834
  I0711 07:15:15.380478 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2834 create -f -'
  I0711 07:15:15.460818 20 builder.go:146] stderr: ""
  I0711 07:15:15.460874 20 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 07/11/24 07:15:15.46
  E0711 07:15:15.698426      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:15:16.465910 20 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0711 07:15:16.465943 20 framework.go:733] Found 0 / 1
  E0711 07:15:16.699068      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:15:17.465717 20 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0711 07:15:17.465756 20 framework.go:733] Found 1 / 1
  I0711 07:15:17.465770 20 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0711 07:15:17.470126 20 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0711 07:15:17.470147 20 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0711 07:15:17.470153 20 kubectl.go:1547] wait on agnhost-primary startup in kubectl-2834 
  I0711 07:15:17.470258 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2834 logs agnhost-primary-7lwgb agnhost-primary'
  I0711 07:15:17.524592 20 builder.go:146] stderr: ""
  I0711 07:15:17.524648 20 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 07/11/24 07:15:17.524
  I0711 07:15:17.524722 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2834 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I0711 07:15:17.582124 20 builder.go:146] stderr: ""
  I0711 07:15:17.582172 20 builder.go:147] stdout: "service/rm2 exposed\n"
  I0711 07:15:17.590956 20 utils.go:1179] Service rm2 in namespace kubectl-2834 found.
  E0711 07:15:17.699244      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:18.699461      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 07/11/24 07:15:19.6
  I0711 07:15:19.600610 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-2834 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I0711 07:15:19.658564 20 builder.go:146] stderr: ""
  I0711 07:15:19.658709 20 builder.go:147] stdout: "service/rm3 exposed\n"
  I0711 07:15:19.664290 20 utils.go:1179] Service rm3 in namespace kubectl-2834 found.
  E0711 07:15:19.699757      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:20.699989      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:15:21.672463 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2834" for this suite. @ 07/11/24 07:15:21.676
• [6.325 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 07/11/24 07:15:21.683
  I0711 07:15:21.683618 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename projected @ 07/11/24 07:15:21.684
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:15:21.699
  E0711 07:15:21.700104      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:15:21.701
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 07:15:21.704
  E0711 07:15:22.700272      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:23.700389      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:24.700465      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:25.701439      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:15:25.727
  I0711 07:15:25.731156 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod downwardapi-volume-eec88741-9096-46ae-b617-cf5119829285 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 07:15:25.738
  I0711 07:15:25.754580 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8068" for this suite. @ 07/11/24 07:15:25.757
• [4.082 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 07/11/24 07:15:25.765
  I0711 07:15:25.765442 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename subpath @ 07/11/24 07:15:25.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:15:25.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:15:25.784
  STEP: Setting up data @ 07/11/24 07:15:25.786
  STEP: Creating pod pod-subpath-test-configmap-mcsq @ 07/11/24 07:15:25.795
  STEP: Creating a pod to test atomic-volume-subpath @ 07/11/24 07:15:25.795
  E0711 07:15:26.702186      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:27.702241      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:28.702343      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:29.702507      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:30.702553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:31.703257      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:32.703353      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:33.703426      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:34.703553      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:35.704431      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:36.704572      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:37.704748      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:38.704826      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:39.705039      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:40.705231      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:41.705541      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:42.706309      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:43.706504      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:44.706625      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:45.707291      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:46.710377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:47.710634      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:48.711324      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:49.711432      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:15:49.875
  I0711 07:15:49.879283 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod pod-subpath-test-configmap-mcsq container test-container-subpath-configmap-mcsq: <nil>
  STEP: delete the pod @ 07/11/24 07:15:49.89
  STEP: Deleting pod pod-subpath-test-configmap-mcsq @ 07/11/24 07:15:49.909
  I0711 07:15:49.909119 20 delete.go:62] Deleting pod "pod-subpath-test-configmap-mcsq" in namespace "subpath-6477"
  I0711 07:15:49.912905 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6477" for this suite. @ 07/11/24 07:15:49.916
• [24.159 seconds]
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 07/11/24 07:15:49.924
  I0711 07:15:49.924401 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename disruption @ 07/11/24 07:15:49.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:15:49.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:15:49.943
  STEP: creating the pdb @ 07/11/24 07:15:49.945
  STEP: Waiting for the pdb to be processed @ 07/11/24 07:15:49.949
  E0711 07:15:50.711656      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:51.711975      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 07/11/24 07:15:51.954
  STEP: Waiting for the pdb to be processed @ 07/11/24 07:15:51.964
  E0711 07:15:52.712147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:53.712261      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 07/11/24 07:15:53.969
  STEP: Waiting for the pdb to be processed @ 07/11/24 07:15:53.979
  STEP: Waiting for the pdb to be deleted @ 07/11/24 07:15:53.991
  I0711 07:15:53.994509 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7553" for this suite. @ 07/11/24 07:15:53.998
• [4.082 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 07/11/24 07:15:54.006
  I0711 07:15:54.006545 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename replicaset @ 07/11/24 07:15:54.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:15:54.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:15:54.022
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 07/11/24 07:15:54.024
  E0711 07:15:54.712352      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:15:55.712588      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 07/11/24 07:15:56.045
  STEP: Then the orphan pod is adopted @ 07/11/24 07:15:56.051
  E0711 07:15:56.712665      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 07/11/24 07:15:57.06
  I0711 07:15:57.064941 20 resource.go:87] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 07/11/24 07:15:57.079
  E0711 07:15:57.712761      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:15:58.090649 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4752" for this suite. @ 07/11/24 07:15:58.094
• [4.096 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1693
  STEP: Creating a kubernetes client @ 07/11/24 07:15:58.102
  I0711 07:15:58.102677 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 07:15:58.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:15:58.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:15:58.12
  STEP: creating Agnhost RC @ 07/11/24 07:15:58.122
  I0711 07:15:58.122974 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-1100 create -f -'
  I0711 07:15:58.201362 20 builder.go:146] stderr: ""
  I0711 07:15:58.201464 20 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 07/11/24 07:15:58.201
  E0711 07:15:58.712763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:15:59.205369 20 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0711 07:15:59.205399 20 framework.go:733] Found 1 / 1
  I0711 07:15:59.205414 20 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 07/11/24 07:15:59.205
  I0711 07:15:59.210679 20 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0711 07:15:59.210696 20 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0711 07:15:59.210746 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-1100 patch pod agnhost-primary-h5b24 -p {"metadata":{"annotations":{"x":"y"}}}'
  I0711 07:15:59.261974 20 builder.go:146] stderr: ""
  I0711 07:15:59.262020 20 builder.go:147] stdout: "pod/agnhost-primary-h5b24 patched\n"
  STEP: checking annotations @ 07/11/24 07:15:59.262
  I0711 07:15:59.266100 20 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0711 07:15:59.266118 20 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0711 07:15:59.266247 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1100" for this suite. @ 07/11/24 07:15:59.269
• [1.176 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 07/11/24 07:15:59.279
  I0711 07:15:59.279030 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename sched-pred @ 07/11/24 07:15:59.279
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:15:59.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:15:59.299
  I0711 07:15:59.300976 20 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0711 07:15:59.308632 20 util.go:400] Waiting for terminating namespaces to be deleted...
  I0711 07:15:59.311908 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-11-2 before test
  I0711 07:15:59.317206 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-vst4d from ingress-nginx-kubernetes-worker started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.317225 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 07:15:59.317231 20 predicates.go:887] calico-node-9r7js from kube-system started at 2024-07-11 05:31:26 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.317236 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 07:15:59.317311 20 predicates.go:887] coredns-5c6d979c47-sb7z6 from kube-system started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.317318 20 predicates.go:889] 	Container coredns ready: true, restart count 0
  I0711 07:15:59.317324 20 predicates.go:887] kube-state-metrics-77cc559b76-46cmg from kube-system started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.317329 20 predicates.go:889] 	Container kube-state-metrics ready: true, restart count 1
  I0711 07:15:59.317362 20 predicates.go:887] metrics-server-v0.7.0-7995f698bf-5zlw4 from kube-system started at 2024-07-11 05:25:49 +0000 UTC (2 container statuses recorded)
  I0711 07:15:59.317367 20 predicates.go:889] 	Container metrics-server ready: true, restart count 0
  I0711 07:15:59.317373 20 predicates.go:889] 	Container metrics-server-nanny ready: true, restart count 0
  I0711 07:15:59.317378 20 predicates.go:887] dashboard-metrics-scraper-55584b484c-j4mdq from kubernetes-dashboard started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.317385 20 predicates.go:889] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I0711 07:15:59.317391 20 predicates.go:887] kubernetes-dashboard-6fd7bf4447-4xclp from kubernetes-dashboard started at 2024-07-11 05:25:49 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.317396 20 predicates.go:889] 	Container kubernetes-dashboard ready: true, restart count 1
  I0711 07:15:59.317402 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-fccgk from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 07:15:59.317407 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 07:15:59.317437 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0711 07:15:59.317450 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-17-237 before test
  I0711 07:15:59.322508 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-7fjdd from ingress-nginx-kubernetes-worker started at 2024-07-11 05:31:54 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.322529 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 07:15:59.322536 20 predicates.go:887] calico-node-795zl from kube-system started at 2024-07-11 05:31:35 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.322541 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 07:15:59.322557 20 predicates.go:887] agnhost-primary-h5b24 from kubectl-1100 started at 2024-07-11 07:15:58 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.322562 20 predicates.go:889] 	Container agnhost-primary ready: true, restart count 0
  I0711 07:15:59.322567 20 predicates.go:887] sonobuoy-e2e-job-46eff94557cb4446 from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 07:15:59.322579 20 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0711 07:15:59.322584 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 07:15:59.322589 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-ll2lq from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 07:15:59.322596 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 07:15:59.322600 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0711 07:15:59.322606 20 predicates.go:121] 
  Logging pods the apiserver thinks is on node ip-172-31-80-240 before test
  I0711 07:15:59.327398 20 predicates.go:887] nginx-ingress-controller-kubernetes-worker-w7fxm from ingress-nginx-kubernetes-worker started at 2024-07-11 06:25:51 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.327409 20 predicates.go:889] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I0711 07:15:59.327415 20 predicates.go:887] calico-node-fcrzw from kube-system started at 2024-07-11 05:32:46 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.327420 20 predicates.go:889] 	Container calico-node ready: true, restart count 0
  I0711 07:15:59.327425 20 predicates.go:887] pod-adoption-release from replicaset-4752 started at 2024-07-11 07:15:54 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.327429 20 predicates.go:889] 	Container pod-adoption-release ready: true, restart count 0
  I0711 07:15:59.327434 20 predicates.go:887] pod-adoption-release-sv25j from replicaset-4752 started at 2024-07-11 07:15:57 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.327439 20 predicates.go:889] 	Container pod-adoption-release ready: true, restart count 0
  I0711 07:15:59.327444 20 predicates.go:887] sonobuoy from sonobuoy started at 2024-07-11 05:34:19 +0000 UTC (1 container statuses recorded)
  I0711 07:15:59.327448 20 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0711 07:15:59.327464 20 predicates.go:887] sonobuoy-systemd-logs-daemon-set-d7bc6a6ac9e24e58-9fdzf from sonobuoy started at 2024-07-11 05:34:21 +0000 UTC (2 container statuses recorded)
  I0711 07:15:59.327468 20 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0711 07:15:59.327473 20 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 07/11/24 07:15:59.327
  E0711 07:15:59.713430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:00.713627      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 07/11/24 07:16:01.348
  STEP: Trying to apply a random label on the found node. @ 07/11/24 07:16:01.362
  STEP: verifying the node has the label kubernetes.io/e2e-8c8eb58c-ec9b-42eb-8d3b-3b3c0c69bfcc 42 @ 07/11/24 07:16:01.372
  STEP: Trying to relaunch the pod, now with labels. @ 07/11/24 07:16:01.376
  E0711 07:16:01.713777      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:02.713838      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-8c8eb58c-ec9b-42eb-8d3b-3b3c0c69bfcc off the node ip-172-31-17-237 @ 07/11/24 07:16:03.401
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-8c8eb58c-ec9b-42eb-8d3b-3b3c0c69bfcc @ 07/11/24 07:16:03.412
  I0711 07:16:03.416235 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-107" for this suite. @ 07/11/24 07:16:03.43
• [4.162 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 07/11/24 07:16:03.441
  I0711 07:16:03.441243 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 07:16:03.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:03.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:03.555
  STEP: creating the pod @ 07/11/24 07:16:03.558
  STEP: submitting the pod to kubernetes @ 07/11/24 07:16:03.558
  STEP: verifying QOS class is set on the pod @ 07/11/24 07:16:03.568
  I0711 07:16:03.574677 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3340" for this suite. @ 07/11/24 07:16:03.578
• [0.144 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 07/11/24 07:16:03.585
  I0711 07:16:03.585841 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename resourcequota @ 07/11/24 07:16:03.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:03.601
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:03.603
  STEP: Counting existing ResourceQuota @ 07/11/24 07:16:03.606
  E0711 07:16:03.714718      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:04.715696      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:05.716444      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:06.716466      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:07.717176      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 07/11/24 07:16:08.61
  STEP: Ensuring resource quota status is calculated @ 07/11/24 07:16:08.617
  E0711 07:16:08.717671      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:09.718026      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:16:10.621842 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-107" for this suite. @ 07/11/24 07:16:10.628
• [7.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 07/11/24 07:16:10.635
  I0711 07:16:10.635663 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename var-expansion @ 07/11/24 07:16:10.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:10.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:10.653
  E0711 07:16:10.718565      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:11.719074      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:16:12.677513 20 delete.go:62] Deleting pod "var-expansion-69b45039-e463-4e5f-b06d-104258a437b8" in namespace "var-expansion-6953"
  I0711 07:16:12.688054 20 delete.go:70] Wait up to 5m0s for pod "var-expansion-69b45039-e463-4e5f-b06d-104258a437b8" to be fully deleted
  E0711 07:16:12.719292      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:13.719479      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:16:14.696891 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6953" for this suite. @ 07/11/24 07:16:14.701
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 07/11/24 07:16:14.71
  I0711 07:16:14.710081 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubelet-test @ 07/11/24 07:16:14.71
  E0711 07:16:14.720155      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:14.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:14.731
  E0711 07:16:15.720721      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:16.720879      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:16:16.761940 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-137" for this suite. @ 07/11/24 07:16:16.766
• [2.063 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 07/11/24 07:16:16.772
  I0711 07:16:16.772933 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename chunking @ 07/11/24 07:16:16.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:16.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:16.792
  STEP: creating a large number of resources @ 07/11/24 07:16:16.794
  E0711 07:16:17.721292      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:18.722143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:19.722454      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:20.722700      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:21.722769      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:22.723189      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:23.723585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:24.724123      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:25.724755      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:26.725069      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:27.725807      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:28.726185      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:29.726325      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:30.726763      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:31.727215      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:32.728143      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:33.729081      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 07/11/24 07:16:34.484
  I0711 07:16:34.528699 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0711 07:16:34.578622 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0711 07:16:34.628324 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0711 07:16:34.678718 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0711 07:16:34.728538 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  E0711 07:16:34.729504      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:16:34.778006 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0711 07:16:34.829194 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0711 07:16:34.879849 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0711 07:16:34.927930 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0711 07:16:34.978898 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0711 07:16:35.029489 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0711 07:16:35.078292 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0711 07:16:35.127568 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0711 07:16:35.179116 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0711 07:16:35.228888 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0711 07:16:35.279002 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0711 07:16:35.329216 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0711 07:16:35.384089 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0711 07:16:35.428964 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0711 07:16:35.479471 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0711 07:16:35.528075 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0711 07:16:35.579151 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0711 07:16:35.629454 20 chunking.go:98] Retrieved 17/17 results with rv 47169 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNjksInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0711 07:16:35.677936 20 chunking.go:98] Retrieved 9/17 results with rv 47169 and continue 
  I0711 07:16:35.729025 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  E0711 07:16:35.729952      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:16:35.779053 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0711 07:16:35.828674 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0711 07:16:35.879081 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0711 07:16:35.929625 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0711 07:16:35.978096 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0711 07:16:36.029859 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0711 07:16:36.079417 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0711 07:16:36.128143 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0711 07:16:36.179375 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0711 07:16:36.228987 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0711 07:16:36.278889 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0711 07:16:36.329394 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0711 07:16:36.378585 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0711 07:16:36.427967 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0711 07:16:36.478781 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0711 07:16:36.529844 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I0711 07:16:36.578270 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0711 07:16:36.629289 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0711 07:16:36.680152 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0711 07:16:36.728126 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  E0711 07:16:36.730163      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:16:36.779407 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0711 07:16:36.829079 20 chunking.go:98] Retrieved 17/17 results with rv 47173 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzMsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0711 07:16:36.878470 20 chunking.go:98] Retrieved 9/17 results with rv 47173 and continue 
  I0711 07:16:36.930859 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I0711 07:16:36.980711 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I0711 07:16:37.028116 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I0711 07:16:37.079642 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I0711 07:16:37.129813 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I0711 07:16:37.178424 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I0711 07:16:37.228863 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I0711 07:16:37.278619 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I0711 07:16:37.328196 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I0711 07:16:37.379364 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I0711 07:16:37.429796 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I0711 07:16:37.478128 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I0711 07:16:37.528627 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I0711 07:16:37.579007 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I0711 07:16:37.628596 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I0711 07:16:37.678227 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I0711 07:16:37.728663 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  E0711 07:16:37.730664      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:16:37.778291 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I0711 07:16:37.828047 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I0711 07:16:37.879315 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I0711 07:16:37.927844 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I0711 07:16:37.978626 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I0711 07:16:38.028775 20 chunking.go:98] Retrieved 17/17 results with rv 47176 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDcxNzYsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I0711 07:16:38.078465 20 chunking.go:98] Retrieved 9/17 results with rv 47176 and continue 
  STEP: retrieving those results all at once @ 07/11/24 07:16:38.078
  I0711 07:16:38.134858 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-5692" for this suite. @ 07/11/24 07:16:38.179
• [21.459 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:833
  STEP: Creating a kubernetes client @ 07/11/24 07:16:38.232
  I0711 07:16:38.232824 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename job @ 07/11/24 07:16:38.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:38.249
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:38.252
  STEP: Creating a job @ 07/11/24 07:16:38.254
  STEP: Ensure pods equal to parallelism count is attached to the job @ 07/11/24 07:16:38.259
  E0711 07:16:38.732066      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:39.732210      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 07/11/24 07:16:40.265
  STEP: updating /status @ 07/11/24 07:16:40.273
  STEP: get /status @ 07/11/24 07:16:40.281
  I0711 07:16:40.285367 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-922" for this suite. @ 07/11/24 07:16:40.288
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 07/11/24 07:16:40.295
  I0711 07:16:40.295923 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename containers @ 07/11/24 07:16:40.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:40.311
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:40.314
  STEP: Creating a pod to test override command @ 07/11/24 07:16:40.316
  E0711 07:16:40.733045      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:41.733171      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:16:42.337
  I0711 07:16:42.341732 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod client-containers-b1cbd975-abf2-4e66-a57b-ef19640b1ecc container agnhost-container: <nil>
  STEP: delete the pod @ 07/11/24 07:16:42.35
  I0711 07:16:42.369705 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3698" for this suite. @ 07/11/24 07:16:42.374
• [2.086 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 07/11/24 07:16:42.381
  I0711 07:16:42.381945 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename deployment @ 07/11/24 07:16:42.382
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:42.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:42.402
  I0711 07:16:42.404523 20 deployment.go:1645] Creating simple deployment test-new-deployment
  I0711 07:16:42.424989 20 deployment.go:222] deployment "test-new-deployment" doesn't have the required revision set
  E0711 07:16:42.733286      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:43.733369      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 07/11/24 07:16:44.44
  STEP: updating a scale subresource @ 07/11/24 07:16:44.443
  STEP: verifying the deployment Spec.Replicas was modified @ 07/11/24 07:16:44.45
  STEP: Patch a scale subresource @ 07/11/24 07:16:44.453
  I0711 07:16:44.474666 20 deployment.go:633] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5583",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "871b9947-50e2-41e3-8f6f-c01c2b0b96df",
      ResourceVersion: (string) (len=5) "47505",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856279002,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279002,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279003,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279003,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279003,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279003,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279002,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-77db57d8df\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0711 07:16:44.483243 20 deployment.go:39] New ReplicaSet "test-new-deployment-77db57d8df" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-77db57d8df",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5583",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "27ae3af2-4968-453e-9b2f-1368d9bd9bc1",
      ResourceVersion: (string) (len=5) "47511",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856279002,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "4",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "5",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "871b9947-50e2-41e3-8f6f-c01c2b0b96df",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279003,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279004,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 38 37 31 62 39 39  34 37 2d 35 30 65 32 2d  |\"871b9947-50e2-|
              00000120  34 31 65 33 2d 38 66 36  66 2d 63 30 31 63 32 62  |41e3-8f6f-c01c2b|
              00000130  30 62 39 36 64 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0b96df\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(4),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0711 07:16:44.489115 20 deployment.go:67] Pod "test-new-deployment-77db57d8df-fq8nl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-77db57d8df-fq8nl",
      GenerateName: (string) (len=31) "test-new-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5583",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "201f8674-e01b-47fc-ae14-012fe416473a",
      ResourceVersion: (string) (len=5) "47509",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856279004,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-77db57d8df",
          UID: (types.UID) (len=36) "27ae3af2-4968-453e-9b2f-1368d9bd9bc1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279004,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 37  61 65 33 61 66 32 2d 34  |d\":\"27ae3af2-4|
              00000090  39 36 38 2d 34 35 33 65  2d 39 62 32 66 2d 31 33  |968-453e-9b2f-13|
              000000a0  36 38 64 39 62 64 39 62  63 31 5c 22 7d 22 3a 7b  |68d9bd9bc1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-srdsl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-srdsl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-237",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279004,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 07:16:44.490350 20 deployment.go:67] Pod "test-new-deployment-77db57d8df-nw2j9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-77db57d8df-nw2j9",
      GenerateName: (string) (len=31) "test-new-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-5583",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "98ef9b45-0887-475c-bb3a-6419105a9bec",
      ResourceVersion: (string) (len=5) "47269",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856279002,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-77db57d8df",
          UID: (types.UID) (len=36) "27ae3af2-4968-453e-9b2f-1368d9bd9bc1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279002,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 37  61 65 33 61 66 32 2d 34  |d\":\"27ae3af2-4|
              00000090  39 36 38 2d 34 35 33 65  2d 39 62 32 66 2d 31 33  |968-453e-9b2f-13|
              000000a0  36 38 64 39 62 64 39 62  63 31 5c 22 7d 22 3a 7b  |68d9bd9bc1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279003,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 33 37  2e 34 39 5c 22 7d 22 3a  |2.168.37.49\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9xvvs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9xvvs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-240",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279003,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279002,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279003,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279003,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63856279002,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.240",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.80.240"
        }
      },
      PodIP: (string) (len=13) "192.168.37.49",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.37.49"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63856279002,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63856279002,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://10f3ce122b590fafd1a96e7054062561a8a0544ce2f12d9501d9839bffb0e140",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0711 07:16:44.491753 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5583" for this suite. @ 07/11/24 07:16:44.498
• [2.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 07/11/24 07:16:44.509
  I0711 07:16:44.509071 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename podtemplate @ 07/11/24 07:16:44.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:44.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:44.532
  I0711 07:16:44.589301 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9553" for this suite. @ 07/11/24 07:16:44.593
• [0.092 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 07/11/24 07:16:44.601
  I0711 07:16:44.601464 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename watch @ 07/11/24 07:16:44.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:44.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:44.618
  STEP: creating a watch on configmaps with a certain label @ 07/11/24 07:16:44.621
  STEP: creating a new configmap @ 07/11/24 07:16:44.622
  STEP: modifying the configmap once @ 07/11/24 07:16:44.627
  STEP: changing the label value of the configmap @ 07/11/24 07:16:44.634
  STEP: Expecting to observe a delete notification for the watched object @ 07/11/24 07:16:44.642
  I0711 07:16:44.643081 20 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4654  f69b8909-3798-4ff7-9cbd-c3865fdd2f1d 47559 0 2024-07-11 07:16:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-07-11 07:16:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 07:16:44.643242 20 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4654  f69b8909-3798-4ff7-9cbd-c3865fdd2f1d 47562 0 2024-07-11 07:16:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-07-11 07:16:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 07:16:44.643354 20 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4654  f69b8909-3798-4ff7-9cbd-c3865fdd2f1d 47564 0 2024-07-11 07:16:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-07-11 07:16:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 07/11/24 07:16:44.643
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 07/11/24 07:16:44.651
  E0711 07:16:44.734117      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:45.735006      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:46.735101      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:47.735229      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:48.735513      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:49.735585      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:50.735982      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:51.736192      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:52.736294      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:53.737022      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 07/11/24 07:16:54.653
  STEP: modifying the configmap a third time @ 07/11/24 07:16:54.662
  STEP: deleting the configmap @ 07/11/24 07:16:54.67
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 07/11/24 07:16:54.677
  I0711 07:16:54.677633 20 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4654  f69b8909-3798-4ff7-9cbd-c3865fdd2f1d 47832 0 2024-07-11 07:16:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-07-11 07:16:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 07:16:54.677766 20 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4654  f69b8909-3798-4ff7-9cbd-c3865fdd2f1d 47833 0 2024-07-11 07:16:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-07-11 07:16:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 07:16:54.677882 20 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4654  f69b8909-3798-4ff7-9cbd-c3865fdd2f1d 47834 0 2024-07-11 07:16:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-07-11 07:16:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0711 07:16:54.678002 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4654" for this suite. @ 07/11/24 07:16:54.682
• [10.090 seconds]
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 07/11/24 07:16:54.691
  I0711 07:16:54.691337 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename downward-api @ 07/11/24 07:16:54.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:54.706
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:54.709
  STEP: Creating a pod to test downward API volume plugin @ 07/11/24 07:16:54.711
  E0711 07:16:54.737527      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:55.737850      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:56.738723      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:16:57.738894      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:16:58.737
  E0711 07:16:58.739522      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:16:58.740745 20 output.go:196] Trying to get logs from node ip-172-31-80-240 pod downwardapi-volume-51305afb-2abe-4ed6-8aad-5f2ff120d038 container client-container: <nil>
  STEP: delete the pod @ 07/11/24 07:16:58.752
  I0711 07:16:58.772421 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-691" for this suite. @ 07/11/24 07:16:58.78
• [4.098 seconds]
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 07/11/24 07:16:58.789
  I0711 07:16:58.789666 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename dns @ 07/11/24 07:16:58.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:16:58.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:16:58.805
  STEP: Creating a test headless service @ 07/11/24 07:16:58.808
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9593.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9593.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9593.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9593.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9593.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9593.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9593.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9593.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9593.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9593.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 32.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.32_udp@PTR;check="$$(dig +tcp +noall +answer +search 32.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.32_tcp@PTR;sleep 1; done
   @ 07/11/24 07:16:58.829
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9593.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9593.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9593.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9593.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9593.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9593.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9593.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9593.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9593.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9593.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 32.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.32_udp@PTR;check="$$(dig +tcp +noall +answer +search 32.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.32_tcp@PTR;sleep 1; done
   @ 07/11/24 07:16:58.829
  STEP: creating a pod to probe DNS @ 07/11/24 07:16:58.829
  STEP: submitting the pod to kubernetes @ 07/11/24 07:16:58.829
  E0711 07:16:59.739991      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:00.740088      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 07/11/24 07:17:00.855
  STEP: looking for the results for each expected name from probers @ 07/11/24 07:17:00.859
  I0711 07:17:00.863841 20 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-9593.svc.cluster.local from pod dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26: the server could not find the requested resource (get pods dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26)
  I0711 07:17:00.868447 20 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-9593.svc.cluster.local from pod dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26: the server could not find the requested resource (get pods dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26)
  I0711 07:17:00.872641 20 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local from pod dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26: the server could not find the requested resource (get pods dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26)
  I0711 07:17:00.876387 20 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local from pod dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26: the server could not find the requested resource (get pods dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26)
  I0711 07:17:00.894790 20 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-9593.svc.cluster.local from pod dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26: the server could not find the requested resource (get pods dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26)
  I0711 07:17:00.898696 20 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-9593.svc.cluster.local from pod dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26: the server could not find the requested resource (get pods dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26)
  I0711 07:17:00.902322 20 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local from pod dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26: the server could not find the requested resource (get pods dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26)
  I0711 07:17:00.905932 20 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local from pod dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26: the server could not find the requested resource (get pods dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26)
  I0711 07:17:00.922116 20 dns_common.go:489] Lookups using dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26 failed for: [wheezy_udp@dns-test-service.dns-9593.svc.cluster.local wheezy_tcp@dns-test-service.dns-9593.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local jessie_udp@dns-test-service.dns-9593.svc.cluster.local jessie_tcp@dns-test-service.dns-9593.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9593.svc.cluster.local]

  I0711 07:17:00.929679 20 dns_common.go:495] Pod client logs for webserver: 
  I0711 07:17:00.935616 20 dns_common.go:495] Pod client logs for querier: 
  I0711 07:17:00.941765 20 dns_common.go:495] Pod client logs for jessie-querier: 
  E0711 07:17:01.741096      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:02.741246      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:03.741339      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:04.741441      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:05.741791      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:17:05.924559 20 dns_common.go:527] DNS probes using dns-9593/dns-test-3cd0c52a-ad9d-4758-a602-089dea955b26 succeeded

  STEP: deleting the pod @ 07/11/24 07:17:05.924
  STEP: deleting the test service @ 07/11/24 07:17:05.939
  STEP: deleting the test headless service @ 07/11/24 07:17:05.962
  I0711 07:17:05.978067 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9593" for this suite. @ 07/11/24 07:17:05.982
• [7.199 seconds]
------------------------------
S
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 07/11/24 07:17:05.989
  I0711 07:17:05.989016 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 07/11/24 07:17:05.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:06.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:06.005
  STEP: creating a target pod @ 07/11/24 07:17:06.007
  E0711 07:17:06.741914      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:07.742247      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 07/11/24 07:17:08.033
  E0711 07:17:08.743165      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:09.743661      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 07/11/24 07:17:10.05
  I0711 07:17:10.050775 20 exec_util.go:55] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-7237 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:17:10.050792 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:17:10.051295 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:17:10.051332 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-7237/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0711 07:17:10.099429 20 exec_util.go:106] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 07/11/24 07:17:10.107
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 07/11/24 07:17:10.111
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 07/11/24 07:17:10.123
  I0711 07:17:10.127847 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-7237" for this suite. @ 07/11/24 07:17:10.131
• [4.151 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 07/11/24 07:17:10.14
  I0711 07:17:10.140419 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 07/11/24 07:17:10.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:10.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:10.156
  STEP: create the container to handle the HTTPGet hook request. @ 07/11/24 07:17:10.162
  E0711 07:17:10.744487      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:11.744764      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 07/11/24 07:17:12.187
  E0711 07:17:12.745377      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:13.745570      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 07/11/24 07:17:14.208
  E0711 07:17:14.745750      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:15.746452      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 07/11/24 07:17:16.227
  I0711 07:17:16.234085 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1326" for this suite. @ 07/11/24 07:17:16.238
• [6.106 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 07/11/24 07:17:16.246
  I0711 07:17:16.246559 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename svcaccounts @ 07/11/24 07:17:16.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:16.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:16.266
  I0711 07:17:16.271892 20 service_accounts.go:754] Got root ca configmap in namespace "svcaccounts-7814"
  I0711 07:17:16.277969 20 service_accounts.go:757] Deleted root ca configmap in namespace "svcaccounts-7814"
  E0711 07:17:16.746623      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 07/11/24 07:17:16.778
  I0711 07:17:16.782645 20 service_accounts.go:771] Recreated root ca configmap in namespace "svcaccounts-7814"
  I0711 07:17:16.787961 20 service_accounts.go:782] Updated root ca configmap in namespace "svcaccounts-7814"
  STEP: waiting for the root ca configmap reconciled @ 07/11/24 07:17:17.288
  I0711 07:17:17.293089 20 service_accounts.go:800] Reconciled root ca configmap in namespace "svcaccounts-7814"
  I0711 07:17:17.293236 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7814" for this suite. @ 07/11/24 07:17:17.298
• [1.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 07/11/24 07:17:17.307
  I0711 07:17:17.307931 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pods @ 07/11/24 07:17:17.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:17.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:17.323
  STEP: creating pod @ 07/11/24 07:17:17.325
  E0711 07:17:17.746753      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:18.747005      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:17:19.353345 20 pods.go:83] Pod pod-hostip-ddeb0e80-9c24-46a3-a47b-74039876344d has hostIP: 172.31.17.237
  I0711 07:17:19.353448 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-94" for this suite. @ 07/11/24 07:17:19.356
• [2.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1858
  STEP: Creating a kubernetes client @ 07/11/24 07:17:19.363
  I0711 07:17:19.363371 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename kubectl @ 07/11/24 07:17:19.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:19.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:19.382
  STEP: Starting the proxy @ 07/11/24 07:17:19.384
  I0711 07:17:19.384605 20 util.go:592] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=kubectl-5577 proxy --unix-socket=/tmp/kubectl-proxy-unix834282411/test'
  STEP: retrieving proxy /api/ output @ 07/11/24 07:17:19.415
  I0711 07:17:19.416154 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5577" for this suite. @ 07/11/24 07:17:19.42
• [0.068 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 07/11/24 07:17:19.431
  I0711 07:17:19.431225 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename webhook @ 07/11/24 07:17:19.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:19.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:19.446
  STEP: Setting up server cert @ 07/11/24 07:17:19.469
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 07/11/24 07:17:19.725
  STEP: Deploying the webhook pod @ 07/11/24 07:17:19.734
  E0711 07:17:19.747357      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Wait for the deployment to be ready @ 07/11/24 07:17:19.748
  I0711 07:17:19.754766 20 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0711 07:17:20.747773      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:21.747962      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 07/11/24 07:17:21.766
  STEP: Verifying the service has paired with the endpoint @ 07/11/24 07:17:21.782
  E0711 07:17:22.748120      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:17:22.783429 20 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 07/11/24 07:17:22.856
  STEP: Creating a configMap that should be mutated @ 07/11/24 07:17:22.865
  STEP: Deleting the collection of validation webhooks @ 07/11/24 07:17:22.886
  STEP: Creating a configMap that should not be mutated @ 07/11/24 07:17:22.945
  I0711 07:17:23.005724 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-367" for this suite. @ 07/11/24 07:17:23.01
  STEP: Destroying namespace "webhook-markers-7805" for this suite. @ 07/11/24 07:17:23.021
• [3.598 seconds]
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 07/11/24 07:17:23.029
  I0711 07:17:23.029071 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename disruption @ 07/11/24 07:17:23.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:23.054
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:23.062
  STEP: Waiting for the pdb to be processed @ 07/11/24 07:17:23.076
  STEP: Waiting for all pods to be running @ 07/11/24 07:17:23.112
  I0711 07:17:23.118822 20 disruption.go:578] running pods: 0 < 3
  E0711 07:17:23.749170      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:24.749401      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:17:25.122951 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9881" for this suite. @ 07/11/24 07:17:25.126
• [2.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 07/11/24 07:17:25.134
  I0711 07:17:25.134996 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename conformance-tests @ 07/11/24 07:17:25.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:25.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:25.155
  STEP: Getting node addresses @ 07/11/24 07:17:25.157
  I0711 07:17:25.157533 20 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I0711 07:17:25.162400 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-3488" for this suite. @ 07/11/24 07:17:25.166
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 07/11/24 07:17:25.174
  I0711 07:17:25.174648 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename pod-network-test @ 07/11/24 07:17:25.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:25.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:25.191
  STEP: Performing setup for networking test in namespace pod-network-test-6288 @ 07/11/24 07:17:25.194
  STEP: creating a selector @ 07/11/24 07:17:25.194
  STEP: Creating the service pods in kubernetes @ 07/11/24 07:17:25.194
  I0711 07:17:25.194112 20 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0711 07:17:25.750263      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:26.750394      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:27.750430      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:28.750639      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:29.750889      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:30.751158      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:31.752153      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:32.752265      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:33.752382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:34.752467      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:35.752931      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:36.753355      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 07/11/24 07:17:37.28
  E0711 07:17:37.754147      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:38.754382      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:17:39.300158 20 utils.go:779] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I0711 07:17:39.300194 20 networking.go:42] Breadth first check of 192.168.122.74 on host 172.31.11.2...
  I0711 07:17:39.304434 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.37.62:9080/dial?request=hostname&protocol=http&host=192.168.122.74&port=8083&tries=1'] Namespace:pod-network-test-6288 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:17:39.304457 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:17:39.304919 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:17:39.304975 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6288/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.37.62%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.122.74%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0711 07:17:39.359872 20 utils.go:331] Waiting for responses: map[]
  I0711 07:17:39.359946 20 utils.go:335] reached 192.168.122.74 after 0/1 tries
  I0711 07:17:39.359958 20 networking.go:42] Breadth first check of 192.168.133.66 on host 172.31.17.237...
  I0711 07:17:39.363859 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.37.62:9080/dial?request=hostname&protocol=http&host=192.168.133.66&port=8083&tries=1'] Namespace:pod-network-test-6288 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:17:39.363879 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:17:39.364325 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:17:39.364375 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6288/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.37.62%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.133.66%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0711 07:17:39.410748 20 utils.go:331] Waiting for responses: map[]
  I0711 07:17:39.410784 20 utils.go:335] reached 192.168.133.66 after 0/1 tries
  I0711 07:17:39.410793 20 networking.go:42] Breadth first check of 192.168.37.6 on host 172.31.80.240...
  I0711 07:17:39.415033 20 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.37.62:9080/dial?request=hostname&protocol=http&host=192.168.37.6&port=8083&tries=1'] Namespace:pod-network-test-6288 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0711 07:17:39.415055 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  I0711 07:17:39.415441 20 exec_util.go:62] ExecWithOptions: Clientset creation
  I0711 07:17:39.415481 20 exec_util.go:79] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6288/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.37.62%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.37.6%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0711 07:17:39.465524 20 utils.go:331] Waiting for responses: map[]
  I0711 07:17:39.465557 20 utils.go:335] reached 192.168.37.6 after 0/1 tries
  I0711 07:17:39.465567 20 networking.go:53] Going to retry 0 out of 3 pods....
  I0711 07:17:39.465646 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6288" for this suite. @ 07/11/24 07:17:39.47
• [14.303 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 07/11/24 07:17:39.478
  I0711 07:17:39.478393 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename emptydir @ 07/11/24 07:17:39.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:39.494
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:39.496
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 07/11/24 07:17:39.498
  E0711 07:17:39.754768      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:40.755012      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:41.755065      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:42.755282      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 07/11/24 07:17:43.522
  I0711 07:17:43.526082 20 output.go:196] Trying to get logs from node ip-172-31-17-237 pod pod-ae1aa84e-039c-42de-abcb-6971c126a149 container test-container: <nil>
  STEP: delete the pod @ 07/11/24 07:17:43.532
  I0711 07:17:43.548881 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4073" for this suite. @ 07/11/24 07:17:43.552
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2240
  STEP: Creating a kubernetes client @ 07/11/24 07:17:43.56
  I0711 07:17:43.560206 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename services @ 07/11/24 07:17:43.56
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:43.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:43.582
  STEP: creating service in namespace services-3544 @ 07/11/24 07:17:43.584
  STEP: creating service affinity-nodeport-transition in namespace services-3544 @ 07/11/24 07:17:43.584
  STEP: creating replication controller affinity-nodeport-transition in namespace services-3544 @ 07/11/24 07:17:43.6
  I0711 07:17:43.612448      20 runners.go:198] Created replication controller with name: affinity-nodeport-transition, namespace: services-3544, replica count: 3
  E0711 07:17:43.756282      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:44.757029      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:45.757472      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:17:46.663795      20 runners.go:198] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0711 07:17:46.678938 20 resource.go:361] Creating new exec pod
  E0711 07:17:46.757506      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:47.758105      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:48.758732      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:17:49.694862 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-3544 exec execpod-affinityn2nd7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  E0711 07:17:49.759597      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:17:49.788021 20 builder.go:146] stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  I0711 07:17:49.788067 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 07:17:49.788173 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-3544 exec execpod-affinityn2nd7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.162 80'
  I0711 07:17:49.878236 20 builder.go:146] stderr: "+ nc -v -t -w 2 10.152.183.162 80\n+ echo hostName\nConnection to 10.152.183.162 80 port [tcp/http] succeeded!\n"
  I0711 07:17:49.878284 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 07:17:49.878365 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-3544 exec execpod-affinityn2nd7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.11.2 30191'
  I0711 07:17:49.964046 20 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.11.2 30191\n+ echo hostName\nConnection to 172.31.11.2 30191 port [tcp/*] succeeded!\n"
  I0711 07:17:49.964097 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 07:17:49.964310 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-3544 exec execpod-affinityn2nd7 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.17.237 30191'
  I0711 07:17:50.054350 20 builder.go:146] stderr: "+ nc -v -t -w 2 172.31.17.237 30191\n+ echo hostName\nConnection to 172.31.17.237 30191 port [tcp/*] succeeded!\n"
  I0711 07:17:50.054390 20 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0711 07:17:50.064350 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-3544 exec execpod-affinityn2nd7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.11.2:30191/ ; done'
  I0711 07:17:50.210254 20 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n"
  I0711 07:17:50.210315 20 builder.go:147] stdout: "\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-s5ppx\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-7jtrg\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-s5ppx\naffinity-nodeport-transition-s5ppx\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-7jtrg\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-s5ppx\naffinity-nodeport-transition-2nt65"
  I0711 07:17:50.210327 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.210334 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.210341 20 service.go:242] Received response from host: affinity-nodeport-transition-s5ppx
  I0711 07:17:50.210346 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.210352 20 service.go:242] Received response from host: affinity-nodeport-transition-7jtrg
  I0711 07:17:50.210359 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.210365 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.210369 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.210375 20 service.go:242] Received response from host: affinity-nodeport-transition-s5ppx
  I0711 07:17:50.210380 20 service.go:242] Received response from host: affinity-nodeport-transition-s5ppx
  I0711 07:17:50.210385 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.210389 20 service.go:242] Received response from host: affinity-nodeport-transition-7jtrg
  I0711 07:17:50.210395 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.210400 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.210404 20 service.go:242] Received response from host: affinity-nodeport-transition-s5ppx
  I0711 07:17:50.210409 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.221471 20 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2603319967 --namespace=services-3544 exec execpod-affinityn2nd7 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.11.2:30191/ ; done'
  I0711 07:17:50.366479 20 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.11.2:30191/\n"
  I0711 07:17:50.366527 20 builder.go:147] stdout: "\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65\naffinity-nodeport-transition-2nt65"
  I0711 07:17:50.366541 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366549 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366555 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366561 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366568 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366573 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366578 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366584 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366589 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366594 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366601 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366608 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366613 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366618 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366623 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366628 20 service.go:242] Received response from host: affinity-nodeport-transition-2nt65
  I0711 07:17:50.366692 20 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3544, will wait for the garbage collector to delete the pods @ 07/11/24 07:17:50.381
  I0711 07:17:50.444996 20 resources.go:139] Deleting ReplicationController affinity-nodeport-transition took: 8.641309ms
  I0711 07:17:50.545156 20 resources.go:163] Terminating ReplicationController affinity-nodeport-transition pods took: 100.155001ms
  E0711 07:17:50.759777      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:51.760455      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:52.761528      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:17:53.472735 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3544" for this suite. @ 07/11/24 07:17:53.476
• [9.923 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:668
  STEP: Creating a kubernetes client @ 07/11/24 07:17:53.483
  I0711 07:17:53.483667 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename job @ 07/11/24 07:17:53.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:53.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:53.503
  STEP: Creating a job @ 07/11/24 07:17:53.505
  STEP: Ensuring active pods == parallelism @ 07/11/24 07:17:53.511
  E0711 07:17:53.761662      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:54.761915      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 07/11/24 07:17:55.516
  STEP: deleting Job.batch foo in namespace job-8088, will wait for the garbage collector to delete the pods @ 07/11/24 07:17:55.516
  I0711 07:17:55.579140 20 resources.go:139] Deleting Job.batch foo took: 8.789579ms
  I0711 07:17:55.679419 20 resources.go:163] Terminating Job.batch foo pods took: 100.275189ms
  E0711 07:17:55.762692      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 07/11/24 07:17:56.48
  I0711 07:17:56.485002 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8088" for this suite. @ 07/11/24 07:17:56.489
• [3.013 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 07/11/24 07:17:56.497
  I0711 07:17:56.497450 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename container-runtime @ 07/11/24 07:17:56.497
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:17:56.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:17:56.516
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 07/11/24 07:17:56.527
  E0711 07:17:56.763684      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:57.763719      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:58.764285      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:17:59.765021      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:00.765380      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:01.766301      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:02.766625      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:03.766712      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:04.766811      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:05.767822      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:06.768751      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:07.768832      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:08.769596      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:09.769810      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:10.770338      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:11.771294      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 07/11/24 07:18:12.609
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 07/11/24 07:18:12.613
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 07/11/24 07:18:12.621
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 07/11/24 07:18:12.621
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 07/11/24 07:18:12.645
  E0711 07:18:12.771702      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:13.772171      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 07/11/24 07:18:14.66
  E0711 07:18:14.772845      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 07/11/24 07:18:15.67
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 07/11/24 07:18:15.677
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 07/11/24 07:18:15.677
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 07/11/24 07:18:15.703
  E0711 07:18:15.773760      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 07/11/24 07:18:16.715
  E0711 07:18:16.773804      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 07/11/24 07:18:17.724
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 07/11/24 07:18:17.731
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 07/11/24 07:18:17.731
  I0711 07:18:17.761018 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4799" for this suite. @ 07/11/24 07:18:17.765
• [21.276 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:350
  STEP: Creating a kubernetes client @ 07/11/24 07:18:17.773
  I0711 07:18:17.773752 20 util.go:506] >>> kubeConfig: /tmp/kubeconfig-2603319967
  STEP: Building a namespace api object, basename security-context-test @ 07/11/24 07:18:17.774
  E0711 07:18:17.774448      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 07/11/24 07:18:17.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 07/11/24 07:18:17.792
  E0711 07:18:18.774598      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:19.775046      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:20.775311      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0711 07:18:21.775631      20 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0711 07:18:21.819665 20 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-740" for this suite. @ 07/11/24 07:18:21.824
• [4.060 seconds]
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0711 07:18:21.833969 20 suites.go:34] Running AfterSuite actions on node 1
  I0711 07:18:21.833986 20 util.go:614] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:612
[ReportAfterSuite] PASSED [0.048 seconds]
------------------------------

Ran 402 of 7197 Specs in 6225.554 seconds
SUCCESS! -- 402 Passed | 0 Failed | 0 Pending | 6795 Skipped
PASS

Ginkgo ran 1 suite in 1h43m46.310397998s
Test Suite Passed
