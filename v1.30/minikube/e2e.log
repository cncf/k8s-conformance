  I0521 16:39:25.168176      22 e2e.go:109] Starting e2e run "2e7e1833-6abb-47fa-bc98-ecd17b7a0354" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1716309564 - will randomize all specs

Will run 402 of 7197 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0521 16:39:25.272627 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:39:25.273211 22 helper.go:48] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0521 16:39:25.286580 22 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0521 16:39:25.288303 22 e2e.go:153] 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kindnet' (0 seconds elapsed)
  I0521 16:39:25.288328 22 e2e.go:153] 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  I0521 16:39:25.288339 22 e2e.go:245] e2e test version: v1.30.1
  I0521 16:39:25.288800 22 e2e.go:254] kube-apiserver version: v1.30.1
  I0521 16:39:25.288846 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:39:25.290381 22 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.018 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 05/21/24 16:39:25.371
  I0521 16:39:25.371616 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 16:39:25.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:39:25.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:39:25.38
  STEP: Creating configMap with name configmap-test-upd-40241da0-a60c-47bb-a434-677f1042d097 @ 05/21/24 16:39:25.383
  STEP: Creating the pod @ 05/21/24 16:39:25.386
  STEP: Waiting for pod with text data @ 05/21/24 16:39:35.418
  STEP: Waiting for pod with binary data @ 05/21/24 16:39:35.437
  I0521 16:39:35.443300 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6934" for this suite. @ 05/21/24 16:39:35.445
• [10.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 05/21/24 16:39:35.452
  I0521 16:39:35.452686 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:39:35.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:39:35.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:39:35.465
  STEP: Creating projection with secret that has name projected-secret-test-77afac9d-d7bd-406d-959e-89d18aabd38f @ 05/21/24 16:39:35.467
  STEP: Creating a pod to test consume secrets @ 05/21/24 16:39:35.473
  STEP: Saw pod success @ 05/21/24 16:39:39.494
  I0521 16:39:39.497499 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-731ca8b8-7f84-4f18-9d69-30f3175987ab container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 16:39:39.504
  I0521 16:39:39.520891 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4827" for this suite. @ 05/21/24 16:39:39.524
• [4.076 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 05/21/24 16:39:39.528
  I0521 16:39:39.528994 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename chunking @ 05/21/24 16:39:39.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:39:39.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:39:39.543
  STEP: creating a large number of resources @ 05/21/24 16:39:39.546
  STEP: retrieving those results in paged fashion several times @ 05/21/24 16:39:57.238
  I0521 16:39:57.286512 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I0521 16:39:57.336465 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDMzXHUwMDAwIn0
  I0521 16:39:57.386709 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDUwXHUwMDAwIn0
  I0521 16:39:57.436548 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDY3XHUwMDAwIn0
  I0521 16:39:57.487052 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDg0XHUwMDAwIn0
  I0521 16:39:57.536318 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTAxXHUwMDAwIn0
  I0521 16:39:57.584635 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE4XHUwMDAwIn0
  I0521 16:39:57.637043 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTM1XHUwMDAwIn0
  I0521 16:39:57.686288 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTUyXHUwMDAwIn0
  I0521 16:39:57.735961 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTY5XHUwMDAwIn0
  I0521 16:39:57.785990 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTg2XHUwMDAwIn0
  I0521 16:39:57.835901 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjAzXHUwMDAwIn0
  I0521 16:39:57.886122 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjIwXHUwMDAwIn0
  I0521 16:39:57.936203 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM3XHUwMDAwIn0
  I0521 16:39:57.986400 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjU0XHUwMDAwIn0
  I0521 16:39:58.036359 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjcxXHUwMDAwIn0
  I0521 16:39:58.084270 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjg4XHUwMDAwIn0
  I0521 16:39:58.136171 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzA1XHUwMDAwIn0
  I0521 16:39:58.186367 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzIyXHUwMDAwIn0
  I0521 16:39:58.235879 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzM5XHUwMDAwIn0
  I0521 16:39:58.285820 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU2XHUwMDAwIn0
  I0521 16:39:58.335519 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzczXHUwMDAwIn0
  I0521 16:39:58.385798 22 chunking.go:98] Retrieved 17/17 results with rv 1294 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5NCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzkwXHUwMDAwIn0
  I0521 16:39:58.435242 22 chunking.go:98] Retrieved 9/17 results with rv 1294 and continue 
  I0521 16:39:58.485666 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I0521 16:39:58.535914 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDMzXHUwMDAwIn0
  I0521 16:39:58.585954 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDUwXHUwMDAwIn0
  I0521 16:39:58.635737 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDY3XHUwMDAwIn0
  I0521 16:39:58.685755 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDg0XHUwMDAwIn0
  I0521 16:39:58.735233 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTAxXHUwMDAwIn0
  I0521 16:39:58.786086 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE4XHUwMDAwIn0
  I0521 16:39:58.836096 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTM1XHUwMDAwIn0
  I0521 16:39:58.886108 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTUyXHUwMDAwIn0
  I0521 16:39:58.935690 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTY5XHUwMDAwIn0
  I0521 16:39:58.985412 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTg2XHUwMDAwIn0
  I0521 16:39:59.034595 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjAzXHUwMDAwIn0
  I0521 16:39:59.087118 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjIwXHUwMDAwIn0
  I0521 16:39:59.136108 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM3XHUwMDAwIn0
  I0521 16:39:59.185444 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjU0XHUwMDAwIn0
  I0521 16:39:59.235897 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjcxXHUwMDAwIn0
  I0521 16:39:59.286429 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjg4XHUwMDAwIn0
  I0521 16:39:59.336594 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzA1XHUwMDAwIn0
  I0521 16:39:59.385542 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzIyXHUwMDAwIn0
  I0521 16:39:59.436633 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzM5XHUwMDAwIn0
  I0521 16:39:59.486016 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU2XHUwMDAwIn0
  I0521 16:39:59.536089 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzczXHUwMDAwIn0
  I0521 16:39:59.584986 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzkwXHUwMDAwIn0
  I0521 16:39:59.635777 22 chunking.go:98] Retrieved 9/17 results with rv 1296 and continue 
  I0521 16:39:59.685649 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I0521 16:39:59.736651 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDMzXHUwMDAwIn0
  I0521 16:39:59.786471 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDUwXHUwMDAwIn0
  I0521 16:39:59.836723 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDY3XHUwMDAwIn0
  I0521 16:39:59.886639 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDg0XHUwMDAwIn0
  I0521 16:39:59.936926 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTAxXHUwMDAwIn0
  I0521 16:39:59.985690 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE4XHUwMDAwIn0
  I0521 16:40:00.035938 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTM1XHUwMDAwIn0
  I0521 16:40:00.086011 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTUyXHUwMDAwIn0
  I0521 16:40:00.135379 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTY5XHUwMDAwIn0
  I0521 16:40:00.185020 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTg2XHUwMDAwIn0
  I0521 16:40:00.233988 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjAzXHUwMDAwIn0
  I0521 16:40:00.285851 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjIwXHUwMDAwIn0
  I0521 16:40:00.336148 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM3XHUwMDAwIn0
  I0521 16:40:00.386028 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjU0XHUwMDAwIn0
  I0521 16:40:00.435931 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjcxXHUwMDAwIn0
  I0521 16:40:00.485831 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjg4XHUwMDAwIn0
  I0521 16:40:00.536709 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzA1XHUwMDAwIn0
  I0521 16:40:00.586703 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzIyXHUwMDAwIn0
  I0521 16:40:00.633853 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzM5XHUwMDAwIn0
  I0521 16:40:00.685421 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU2XHUwMDAwIn0
  I0521 16:40:00.735819 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzczXHUwMDAwIn0
  I0521 16:40:00.785102 22 chunking.go:98] Retrieved 17/17 results with rv 1296 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTI5Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzkwXHUwMDAwIn0
  I0521 16:40:00.834725 22 chunking.go:98] Retrieved 9/17 results with rv 1296 and continue 
  STEP: retrieving those results all at once @ 05/21/24 16:40:00.834
  I0521 16:40:00.897579 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-6198" for this suite. @ 05/21/24 16:40:00.936
• [21.459 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 05/21/24 16:40:00.988
  I0521 16:40:00.988882 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename namespaces @ 05/21/24 16:40:00.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:40:01.002
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:40:01.005
  STEP: Updating Namespace "namespaces-4701" @ 05/21/24 16:40:01.008
  I0521 16:40:01.015184 22 namespace.go:389] Namespace "namespaces-4701" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"2e7e1833-6abb-47fa-bc98-ecd17b7a0354", "kubernetes.io/metadata.name":"namespaces-4701", "namespaces-4701":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0521 16:40:01.015311 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4701" for this suite. @ 05/21/24 16:40:01.018
• [0.034 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 05/21/24 16:40:01.022
  I0521 16:40:01.022923 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 16:40:01.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:40:01.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:40:01.038
  STEP: Setting up server cert @ 05/21/24 16:40:01.051
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 16:40:01.248
  STEP: Deploying the webhook pod @ 05/21/24 16:40:01.252
  STEP: Wait for the deployment to be ready @ 05/21/24 16:40:01.259
  I0521 16:40:01.262087 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/21/24 16:40:03.27
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:40:03.283
  I0521 16:40:04.283772 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 05/21/24 16:40:04.291
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 05/21/24 16:40:04.292
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 05/21/24 16:40:04.292
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 05/21/24 16:40:04.292
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 05/21/24 16:40:04.293
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/21/24 16:40:04.293
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 05/21/24 16:40:04.294
  I0521 16:40:04.325607 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2318" for this suite. @ 05/21/24 16:40:04.327
  STEP: Destroying namespace "webhook-markers-3160" for this suite. @ 05/21/24 16:40:04.334
• [3.317 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 05/21/24 16:40:04.34
  I0521 16:40:04.340201 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 16:40:04.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:40:04.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:40:04.354
  STEP: Setting up server cert @ 05/21/24 16:40:04.381
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 16:40:04.501
  STEP: Deploying the webhook pod @ 05/21/24 16:40:04.505
  STEP: Wait for the deployment to be ready @ 05/21/24 16:40:04.511
  I0521 16:40:04.515374 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/21/24 16:40:06.525
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:40:06.535
  I0521 16:40:07.536382 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0521 16:40:07.544139 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8196-crds.webhook.example.com via the AdmissionRegistration API @ 05/21/24 16:40:08.06
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/21/24 16:40:08.079
  I0521 16:40:10.649856 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5209" for this suite. @ 05/21/24 16:40:10.653
  STEP: Destroying namespace "webhook-markers-9650" for this suite. @ 05/21/24 16:40:10.658
• [6.324 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 05/21/24 16:40:10.664
  I0521 16:40:10.664120 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-preemption @ 05/21/24 16:40:10.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:40:10.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:40:10.671
  I0521 16:40:10.684811 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  I0521 16:41:10.689908 22 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/21/24 16:41:10.692
  I0521 16:41:10.692569 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/21/24 16:41:10.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:10.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:41:10.708
  I0521 16:41:10.723653 22 preemption.go:818] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0521 16:41:10.726505 22 preemption.go:824] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  I0521 16:41:10.777493 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2891" for this suite. @ 05/21/24 16:41:10.778
  I0521 16:41:10.781961 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-8668" for this suite. @ 05/21/24 16:41:10.784
• [60.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:397
  STEP: Creating a kubernetes client @ 05/21/24 16:41:10.788
  I0521 16:41:10.788609 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 16:41:10.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:10.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:41:10.804
  STEP: creating all guestbook components @ 05/21/24 16:41:10.806
  I0521 16:41:10.806166 22 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0521 16:41:10.806299 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 create -f -'
  I0521 16:41:10.893968 22 builder.go:146] stderr: ""
  I0521 16:41:10.894041 22 builder.go:147] stdout: "service/agnhost-replica created\n"
  I0521 16:41:10.894119 22 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0521 16:41:10.894292 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 create -f -'
  I0521 16:41:10.963917 22 builder.go:146] stderr: ""
  I0521 16:41:10.963973 22 builder.go:147] stdout: "service/agnhost-primary created\n"
  I0521 16:41:10.964024 22 kubectl.go:403] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0521 16:41:10.964094 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 create -f -'
  I0521 16:41:11.048071 22 builder.go:146] stderr: ""
  I0521 16:41:11.048106 22 builder.go:147] stdout: "service/frontend created\n"
  I0521 16:41:11.048155 22 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0521 16:41:11.048243 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 create -f -'
  I0521 16:41:11.103764 22 builder.go:146] stderr: ""
  I0521 16:41:11.103798 22 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I0521 16:41:11.103853 22 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0521 16:41:11.103938 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 create -f -'
  I0521 16:41:11.172374 22 builder.go:146] stderr: ""
  I0521 16:41:11.172407 22 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I0521 16:41:11.172457 22 kubectl.go:403] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0521 16:41:11.172540 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 create -f -'
  I0521 16:41:11.232364 22 builder.go:146] stderr: ""
  I0521 16:41:11.232399 22 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 05/21/24 16:41:11.232
  I0521 16:41:11.232450 22 kubectl.go:2271] Waiting for all frontend pods to be Running.
  I0521 16:41:21.284395 22 kubectl.go:2275] Waiting for frontend to serve content.
  I0521 16:41:21.294870 22 kubectl.go:2280] Trying to add a new entry to the guestbook.
  I0521 16:41:21.302275 22 kubectl.go:2285] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 05/21/24 16:41:21.308
  I0521 16:41:21.308969 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 delete --grace-period=0 --force -f -'
  I0521 16:41:21.363235 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0521 16:41:21.363274 22 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 05/21/24 16:41:21.363
  I0521 16:41:21.363370 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 delete --grace-period=0 --force -f -'
  I0521 16:41:21.405176 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0521 16:41:21.405278 22 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/21/24 16:41:21.405
  I0521 16:41:21.405363 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 delete --grace-period=0 --force -f -'
  I0521 16:41:21.447945 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0521 16:41:21.447979 22 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/21/24 16:41:21.448
  I0521 16:41:21.448095 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 delete --grace-period=0 --force -f -'
  I0521 16:41:21.491625 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0521 16:41:21.491658 22 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 05/21/24 16:41:21.491
  I0521 16:41:21.491757 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 delete --grace-period=0 --force -f -'
  I0521 16:41:21.539941 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0521 16:41:21.539986 22 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 05/21/24 16:41:21.54
  I0521 16:41:21.540158 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1563 delete --grace-period=0 --force -f -'
  I0521 16:41:21.584180 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0521 16:41:21.584258 22 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I0521 16:41:21.584326 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1563" for this suite. @ 05/21/24 16:41:21.588
• [10.803 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 05/21/24 16:41:21.592
  I0521 16:41:21.592068 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replication-controller @ 05/21/24 16:41:21.592
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:21.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:41:21.604
  I0521 16:41:21.606790 22 rc.go:544] Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 05/21/24 16:41:22.616
  STEP: Checking rc "condition-test" has the desired failure condition set @ 05/21/24 16:41:22.623
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 05/21/24 16:41:23.63
  I0521 16:41:23.640250 22 rc.go:730] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 05/21/24 16:41:23.64
  I0521 16:41:24.647973 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2076" for this suite. @ 05/21/24 16:41:24.651
• [3.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 05/21/24 16:41:24.656
  I0521 16:41:24.656681 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename apf @ 05/21/24 16:41:24.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:24.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:41:24.665
  STEP: getting /apis @ 05/21/24 16:41:24.666
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/21/24 16:41:24.668
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/21/24 16:41:24.669
  STEP: creating @ 05/21/24 16:41:24.669
  STEP: getting @ 05/21/24 16:41:24.676
  STEP: listing @ 05/21/24 16:41:24.677
  STEP: watching @ 05/21/24 16:41:24.679
  I0521 16:41:24.679509 22 flowcontrol.go:620] starting watch
  STEP: patching @ 05/21/24 16:41:24.68
  STEP: updating @ 05/21/24 16:41:24.685
  I0521 16:41:24.690744 22 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 05/21/24 16:41:24.69
  STEP: patching /status @ 05/21/24 16:41:24.693
  STEP: updating /status @ 05/21/24 16:41:24.698
  STEP: deleting @ 05/21/24 16:41:24.704
  STEP: deleting a collection @ 05/21/24 16:41:24.714
  I0521 16:41:24.724920 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-6566" for this suite. @ 05/21/24 16:41:24.726
• [0.077 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 05/21/24 16:41:24.734
  I0521 16:41:24.734056 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:41:24.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:24.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:41:24.747
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-11306778-0f1f-4774-9a36-ce1c08dcb1b7 @ 05/21/24 16:41:24.751
  STEP: Creating the pod @ 05/21/24 16:41:24.753
  STEP: Updating configmap projected-configmap-test-upd-11306778-0f1f-4774-9a36-ce1c08dcb1b7 @ 05/21/24 16:41:26.781
  STEP: waiting to observe update in volume @ 05/21/24 16:41:26.785
  I0521 16:41:30.815124 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8101" for this suite. @ 05/21/24 16:41:30.817
• [6.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 05/21/24 16:41:30.822
  I0521 16:41:30.822760 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename dns @ 05/21/24 16:41:30.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:30.833
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:41:30.835
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 05/21/24 16:41:30.838
  I0521 16:41:30.844862 22 dns.go:419] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3081  bd984845-bb13-4c13-bec0-33e6de95fc52 2266 0 2024-05-21 16:41:30 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-05-21 16:41:30 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nnstg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nnstg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  STEP: Verifying customized DNS suffix list is configured on pod... @ 05/21/24 16:41:32.853
  I0521 16:41:32.853175 22 exec_util.go:55] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3081 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:41:32.853220 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:41:32.853885 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:41:32.853960 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-3081/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 05/21/24 16:41:32.929
  I0521 16:41:32.929136 22 exec_util.go:55] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3081 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:41:32.929149 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:41:32.929446 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:41:32.929487 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-3081/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0521 16:41:32.978278 22 dns.go:421] Deleting pod test-dns-nameservers...
  I0521 16:41:32.988142 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3081" for this suite. @ 05/21/24 16:41:32.99
• [2.170 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 05/21/24 16:41:32.992
  I0521 16:41:32.992776 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 16:41:32.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:33
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:41:33.002
  STEP: Creating a ResourceQuota with best effort scope @ 05/21/24 16:41:33.003
  STEP: Ensuring ResourceQuota status is calculated @ 05/21/24 16:41:33.007
  STEP: Creating a ResourceQuota with not best effort scope @ 05/21/24 16:41:35.012
  STEP: Ensuring ResourceQuota status is calculated @ 05/21/24 16:41:35.019
  STEP: Creating a best-effort pod @ 05/21/24 16:41:37.023
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 05/21/24 16:41:37.036
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 05/21/24 16:41:39.041
  STEP: Deleting the pod @ 05/21/24 16:41:41.046
  STEP: Ensuring resource quota status released the pod usage @ 05/21/24 16:41:41.06
  STEP: Creating a not best-effort pod @ 05/21/24 16:41:43.066
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 05/21/24 16:41:43.079
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 05/21/24 16:41:45.085
  STEP: Deleting the pod @ 05/21/24 16:41:47.091
  STEP: Ensuring resource quota status released the pod usage @ 05/21/24 16:41:47.104
  I0521 16:41:49.110632 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5910" for this suite. @ 05/21/24 16:41:49.114
• [16.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:358
  STEP: Creating a kubernetes client @ 05/21/24 16:41:49.12
  I0521 16:41:49.120934 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/21/24 16:41:49.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:49.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:41:49.134
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 05/21/24 16:41:49.137
  I0521 16:41:49.137738 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:41:50.329532 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:41:54.974601 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6515" for this suite. @ 05/21/24 16:41:54.977
• [5.861 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 05/21/24 16:41:54.981
  I0521 16:41:54.981916 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename namespaces @ 05/21/24 16:41:54.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:54.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:41:54.991
  STEP: Creating a test namespace @ 05/21/24 16:41:54.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:41:55
  STEP: Creating a pod in the namespace @ 05/21/24 16:41:55.002
  STEP: Waiting for the pod to have running status @ 05/21/24 16:41:55.007
  STEP: Deleting the namespace @ 05/21/24 16:41:57.014
  STEP: Waiting for the namespace to be removed. @ 05/21/24 16:41:57.02
  STEP: Recreating the namespace @ 05/21/24 16:42:08.025
  STEP: Verifying there are no pods in the namespace @ 05/21/24 16:42:08.038
  I0521 16:42:08.041497 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1112" for this suite. @ 05/21/24 16:42:08.044
  STEP: Destroying namespace "nsdeletetest-5112" for this suite. @ 05/21/24 16:42:08.049
  I0521 16:42:08.052625 22 framework.go:370] Namespace nsdeletetest-5112 was already deleted
  STEP: Destroying namespace "nsdeletetest-4621" for this suite. @ 05/21/24 16:42:08.052
• [13.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 05/21/24 16:42:08.057
  I0521 16:42:08.057965 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename daemonsets @ 05/21/24 16:42:08.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:08.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:08.072
  STEP: Creating a simple DaemonSet "daemon-set" @ 05/21/24 16:42:08.087
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/21/24 16:42:08.091
  I0521 16:42:08.097169 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 16:42:08.097286 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  I0521 16:42:09.101141 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 16:42:09.101235 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  I0521 16:42:10.098653 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0521 16:42:10.098701 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 05/21/24 16:42:10.1
  I0521 16:42:10.117388 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 16:42:10.117458 22 fixtures.go:130] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  I0521 16:42:11.118812 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0521 16:42:11.118864 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 05/21/24 16:42:11.118
  STEP: Deleting DaemonSet "daemon-set" @ 05/21/24 16:42:11.122
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3038, will wait for the garbage collector to delete the pods @ 05/21/24 16:42:11.122
  I0521 16:42:11.182795 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.25249ms
  I0521 16:42:11.283851 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.049703ms
  I0521 16:42:12.888739 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 16:42:12.888807 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0521 16:42:12.894176 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2486"},"items":null}

  I0521 16:42:12.896569 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2486"},"items":null}

  I0521 16:42:12.907435 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3038" for this suite. @ 05/21/24 16:42:12.91
• [4.857 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 05/21/24 16:42:12.915
  I0521 16:42:12.915249 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename dns @ 05/21/24 16:42:12.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:12.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:12.928
  STEP: Creating a test headless service @ 05/21/24 16:42:12.93
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9671.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9671.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 05/21/24 16:42:12.934
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9671.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9671.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 05/21/24 16:42:12.934
  STEP: creating a pod to probe DNS @ 05/21/24 16:42:12.934
  STEP: submitting the pod to kubernetes @ 05/21/24 16:42:12.934
  STEP: retrieving the pod @ 05/21/24 16:42:28.98
  STEP: looking for the results for each expected name from probers @ 05/21/24 16:42:28.982
  I0521 16:42:28.992671 22 dns_common.go:527] DNS probes using dns-9671/dns-test-b298ffa7-e33e-4e49-b0f3-53990269035e succeeded

  STEP: deleting the pod @ 05/21/24 16:42:28.992
  STEP: deleting the test headless service @ 05/21/24 16:42:29.005
  I0521 16:42:29.015477 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9671" for this suite. @ 05/21/24 16:42:29.018
• [16.108 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1459
  STEP: Creating a kubernetes client @ 05/21/24 16:42:29.023
  I0521 16:42:29.023335 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 16:42:29.024
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:29.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:29.032
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-9665 @ 05/21/24 16:42:29.034
  STEP: changing the ExternalName service to type=NodePort @ 05/21/24 16:42:29.036
  STEP: creating replication controller externalname-service in namespace services-9665 @ 05/21/24 16:42:29.046
  I0521 16:42:29.054706      22 runners.go:198] Created replication controller with name: externalname-service, namespace: services-9665, replica count: 2
  I0521 16:42:32.106311      22 runners.go:198] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0521 16:42:32.106369 22 resource.go:361] Creating new exec pod
  I0521 16:42:35.126370 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-9665 exec execpodj9l5f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0521 16:42:35.222242 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0521 16:42:35.222291 22 builder.go:147] stdout: "externalname-service-vtssw"
  I0521 16:42:35.222383 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-9665 exec execpodj9l5f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.156.107 80'
  I0521 16:42:35.313022 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.110.156.107 80\nConnection to 10.110.156.107 80 port [tcp/http] succeeded!\n"
  I0521 16:42:35.313084 22 builder.go:147] stdout: "externalname-service-vtssw"
  I0521 16:42:35.313231 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-9665 exec execpodj9l5f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.2 30292'
  I0521 16:42:35.406733 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.2 30292\nConnection to 192.168.67.2 30292 port [tcp/*] succeeded!\n"
  I0521 16:42:35.406806 22 builder.go:147] stdout: ""
  I0521 16:42:36.314001 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-9665 exec execpodj9l5f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.2 30292'
  I0521 16:42:36.411267 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.2 30292\nConnection to 192.168.67.2 30292 port [tcp/*] succeeded!\n"
  I0521 16:42:36.411323 22 builder.go:147] stdout: ""
  I0521 16:42:37.314012 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-9665 exec execpodj9l5f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.2 30292'
  I0521 16:42:37.422043 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.2 30292\nConnection to 192.168.67.2 30292 port [tcp/*] succeeded!\n"
  I0521 16:42:37.422110 22 builder.go:147] stdout: "externalname-service-vtssw"
  I0521 16:42:37.422236 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-9665 exec execpodj9l5f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.3 30292'
  I0521 16:42:37.518842 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.3 30292\nConnection to 192.168.67.3 30292 port [tcp/*] succeeded!\n"
  I0521 16:42:37.518900 22 builder.go:147] stdout: "externalname-service-gvsrk"
  I0521 16:42:37.518997 22 service.go:1468] Cleaning up the ExternalName to NodePort test service
  I0521 16:42:37.539678 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9665" for this suite. @ 05/21/24 16:42:37.541
• [8.523 seconds]
------------------------------
SSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 05/21/24 16:42:37.546
  I0521 16:42:37.546055 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename runtimeclass @ 05/21/24 16:42:37.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:37.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:37.559
  I0521 16:42:39.587278 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9337" for this suite. @ 05/21/24 16:42:39.59
• [2.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 05/21/24 16:42:39.597
  I0521 16:42:39.597155 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/21/24 16:42:39.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:39.61
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:39.613
  I0521 16:42:39.616428 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:42:40.154696 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1393" for this suite. @ 05/21/24 16:42:40.157
• [0.565 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 05/21/24 16:42:40.162
  I0521 16:42:40.162364 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replicaset @ 05/21/24 16:42:40.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:40.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:40.174
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 05/21/24 16:42:40.176
  I0521 16:42:40.181244 22 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  I0521 16:42:45.185618 22 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/21/24 16:42:45.185
  STEP: getting scale subresource @ 05/21/24 16:42:45.185
  STEP: updating a scale subresource @ 05/21/24 16:42:45.186
  STEP: verifying the replicaset Spec.Replicas was modified @ 05/21/24 16:42:45.19
  STEP: Patch a scale subresource @ 05/21/24 16:42:45.192
  I0521 16:42:45.202991 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7168" for this suite. @ 05/21/24 16:42:45.207
• [5.053 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 05/21/24 16:42:45.215
  I0521 16:42:45.215744 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename podtemplate @ 05/21/24 16:42:45.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:45.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:45.237
  STEP: Create a pod template @ 05/21/24 16:42:45.24
  STEP: Replace a pod template @ 05/21/24 16:42:45.243
  I0521 16:42:45.250701 22 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I0521 16:42:45.250769 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-3625" for this suite. @ 05/21/24 16:42:45.253
• [0.043 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 05/21/24 16:42:45.259
  I0521 16:42:45.259018 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:42:45.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:45.267
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:45.269
  STEP: Creating configMap with name projected-configmap-test-volume-27ad3cff-8fd8-4d34-a06c-53f03c7a959f @ 05/21/24 16:42:45.271
  STEP: Creating a pod to test consume configMaps @ 05/21/24 16:42:45.277
  STEP: Saw pod success @ 05/21/24 16:42:49.296
  I0521 16:42:49.299160 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-5453af0a-53ef-4f11-855c-1d1ed48c910d container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 16:42:49.305
  I0521 16:42:49.319917 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4481" for this suite. @ 05/21/24 16:42:49.322
• [4.069 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:310
  STEP: Creating a kubernetes client @ 05/21/24 16:42:49.328
  I0521 16:42:49.328572 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/21/24 16:42:49.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:49.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:49.342
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 05/21/24 16:42:49.345
  I0521 16:42:49.346416 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 05/21/24 16:42:54.025
  I0521 16:42:54.025500 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:42:55.178180 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:42:59.796799 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9216" for this suite. @ 05/21/24 16:42:59.802
• [10.481 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 05/21/24 16:42:59.809
  I0521 16:42:59.809606 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 16:42:59.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:42:59.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:42:59.822
  STEP: Setting up server cert @ 05/21/24 16:42:59.839
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 16:43:00.071
  STEP: Deploying the webhook pod @ 05/21/24 16:43:00.076
  STEP: Wait for the deployment to be ready @ 05/21/24 16:43:00.083
  I0521 16:43:00.087861 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/21/24 16:43:02.096
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:43:02.107
  I0521 16:43:03.108125 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0521 16:43:03.115683 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5994-crds.webhook.example.com via the AdmissionRegistration API @ 05/21/24 16:43:03.63
  STEP: Creating a custom resource while v1 is storage version @ 05/21/24 16:43:03.649
  STEP: Patching Custom Resource Definition to set v2 as storage @ 05/21/24 16:43:05.692
  STEP: Patching the custom resource while v2 is storage version @ 05/21/24 16:43:05.706
  I0521 16:43:06.297721 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2369" for this suite. @ 05/21/24 16:43:06.301
  STEP: Destroying namespace "webhook-markers-5211" for this suite. @ 05/21/24 16:43:06.307
• [6.505 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 05/21/24 16:43:06.314
  I0521 16:43:06.314950 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 16:43:06.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:43:06.326
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:43:06.33
  STEP: Creating configMap with name configmap-test-volume-map-9788628d-c883-4d88-a990-e8ef9fcbaf20 @ 05/21/24 16:43:06.333
  STEP: Creating a pod to test consume configMaps @ 05/21/24 16:43:06.338
  STEP: Saw pod success @ 05/21/24 16:43:10.361
  I0521 16:43:10.363625 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-f97dda83-b8ef-42a1-95fc-dab36a7ff59b container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 16:43:10.37
  I0521 16:43:10.385580 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1675" for this suite. @ 05/21/24 16:43:10.388
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 05/21/24 16:43:10.393
  I0521 16:43:10.393675 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename daemonsets @ 05/21/24 16:43:10.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:43:10.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:43:10.411
  STEP: Creating simple DaemonSet "daemon-set" @ 05/21/24 16:43:10.423
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/21/24 16:43:10.427
  I0521 16:43:10.430622 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 16:43:10.430643 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  I0521 16:43:11.433361 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 16:43:11.433406 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  I0521 16:43:12.436694 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0521 16:43:12.436743 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 05/21/24 16:43:12.438
  I0521 16:43:12.455970 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 16:43:12.456026 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  I0521 16:43:13.457287 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 16:43:13.457329 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  I0521 16:43:14.456739 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 16:43:14.456781 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  I0521 16:43:15.453476 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0521 16:43:15.453528 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/21/24 16:43:15.455
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7184, will wait for the garbage collector to delete the pods @ 05/21/24 16:43:15.455
  I0521 16:43:15.511505 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 3.735777ms
  I0521 16:43:15.611956 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.446685ms
  I0521 16:43:17.217947 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 16:43:17.218024 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0521 16:43:17.220430 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3025"},"items":null}

  I0521 16:43:17.222577 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3025"},"items":null}

  I0521 16:43:17.234713 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7184" for this suite. @ 05/21/24 16:43:17.237
• [6.849 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 05/21/24 16:43:17.243
  I0521 16:43:17.243334 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 16:43:17.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:43:17.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:43:17.255
  I0521 16:43:17.256899 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: creating the pod @ 05/21/24 16:43:17.257
  STEP: submitting the pod to kubernetes @ 05/21/24 16:43:17.257
  I0521 16:43:19.283288 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2464" for this suite. @ 05/21/24 16:43:19.285
• [2.048 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:443
  STEP: Creating a kubernetes client @ 05/21/24 16:43:19.291
  I0521 16:43:19.291903 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/21/24 16:43:19.293
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:43:19.305
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:43:19.307
  STEP: set up a multi version CRD @ 05/21/24 16:43:19.31
  I0521 16:43:19.310861 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: mark a version not serverd @ 05/21/24 16:43:22.321
  STEP: check the unserved version gets removed @ 05/21/24 16:43:22.331
  STEP: check the other version is not changed @ 05/21/24 16:43:22.958
  I0521 16:43:25.299394 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1891" for this suite. @ 05/21/24 16:43:25.304
• [6.018 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1693
  STEP: Creating a kubernetes client @ 05/21/24 16:43:25.309
  I0521 16:43:25.309902 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 16:43:25.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:43:25.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:43:25.322
  STEP: creating Agnhost RC @ 05/21/24 16:43:25.324
  I0521 16:43:25.324830 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4739 create -f -'
  I0521 16:43:25.404465 22 builder.go:146] stderr: ""
  I0521 16:43:25.404541 22 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/21/24 16:43:25.404
  I0521 16:43:26.409559 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 16:43:26.409609 22 framework.go:733] Found 0 / 1
  I0521 16:43:27.411134 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 16:43:27.411217 22 framework.go:733] Found 1 / 1
  I0521 16:43:27.411250 22 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 05/21/24 16:43:27.411
  I0521 16:43:27.414259 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 16:43:27.414308 22 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0521 16:43:27.414392 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4739 patch pod agnhost-primary-n7w2n -p {"metadata":{"annotations":{"x":"y"}}}'
  I0521 16:43:27.459231 22 builder.go:146] stderr: ""
  I0521 16:43:27.459270 22 builder.go:147] stdout: "pod/agnhost-primary-n7w2n patched\n"
  STEP: checking annotations @ 05/21/24 16:43:27.459
  I0521 16:43:27.460804 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 16:43:27.460823 22 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0521 16:43:27.460887 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4739" for this suite. @ 05/21/24 16:43:27.462
• [2.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1420
  STEP: Creating a kubernetes client @ 05/21/24 16:43:27.465
  I0521 16:43:27.465694 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 16:43:27.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:43:27.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:43:27.473
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-8232 @ 05/21/24 16:43:27.474
  STEP: changing the ExternalName service to type=ClusterIP @ 05/21/24 16:43:27.477
  STEP: creating replication controller externalname-service in namespace services-8232 @ 05/21/24 16:43:27.485
  I0521 16:43:27.491168      22 runners.go:198] Created replication controller with name: externalname-service, namespace: services-8232, replica count: 2
  I0521 16:43:30.542756      22 runners.go:198] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0521 16:43:30.542821 22 resource.go:361] Creating new exec pod
  I0521 16:43:33.557381 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8232 exec execpodndl86 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0521 16:43:33.647256 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I0521 16:43:33.647299 22 builder.go:147] stdout: "externalname-service-8ntv5"
  I0521 16:43:33.647381 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8232 exec execpodndl86 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.210.36 80'
  I0521 16:43:33.739533 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.106.210.36 80\nConnection to 10.106.210.36 80 port [tcp/http] succeeded!\n"
  I0521 16:43:33.739592 22 builder.go:147] stdout: "externalname-service-8ntv5"
  I0521 16:43:33.739690 22 service.go:1429] Cleaning up the ExternalName to ClusterIP test service
  I0521 16:43:33.759120 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8232" for this suite. @ 05/21/24 16:43:33.761
• [6.301 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 05/21/24 16:43:33.766
  I0521 16:43:33.766813 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename init-container @ 05/21/24 16:43:33.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:43:33.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:43:33.783
  STEP: creating the pod @ 05/21/24 16:43:33.784
  I0521 16:43:33.784901 22 init_container.go:374] PodSpec: initContainers in spec.initContainers
  I0521 16:44:12.230845 22 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a34db3e8-ca26-4763-a622-4d9430277914", GenerateName:"", Namespace:"init-container-5751", SelfLink:"", UID:"41bc179f-33c1-47af-a7a1-b7dcb679a49b", ResourceVersion:"3286", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 16, 43, 33, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"784894625"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 16, 43, 33, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00455c138), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 16, 44, 12, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00455c180), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-4hn5m", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0063ee1c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-4hn5m", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-4hn5m", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-4hn5m", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004be6ee8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8sconformance-m02", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00622e100), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004be6f60)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004be6f80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004be6f88), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004be6f8c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc005e9e2e0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 21, 16, 43, 34, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 21, 16, 43, 33, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 21, 16, 43, 33, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 21, 16, 43, 33, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.May, 21, 16, 43, 33, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.67.3", HostIPs:[]v1.HostIP{v1.HostIP{IP:"192.168.67.3"}}, PodIP:"10.244.1.30", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.1.30"}}, StartTime:time.Date(2024, time.May, 21, 16, 43, 33, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0009f8a80)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0009f8bd0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"docker-pullable://registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"docker://7f3add8a0589a6c19afea5bc791c19d1c499f70e62e65db3305562f1ea44625b", Started:(*bool)(0xc004be702a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0063ee220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc004be703f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0063ee200), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc004be700f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I0521 16:44:12.231024 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5751" for this suite. @ 05/21/24 16:44:12.233
• [38.470 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 05/21/24 16:44:12.236
  I0521 16:44:12.236863 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/21/24 16:44:12.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:12.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:12.248
  I0521 16:44:12.251021 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:44:15.308270 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-881" for this suite. @ 05/21/24 16:44:15.312
• [3.083 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 05/21/24 16:44:15.319
  I0521 16:44:15.319882 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename init-container @ 05/21/24 16:44:15.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:15.331
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:15.334
  STEP: creating the pod @ 05/21/24 16:44:15.337
  I0521 16:44:15.337335 22 init_container.go:499] PodSpec: initContainers in spec.initContainers
  I0521 16:44:18.414549 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2001" for this suite. @ 05/21/24 16:44:18.418
• [3.103 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 05/21/24 16:44:18.423
  I0521 16:44:18.423448 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubelet-test @ 05/21/24 16:44:18.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:18.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:18.437
  I0521 16:44:18.457595 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-24" for this suite. @ 05/21/24 16:44:18.46
• [0.041 seconds]
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 05/21/24 16:44:18.464
  I0521 16:44:18.464639 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 16:44:18.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:18.472
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:18.474
  STEP: Creating Pod @ 05/21/24 16:44:18.476
  STEP: Reading file content from the nginx-container @ 05/21/24 16:44:20.491
  I0521 16:44:20.491393 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-9544 PodName:pod-sharedvolume-a5462ca8-ef80-4bfa-a115-c7fc6d65e519 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:44:20.491421 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:44:20.492075 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:44:20.492150 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-9544/pods/pod-sharedvolume-a5462ca8-ef80-4bfa-a115-c7fc6d65e519/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  I0521 16:44:20.559909 22 exec_util.go:106] Exec stderr: ""
  I0521 16:44:20.560386 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9544" for this suite. @ 05/21/24 16:44:20.563
• [2.104 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 05/21/24 16:44:20.568
  I0521 16:44:20.568427 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename svcaccounts @ 05/21/24 16:44:20.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:20.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:20.583
  STEP: Creating ServiceAccount "e2e-sa-zcnx5"  @ 05/21/24 16:44:20.585
  I0521 16:44:20.588775 22 service_accounts.go:825] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-zcnx5"  @ 05/21/24 16:44:20.588
  I0521 16:44:20.593372 22 service_accounts.go:839] AutomountServiceAccountToken: true
  I0521 16:44:20.593464 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-424" for this suite. @ 05/21/24 16:44:20.596
• [0.032 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 05/21/24 16:44:20.6
  I0521 16:44:20.600340 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename apf @ 05/21/24 16:44:20.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:20.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:20.614
  STEP: getting /apis @ 05/21/24 16:44:20.616
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 05/21/24 16:44:20.618
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 05/21/24 16:44:20.618
  STEP: creating @ 05/21/24 16:44:20.619
  STEP: getting @ 05/21/24 16:44:20.626
  STEP: listing @ 05/21/24 16:44:20.628
  STEP: watching @ 05/21/24 16:44:20.629
  I0521 16:44:20.629921 22 flowcontrol.go:394] starting watch
  STEP: patching @ 05/21/24 16:44:20.63
  STEP: updating @ 05/21/24 16:44:20.635
  I0521 16:44:20.639457 22 flowcontrol.go:422] waiting for watch events with expected annotations
  I0521 16:44:20.639482 22 flowcontrol.go:438] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 05/21/24 16:44:20.639
  STEP: patching /status @ 05/21/24 16:44:20.64
  STEP: updating /status @ 05/21/24 16:44:20.644
  STEP: deleting @ 05/21/24 16:44:20.668
  STEP: deleting a collection @ 05/21/24 16:44:20.677
  I0521 16:44:20.690531 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-1839" for this suite. @ 05/21/24 16:44:20.692
• [0.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 05/21/24 16:44:20.697
  I0521 16:44:20.697664 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-runtime @ 05/21/24 16:44:20.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:20.708
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:20.711
  STEP: create the container @ 05/21/24 16:44:20.714
  W0521 16:44:20.723718      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 05/21/24 16:44:20.723
  STEP: get the container status @ 05/21/24 16:44:23.74
  STEP: the container should be terminated @ 05/21/24 16:44:23.742
  STEP: the termination message should be set @ 05/21/24 16:44:23.742
  I0521 16:44:23.742603 22 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/21/24 16:44:23.742
  I0521 16:44:23.755026 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4842" for this suite. @ 05/21/24 16:44:23.757
• [3.064 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 05/21/24 16:44:23.762
  I0521 16:44:23.762023 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename field-validation @ 05/21/24 16:44:23.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:23.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:23.777
  I0521 16:44:23.779490 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  W0521 16:44:26.326489      22 warnings.go:70] unknown field "alpha"
  W0521 16:44:26.326531      22 warnings.go:70] unknown field "beta"
  W0521 16:44:26.326544      22 warnings.go:70] unknown field "delta"
  W0521 16:44:26.326553      22 warnings.go:70] unknown field "epsilon"
  W0521 16:44:26.326563      22 warnings.go:70] unknown field "gamma"
  I0521 16:44:26.860072 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8650" for this suite. @ 05/21/24 16:44:26.862
• [3.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 05/21/24 16:44:26.869
  I0521 16:44:26.869036 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replication-controller @ 05/21/24 16:44:26.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:26.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:26.884
  STEP: Creating replication controller my-hostname-basic-2a527ee6-325f-4575-89ef-60eda76301f0 @ 05/21/24 16:44:26.885
  I0521 16:44:26.892306 22 resource.go:87] Pod name my-hostname-basic-2a527ee6-325f-4575-89ef-60eda76301f0: Found 0 pods out of 1
  I0521 16:44:31.895794 22 resource.go:87] Pod name my-hostname-basic-2a527ee6-325f-4575-89ef-60eda76301f0: Found 1 pods out of 1
  I0521 16:44:31.895831 22 rc.go:507] Ensuring all pods for ReplicationController "my-hostname-basic-2a527ee6-325f-4575-89ef-60eda76301f0" are running
  I0521 16:44:31.900109 22 rc.go:523] Pod "my-hostname-basic-2a527ee6-325f-4575-89ef-60eda76301f0-7mhws" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 16:44:28 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 16:44:26 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 16:44:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 16:44:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 16:44:26 +0000 UTC Reason: Message:}])
  I0521 16:44:31.900144 22 rc.go:531] Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/21/24 16:44:31.9
  I0521 16:44:31.908548 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5407" for this suite. @ 05/21/24 16:44:31.91
• [5.045 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3161
  STEP: Creating a kubernetes client @ 05/21/24 16:44:31.914
  I0521 16:44:31.914202 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 16:44:31.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:31.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:31.926
  STEP: creating an Endpoint @ 05/21/24 16:44:31.929
  STEP: waiting for available Endpoint @ 05/21/24 16:44:31.931
  STEP: listing all Endpoints @ 05/21/24 16:44:31.932
  STEP: updating the Endpoint @ 05/21/24 16:44:31.933
  STEP: fetching the Endpoint @ 05/21/24 16:44:31.937
  STEP: patching the Endpoint @ 05/21/24 16:44:31.938
  STEP: fetching the Endpoint @ 05/21/24 16:44:31.943
  STEP: deleting the Endpoint by Collection @ 05/21/24 16:44:31.944
  STEP: waiting for Endpoint deletion @ 05/21/24 16:44:31.947
  STEP: fetching the Endpoint @ 05/21/24 16:44:31.947
  I0521 16:44:31.949224 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3942" for this suite. @ 05/21/24 16:44:31.95
• [0.039 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 05/21/24 16:44:31.953
  I0521 16:44:31.953073 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 16:44:31.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:31.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:31.963
  STEP: Counting existing ResourceQuota @ 05/21/24 16:44:31.964
  STEP: Creating a ResourceQuota @ 05/21/24 16:44:36.966
  STEP: Ensuring resource quota status is calculated @ 05/21/24 16:44:36.971
  STEP: Creating a ReplicaSet @ 05/21/24 16:44:38.976
  STEP: Ensuring resource quota status captures replicaset creation @ 05/21/24 16:44:38.989
  STEP: Deleting a ReplicaSet @ 05/21/24 16:44:40.997
  STEP: Ensuring resource quota status released usage @ 05/21/24 16:44:41.004
  I0521 16:44:43.009729 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7316" for this suite. @ 05/21/24 16:44:43.012
• [11.065 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 05/21/24 16:44:43.018
  I0521 16:44:43.018863 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 16:44:43.019
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:43.03
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:43.032
  STEP: Setting up server cert @ 05/21/24 16:44:43.046
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 16:44:43.324
  STEP: Deploying the webhook pod @ 05/21/24 16:44:43.328
  STEP: Wait for the deployment to be ready @ 05/21/24 16:44:43.335
  I0521 16:44:43.338507 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/21/24 16:44:45.348
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:44:45.359
  I0521 16:44:46.360295 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/21/24 16:44:46.364
  STEP: create a pod @ 05/21/24 16:44:46.375
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 05/21/24 16:44:48.386
  I0521 16:44:48.387083 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=webhook-7456 attach --namespace=webhook-7456 to-be-attached-pod -i -c=container1'
  I0521 16:44:48.463757 22 builder.go:135] rc: 1
  I0521 16:44:48.489016 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7456" for this suite. @ 05/21/24 16:44:48.491
  STEP: Destroying namespace "webhook-markers-3822" for this suite. @ 05/21/24 16:44:48.497
• [5.482 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 05/21/24 16:44:48.501
  I0521 16:44:48.501046 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename tables @ 05/21/24 16:44:48.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:48.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:48.514
  I0521 16:44:48.518369 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-5373" for this suite. @ 05/21/24 16:44:48.52
• [0.023 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 05/21/24 16:44:48.524
  I0521 16:44:48.524089 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename csistoragecapacity @ 05/21/24 16:44:48.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:48.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:48.535
  STEP: getting /apis @ 05/21/24 16:44:48.537
  STEP: getting /apis/storage.k8s.io @ 05/21/24 16:44:48.54
  STEP: getting /apis/storage.k8s.io/v1 @ 05/21/24 16:44:48.541
  STEP: creating @ 05/21/24 16:44:48.542
  STEP: watching @ 05/21/24 16:44:48.553
  I0521 16:44:48.553357 22 csistoragecapacity.go:143] starting watch
  STEP: getting @ 05/21/24 16:44:48.557
  STEP: listing in namespace @ 05/21/24 16:44:48.558
  STEP: listing across namespaces @ 05/21/24 16:44:48.56
  STEP: patching @ 05/21/24 16:44:48.561
  STEP: updating @ 05/21/24 16:44:48.565
  I0521 16:44:48.568600 22 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I0521 16:44:48.568709 22 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 05/21/24 16:44:48.568
  STEP: deleting a collection @ 05/21/24 16:44:48.574
  I0521 16:44:48.582051 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-7213" for this suite. @ 05/21/24 16:44:48.584
• [0.065 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 05/21/24 16:44:48.588
  I0521 16:44:48.588805 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:44:48.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:48.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:48.599
  STEP: Creating configMap with name projected-configmap-test-volume-650ad1b4-084d-4d01-97a8-43c11172dd84 @ 05/21/24 16:44:48.601
  STEP: Creating a pod to test consume configMaps @ 05/21/24 16:44:48.604
  STEP: Saw pod success @ 05/21/24 16:44:52.624
  I0521 16:44:52.627686 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-547bace5-e790-49ab-9156-b9eeeee81dff container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 16:44:52.644
  I0521 16:44:52.655209 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5361" for this suite. @ 05/21/24 16:44:52.656
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 05/21/24 16:44:52.66
  I0521 16:44:52.660147 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/21/24 16:44:52.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:52.669
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:52.67
  I0521 16:44:52.672325 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:44:55.730864 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-9236" for this suite. @ 05/21/24 16:44:55.734
• [3.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 05/21/24 16:44:55.743
  I0521 16:44:55.743781 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename podtemplate @ 05/21/24 16:44:55.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:55.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:55.757
  STEP: Create set of pod templates @ 05/21/24 16:44:55.76
  I0521 16:44:55.766158 22 podtemplates.go:143] created test-podtemplate-1
  I0521 16:44:55.769937 22 podtemplates.go:143] created test-podtemplate-2
  I0521 16:44:55.774506 22 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 05/21/24 16:44:55.774
  STEP: delete collection of pod templates @ 05/21/24 16:44:55.776
  I0521 16:44:55.776581 22 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 05/21/24 16:44:55.785
  I0521 16:44:55.786029 22 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I0521 16:44:55.788281 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-1895" for this suite. @ 05/21/24 16:44:55.79
• [0.052 seconds]
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 05/21/24 16:44:55.795
  I0521 16:44:55.795554 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 16:44:55.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:55.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:55.807
  STEP: creating pod @ 05/21/24 16:44:55.809
  I0521 16:44:57.828136 22 pods.go:83] Pod pod-hostip-69588eb1-18c3-4d79-8155-6b57f99b4602 has hostIP: 192.168.67.3
  I0521 16:44:57.828283 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8729" for this suite. @ 05/21/24 16:44:57.831
• [2.040 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 05/21/24 16:44:57.835
  I0521 16:44:57.835750 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename init-container @ 05/21/24 16:44:57.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:44:57.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:44:57.85
  STEP: creating the pod @ 05/21/24 16:44:57.852
  I0521 16:44:57.852182 22 init_container.go:294] PodSpec: initContainers in spec.initContainers
  I0521 16:45:00.916844 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3618" for this suite. @ 05/21/24 16:45:00.919
• [3.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 05/21/24 16:45:00.925
  I0521 16:45:00.925432 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 05/21/24 16:45:00.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:45:00.934
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:45:00.937
  STEP: Setting up the test @ 05/21/24 16:45:00.939
  STEP: Creating hostNetwork=false pod @ 05/21/24 16:45:00.939
  STEP: Creating hostNetwork=true pod @ 05/21/24 16:45:02.95
  STEP: Running the test @ 05/21/24 16:45:04.961
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 05/21/24 16:45:04.961
  I0521 16:45:04.961175 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:04.961207 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:04.961690 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:04.961736 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0521 16:45:05.005346 22 exec_util.go:106] Exec stderr: ""
  I0521 16:45:05.005395 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:05.005406 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:05.005821 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:05.005869 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0521 16:45:05.050707 22 exec_util.go:106] Exec stderr: ""
  I0521 16:45:05.050756 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:05.050765 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:05.051251 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:05.051309 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0521 16:45:05.098876 22 exec_util.go:106] Exec stderr: ""
  I0521 16:45:05.098927 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:05.098939 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:05.099402 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:05.099442 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0521 16:45:05.139727 22 exec_util.go:106] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 05/21/24 16:45:05.139
  I0521 16:45:05.139797 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:05.139808 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:05.140143 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:05.140182 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0521 16:45:05.185387 22 exec_util.go:106] Exec stderr: ""
  I0521 16:45:05.185463 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:05.185487 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:05.186294 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:05.186372 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I0521 16:45:05.248547 22 exec_util.go:106] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 05/21/24 16:45:05.248
  I0521 16:45:05.248728 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:05.248747 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:05.249381 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:05.249461 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0521 16:45:05.315408 22 exec_util.go:106] Exec stderr: ""
  I0521 16:45:05.315487 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:05.315505 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:05.316167 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:05.316264 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I0521 16:45:05.363267 22 exec_util.go:106] Exec stderr: ""
  I0521 16:45:05.363325 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:05.363337 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:05.363818 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:05.363879 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0521 16:45:05.425869 22 exec_util.go:106] Exec stderr: ""
  I0521 16:45:05.425940 22 exec_util.go:55] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2550 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:45:05.425959 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:45:05.426651 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:45:05.426728 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2550/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I0521 16:45:05.484746 22 exec_util.go:106] Exec stderr: ""
  I0521 16:45:05.484895 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-2550" for this suite. @ 05/21/24 16:45:05.488
• [4.568 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2218
  STEP: Creating a kubernetes client @ 05/21/24 16:45:05.494
  I0521 16:45:05.494895 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 16:45:05.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:45:05.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:45:05.508
  STEP: creating service in namespace services-6171 @ 05/21/24 16:45:05.51
  STEP: creating service affinity-nodeport in namespace services-6171 @ 05/21/24 16:45:05.51
  STEP: creating replication controller affinity-nodeport in namespace services-6171 @ 05/21/24 16:45:05.523
  I0521 16:45:05.531879      22 runners.go:198] Created replication controller with name: affinity-nodeport, namespace: services-6171, replica count: 3
  I0521 16:45:08.583459      22 runners.go:198] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0521 16:45:08.593586 22 resource.go:361] Creating new exec pod
  I0521 16:45:11.614348 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-6171 exec execpod-affinityqwpr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I0521 16:45:11.712318 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  I0521 16:45:11.712366 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 16:45:11.712443 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-6171 exec execpod-affinityqwpr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.111.120.234 80'
  I0521 16:45:11.816423 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.111.120.234 80\nConnection to 10.111.120.234 80 port [tcp/http] succeeded!\n"
  I0521 16:45:11.816468 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 16:45:11.816541 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-6171 exec execpod-affinityqwpr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.2 30092'
  I0521 16:45:11.930161 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.2 30092\nConnection to 192.168.67.2 30092 port [tcp/*] succeeded!\n"
  I0521 16:45:11.930279 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 16:45:11.930351 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-6171 exec execpod-affinityqwpr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.3 30092'
  I0521 16:45:12.017580 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.3 30092\nConnection to 192.168.67.3 30092 port [tcp/*] succeeded!\n"
  I0521 16:45:12.017614 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 16:45:12.017726 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-6171 exec execpod-affinityqwpr4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.67.2:30092/ ; done'
  I0521 16:45:12.172879 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:30092/\n"
  I0521 16:45:12.172933 22 builder.go:147] stdout: "\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r\naffinity-nodeport-rsx8r"
  I0521 16:45:12.172949 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.172959 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.172967 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.172974 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.172982 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.172989 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.172996 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173006 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173014 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173023 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173031 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173038 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173046 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173054 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173061 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173071 22 service.go:242] Received response from host: affinity-nodeport-rsx8r
  I0521 16:45:12.173134 22 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-6171, will wait for the garbage collector to delete the pods @ 05/21/24 16:45:12.178
  I0521 16:45:12.234556 22 resources.go:139] Deleting ReplicationController affinity-nodeport took: 3.488854ms
  I0521 16:45:12.335433 22 resources.go:163] Terminating ReplicationController affinity-nodeport pods took: 100.873613ms
  I0521 16:45:15.454863 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6171" for this suite. @ 05/21/24 16:45:15.457
• [9.966 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 05/21/24 16:45:15.461
  I0521 16:45:15.461855 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 16:45:15.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:45:15.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:45:15.475
  STEP: Creating configMap with name configmap-test-upd-69e4c936-f61d-4254-b0f8-adb59b8a0547 @ 05/21/24 16:45:15.479
  STEP: Creating the pod @ 05/21/24 16:45:15.482
  STEP: Updating configmap configmap-test-upd-69e4c936-f61d-4254-b0f8-adb59b8a0547 @ 05/21/24 16:45:17.499
  STEP: waiting to observe update in volume @ 05/21/24 16:45:17.502
  I0521 16:46:41.934033 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-63" for this suite. @ 05/21/24 16:46:41.937
• [86.483 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 05/21/24 16:46:41.945
  I0521 16:46:41.945538 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-webhook @ 05/21/24 16:46:41.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:46:41.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:46:41.961
  STEP: Setting up server cert @ 05/21/24 16:46:41.963
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/21/24 16:46:42.176
  STEP: Deploying the custom resource conversion webhook pod @ 05/21/24 16:46:42.182
  STEP: Wait for the deployment to be ready @ 05/21/24 16:46:42.189
  I0521 16:46:42.193828 22 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/21/24 16:46:44.199
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:46:44.207
  I0521 16:46:45.208430 22 util.go:427] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0521 16:46:45.213938 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Creating a v1 custom resource @ 05/21/24 16:46:47.785
  STEP: v2 custom resource should be converted @ 05/21/24 16:46:47.789
  I0521 16:46:48.332118 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-6436" for this suite. @ 05/21/24 16:46:48.334
• [6.396 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 05/21/24 16:46:48.341
  I0521 16:46:48.341547 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 16:46:48.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:46:48.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:46:48.363
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 16:46:48.365
  STEP: Saw pod success @ 05/21/24 16:46:50.375
  I0521 16:46:50.379030 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-5de86cf3-7b20-44bf-816e-12fce7237a57 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 16:46:50.386
  I0521 16:46:50.402353 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8871" for this suite. @ 05/21/24 16:46:50.405
• [2.068 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3572
  STEP: Creating a kubernetes client @ 05/21/24 16:46:50.41
  I0521 16:46:50.410106 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 16:46:50.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:46:50.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:46:50.42
  STEP: creating a collection of services @ 05/21/24 16:46:50.422
  I0521 16:46:50.422516 22 service.go:3608] Creating e2e-svc-a-klr2z
  I0521 16:46:50.433392 22 service.go:3608] Creating e2e-svc-b-769xk
  I0521 16:46:50.445480 22 service.go:3608] Creating e2e-svc-c-l7lln
  STEP: deleting service collection @ 05/21/24 16:46:50.459
  I0521 16:46:50.479327 22 service.go:3643] Collection of services has been deleted
  I0521 16:46:50.479443 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9048" for this suite. @ 05/21/24 16:46:50.481
• [0.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 05/21/24 16:46:50.486
  I0521 16:46:50.486774 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 16:46:50.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:46:50.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:46:50.497
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 16:46:50.498
  STEP: Saw pod success @ 05/21/24 16:46:54.514
  I0521 16:46:54.517042 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-19d9b2b0-289e-4942-a092-64eba6b1c14b container client-container: <nil>
  STEP: delete the pod @ 05/21/24 16:46:54.523
  I0521 16:46:54.535811 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4292" for this suite. @ 05/21/24 16:46:54.539
• [4.058 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 05/21/24 16:46:54.545
  I0521 16:46:54.545343 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename subpath @ 05/21/24 16:46:54.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:46:54.557
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:46:54.559
  STEP: Setting up data @ 05/21/24 16:46:54.561
  STEP: Creating pod pod-subpath-test-secret-v9fl @ 05/21/24 16:46:54.57
  STEP: Creating a pod to test atomic-volume-subpath @ 05/21/24 16:46:54.57
  STEP: Saw pod success @ 05/21/24 16:47:16.635
  I0521 16:47:16.637843 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-secret-v9fl container test-container-subpath-secret-v9fl: <nil>
  STEP: delete the pod @ 05/21/24 16:47:16.644
  STEP: Deleting pod pod-subpath-test-secret-v9fl @ 05/21/24 16:47:16.656
  I0521 16:47:16.656438 22 delete.go:62] Deleting pod "pod-subpath-test-secret-v9fl" in namespace "subpath-3795"
  I0521 16:47:16.658164 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3795" for this suite. @ 05/21/24 16:47:16.659
• [22.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 05/21/24 16:47:16.663
  I0521 16:47:16.663885 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 16:47:16.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:16.675
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:16.676
  STEP: Creating configMap with name configmap-test-volume-map-2926a62c-c32b-4fe0-8dfd-5367c5e5cd35 @ 05/21/24 16:47:16.678
  STEP: Creating a pod to test consume configMaps @ 05/21/24 16:47:16.681
  STEP: Saw pod success @ 05/21/24 16:47:18.688
  I0521 16:47:18.689944 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-d79caee6-a183-4aca-8d61-651be0152dcf container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 16:47:18.694
  I0521 16:47:18.702119 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9636" for this suite. @ 05/21/24 16:47:18.703
• [2.043 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 05/21/24 16:47:18.706
  I0521 16:47:18.706840 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename gc @ 05/21/24 16:47:18.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:18.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:18.715
  STEP: create the rc @ 05/21/24 16:47:18.717
  W0521 16:47:18.723673      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 05/21/24 16:47:23.73
  STEP: wait for all pods to be garbage collected @ 05/21/24 16:47:23.741
  STEP: Gathering metrics @ 05/21/24 16:47:28.747
  I0521 16:47:28.816174 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0521 16:47:28.816275 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3675" for this suite. @ 05/21/24 16:47:28.818
• [10.114 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 05/21/24 16:47:28.821
  I0521 16:47:28.821064 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:47:28.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:28.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:28.831
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 16:47:28.832
  STEP: Saw pod success @ 05/21/24 16:47:30.841
  I0521 16:47:30.842858 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-4f1c81aa-ba99-4793-8d87-01492d3a5091 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 16:47:30.847
  I0521 16:47:30.856215 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2166" for this suite. @ 05/21/24 16:47:30.857
• [2.041 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 05/21/24 16:47:30.862
  I0521 16:47:30.862312 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename field-validation @ 05/21/24 16:47:30.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:30.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:30.872
  I0521 16:47:30.873509 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:47:33.943915 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-750" for this suite. @ 05/21/24 16:47:33.945
• [3.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 05/21/24 16:47:33.949
  I0521 16:47:33.949184 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 16:47:33.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:33.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:33.959
  STEP: Setting up server cert @ 05/21/24 16:47:33.969
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 16:47:34.077
  STEP: Deploying the webhook pod @ 05/21/24 16:47:34.081
  STEP: Wait for the deployment to be ready @ 05/21/24 16:47:34.088
  I0521 16:47:34.091399 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/21/24 16:47:36.102
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:47:36.113
  I0521 16:47:37.114419 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 05/21/24 16:47:37.122
  STEP: create a pod that should be updated by the webhook @ 05/21/24 16:47:37.141
  I0521 16:47:37.189585 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3823" for this suite. @ 05/21/24 16:47:37.191
  STEP: Destroying namespace "webhook-markers-4094" for this suite. @ 05/21/24 16:47:37.196
• [3.250 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:446
  STEP: Creating a kubernetes client @ 05/21/24 16:47:37.199
  I0521 16:47:37.199094 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-pred @ 05/21/24 16:47:37.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:37.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:37.207
  I0521 16:47:37.208577 22 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0521 16:47:37.210798 22 util.go:400] Waiting for terminating namespaces to be deleted...
  I0521 16:47:37.211797 22 predicates.go:121] 
  Logging pods the apiserver thinks is on node k8sconformance before test
  I0521 16:47:37.214118 22 predicates.go:887] coredns-7db6d8ff4d-5h9wx from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.214136 22 predicates.go:889] 	Container coredns ready: true, restart count 1
  I0521 16:47:37.214146 22 predicates.go:887] etcd-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.214153 22 predicates.go:889] 	Container etcd ready: true, restart count 0
  I0521 16:47:37.214160 22 predicates.go:887] kindnet-x4z6c from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.214166 22 predicates.go:889] 	Container kindnet-cni ready: true, restart count 0
  I0521 16:47:37.214176 22 predicates.go:887] kube-apiserver-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.214182 22 predicates.go:889] 	Container kube-apiserver ready: true, restart count 0
  I0521 16:47:37.214221 22 predicates.go:887] kube-controller-manager-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.214228 22 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 0
  I0521 16:47:37.214236 22 predicates.go:887] kube-proxy-bk2bg from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.214242 22 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0521 16:47:37.214249 22 predicates.go:887] kube-scheduler-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.214257 22 predicates.go:889] 	Container kube-scheduler ready: true, restart count 0
  I0521 16:47:37.214264 22 predicates.go:887] storage-provisioner from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.214269 22 predicates.go:889] 	Container storage-provisioner ready: true, restart count 1
  I0521 16:47:37.214276 22 predicates.go:887] sonobuoy-systemd-logs-daemon-set-05530e69374c4820-8kzzl from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 16:47:37.214284 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 16:47:37.214290 22 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0521 16:47:37.214301 22 predicates.go:121] 
  Logging pods the apiserver thinks is on node k8sconformance-m02 before test
  I0521 16:47:37.216304 22 predicates.go:887] kindnet-cp6pr from kube-system started at 2024-05-21 16:34:28 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.216320 22 predicates.go:889] 	Container kindnet-cni ready: true, restart count 0
  I0521 16:47:37.216326 22 predicates.go:887] kube-proxy-8nnv4 from kube-system started at 2024-05-21 16:34:28 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.216330 22 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0521 16:47:37.216335 22 predicates.go:887] sonobuoy from sonobuoy started at 2024-05-21 16:38:41 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.216339 22 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0521 16:47:37.216343 22 predicates.go:887] sonobuoy-e2e-job-6986495216344806 from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 16:47:37.216347 22 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0521 16:47:37.216351 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 16:47:37.216355 22 predicates.go:887] sonobuoy-systemd-logs-daemon-set-05530e69374c4820-9t6gh from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 16:47:37.216359 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 16:47:37.216362 22 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0521 16:47:37.216366 22 predicates.go:887] webhook-to-be-mutated from webhook-3823 started at 2024-05-21 16:47:37 +0000 UTC (1 container statuses recorded)
  I0521 16:47:37.216370 22 predicates.go:889] 	Container example ready: false, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 05/21/24 16:47:37.216
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17d18ee755578d3e], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] @ 05/21/24 16:47:37.228
  I0521 16:47:38.228721 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-232" for this suite. @ 05/21/24 16:47:38.231
• [1.039 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 05/21/24 16:47:38.238
  I0521 16:47:38.238729 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename events @ 05/21/24 16:47:38.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:38.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:38.25
  STEP: creating a test event @ 05/21/24 16:47:38.253
  STEP: listing all events in all namespaces @ 05/21/24 16:47:38.257
  STEP: patching the test event @ 05/21/24 16:47:38.262
  STEP: fetching the test event @ 05/21/24 16:47:38.266
  STEP: updating the test event @ 05/21/24 16:47:38.268
  STEP: getting the test event @ 05/21/24 16:47:38.277
  STEP: deleting the test event @ 05/21/24 16:47:38.28
  STEP: listing all events in all namespaces @ 05/21/24 16:47:38.284
  I0521 16:47:38.289184 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1854" for this suite. @ 05/21/24 16:47:38.292
• [0.058 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 05/21/24 16:47:38.299
  I0521 16:47:38.299338 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename deployment @ 05/21/24 16:47:38.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:38.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:38.315
  I0521 16:47:38.317335 22 deployment.go:1196] Creating deployment "webserver-deployment"
  I0521 16:47:38.320933 22 deployment.go:1200] Waiting for observed generation 1
  I0521 16:47:40.327906 22 deployment.go:1205] Waiting for all required pods to come up
  I0521 16:47:40.332337 22 resource.go:87] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 05/21/24 16:47:40.332
  I0521 16:47:40.332477 22 deployment.go:1209] Waiting for deployment "webserver-deployment" to complete
  I0521 16:47:40.337126 22 deployment.go:1218] Updating deployment "webserver-deployment" with a non-existent image
  I0521 16:47:40.347882 22 deployment.go:313] Updating deployment webserver-deployment
  I0521 16:47:40.347958 22 deployment.go:1224] Waiting for observed generation 2
  I0521 16:47:42.359136 22 deployment.go:1234] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I0521 16:47:42.361517 22 deployment.go:1239] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0521 16:47:42.363338 22 deployment.go:1244] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0521 16:47:42.369181 22 deployment.go:1258] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0521 16:47:42.369291 22 deployment.go:1263] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0521 16:47:42.373914 22 deployment.go:1268] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0521 16:47:42.377973 22 deployment.go:1275] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0521 16:47:42.378017 22 deployment.go:1283] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0521 16:47:42.386143 22 deployment.go:313] Updating deployment webserver-deployment
  I0521 16:47:42.386205 22 deployment.go:1289] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0521 16:47:42.391211 22 deployment.go:1297] Verifying that first rollout's replicaset has .spec.replicas = 20
  I0521 16:47:42.394866 22 deployment.go:1303] Verifying that second rollout's replicaset has .spec.replicas = 13
  I0521 16:47:42.403591 22 deployment.go:633] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "df1db73a-40fd-4bbb-9602-8e5cc5c8d8dc",
      ResourceVersion: (string) (len=4) "4707",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-67c89d485c\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0521 16:47:42.412775 22 deployment.go:39] New ReplicaSet "webserver-deployment-67c89d485c" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-67c89d485c",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e62b2c65-30a2-4c60-a375-574fb33015de",
      ResourceVersion: (string) (len=4) "4711",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "df1db73a-40fd-4bbb-9602-8e5cc5c8d8dc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 66 31 64 62 37  33 61 2d 34 30 66 64 2d  |\"df1db73a-40fd-|
              00000120  34 62 62 62 2d 39 36 30  32 2d 38 65 35 63 63 35  |4bbb-9602-8e5cc5|
              00000130  63 38 64 38 64 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c8d8dc\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 16:47:42.414795 22 deployment.go:44] All old ReplicaSets of Deployment "webserver-deployment":
  I0521 16:47:42.415459 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-77db57d8df",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
      ResourceVersion: (string) (len=4) "4708",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "df1db73a-40fd-4bbb-9602-8e5cc5c8d8dc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 66 31 64 62 37  33 61 2d 34 30 66 64 2d  |\"df1db73a-40fd-|
              00000120  34 62 62 62 2d 39 36 30  32 2d 38 65 35 63 63 35  |4bbb-9602-8e5cc5|
              00000130  63 38 64 38 64 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c8d8dc\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 16:47:42.429502 22 deployment.go:67] Pod "webserver-deployment-67c89d485c-7tqqm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-7tqqm",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "25a66779-0f91-4402-8f35-5d13f91a7bc5",
      ResourceVersion: (string) (len=4) "4688",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "e62b2c65-30a2-4c60-a375-574fb33015de",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  32 62 32 63 36 35 2d 33  |d\":\"e62b2c65-3|
              00000090  30 61 32 2d 34 63 36 30  2d 61 33 37 35 2d 35 37  |0a2-4c60-a375-57|
              000000a0  34 66 62 33 33 30 31 35  64 65 5c 22 7d 22 3a 7b  |4fb33015de\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=705) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 31 2e 35 38 5c 22  7d 22 3a 7b 22 2e 22 3a  |4.1.58\"}":{".":|
              000002a0  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              000002b0  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              000002c0  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-p2fxs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-p2fxs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.58",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.58"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=169) "Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.432173 22 deployment.go:67] Pod "webserver-deployment-67c89d485c-9x6fk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-9x6fk",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "df0e57d8-f253-4571-b89b-990feab4ee24",
      ResourceVersion: (string) (len=4) "4676",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "e62b2c65-30a2-4c60-a375-574fb33015de",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  32 62 32 63 36 35 2d 33  |d\":\"e62b2c65-3|
              00000090  30 61 32 2d 34 63 36 30  2d 61 33 37 35 2d 35 37  |0a2-4c60-a375-57|
              000000a0  34 66 62 33 33 30 31 35  64 65 5c 22 7d 22 3a 7b  |4fb33015de\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=705) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 30 2e 31 38 5c 22  7d 22 3a 7b 22 2e 22 3a  |4.0.18\"}":{".":|
              000002a0  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              000002b0  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              000002c0  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-f2wtg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-f2wtg",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.18",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.18"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=169) "Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.434548 22 deployment.go:67] Pod "webserver-deployment-67c89d485c-9x9lp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-9x9lp",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5a51e73f-7612-49df-8070-77a163d24595",
      ResourceVersion: (string) (len=4) "4661",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "e62b2c65-30a2-4c60-a375-574fb33015de",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  32 62 32 63 36 35 2d 33  |d\":\"e62b2c65-3|
              00000090  30 61 32 2d 34 63 36 30  2d 61 33 37 35 2d 35 37  |0a2-4c60-a375-57|
              000000a0  34 66 62 33 33 30 31 35  64 65 5c 22 7d 22 3a 7b  |4fb33015de\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-w4s89",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-w4s89",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.436651 22 deployment.go:67] Pod "webserver-deployment-67c89d485c-b2mwz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-b2mwz",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "94267d70-bdba-4367-b4f9-853eab5835c4",
      ResourceVersion: (string) (len=4) "4723",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "e62b2c65-30a2-4c60-a375-574fb33015de",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  32 62 32 63 36 35 2d 33  |d\":\"e62b2c65-3|
              00000090  30 61 32 2d 34 63 36 30  2d 61 33 37 35 2d 35 37  |0a2-4c60-a375-57|
              000000a0  34 66 62 33 33 30 31 35  64 65 5c 22 7d 22 3a 7b  |4fb33015de\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ql82p",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ql82p",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.437671 22 deployment.go:67] Pod "webserver-deployment-67c89d485c-bjjb4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-bjjb4",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9bb74605-7afb-4732-ad3c-54480ee3f69b",
      ResourceVersion: (string) (len=4) "4726",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "e62b2c65-30a2-4c60-a375-574fb33015de",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  32 62 32 63 36 35 2d 33  |d\":\"e62b2c65-3|
              00000090  30 61 32 2d 34 63 36 30  2d 61 33 37 35 2d 35 37  |0a2-4c60-a375-57|
              000000a0  34 66 62 33 33 30 31 35  64 65 5c 22 7d 22 3a 7b  |4fb33015de\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-74qcs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-74qcs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.438873 22 deployment.go:67] Pod "webserver-deployment-67c89d485c-fpz2n" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-fpz2n",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4573600f-5554-4bb6-ba7d-652015474554",
      ResourceVersion: (string) (len=4) "4660",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "e62b2c65-30a2-4c60-a375-574fb33015de",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  32 62 32 63 36 35 2d 33  |d\":\"e62b2c65-3|
              00000090  30 61 32 2d 34 63 36 30  2d 61 33 37 35 2d 35 37  |0a2-4c60-a375-57|
              000000a0  34 66 62 33 33 30 31 35  64 65 5c 22 7d 22 3a 7b  |4fb33015de\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4pps6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4pps6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.440602 22 deployment.go:67] Pod "webserver-deployment-67c89d485c-kql8s" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-kql8s",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d4a6cd67-237c-48b3-92a7-84470927e629",
      ResourceVersion: (string) (len=4) "4724",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "e62b2c65-30a2-4c60-a375-574fb33015de",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  32 62 32 63 36 35 2d 33  |d\":\"e62b2c65-3|
              00000090  30 61 32 2d 34 63 36 30  2d 61 33 37 35 2d 35 37  |0a2-4c60-a375-57|
              000000a0  34 66 62 33 33 30 31 35  64 65 5c 22 7d 22 3a 7b  |4fb33015de\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pwpxb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pwpxb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.441782 22 deployment.go:67] Pod "webserver-deployment-67c89d485c-n8gfj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-67c89d485c-n8gfj",
      GenerateName: (string) (len=32) "webserver-deployment-67c89d485c-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "72e1ff7f-f672-4606-ba58-4deae27f5c51",
      ResourceVersion: (string) (len=4) "4685",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "67c89d485c"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-67c89d485c",
          UID: (types.UID) (len=36) "e62b2c65-30a2-4c60-a375-574fb33015de",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  32 62 32 63 36 35 2d 33  |d\":\"e62b2c65-3|
              00000090  30 61 32 2d 34 63 36 30  2d 61 33 37 35 2d 35 37  |0a2-4c60-a375-57|
              000000a0  34 66 62 33 33 30 31 35  64 65 5c 22 7d 22 3a 7b  |4fb33015de\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=705) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 30 2e 32 34  |:{\"ip\":\"10.24|
              00000290  34 2e 31 2e 35 39 5c 22  7d 22 3a 7b 22 2e 22 3a  |4.1.59\"}":{".":|
              000002a0  7b 7d 2c 22 66 3a 69 70  22 3a 7b 7d 7d 7d 2c 22  |{},"f:ip":{}}},"|
              000002b0  66 3a 73 74 61 72 74 54  69 6d 65 22 3a 7b 7d 7d  |f:startTime":{}}|
              000002c0  7d                                                |}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ks6pm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ks6pm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906861,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906860,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.59",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.59"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906860,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=169) "Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.443166 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-5rdnl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-5rdnl",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "333b0aee-cf10-4d80-802a-98871b28891d",
      ResourceVersion: (string) (len=4) "4727",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hn8xr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hn8xr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.444116 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-8hxsh" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-8hxsh",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4345c151-8263-4f45-90b1-1db763106177",
      ResourceVersion: (string) (len=4) "4597",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 31  34 5c 22 7d 22 3a 7b 22  |.244.0.14\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9pkbf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9pkbf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.14",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.14"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851906859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://651334139dffa9f57a3324a7f9181f8bd8f8d20215b194c4d4c14d279bff8554",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.445923 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-8mt8k" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-8mt8k",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "75282b0c-8943-4208-b0d3-6eb09d2d898d",
      ResourceVersion: (string) (len=4) "4590",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 31  37 5c 22 7d 22 3a 7b 22  |.244.0.17\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rrvkl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rrvkl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.17",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.17"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851906859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://55e487d3ce88dd08f1c78e25512f285e6059043635584972695f83ae39b2ad13",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.447414 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-gw2v7" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-gw2v7",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4b5900f3-9d3f-46d9-ac24-fb6261d4971f",
      ResourceVersion: (string) (len=4) "4593",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 31  36 5c 22 7d 22 3a 7b 22  |.244.0.16\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-b6fxv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-b6fxv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.16",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.16"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851906859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://1bee845833d6e4b67f76cfd27f9eca217ca76abe16f763cbebd33790deb21cdb",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.448973 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-h4hz9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-h4hz9",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ab7c9dd6-c855-4937-aaed-43947e662241",
      ResourceVersion: (string) (len=4) "4611",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 35  33 5c 22 7d 22 3a 7b 22  |.244.1.53\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6qwwp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6qwwp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.53",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.53"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851906859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://40c5c296c6a97f636cebb6f81169511736c9a430819fe0f476d702b59e634eff",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.450379 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-hb5mp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-hb5mp",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2d82eb25-5da7-4276-8e8d-990957940491",
      ResourceVersion: (string) (len=4) "4719",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-65zxk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-65zxk",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.451342 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-jkqh7" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-jkqh7",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0c9bfac9-593e-4f36-9093-b62954a01b99",
      ResourceVersion: (string) (len=4) "4603",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 35  35 5c 22 7d 22 3a 7b 22  |.244.1.55\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4l6rb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4l6rb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.55",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.55"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851906859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://b5270a1039398d541db24e476e9741907b7f7e55b262c4e030e620bd30d73579",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.452535 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-llj8k" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-llj8k",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "20139ae5-883c-448b-bb7e-78e451bc5709",
      ResourceVersion: (string) (len=4) "4722",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tvpld",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tvpld",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.453352 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-lpnhn" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-lpnhn",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "09b2e401-d901-4a06-87ae-091dc1e97464",
      ResourceVersion: (string) (len=4) "4588",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 31  35 5c 22 7d 22 3a 7b 22  |.244.0.15\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vcgkc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vcgkc",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.15",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.15"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851906859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://b4bcefbf9ead88ee4e15f434b79593161e0ddfd93822094503efcf2f0228173a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.454781 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-q8n68" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-q8n68",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f6e4ff92-275b-4852-85df-5b5d437cc2dc",
      ResourceVersion: (string) (len=4) "4725",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7gnhn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7gnhn",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.455768 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-qkwq4" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-qkwq4",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f3ffa073-5e83-4ca0-88ff-0525fff87801",
      ResourceVersion: (string) (len=4) "4600",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 35  36 5c 22 7d 22 3a 7b 22  |.244.1.56\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sz6df",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sz6df",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.56",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.56"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851906859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://c668d53731d746bc7cdd1af2be77d8f7f28ef3579f94cd614b8c327fb417774c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.457168 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-rqz42" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-rqz42",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "12cda6b5-2125-4f86-8b4e-88e89d96f660",
      ResourceVersion: (string) (len=4) "4585",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 31  33 5c 22 7d 22 3a 7b 22  |.244.0.13\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t2zkg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t2zkg",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906859,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906858,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.13",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.13"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906858,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851906859,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://4f2fcaa766c9ee9dfd334931f545f3996817febb1e210ea704f55208d92b45b6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.458397 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-sv4xq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-sv4xq",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "46be559d-75d7-4384-943a-4837c7dca5a0",
      ResourceVersion: (string) (len=4) "4721",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t6lcw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t6lcw",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.459922 22 deployment.go:67] Pod "webserver-deployment-77db57d8df-t8c9w" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-77db57d8df-t8c9w",
      GenerateName: (string) (len=32) "webserver-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-1805",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f84deab7-09aa-430c-8274-5c107d6f5bc8",
      ResourceVersion: (string) (len=4) "4713",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851906862,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-77db57d8df",
          UID: (types.UID) (len=36) "15cdcfe0-cf4e-4940-8941-fb36ba010538",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 35  63 64 63 66 65 30 2d 63  |d\":\"15cdcfe0-c|
              00000090  66 34 65 2d 34 39 34 30  2d 38 39 34 31 2d 66 62  |f4e-4940-8941-fb|
              000000a0  33 36 62 61 30 31 30 35  33 38 5c 22 7d 22 3a 7b  |36ba010538\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pwdl5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pwdl5",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851906862,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:47:42.460656 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1805" for this suite. @ 05/21/24 16:47:42.468
• [4.180 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 05/21/24 16:47:42.479
  I0521 16:47:42.479625 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:47:42.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:42.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:42.49
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 16:47:42.491
  STEP: Saw pod success @ 05/21/24 16:47:46.509
  I0521 16:47:46.513083 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-2be5da8d-1e28-4899-ad47-cb931e1f340e container client-container: <nil>
  STEP: delete the pod @ 05/21/24 16:47:46.52
  I0521 16:47:46.536547 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5232" for this suite. @ 05/21/24 16:47:46.539
• [4.064 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 05/21/24 16:47:46.543
  I0521 16:47:46.543812 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 16:47:46.544
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:46.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:46.557
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 16:47:46.559
  STEP: Saw pod success @ 05/21/24 16:47:50.576
  I0521 16:47:50.578647 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-2a220d63-bbc9-42e7-94b2-54e74b51e8fe container client-container: <nil>
  STEP: delete the pod @ 05/21/24 16:47:50.586
  I0521 16:47:50.598700 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6530" for this suite. @ 05/21/24 16:47:50.601
• [4.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 05/21/24 16:47:50.609
  I0521 16:47:50.609073 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename var-expansion @ 05/21/24 16:47:50.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:50.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:50.624
  STEP: Creating a pod to test substitution in container's command @ 05/21/24 16:47:50.626
  STEP: Saw pod success @ 05/21/24 16:47:54.638
  I0521 16:47:54.641652 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod var-expansion-95e834ae-0aa5-4e27-b53b-e6ed86abe57e container dapi-container: <nil>
  STEP: delete the pod @ 05/21/24 16:47:54.649
  I0521 16:47:54.667182 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3300" for this suite. @ 05/21/24 16:47:54.67
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 05/21/24 16:47:54.68
  I0521 16:47:54.680398 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 16:47:54.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:54.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:54.695
  STEP: Setting up server cert @ 05/21/24 16:47:54.715
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 16:47:55.029
  STEP: Deploying the webhook pod @ 05/21/24 16:47:55.033
  STEP: Wait for the deployment to be ready @ 05/21/24 16:47:55.042
  I0521 16:47:55.047303 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 05/21/24 16:47:57.057
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:47:57.069
  I0521 16:47:58.069306 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 05/21/24 16:47:58.073
  STEP: create a configmap that should be updated by the webhook @ 05/21/24 16:47:58.084
  I0521 16:47:58.122643 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9054" for this suite. @ 05/21/24 16:47:58.125
  STEP: Destroying namespace "webhook-markers-448" for this suite. @ 05/21/24 16:47:58.13
• [3.454 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 05/21/24 16:47:58.134
  I0521 16:47:58.134382 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 16:47:58.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:47:58.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:47:58.144
  STEP: Creating pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900 @ 05/21/24 16:47:58.146
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/21/24 16:48:00.156
  I0521 16:48:00.158298 22 container_probe.go:1749] Initial restart count of pod test-webserver-6e443588-0603-4276-903c-842746fc9479 is 0
  I0521 16:48:00.160467 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:02.163567 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:04.167179 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:06.169224 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:08.174699 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:10.180541 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:12.187516 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:14.192315 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:16.194564 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:18.200034 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:20.205376 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:22.211551 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:24.214495 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:26.217277 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:28.221686 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:30.224476 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:32.228004 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:34.230822 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:36.236676 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:38.239173 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:40.244424 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:42.246572 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:44.251748 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:46.256673 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:48.262964 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:50.268027 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:52.271264 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:54.276442 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:56.282326 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:48:58.286751 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:00.292570 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:02.298564 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:04.303626 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:06.309016 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:08.312898 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:10.315688 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:12.321873 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:14.327621 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:16.331652 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:18.336429 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:20.341325 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:22.347941 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:24.355889 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:26.359713 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:28.363486 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:30.367519 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:32.372804 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:34.378728 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:36.384356 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:38.390472 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:40.395928 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:42.402830 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:44.408884 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:46.414647 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:48.420024 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:50.423145 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:52.429842 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:54.435322 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:56.440478 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:49:58.446414 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:00.452444 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:02.458114 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:04.464170 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:06.469907 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:08.474699 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:10.481302 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:12.488256 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:14.495126 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:16.498569 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:18.502125 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:20.506401 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:22.513021 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:24.518366 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:26.524550 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:28.530157 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:30.536167 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:32.543035 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:34.548146 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:36.554170 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:38.558012 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:40.560045 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:42.564287 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:44.569802 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:46.572590 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:48.578306 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:50.583803 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:52.589467 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:54.595620 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:56.601326 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:50:58.607601 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:00.614411 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:02.621351 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:04.627992 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:06.633406 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:08.640437 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:10.646218 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:12.652613 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:14.658761 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:16.664458 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:18.668073 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:20.670731 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:22.673956 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:24.677712 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:26.680669 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:28.683146 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:30.687509 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:32.694293 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:34.699329 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:36.705420 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:38.711490 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:40.717108 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:42.724883 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:44.731273 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:46.737738 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:48.741261 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:50.745508 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:52.751096 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:54.756901 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:56.763325 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  I0521 16:51:58.769240 22 container_probe.go:1759] Get pod test-webserver-6e443588-0603-4276-903c-842746fc9479 in namespace container-probe-6900
  STEP: deleting the pod @ 05/21/24 16:52:00.77
  I0521 16:52:00.785747 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6900" for this suite. @ 05/21/24 16:52:00.79
• [242.663 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:154
  STEP: Creating a kubernetes client @ 05/21/24 16:52:00.798
  I0521 16:52:00.798415 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/21/24 16:52:00.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:00.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:00.81
  I0521 16:52:00.811942 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/21/24 16:52:02.063
  I0521 16:52:02.063720 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-924 --namespace=crd-publish-openapi-924 create -f -'
  I0521 16:52:02.145990 22 builder.go:146] stderr: ""
  I0521 16:52:02.146036 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9133-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0521 16:52:02.146080 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-924 --namespace=crd-publish-openapi-924 delete e2e-test-crd-publish-openapi-9133-crds test-cr'
  I0521 16:52:02.195876 22 builder.go:146] stderr: ""
  I0521 16:52:02.195929 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9133-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I0521 16:52:02.195980 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-924 --namespace=crd-publish-openapi-924 apply -f -'
  I0521 16:52:02.263073 22 builder.go:146] stderr: ""
  I0521 16:52:02.263115 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9133-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0521 16:52:02.263159 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-924 --namespace=crd-publish-openapi-924 delete e2e-test-crd-publish-openapi-9133-crds test-cr'
  I0521 16:52:02.327056 22 builder.go:146] stderr: ""
  I0521 16:52:02.327106 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9133-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 05/21/24 16:52:02.327
  I0521 16:52:02.327179 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-924 explain e2e-test-crd-publish-openapi-9133-crds'
  I0521 16:52:02.394414 22 builder.go:146] stderr: ""
  I0521 16:52:02.394484 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-9133-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  I0521 16:52:03.623670 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-924" for this suite. @ 05/21/24 16:52:03.629
• [2.835 seconds]
------------------------------
SS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 05/21/24 16:52:03.633
  I0521 16:52:03.633520 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename controllerrevisions @ 05/21/24 16:52:03.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:03.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:03.645
  STEP: Creating DaemonSet "e2e-9f5kb-daemon-set" @ 05/21/24 16:52:03.656
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/21/24 16:52:03.662
  I0521 16:52:03.668261 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-9f5kb-daemon-set: 0
  I0521 16:52:03.668296 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  I0521 16:52:04.666901 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-9f5kb-daemon-set: 0
  I0521 16:52:04.666941 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  I0521 16:52:05.668016 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-9f5kb-daemon-set: 2
  I0521 16:52:05.668070 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset e2e-9f5kb-daemon-set
  STEP: Confirm DaemonSet "e2e-9f5kb-daemon-set" successfully created with "daemonset-name=e2e-9f5kb-daemon-set" label @ 05/21/24 16:52:05.67
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-9f5kb-daemon-set" @ 05/21/24 16:52:05.675
  I0521 16:52:05.677145 22 controller_revision.go:162] Located ControllerRevision: "e2e-9f5kb-daemon-set-788799585b"
  STEP: Patching ControllerRevision "e2e-9f5kb-daemon-set-788799585b" @ 05/21/24 16:52:05.678
  I0521 16:52:05.683426 22 controller_revision.go:173] e2e-9f5kb-daemon-set-788799585b has been patched
  STEP: Create a new ControllerRevision @ 05/21/24 16:52:05.683
  I0521 16:52:05.688438 22 controller_revision.go:191] Created ControllerRevision: e2e-9f5kb-daemon-set-7776f4d484
  STEP: Confirm that there are two ControllerRevisions @ 05/21/24 16:52:05.688
  I0521 16:52:05.688508 22 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0521 16:52:05.690570 22 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-9f5kb-daemon-set-788799585b" @ 05/21/24 16:52:05.69
  STEP: Confirm that there is only one ControllerRevision @ 05/21/24 16:52:05.694
  I0521 16:52:05.694248 22 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0521 16:52:05.695962 22 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-9f5kb-daemon-set-7776f4d484" @ 05/21/24 16:52:05.697
  I0521 16:52:05.705368 22 controller_revision.go:220] e2e-9f5kb-daemon-set-7776f4d484 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 05/21/24 16:52:05.705
  W0521 16:52:05.714449      22 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 05/21/24 16:52:05.714
  I0521 16:52:05.714629 22 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0521 16:52:06.715518 22 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0521 16:52:06.717817 22 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-9f5kb-daemon-set-7776f4d484=updated" @ 05/21/24 16:52:06.717
  STEP: Confirm that there is only one ControllerRevision @ 05/21/24 16:52:06.722
  I0521 16:52:06.722120 22 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0521 16:52:06.727237 22 controller_revision.go:265] Found 1 ControllerRevisions
  I0521 16:52:06.729210 22 controller_revision.go:246] ControllerRevision "e2e-9f5kb-daemon-set-7fd7dbbf65" has revision 3
  STEP: Deleting DaemonSet "e2e-9f5kb-daemon-set" @ 05/21/24 16:52:06.731
  STEP: deleting DaemonSet.extensions e2e-9f5kb-daemon-set in namespace controllerrevisions-6417, will wait for the garbage collector to delete the pods @ 05/21/24 16:52:06.731
  I0521 16:52:06.787524 22 resources.go:139] Deleting DaemonSet.extensions e2e-9f5kb-daemon-set took: 4.233664ms
  I0521 16:52:06.890056 22 resources.go:163] Terminating DaemonSet.extensions e2e-9f5kb-daemon-set pods took: 102.531574ms
  I0521 16:52:08.293295 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-9f5kb-daemon-set: 0
  I0521 16:52:08.293329 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-9f5kb-daemon-set
  I0521 16:52:08.295376 22 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"5478"},"items":null}

  I0521 16:52:08.296910 22 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"5478"},"items":null}

  I0521 16:52:08.303099 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-6417" for this suite. @ 05/21/24 16:52:08.305
• [4.677 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 05/21/24 16:52:08.31
  I0521 16:52:08.310268 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/21/24 16:52:08.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:08.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:08.319
  STEP: creating a target pod @ 05/21/24 16:52:08.322
  STEP: adding an ephemeral container @ 05/21/24 16:52:10.336
  STEP: checking pod container endpoints @ 05/21/24 16:52:12.358
  I0521 16:52:12.358671 22 exec_util.go:55] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4598 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:52:12.358691 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:52:12.359333 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:52:12.359414 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-4598/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0521 16:52:12.430593 22 exec_util.go:106] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 05/21/24 16:52:12.448
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 05/21/24 16:52:12.453
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 05/21/24 16:52:12.465
  I0521 16:52:12.468900 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-4598" for this suite. @ 05/21/24 16:52:12.471
• [4.175 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 05/21/24 16:52:12.485
  I0521 16:52:12.485573 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename field-validation @ 05/21/24 16:52:12.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:12.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:12.503
  STEP: apply creating a deployment @ 05/21/24 16:52:12.505
  I0521 16:52:12.516250 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9901" for this suite. @ 05/21/24 16:52:12.518
• [0.039 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 05/21/24 16:52:12.524
  I0521 16:52:12.524952 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename watch @ 05/21/24 16:52:12.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:12.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:12.539
  STEP: creating a watch on configmaps @ 05/21/24 16:52:12.542
  STEP: creating a new configmap @ 05/21/24 16:52:12.543
  STEP: modifying the configmap once @ 05/21/24 16:52:12.55
  STEP: closing the watch once it receives two notifications @ 05/21/24 16:52:12.558
  I0521 16:52:12.558638 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6073  b5850435-e6dd-40bb-b5db-30dfeb767060 5515 0 2024-05-21 16:52:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-21 16:52:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 16:52:12.558766 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6073  b5850435-e6dd-40bb-b5db-30dfeb767060 5516 0 2024-05-21 16:52:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-21 16:52:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 05/21/24 16:52:12.558
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 05/21/24 16:52:12.566
  STEP: deleting the configmap @ 05/21/24 16:52:12.567
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 05/21/24 16:52:12.573
  I0521 16:52:12.573885 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6073  b5850435-e6dd-40bb-b5db-30dfeb767060 5517 0 2024-05-21 16:52:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-21 16:52:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 16:52:12.573982 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6073  b5850435-e6dd-40bb-b5db-30dfeb767060 5518 0 2024-05-21 16:52:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-05-21 16:52:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 16:52:12.574039 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6073" for this suite. @ 05/21/24 16:52:12.578
• [0.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 05/21/24 16:52:12.585
  I0521 16:52:12.585700 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 16:52:12.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:12.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:12.609
  STEP: creating a Pod with a static label @ 05/21/24 16:52:12.615
  STEP: watching for Pod to be ready @ 05/21/24 16:52:12.625
  I0521 16:52:12.630581 22 pods.go:945] observed Pod pod-test in namespace pods-4397 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0521 16:52:12.630636 22 pods.go:945] observed Pod pod-test in namespace pods-4397 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:12 +0000 UTC  }]
  I0521 16:52:12.641075 22 pods.go:945] observed Pod pod-test in namespace pods-4397 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:12 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:12 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:12 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:12 +0000 UTC  }]
  I0521 16:52:13.320262 22 pods.go:948] Found Pod pod-test in namespace pods-4397 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:13 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 16:52:12 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 05/21/24 16:52:13.322
  STEP: getting the Pod and ensuring that it's patched @ 05/21/24 16:52:13.329
  STEP: replacing the Pod's status Ready condition to False @ 05/21/24 16:52:13.331
  STEP: check the Pod again to ensure its Ready conditions are False @ 05/21/24 16:52:13.338
  STEP: deleting the Pod via a Collection with a LabelSelector @ 05/21/24 16:52:13.338
  STEP: watching for the Pod to be deleted @ 05/21/24 16:52:13.343
  I0521 16:52:13.344459 22 pods.go:1058] observed event type MODIFIED
  I0521 16:52:15.346808 22 pods.go:1058] observed event type MODIFIED
  I0521 16:52:15.421416 22 pods.go:1058] observed event type MODIFIED
  I0521 16:52:16.350274 22 pods.go:1058] observed event type MODIFIED
  I0521 16:52:16.357176 22 pods.go:1058] observed event type MODIFIED
  I0521 16:52:16.361801 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4397" for this suite. @ 05/21/24 16:52:16.363
• [3.781 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1368
  STEP: Creating a kubernetes client @ 05/21/24 16:52:16.367
  I0521 16:52:16.367598 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 16:52:16.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:16.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:16.378
  STEP: validating cluster-info @ 05/21/24 16:52:16.379
  I0521 16:52:16.379786 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-1700 cluster-info'
  I0521 16:52:16.415309 22 builder.go:146] stderr: ""
  I0521 16:52:16.415346 22 builder.go:147] stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0521 16:52:16.415446 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1700" for this suite. @ 05/21/24 16:52:16.417
• [0.053 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 05/21/24 16:52:16.421
  I0521 16:52:16.421068 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 16:52:16.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:16.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:16.432
  STEP: Create a pod @ 05/21/24 16:52:16.433
  STEP: patching /status @ 05/21/24 16:52:18.444
  I0521 16:52:18.449602 22 pods.go:1124] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0521 16:52:18.449700 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8381" for this suite. @ 05/21/24 16:52:18.452
• [2.037 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 05/21/24 16:52:18.457
  I0521 16:52:18.457841 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replication-controller @ 05/21/24 16:52:18.458
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:18.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:18.466
  STEP: creating a ReplicationController @ 05/21/24 16:52:18.47
  STEP: waiting for RC to be added @ 05/21/24 16:52:18.475
  STEP: waiting for available Replicas @ 05/21/24 16:52:18.475
  STEP: patching ReplicationController @ 05/21/24 16:52:19.41
  STEP: waiting for RC to be modified @ 05/21/24 16:52:19.417
  STEP: patching ReplicationController status @ 05/21/24 16:52:19.417
  STEP: waiting for RC to be modified @ 05/21/24 16:52:19.421
  STEP: waiting for available Replicas @ 05/21/24 16:52:19.421
  STEP: fetching ReplicationController status @ 05/21/24 16:52:19.423
  STEP: patching ReplicationController scale @ 05/21/24 16:52:19.425
  STEP: waiting for RC to be modified @ 05/21/24 16:52:19.43
  STEP: waiting for ReplicationController's scale to be the max amount @ 05/21/24 16:52:19.431
  STEP: fetching ReplicationController; ensuring that it's patched @ 05/21/24 16:52:20.106
  STEP: updating ReplicationController status @ 05/21/24 16:52:20.107
  STEP: waiting for RC to be modified @ 05/21/24 16:52:20.111
  STEP: listing all ReplicationControllers @ 05/21/24 16:52:20.111
  STEP: checking that ReplicationController has expected values @ 05/21/24 16:52:20.112
  STEP: deleting ReplicationControllers by collection @ 05/21/24 16:52:20.112
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 05/21/24 16:52:20.117
  I0521 16:52:20.152625 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0521 16:52:20.152804      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-3742" for this suite. @ 05/21/24 16:52:20.155
• [1.704 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 05/21/24 16:52:20.161
  I0521 16:52:20.161545 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 16:52:20.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:20.17
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:20.172
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/21/24 16:52:20.173
  E0521 16:52:21.153559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:22.154502      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:23.154734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:24.154721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:52:24.192
  I0521 16:52:24.195616 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-e2690b40-cbac-4bf0-b2fe-941a09f518e6 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 16:52:24.203
  I0521 16:52:24.218255 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-120" for this suite. @ 05/21/24 16:52:24.221
• [4.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 05/21/24 16:52:24.225
  I0521 16:52:24.225925 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename subpath @ 05/21/24 16:52:24.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:24.238
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:24.24
  STEP: Setting up data @ 05/21/24 16:52:24.243
  STEP: Creating pod pod-subpath-test-downwardapi-tqzg @ 05/21/24 16:52:24.251
  STEP: Creating a pod to test atomic-volume-subpath @ 05/21/24 16:52:24.251
  E0521 16:52:25.154762      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:26.155458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:27.156487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:28.157435      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:29.158394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:30.158398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:31.159450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:32.159611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:33.159712      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:34.160716      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:35.161002      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:36.161340      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:37.161382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:38.161646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:39.162699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:40.163179      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:41.163517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:42.164532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:43.164590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:44.165020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:45.165983      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:46.166488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:47.166814      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:48.167736      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:52:48.302
  I0521 16:52:48.304244 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-downwardapi-tqzg container test-container-subpath-downwardapi-tqzg: <nil>
  STEP: delete the pod @ 05/21/24 16:52:48.308
  STEP: Deleting pod pod-subpath-test-downwardapi-tqzg @ 05/21/24 16:52:48.315
  I0521 16:52:48.316017 22 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-tqzg" in namespace "subpath-3864"
  I0521 16:52:48.317204 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3864" for this suite. @ 05/21/24 16:52:48.318
• [24.095 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 05/21/24 16:52:48.321
  I0521 16:52:48.321475 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 16:52:48.322
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:48.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:48.33
  STEP: Creating the pod @ 05/21/24 16:52:48.331
  E0521 16:52:49.168320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:50.168718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:52:50.858271 22 pod_client.go:141] Successfully updated pod "labelsupdateab56f71a-0432-4701-b74e-f5bbc0b9c927"
  E0521 16:52:51.169938      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:52.170637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:53.171749      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:54.171738      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:52:54.881165 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6463" for this suite. @ 05/21/24 16:52:54.884
• [6.567 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 05/21/24 16:52:54.889
  I0521 16:52:54.889577 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename endpointslice @ 05/21/24 16:52:54.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:54.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:54.902
  E0521 16:52:55.172786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:56.172932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:52:56.941287 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8070" for this suite. @ 05/21/24 16:52:56.943
• [2.058 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 05/21/24 16:52:56.947
  I0521 16:52:56.947402 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 05/21/24 16:52:56.948
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:52:56.958
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:52:56.961
  STEP: creating a target pod @ 05/21/24 16:52:56.963
  E0521 16:52:57.173165      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:52:58.173701      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 05/21/24 16:52:58.979
  E0521 16:52:59.173814      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:00.174687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 05/21/24 16:53:00.995
  I0521 16:53:00.995561 22 exec_util.go:55] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6276 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:53:00.995577 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:53:00.996024 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:53:00.996071 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-6276/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I0521 16:53:01.050495 22 exec_util.go:106] Exec stderr: ""
  I0521 16:53:01.055028 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-6276" for this suite. @ 05/21/24 16:53:01.057
• [4.116 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 05/21/24 16:53:01.063
  I0521 16:53:01.063171 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 16:53:01.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:01.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:01.076
  STEP: Creating configMap that has name configmap-test-emptyKey-1972db8b-4de3-42be-9c7b-dc3cfaac68ef @ 05/21/24 16:53:01.078
  I0521 16:53:01.080792 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4219" for this suite. @ 05/21/24 16:53:01.085
• [0.026 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 05/21/24 16:53:01.089
  I0521 16:53:01.089258 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/21/24 16:53:01.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:01.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:01.099
  STEP: create the container to handle the HTTPGet hook request. @ 05/21/24 16:53:01.103
  E0521 16:53:01.174787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:02.175896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/21/24 16:53:03.127
  E0521 16:53:03.176760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:04.177604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/21/24 16:53:05.142
  E0521 16:53:05.178004      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:06.178451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/21/24 16:53:07.154
  I0521 16:53:07.172034 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9927" for this suite. @ 05/21/24 16:53:07.174
  E0521 16:53:07.179481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
• [6.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 05/21/24 16:53:07.18
  I0521 16:53:07.180739 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:53:07.181
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:07.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:07.193
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 16:53:07.196
  E0521 16:53:08.179587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:09.179753      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:53:09.208
  I0521 16:53:09.211140 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-e2215551-6cb4-4eb9-87d5-0003c2db63e1 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 16:53:09.218
  I0521 16:53:09.234889 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3893" for this suite. @ 05/21/24 16:53:09.237
• [2.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 05/21/24 16:53:09.24
  I0521 16:53:09.240778 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename field-validation @ 05/21/24 16:53:09.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:09.25
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:09.252
  I0521 16:53:09.253623 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 16:53:10.180569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:11.180955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0521 16:53:11.797419      22 warnings.go:70] unknown field "alpha"
  W0521 16:53:11.797459      22 warnings.go:70] unknown field "beta"
  W0521 16:53:11.797473      22 warnings.go:70] unknown field "delta"
  W0521 16:53:11.797482      22 warnings.go:70] unknown field "epsilon"
  W0521 16:53:11.797491      22 warnings.go:70] unknown field "gamma"
  E0521 16:53:12.181939      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:53:12.328845 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4731" for this suite. @ 05/21/24 16:53:12.331
• [3.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 05/21/24 16:53:12.334
  I0521 16:53:12.334851 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename events @ 05/21/24 16:53:12.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:12.343
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:12.345
  STEP: Create set of events @ 05/21/24 16:53:12.347
  I0521 16:53:12.349461 22 core_events.go:198] created test-event-1
  I0521 16:53:12.354049 22 core_events.go:198] created test-event-2
  I0521 16:53:12.356592 22 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 05/21/24 16:53:12.356
  STEP: delete collection of events @ 05/21/24 16:53:12.358
  I0521 16:53:12.358233 22 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/21/24 16:53:12.366
  I0521 16:53:12.366621 22 core_events.go:230] requesting list of events to confirm quantity
  I0521 16:53:12.368036 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-5021" for this suite. @ 05/21/24 16:53:12.369
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 05/21/24 16:53:12.374
  I0521 16:53:12.374085 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename deployment @ 05/21/24 16:53:12.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:12.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:12.383
  STEP: creating a Deployment @ 05/21/24 16:53:12.386
  STEP: waiting for Deployment to be created @ 05/21/24 16:53:12.391
  STEP: waiting for all Replicas to be Ready @ 05/21/24 16:53:12.392
  I0521 16:53:12.393839 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0521 16:53:12.393891 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0521 16:53:12.402644 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0521 16:53:12.402670 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0521 16:53:12.409308 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0521 16:53:12.409352 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0521 16:53:12.427657 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0521 16:53:12.427690 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0521 16:53:13.182460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:53:13.577071 22 deployment.go:246] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0521 16:53:13.577117 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0521 16:53:13.964230 22 deployment.go:248] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 05/21/24 16:53:13.964
  I0521 16:53:13.981988 22 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 05/21/24 16:53:13.982
  I0521 16:53:13.985502 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0
  I0521 16:53:13.985580 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0
  I0521 16:53:13.985714 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0
  I0521 16:53:13.985787 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0
  I0521 16:53:13.986474 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0
  I0521 16:53:13.986542 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0
  I0521 16:53:13.986585 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0
  I0521 16:53:13.986608 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 0
  I0521 16:53:13.986937 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:13.986961 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:13.986988 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:13.987006 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:13.987151 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:13.987263 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:13.999282 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:13.999345 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:14.012905 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:14.012970 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:14.027985 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:14.028126 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:14.033010 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:14.033040 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  E0521 16:53:14.183355      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:53:14.990443 22 deployment.go:309] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:14.990474 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:15.011903 22 deployment.go:311] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  STEP: listing Deployments @ 05/21/24 16:53:15.011
  I0521 16:53:15.013854 22 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 05/21/24 16:53:15.013
  I0521 16:53:15.023565 22 deployment.go:360] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 05/21/24 16:53:15.023
  I0521 16:53:15.033682 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0521 16:53:15.036493 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0521 16:53:15.060018 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0521 16:53:15.071796 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0521 16:53:15.076660 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0521 16:53:15.184317      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:53:16.023466 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0521 16:53:16.037758 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0521 16:53:16.045650 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0521 16:53:16.060199 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0521 16:53:16.184649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:17.185319      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:53:17.682472 22 deployment.go:389] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 05/21/24 16:53:17.702
  STEP: fetching the DeploymentStatus @ 05/21/24 16:53:17.71
  I0521 16:53:17.714784 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:17.714816 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:17.714829 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:17.714959 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:17.714973 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 1
  I0521 16:53:17.714983 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:17.715034 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:17.715135 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:17.715154 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 2
  I0521 16:53:17.715166 22 deployment.go:449] observed Deployment test-deployment in namespace deployment-2432 with ReadyReplicas 3
  STEP: deleting the Deployment @ 05/21/24 16:53:17.715
  I0521 16:53:17.719790 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.719861 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.719909 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.719955 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.720031 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.720059 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.720154 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.720179 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.720216 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.720284 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.720301 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.720317 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.720433 22 deployment.go:475] observed event type MODIFIED
  I0521 16:53:17.722495 22 deployment.go:650] Log out all the ReplicaSets if there is no deployment created
  I0521 16:53:17.724707 22 deployment.go:657] ReplicaSet "test-deployment-5bf4984755":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-5bf4984755",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2432",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b11da3e2-1aad-43c9-b93e-3c63a3828dd9",
      ResourceVersion: (string) (len=4) "6059",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907192,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5bf4984755",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "f1df2e4a-5964-4096-9e7c-bf96a34bafa4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907194,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 66 31 64 66  32 65 34 61 2d 35 39 36  |":\"f1df2e4a-596|
              00000130  34 2d 34 30 39 36 2d 39  65 37 63 2d 62 66 39 36  |4-4096-9e7c-bf96|
              00000140  61 33 34 62 61 66 61 34  5c 22 7d 22 3a 7b 7d 7d  |a34bafa4\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "5bf4984755",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "5bf4984755",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0521 16:53:17.728710 22 deployment.go:657] ReplicaSet "test-deployment-65fbf5b65d":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-65fbf5b65d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2432",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "361a393b-8f02-4132-8d49-006ed26c9e35",
      ResourceVersion: (string) (len=4) "6143",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907194,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "f1df2e4a-5964-4096-9e7c-bf96a34bafa4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907197,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 66 31 64 66  32 65 34 61 2d 35 39 36  |":\"f1df2e4a-596|
              00000130  34 2d 34 30 39 36 2d 39  65 37 63 2d 62 66 39 36  |4-4096-9e7c-bf96|
              00000140  61 33 34 62 61 66 61 34  5c 22 7d 22 3a 7b 7d 7d  |a34bafa4\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907197,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=25) "registry.k8s.io/pause:3.9",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0521 16:53:17.731300 22 deployment.go:669] pod: "test-deployment-65fbf5b65d-cr9z9":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-65fbf5b65d-cr9z9",
      GenerateName: (string) (len=27) "test-deployment-65fbf5b65d-",
      Namespace: (string) (len=15) "deployment-2432",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "25a22991-1f01-4696-ad4d-545e16c6234c",
      ResourceVersion: (string) (len=4) "6121",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907195,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907198,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-65fbf5b65d",
          UID: (types.UID) (len=36) "361a393b-8f02-4132-8d49-006ed26c9e35",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  33 36 31 61 33 39 33 62  |uid\":\"361a393b|
              000000a0  2d 38 66 30 32 2d 34 31  33 32 2d 38 64 34 39 2d  |-8f02-4132-8d49-|
              000000b0  30 30 36 65 64 32 36 63  39 65 33 35 5c 22 7d 22  |006ed26c9e35\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907196,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 32  36 5c 22 7d 22 3a 7b 22  |.244.0.26\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nngpx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nngpx",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907196,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907196,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907196,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.26",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.26"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907195,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851907195,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=111) "docker-pullable://registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=73) "docker://873e81c1983feeaf964db7db3f78ee29694ec4ed9fe139a15a9220752e2f53d7",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0521 16:53:17.733096 22 deployment.go:669] pod: "test-deployment-65fbf5b65d-wkpfw":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-65fbf5b65d-wkpfw",
      GenerateName: (string) (len=27) "test-deployment-65fbf5b65d-",
      Namespace: (string) (len=15) "deployment-2432",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b470d58f-d509-4e7b-b627-38de68fc6eef",
      ResourceVersion: (string) (len=4) "6139",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907194,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907199,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "65fbf5b65d",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-65fbf5b65d",
          UID: (types.UID) (len=36) "361a393b-8f02-4132-8d49-006ed26c9e35",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907194,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  33 36 31 61 33 39 33 62  |uid\":\"361a393b|
              000000a0  2d 38 66 30 32 2d 34 31  33 32 2d 38 64 34 39 2d  |-8f02-4132-8d49-|
              000000b0  30 30 36 65 64 32 36 63  39 65 33 35 5c 22 7d 22  |006ed26c9e35\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907194,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 37  37 5c 22 7d 22 3a 7b 22  |.244.1.77\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bcgvx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bcgvx",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907194,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907194,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907194,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907194,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907194,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.77",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.77"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907194,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851907194,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=111) "docker-pullable://registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=73) "docker://ead82663f3f4274c9a9fc9e06bf0d30e4f341e8714640d396adfd51829c4e60c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0521 16:53:17.734691 22 deployment.go:657] ReplicaSet "test-deployment-6b9f8f4d48":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-6b9f8f4d48",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2432",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7b807cea-3002-4bc8-83b7-3ec29bf0b700",
      ResourceVersion: (string) (len=4) "6135",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907195,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "f1df2e4a-5964-4096-9e7c-bf96a34bafa4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907196,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 66 31 64 66  32 65 34 61 2d 35 39 36  |":\"f1df2e4a-596|
              00000130  34 2d 34 30 39 36 2d 39  65 37 63 2d 62 66 39 36  |4-4096-9e7c-bf96|
              00000140  61 33 34 62 61 66 61 34  5c 22 7d 22 3a 7b 7d 7d  |a34bafa4\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907197,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0521 16:53:17.737927 22 deployment.go:669] pod: "test-deployment-6b9f8f4d48-vmchz":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6b9f8f4d48-vmchz",
      GenerateName: (string) (len=27) "test-deployment-6b9f8f4d48-",
      Namespace: (string) (len=15) "deployment-2432",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4c259fe2-3a7e-4ece-b4fe-fee52ed2b994",
      ResourceVersion: (string) (len=4) "6152",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907195,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907198,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(1),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6b9f8f4d48",
          UID: (types.UID) (len=36) "7b807cea-3002-4bc8-83b7-3ec29bf0b700",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  37 62 38 30 37 63 65 61  |uid\":\"7b807cea|
              000000a0  2d 33 30 30 32 2d 34 62  63 38 2d 38 33 62 37 2d  |-3002-4bc8-83b7-|
              000000b0  33 65 63 32 39 62 66 30  62 37 30 30 5c 22 7d 22  |3ec29bf0b700\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 37  38 5c 22 7d 22 3a 7b 22  |.244.1.78\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2s2tq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2s2tq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907195,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.78",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.78"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907195,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851907195,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://bc0cc4d820c438849c1a2b18ccbd696f0194f15943504b2f29c6ad40cd9ed587",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0521 16:53:17.739077 22 deployment.go:669] pod: "test-deployment-6b9f8f4d48-x4dk5":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6b9f8f4d48-x4dk5",
      GenerateName: (string) (len=27) "test-deployment-6b9f8f4d48-",
      Namespace: (string) (len=15) "deployment-2432",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0f04b133-bedf-4569-809b-a38e3f3f54db",
      ResourceVersion: (string) (len=4) "6151",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907196,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907198,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(1),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b9f8f4d48",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6b9f8f4d48",
          UID: (types.UID) (len=36) "7b807cea-3002-4bc8-83b7-3ec29bf0b700",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907196,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  37 62 38 30 37 63 65 61  |uid\":\"7b807cea|
              000000a0  2d 33 30 30 32 2d 34 62  63 38 2d 38 33 62 37 2d  |-3002-4bc8-83b7-|
              000000b0  33 65 63 32 39 62 66 30  62 37 30 30 5c 22 7d 22  |3ec29bf0b700\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907197,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 30 2e 32  37 5c 22 7d 22 3a 7b 22  |.244.0.27\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fh44w",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fh44w",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907197,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907196,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907197,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907197,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907196,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) (len=11) "10.244.0.27",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.0.27"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907196,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851907196,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://078142a83c7ef7623d813c085ff06c8698df9f6b3204b018cfd539aa416a2226",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0521 16:53:17.739912 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2432" for this suite. @ 05/21/24 16:53:17.744
• [5.374 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 05/21/24 16:53:17.748
  I0521 16:53:17.748559 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 16:53:17.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:17.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:17.769
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/21/24 16:53:17.771
  E0521 16:53:18.185801      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:19.186290      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:20.186756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:21.186846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:53:21.787
  I0521 16:53:21.790740 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-d9392717-a757-4c19-b5a9-c478a7c4b394 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 16:53:21.798
  I0521 16:53:21.814349 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2058" for this suite. @ 05/21/24 16:53:21.817
• [4.073 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 05/21/24 16:53:21.821
  I0521 16:53:21.821813 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/21/24 16:53:21.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:21.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:21.837
  E0521 16:53:22.187503      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:23.187925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 05/21/24 16:53:23.863
  STEP: Cleaning up the configmap @ 05/21/24 16:53:23.868
  STEP: Cleaning up the pod @ 05/21/24 16:53:23.872
  I0521 16:53:23.884731 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-6582" for this suite. @ 05/21/24 16:53:23.888
• [2.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 05/21/24 16:53:23.893
  I0521 16:53:23.893022 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename field-validation @ 05/21/24 16:53:23.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:23.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:23.907
  I0521 16:53:23.909217 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 16:53:24.188444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:25.189146      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:26.189625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0521 16:53:26.465555      22 warnings.go:70] unknown field "alpha"
  W0521 16:53:26.465587      22 warnings.go:70] unknown field "beta"
  W0521 16:53:26.465598      22 warnings.go:70] unknown field "delta"
  W0521 16:53:26.465605      22 warnings.go:70] unknown field "epsilon"
  W0521 16:53:26.465612      22 warnings.go:70] unknown field "gamma"
  I0521 16:53:27.001302 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5356" for this suite. @ 05/21/24 16:53:27.003
• [3.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:668
  STEP: Creating a kubernetes client @ 05/21/24 16:53:27.01
  I0521 16:53:27.010378 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename job @ 05/21/24 16:53:27.011
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:27.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:27.023
  STEP: Creating a job @ 05/21/24 16:53:27.025
  STEP: Ensuring active pods == parallelism @ 05/21/24 16:53:27.03
  E0521 16:53:27.189852      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:28.190584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 05/21/24 16:53:29.034
  STEP: deleting Job.batch foo in namespace job-5621, will wait for the garbage collector to delete the pods @ 05/21/24 16:53:29.034
  I0521 16:53:29.094708 22 resources.go:139] Deleting Job.batch foo took: 6.924179ms
  E0521 16:53:29.191455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:53:29.195650 22 resources.go:163] Terminating Job.batch foo pods took: 100.937612ms
  E0521 16:53:30.192357      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 05/21/24 16:53:30.296
  I0521 16:53:30.301331 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5621" for this suite. @ 05/21/24 16:53:30.304
• [3.298 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 05/21/24 16:53:30.308
  I0521 16:53:30.308500 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:53:30.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:30.318
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:30.319
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 16:53:30.321
  E0521 16:53:31.192796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:32.193571      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:33.194447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:34.194612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:53:34.338
  I0521 16:53:34.341232 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-ce8a7352-cc53-4f87-a84c-d966e5248691 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 16:53:34.347
  I0521 16:53:34.359715 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9046" for this suite. @ 05/21/24 16:53:34.362
• [4.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 05/21/24 16:53:34.368
  I0521 16:53:34.368962 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename deployment @ 05/21/24 16:53:34.37
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:34.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:34.383
  I0521 16:53:34.385656 22 deployment.go:1645] Creating simple deployment test-new-deployment
  I0521 16:53:34.396453 22 deployment.go:222] deployment "test-new-deployment" doesn't have the required revision set
  E0521 16:53:35.195062      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:36.195344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 05/21/24 16:53:36.408
  STEP: updating a scale subresource @ 05/21/24 16:53:36.41
  STEP: verifying the deployment Spec.Replicas was modified @ 05/21/24 16:53:36.415
  STEP: Patch a scale subresource @ 05/21/24 16:53:36.417
  I0521 16:53:36.432517 22 deployment.go:633] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f57bc706-044c-45e2-8a07-5fafc56a68c4",
      ResourceVersion: (string) (len=4) "6408",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907214,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907214,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907214,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-77db57d8df\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0521 16:53:36.441775 22 deployment.go:39] New ReplicaSet "test-new-deployment-77db57d8df" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-77db57d8df",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f6dad9f3-3e9c-4252-93d3-cffc0a004337",
      ResourceVersion: (string) (len=4) "6413",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907214,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "f57bc706-044c-45e2-8a07-5fafc56a68c4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907216,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 35 37 62 63 37  30 36 2d 30 34 34 63 2d  |\"f57bc706-044c-|
              00000120  34 35 65 32 2d 38 61 30  37 2d 35 66 61 66 63 35  |45e2-8a07-5fafc5|
              00000130  36 61 36 38 63 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |6a68c4\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907216,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 16:53:36.449657 22 deployment.go:67] Pod "test-new-deployment-77db57d8df-5vqt4" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-77db57d8df-5vqt4",
      GenerateName: (string) (len=31) "test-new-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b6e3e5e5-f945-4bc5-a0e8-f91c38947940",
      ResourceVersion: (string) (len=4) "6385",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907214,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-77db57d8df",
          UID: (types.UID) (len=36) "f6dad9f3-3e9c-4252-93d3-cffc0a004337",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907214,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 36  64 61 64 39 66 33 2d 33  |d\":\"f6dad9f3-3|
              00000090  65 39 63 2d 34 32 35 32  2d 39 33 64 33 2d 63 66  |e9c-4252-93d3-cf|
              000000a0  66 63 30 61 30 30 34 33  33 37 5c 22 7d 22 3a 7b  |fc0a004337\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 38  34 5c 22 7d 22 3a 7b 22  |.244.1.84\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wmm4t",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wmm4t",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907214,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907215,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907214,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.84",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.84"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907214,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851907215,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://44ea9f4cb5ec00fa35da2584bdd278e1ec07aba8511badd8fda256198cf20f20",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:53:36.450411 22 deployment.go:67] Pod "test-new-deployment-77db57d8df-r7vn4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-77db57d8df-r7vn4",
      GenerateName: (string) (len=31) "test-new-deployment-77db57d8df-",
      Namespace: (string) (len=15) "deployment-7288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3882600e-fbb2-40fa-9926-546434e914d2",
      ResourceVersion: (string) (len=4) "6416",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907216,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77db57d8df"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-77db57d8df",
          UID: (types.UID) (len=36) "f6dad9f3-3e9c-4252-93d3-cffc0a004337",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907216,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 36  64 61 64 39 66 33 2d 33  |d\":\"f6dad9f3-3|
              00000090  65 39 63 2d 34 32 35 32  2d 39 33 64 33 2d 63 66  |e9c-4252-93d3-cf|
              000000a0  66 63 30 61 30 30 34 33  33 37 5c 22 7d 22 3a 7b  |fc0a004337\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907216,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dpv8d",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dpv8d",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "k8sconformance",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907216,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907216,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907216,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907216,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851907216,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.2",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.2"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851907216,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 16:53:36.451071 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7288" for this suite. @ 05/21/24 16:53:36.453
• [2.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 05/21/24 16:53:36.458
  I0521 16:53:36.458110 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:53:36.458
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:36.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:36.471
  STEP: Creating secret with name projected-secret-test-e39e8510-6240-4847-8126-f9f7f05bbcc0 @ 05/21/24 16:53:36.472
  STEP: Creating a pod to test consume secrets @ 05/21/24 16:53:36.475
  E0521 16:53:37.195812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:38.196532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:53:38.488
  I0521 16:53:38.491414 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-9ecfdf82-bd22-48e8-9d75-9cf2c07733ab container secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 16:53:38.499
  I0521 16:53:38.513834 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-527" for this suite. @ 05/21/24 16:53:38.516
• [2.062 seconds]
------------------------------
SSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 05/21/24 16:53:38.52
  I0521 16:53:38.520831 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename containers @ 05/21/24 16:53:38.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:38.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:38.533
  STEP: Creating a pod to test override arguments @ 05/21/24 16:53:38.535
  E0521 16:53:39.197067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:40.197918      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:53:40.548
  I0521 16:53:40.551579 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod client-containers-5e2dbaa0-f6d1-459c-985c-f67707894181 container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 16:53:40.558
  I0521 16:53:40.572179 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9720" for this suite. @ 05/21/24 16:53:40.575
• [2.059 seconds]
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 05/21/24 16:53:40.58
  I0521 16:53:40.580051 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename dns @ 05/21/24 16:53:40.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:53:40.592
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:53:40.594
  STEP: Creating a test externalName service @ 05/21/24 16:53:40.596
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7672.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local; sleep 1; done
   @ 05/21/24 16:53:40.599
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7672.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local; sleep 1; done
   @ 05/21/24 16:53:40.599
  STEP: creating a pod to probe DNS @ 05/21/24 16:53:40.599
  STEP: submitting the pod to kubernetes @ 05/21/24 16:53:40.599
  E0521 16:53:41.198517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:42.198971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/21/24 16:53:42.615
  STEP: looking for the results for each expected name from probers @ 05/21/24 16:53:42.617
  I0521 16:53:42.624598 22 dns_common.go:552] DNS probes using dns-test-29d0fbc5-6cce-422a-9843-0b903ebee6a6 succeeded

  STEP: changing the externalName to bar.example.com @ 05/21/24 16:53:42.624
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7672.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local; sleep 1; done
   @ 05/21/24 16:53:42.631
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7672.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local; sleep 1; done
   @ 05/21/24 16:53:42.631
  STEP: creating a second pod to probe DNS @ 05/21/24 16:53:42.631
  STEP: submitting the pod to kubernetes @ 05/21/24 16:53:42.631
  E0521 16:53:43.199297      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:44.199554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/21/24 16:53:44.643
  STEP: looking for the results for each expected name from probers @ 05/21/24 16:53:44.645
  I0521 16:53:44.648687 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:53:44.650778 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:53:44.650845 22 dns_common.go:489] Lookups using dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d failed for: [wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local]

  I0521 16:53:44.655846 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 16:53:44.659597 22 dns_common.go:495] Pod client logs for querier: 
  I0521 16:53:44.663348 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 16:53:45.199990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:46.200528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:47.200966      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:48.201423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:49.201771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:53:49.651589 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:53:49.655739 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:53:49.655787 22 dns_common.go:489] Lookups using dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d failed for: [wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local]

  I0521 16:53:49.661745 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 16:53:49.667900 22 dns_common.go:495] Pod client logs for querier: 
  I0521 16:53:49.673485 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 16:53:50.202329      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:51.202684      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:52.203649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:53.204649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:54.205132      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:53:54.652381 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:53:54.655278 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:53:54.655329 22 dns_common.go:489] Lookups using dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d failed for: [wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local]

  I0521 16:53:54.661883 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 16:53:54.672531 22 dns_common.go:495] Pod client logs for querier: 
  I0521 16:53:54.678905 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 16:53:55.205689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:56.206327      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:57.206594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:58.207160      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:53:59.207882      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:53:59.648434 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:53:59.649856 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:53:59.649876 22 dns_common.go:489] Lookups using dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d failed for: [wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local]

  I0521 16:53:59.653882 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 16:53:59.657732 22 dns_common.go:495] Pod client logs for querier: 
  I0521 16:53:59.661050 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 16:54:00.208981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:01.209559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:02.210310      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:03.210735      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:04.211062      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:04.650301 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:54:04.653490 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:54:04.653551 22 dns_common.go:489] Lookups using dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d failed for: [wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local]

  I0521 16:54:04.661759 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 16:54:04.665957 22 dns_common.go:495] Pod client logs for querier: 
  I0521 16:54:04.669422 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 16:54:05.211792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:06.212476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:07.212466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:08.212958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:09.213521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:09.650589 22 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:54:09.653415 22 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local from pod  dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I0521 16:54:09.653451 22 dns_common.go:489] Lookups using dns-7672/dns-test-26d71064-b697-4dbb-a628-b4e87440a80d failed for: [wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local]

  I0521 16:54:09.658069 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 16:54:09.662132 22 dns_common.go:495] Pod client logs for querier: 
  I0521 16:54:09.666698 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 16:54:10.213554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:11.214046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:12.214961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:13.215599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:14.216662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:14.656109 22 dns_common.go:552] DNS probes using dns-test-26d71064-b697-4dbb-a628-b4e87440a80d succeeded

  STEP: changing the service to type=ClusterIP @ 05/21/24 16:54:14.656
  W0521 16:54:14.669739      22 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7672.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7672.svc.cluster.local; sleep 1; done
   @ 05/21/24 16:54:14.669
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7672.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7672.svc.cluster.local; sleep 1; done
   @ 05/21/24 16:54:14.669
  STEP: creating a third pod to probe DNS @ 05/21/24 16:54:14.669
  STEP: submitting the pod to kubernetes @ 05/21/24 16:54:14.671
  E0521 16:54:15.216719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:16.216688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/21/24 16:54:16.684
  STEP: looking for the results for each expected name from probers @ 05/21/24 16:54:16.686
  I0521 16:54:16.694585 22 dns_common.go:552] DNS probes using dns-test-058705de-8def-44a5-8586-b2c30fb27e8b succeeded

  STEP: deleting the pod @ 05/21/24 16:54:16.694
  STEP: deleting the pod @ 05/21/24 16:54:16.707
  STEP: deleting the pod @ 05/21/24 16:54:16.715
  STEP: deleting the test externalName service @ 05/21/24 16:54:16.726
  I0521 16:54:16.750872 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7672" for this suite. @ 05/21/24 16:54:16.752
• [36.177 seconds]
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 05/21/24 16:54:16.756
  I0521 16:54:16.756634 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/21/24 16:54:16.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:16.765
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:16.767
  STEP: create the container to handle the HTTPGet hook request. @ 05/21/24 16:54:16.77
  E0521 16:54:17.217222      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:18.217476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/21/24 16:54:18.784
  E0521 16:54:19.217736      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:20.218362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/21/24 16:54:20.799
  STEP: delete the pod with lifecycle hook @ 05/21/24 16:54:20.806
  E0521 16:54:21.218669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:22.219670      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:22.817896 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4306" for this suite. @ 05/21/24 16:54:22.82
• [6.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 05/21/24 16:54:22.825
  I0521 16:54:22.825589 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 16:54:22.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:22.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:22.839
  STEP: creating the pod @ 05/21/24 16:54:22.841
  STEP: setting up watch @ 05/21/24 16:54:22.841
  STEP: submitting the pod to kubernetes @ 05/21/24 16:54:22.944
  STEP: verifying the pod is in kubernetes @ 05/21/24 16:54:22.954
  STEP: verifying pod creation was observed @ 05/21/24 16:54:22.957
  E0521 16:54:23.220405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:24.221279      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/21/24 16:54:24.964
  STEP: verifying pod deletion was observed @ 05/21/24 16:54:24.971
  E0521 16:54:25.221873      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:26.093826 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8629" for this suite. @ 05/21/24 16:54:26.097
• [3.276 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:866
  STEP: Creating a kubernetes client @ 05/21/24 16:54:26.102
  I0521 16:54:26.102087 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 16:54:26.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:26.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:26.118
  STEP: Setting up server cert @ 05/21/24 16:54:26.136
  E0521 16:54:26.222836      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 16:54:26.361
  STEP: Deploying the webhook pod @ 05/21/24 16:54:26.365
  STEP: Wait for the deployment to be ready @ 05/21/24 16:54:26.372
  I0521 16:54:26.376506 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 16:54:27.223518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:28.224050      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 16:54:28.386
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:54:28.398
  E0521 16:54:29.224728      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:29.399173 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 05/21/24 16:54:29.403
  STEP: create the configmap with a random name @ 05/21/24 16:54:29.426
  STEP: verify the configmap is mutated @ 05/21/24 16:54:29.439
  STEP: create the configmap with 'skip-me' name @ 05/21/24 16:54:29.439
  I0521 16:54:29.471214 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2349" for this suite. @ 05/21/24 16:54:29.474
  STEP: Destroying namespace "webhook-markers-9435" for this suite. @ 05/21/24 16:54:29.478
• [3.380 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 05/21/24 16:54:29.481
  I0521 16:54:29.481616 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replication-controller @ 05/21/24 16:54:29.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:29.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:29.489
  STEP: Creating ReplicationController "e2e-rc-vn6t6" @ 05/21/24 16:54:29.49
  I0521 16:54:29.493491 22 rc.go:792] Get Replication Controller "e2e-rc-vn6t6" to confirm replicas
  E0521 16:54:30.225527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:30.493971 22 rc.go:792] Get Replication Controller "e2e-rc-vn6t6" to confirm replicas
  I0521 16:54:30.496836 22 rc.go:801] Found 1 replicas for "e2e-rc-vn6t6" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-vn6t6" @ 05/21/24 16:54:30.496
  STEP: Updating a scale subresource @ 05/21/24 16:54:30.498
  STEP: Verifying replicas where modified for replication controller "e2e-rc-vn6t6" @ 05/21/24 16:54:30.504
  I0521 16:54:30.505001 22 rc.go:792] Get Replication Controller "e2e-rc-vn6t6" to confirm replicas
  E0521 16:54:31.226112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:31.505915 22 rc.go:792] Get Replication Controller "e2e-rc-vn6t6" to confirm replicas
  I0521 16:54:31.511234 22 rc.go:801] Found 2 replicas for "e2e-rc-vn6t6" replication controller
  I0521 16:54:31.511418 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-645" for this suite. @ 05/21/24 16:54:31.515
• [2.040 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2181
  STEP: Creating a kubernetes client @ 05/21/24 16:54:31.521
  I0521 16:54:31.521576 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 16:54:31.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:31.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:31.535
  STEP: creating service in namespace services-9933 @ 05/21/24 16:54:31.537
  STEP: creating service affinity-clusterip in namespace services-9933 @ 05/21/24 16:54:31.538
  STEP: creating replication controller affinity-clusterip in namespace services-9933 @ 05/21/24 16:54:31.549
  I0521 16:54:31.555964      22 runners.go:198] Created replication controller with name: affinity-clusterip, namespace: services-9933, replica count: 3
  E0521 16:54:32.226374      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:33.226653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:34.227583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:34.607570      22 runners.go:198] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0521 16:54:34.612457 22 resource.go:361] Creating new exec pod
  E0521 16:54:35.227482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:36.228477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:37.229433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:37.621036 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-9933 exec execpod-affinity5rjff -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I0521 16:54:37.708878 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  I0521 16:54:37.708937 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 16:54:37.709035 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-9933 exec execpod-affinity5rjff -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.101.136.149 80'
  I0521 16:54:37.806042 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.101.136.149 80\nConnection to 10.101.136.149 80 port [tcp/http] succeeded!\n"
  I0521 16:54:37.806104 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 16:54:37.806201 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-9933 exec execpod-affinity5rjff -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.101.136.149:80/ ; done'
  I0521 16:54:37.950784 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.101.136.149:80/\n"
  I0521 16:54:37.950814 22 builder.go:147] stdout: "\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt\naffinity-clusterip-jw5bt"
  I0521 16:54:37.950826 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950831 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950837 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950842 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950849 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950854 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950861 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950868 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950874 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950880 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950886 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950892 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950903 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950907 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950912 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950919 22 service.go:242] Received response from host: affinity-clusterip-jw5bt
  I0521 16:54:37.950963 22 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-9933, will wait for the garbage collector to delete the pods @ 05/21/24 16:54:37.96
  I0521 16:54:38.017097 22 resources.go:139] Deleting ReplicationController affinity-clusterip took: 5.106088ms
  I0521 16:54:38.117602 22 resources.go:163] Terminating ReplicationController affinity-clusterip pods took: 100.497733ms
  E0521 16:54:38.230759      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:39.231021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:40.231079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:40.738942 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9933" for this suite. @ 05/21/24 16:54:40.743
• [9.226 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 05/21/24 16:54:40.748
  I0521 16:54:40.748830 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 16:54:40.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:40.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:40.764
  STEP: Creating configMap with name projected-configmap-test-volume-map-1021c8b7-8717-46f7-9568-53d2c1a0e105 @ 05/21/24 16:54:40.766
  STEP: Creating a pod to test consume configMaps @ 05/21/24 16:54:40.77
  E0521 16:54:41.231214      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:42.231537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:43.232588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:44.232948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:54:44.789
  I0521 16:54:44.792304 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-3db4a2a7-50b0-4251-a752-9ebc9dd69980 container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 16:54:44.798
  I0521 16:54:44.809588 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6153" for this suite. @ 05/21/24 16:54:44.81
• [4.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 05/21/24 16:54:44.813
  I0521 16:54:44.813677 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename dns @ 05/21/24 16:54:44.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:44.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:44.821
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/21/24 16:54:44.822
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 05/21/24 16:54:44.822
  STEP: creating a pod to probe DNS @ 05/21/24 16:54:44.822
  STEP: submitting the pod to kubernetes @ 05/21/24 16:54:44.822
  E0521 16:54:45.233687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:46.233996      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/21/24 16:54:46.835
  STEP: looking for the results for each expected name from probers @ 05/21/24 16:54:46.838
  I0521 16:54:46.851543 22 dns_common.go:527] DNS probes using dns-2196/dns-test-f83c74e4-2faf-43c4-9eb8-3ddb82515a4c succeeded

  STEP: deleting the pod @ 05/21/24 16:54:46.851
  I0521 16:54:46.863939 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2196" for this suite. @ 05/21/24 16:54:46.867
• [2.059 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:715
  STEP: Creating a kubernetes client @ 05/21/24 16:54:46.872
  I0521 16:54:46.872569 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 16:54:46.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:46.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:46.884
  STEP: Setting up server cert @ 05/21/24 16:54:46.897
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 16:54:47.166
  STEP: Deploying the webhook pod @ 05/21/24 16:54:47.169
  STEP: Wait for the deployment to be ready @ 05/21/24 16:54:47.176
  I0521 16:54:47.179888 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 16:54:47.233997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:48.235149      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 16:54:49.191
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:54:49.202
  E0521 16:54:49.235904      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:50.203095 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 05/21/24 16:54:50.211
  STEP: verifying the validating webhook match conditions @ 05/21/24 16:54:50.218
  STEP: updating the validating webhook match conditions @ 05/21/24 16:54:50.221
  STEP: verifying the validating webhook match conditions @ 05/21/24 16:54:50.228
  E0521 16:54:50.236402      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:54:50.259882 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5636" for this suite. @ 05/21/24 16:54:50.261
  STEP: Destroying namespace "webhook-markers-1660" for this suite. @ 05/21/24 16:54:50.265
• [3.398 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1833
  STEP: Creating a kubernetes client @ 05/21/24 16:54:50.27
  I0521 16:54:50.270714 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 16:54:50.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:50.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:50.281
  STEP: starting the proxy server @ 05/21/24 16:54:50.282
  I0521 16:54:50.283078 22 util.go:592] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-3076 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 05/21/24 16:54:50.316
  I0521 16:54:50.321900 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0521 16:54:50.323147 22 kubectl.go:2223] kubectl proxy stdout: Starting to serve on 127.0.0.1:37811

  I0521 16:54:50.323148 22 kubectl.go:2228] kubectl proxy stderr: W0521 16:54:50.315973     534 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-3076" for this suite. @ 05/21/24 16:54:50.323
• [0.057 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 05/21/24 16:54:50.327
  I0521 16:54:50.327398 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 16:54:50.327
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:50.333
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:50.335
  STEP: Creating configMap with name configmap-test-volume-4b3789e8-e651-4d00-847b-fbc5fd51617c @ 05/21/24 16:54:50.336
  STEP: Creating a pod to test consume configMaps @ 05/21/24 16:54:50.339
  E0521 16:54:51.237399      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:52.238432      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:53.238550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:54.238976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:54:54.353
  I0521 16:54:54.356406 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-b5e7ecc3-cc14-4d9e-8505-cd44fc9fb444 container configmap-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 16:54:54.363
  I0521 16:54:54.378830 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8095" for this suite. @ 05/21/24 16:54:54.382
• [4.061 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:833
  STEP: Creating a kubernetes client @ 05/21/24 16:54:54.388
  I0521 16:54:54.388846 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename job @ 05/21/24 16:54:54.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:54.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:54.405
  STEP: Creating a job @ 05/21/24 16:54:54.407
  STEP: Ensure pods equal to parallelism count is attached to the job @ 05/21/24 16:54:54.413
  E0521 16:54:55.239280      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:56.239297      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 05/21/24 16:54:56.416
  STEP: updating /status @ 05/21/24 16:54:56.422
  STEP: get /status @ 05/21/24 16:54:56.426
  I0521 16:54:56.428440 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8080" for this suite. @ 05/21/24 16:54:56.43
• [2.045 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 05/21/24 16:54:56.433
  I0521 16:54:56.433509 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sysctl @ 05/21/24 16:54:56.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:56.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:56.444
  STEP: Creating a pod with one valid and two invalid sysctls @ 05/21/24 16:54:56.445
  I0521 16:54:56.448238 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-9430" for this suite. @ 05/21/24 16:54:56.449
• [0.020 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 05/21/24 16:54:56.453
  I0521 16:54:56.453372 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sysctl @ 05/21/24 16:54:56.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:54:56.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:54:56.463
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 05/21/24 16:54:56.464
  STEP: Watching for error events or started pod @ 05/21/24 16:54:56.469
  E0521 16:54:57.239404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:54:58.240563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 05/21/24 16:54:58.473
  E0521 16:54:59.241666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:00.242765      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 05/21/24 16:55:00.483
  STEP: Getting logs from the pod @ 05/21/24 16:55:00.483
  STEP: Checking that the sysctl is actually updated @ 05/21/24 16:55:00.489
  I0521 16:55:00.489503 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-6982" for this suite. @ 05/21/24 16:55:00.492
• [4.045 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 05/21/24 16:55:00.498
  I0521 16:55:00.498359 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/21/24 16:55:00.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:55:00.509
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:55:00.512
  I0521 16:55:00.518747 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-7811" for this suite. @ 05/21/24 16:55:00.521
• [0.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 05/21/24 16:55:00.528
  I0521 16:55:00.528609 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pod-network-test @ 05/21/24 16:55:00.529
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:55:00.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:55:00.544
  STEP: Performing setup for networking test in namespace pod-network-test-1622 @ 05/21/24 16:55:00.547
  STEP: creating a selector @ 05/21/24 16:55:00.547
  STEP: Creating the service pods in kubernetes @ 05/21/24 16:55:00.547
  I0521 16:55:00.547317 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0521 16:55:01.243707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:02.244322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:03.244633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:04.245664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:05.246718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:06.247504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:07.247877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:08.248422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:09.249472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:10.249753      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:11.249921      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:12.250109      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:13.250593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:14.250990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:15.251573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:16.252046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:17.252513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:18.252952      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:19.253300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:20.253835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:21.254948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:22.255797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/21/24 16:55:22.633
  E0521 16:55:23.256494      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:24.257338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:24.653136 22 utils.go:779] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0521 16:55:24.653206 22 networking.go:42] Breadth first check of 10.244.0.30 on host 192.168.67.2...
  I0521 16:55:24.655964 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.106:9080/dial?request=hostname&protocol=udp&host=10.244.0.30&port=8081&tries=1'] Namespace:pod-network-test-1622 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:55:24.656002 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:55:24.656699 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:55:24.656771 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1622/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.106%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.0.30%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0521 16:55:24.727643 22 utils.go:331] Waiting for responses: map[]
  I0521 16:55:24.727690 22 utils.go:335] reached 10.244.0.30 after 0/1 tries
  I0521 16:55:24.727708 22 networking.go:42] Breadth first check of 10.244.1.105 on host 192.168.67.3...
  I0521 16:55:24.730249 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.106:9080/dial?request=hostname&protocol=udp&host=10.244.1.105&port=8081&tries=1'] Namespace:pod-network-test-1622 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 16:55:24.730282 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 16:55:24.730892 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 16:55:24.730962 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-1622/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.106%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.1.105%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0521 16:55:24.790465 22 utils.go:331] Waiting for responses: map[]
  I0521 16:55:24.790499 22 utils.go:335] reached 10.244.1.105 after 0/1 tries
  I0521 16:55:24.790510 22 networking.go:53] Going to retry 0 out of 2 pods....
  I0521 16:55:24.790582 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1622" for this suite. @ 05/21/24 16:55:24.793
• [24.271 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 05/21/24 16:55:24.8
  I0521 16:55:24.800393 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pv @ 05/21/24 16:55:24.801
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:55:24.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:55:24.814
  STEP: Creating initial PV and PVC @ 05/21/24 16:55:24.816
  I0521 16:55:24.816711 22 pv.go:390] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-6264" @ 05/21/24 16:55:24.826
  STEP: Listing PVCs in namespace "pv-6264" @ 05/21/24 16:55:24.828
  STEP: Patching the PV "pv-6264-tcjfb" @ 05/21/24 16:55:24.831
  STEP: Patching the PVC "pvc-txl69" @ 05/21/24 16:55:24.841
  STEP: Getting PV "pv-6264-tcjfb" @ 05/21/24 16:55:24.847
  STEP: Getting PVC "pvc-txl69" @ 05/21/24 16:55:24.851
  STEP: Deleting PVC "pvc-txl69" @ 05/21/24 16:55:24.853
  STEP: Confirm deletion of PVC "pvc-txl69" @ 05/21/24 16:55:24.856
  E0521 16:55:25.257787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:26.258556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-6264-tcjfb" @ 05/21/24 16:55:26.861
  STEP: Confirm deletion of PV "pv-6264-tcjfb" @ 05/21/24 16:55:26.866
  E0521 16:55:27.259633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:28.259664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 05/21/24 16:55:28.874
  I0521 16:55:28.874387 22 pv.go:390] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-6264-znjcr" @ 05/21/24 16:55:28.884
  STEP: Updating the PVC "pvc-clhjg" @ 05/21/24 16:55:28.892
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-clhjg=updated" @ 05/21/24 16:55:28.899
  STEP: Deleting PVC "pvc-clhjg" via DeleteCollection @ 05/21/24 16:55:28.902
  STEP: Confirm deletion of PVC "pvc-clhjg" @ 05/21/24 16:55:28.909
  E0521 16:55:29.260879      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:30.261365      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-6264-znjcr" via DeleteCollection @ 05/21/24 16:55:30.915
  STEP: Confirm deletion of PV "pv-6264-znjcr" @ 05/21/24 16:55:30.923
  E0521 16:55:31.261436      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:32.261703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:32.929844 22 persistent_volumes.go:407] AfterEach: deleting 1 PVCs and 1 PVs...
  I0521 16:55:32.929905 22 pv.go:201] Deleting PersistentVolumeClaim "pvc-clhjg"
  I0521 16:55:32.932538 22 pv.go:189] Deleting PersistentVolume "pv-6264-znjcr"
  I0521 16:55:32.934595 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-6264" for this suite. @ 05/21/24 16:55:32.937
• [8.141 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 05/21/24 16:55:32.941
  I0521 16:55:32.941795 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 16:55:32.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:55:32.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:55:32.956
  STEP: Creating a pod to test downward api env vars @ 05/21/24 16:55:32.959
  E0521 16:55:33.262439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:34.262821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:35.263818      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:36.264335      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:55:36.976
  I0521 16:55:36.977977 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downward-api-131e9ffb-fb26-4cb7-8227-9a0029d4ff79 container dapi-container: <nil>
  STEP: delete the pod @ 05/21/24 16:55:36.984
  I0521 16:55:36.996716 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-189" for this suite. @ 05/21/24 16:55:36.999
• [4.061 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3345
  STEP: Creating a kubernetes client @ 05/21/24 16:55:37.002
  I0521 16:55:37.002819 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 16:55:37.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:55:37.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:55:37.017
  STEP: creating a Service @ 05/21/24 16:55:37.022
  STEP: watching for the Service to be added @ 05/21/24 16:55:37.034
  I0521 16:55:37.037153 22 service.go:3397] Found Service test-service-tvdkt in namespace services-3695 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 32195}]
  I0521 16:55:37.037290 22 service.go:3404] Service test-service-tvdkt created
  STEP: Getting /status @ 05/21/24 16:55:37.037
  I0521 16:55:37.043541 22 service.go:3415] Service test-service-tvdkt has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 05/21/24 16:55:37.043
  STEP: watching for the Service to be patched @ 05/21/24 16:55:37.048
  I0521 16:55:37.050382 22 service.go:3438] observed Service test-service-tvdkt in namespace services-3695 with annotations: map[] & LoadBalancer: {[]}
  I0521 16:55:37.050416 22 service.go:3441] Found Service test-service-tvdkt in namespace services-3695 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc00473eed0 []}]}
  I0521 16:55:37.050435 22 service.go:3448] Service test-service-tvdkt has service status patched
  STEP: updating the ServiceStatus @ 05/21/24 16:55:37.05
  I0521 16:55:37.054818 22 service.go:3468] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 05/21/24 16:55:37.054
  I0521 16:55:37.055785 22 service.go:3479] Observed Service test-service-tvdkt in namespace services-3695 with annotations: map[] & Conditions: {[]}
  I0521 16:55:37.055868 22 service.go:3494] Observed event: &Service{ObjectMeta:{test-service-tvdkt  services-3695  3a77ed34-1313-42ea-a27e-bd93911b5224 7400 0 2024-05-21 16:55:37 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-05-21 16:55:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-05-21 16:55:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:32195,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.105.48.116,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.105.48.116],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,TrafficDistribution:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:*VIP,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  I0521 16:55:37.055886 22 service.go:3486] Found Service test-service-tvdkt in namespace services-3695 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0521 16:55:37.055894 22 service.go:3498] Service test-service-tvdkt has service status updated
  STEP: patching the service @ 05/21/24 16:55:37.055
  STEP: watching for the Service to be patched @ 05/21/24 16:55:37.063
  I0521 16:55:37.065103 22 service.go:3521] observed Service test-service-tvdkt in namespace services-3695 with labels: map[test-service-static:true]
  I0521 16:55:37.065172 22 service.go:3521] observed Service test-service-tvdkt in namespace services-3695 with labels: map[test-service-static:true]
  I0521 16:55:37.065367 22 service.go:3521] observed Service test-service-tvdkt in namespace services-3695 with labels: map[test-service-static:true]
  I0521 16:55:37.065435 22 service.go:3524] Found Service test-service-tvdkt in namespace services-3695 with labels: map[test-service:patched test-service-static:true]
  I0521 16:55:37.065454 22 service.go:3531] Service test-service-tvdkt patched
  STEP: deleting the service @ 05/21/24 16:55:37.065
  STEP: watching for the Service to be deleted @ 05/21/24 16:55:37.077
  I0521 16:55:37.078318 22 service.go:3555] Observed event: ADDED
  I0521 16:55:37.078338 22 service.go:3555] Observed event: MODIFIED
  I0521 16:55:37.078370 22 service.go:3555] Observed event: MODIFIED
  I0521 16:55:37.078424 22 service.go:3555] Observed event: MODIFIED
  I0521 16:55:37.078440 22 service.go:3551] Found Service test-service-tvdkt in namespace services-3695 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0521 16:55:37.078449 22 service.go:3560] Service test-service-tvdkt deleted
  I0521 16:55:37.078542 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3695" for this suite. @ 05/21/24 16:55:37.082
• [0.084 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 05/21/24 16:55:37.086
  I0521 16:55:37.086598 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 16:55:37.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:55:37.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:55:37.095
  STEP: Creating pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186 @ 05/21/24 16:55:37.096
  E0521 16:55:37.264460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:38.264875      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/21/24 16:55:39.109
  I0521 16:55:39.114116 22 container_probe.go:1749] Initial restart count of pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 is 0
  I0521 16:55:39.118152 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:39.265124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:40.265988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:41.123557 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:41.266269      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:42.266767      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:43.128310 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:43.267716      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:44.267973      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:45.132784 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:45.268481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:46.269589      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:47.138648 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:47.269643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:48.270657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:49.144132 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:49.271537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:50.272391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:51.151056 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:51.273467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:52.273532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:53.156128 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:53.274285      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:54.274526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:55.161687 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:55.275566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:56.275934      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:57.167625 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:57.277046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:55:58.277635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:55:59.172959 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:55:59.278266      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:00.278813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:01.178485 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:01.279671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:02.280555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:03.181301 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:03.281581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:04.281860      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:05.187476 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:05.282573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:06.283602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:07.192771 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:07.283988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:08.284807      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:09.198645 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:09.284576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:10.284988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:11.203365 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:11.285606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:12.286251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:13.209696 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:13.286777      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:14.287301      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:15.211999 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:15.288238      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:16.288555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:17.217138 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:17.289542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:18.290582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:19.222716 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:19.290846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:20.291390      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:21.228674 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:21.292049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:22.292562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:23.234468 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:23.293663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:24.294162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:25.240070 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:25.294228      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:26.294563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:27.245288 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  E0521 16:56:27.294645      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:28.295488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:56:29.250684 22 container_probe.go:1759] Get pod busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 in namespace container-probe-4186
  I0521 16:56:29.250739 22 container_probe.go:1763] Restart count of pod container-probe-4186/busybox-bd5b6cdf-f95c-43c2-827d-37deccf41b42 is now 1 (50.136565205s elapsed)
  STEP: deleting the pod @ 05/21/24 16:56:29.25
  I0521 16:56:29.261607 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4186" for this suite. @ 05/21/24 16:56:29.265
• [52.184 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:348
  STEP: Creating a kubernetes client @ 05/21/24 16:56:29.27
  I0521 16:56:29.270595 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename disruption @ 05/21/24 16:56:29.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:56:29.284
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:56:29.288
  STEP: Creating a pdb that targets all three pods in a test replica set @ 05/21/24 16:56:29.291
  E0521 16:56:29.295691      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/21/24 16:56:29.295
  E0521 16:56:30.296806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:31.296815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 05/21/24 16:56:31.304
  STEP: Waiting for all pods to be running @ 05/21/24 16:56:31.304
  I0521 16:56:31.307078 22 disruption.go:567] pods: 0 < 3
  E0521 16:56:32.297669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:33.298822      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/21/24 16:56:33.309
  STEP: Updating the pdb to allow a pod to be evicted @ 05/21/24 16:56:33.317
  STEP: Waiting for the pdb to be processed @ 05/21/24 16:56:33.324
  E0521 16:56:34.298685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:35.299429      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/21/24 16:56:35.329
  STEP: Waiting for all pods to be running @ 05/21/24 16:56:35.329
  STEP: Waiting for the pdb to observed all healthy pods @ 05/21/24 16:56:35.332
  STEP: Patching the pdb to disallow a pod to be evicted @ 05/21/24 16:56:35.351
  STEP: Waiting for the pdb to be processed @ 05/21/24 16:56:35.378
  E0521 16:56:36.299831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:37.300480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 05/21/24 16:56:37.383
  STEP: locating a running pod @ 05/21/24 16:56:37.387
  STEP: Deleting the pdb to allow a pod to be evicted @ 05/21/24 16:56:37.393
  STEP: Waiting for the pdb to be deleted @ 05/21/24 16:56:37.397
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 05/21/24 16:56:37.399
  STEP: Waiting for all pods to be running @ 05/21/24 16:56:37.399
  I0521 16:56:37.412896 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8584" for this suite. @ 05/21/24 16:56:37.417
• [8.152 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 05/21/24 16:56:37.423
  I0521 16:56:37.423656 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 16:56:37.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:56:37.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:56:37.442
  STEP: Creating a pod to test downward api env vars @ 05/21/24 16:56:37.444
  E0521 16:56:38.301622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:39.301694      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:40.302562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:41.303354      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 16:56:41.46
  I0521 16:56:41.463559 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downward-api-9d64d7f3-9d47-42c7-90ef-642866676a40 container dapi-container: <nil>
  STEP: delete the pod @ 05/21/24 16:56:41.472
  I0521 16:56:41.483700 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9113" for this suite. @ 05/21/24 16:56:41.486
• [4.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 05/21/24 16:56:41.49
  I0521 16:56:41.490886 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 16:56:41.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:56:41.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:56:41.504
  STEP: Creating configMap with name cm-test-opt-del-2dc1e1db-099c-4f78-8a92-1c2263492d9b @ 05/21/24 16:56:41.508
  STEP: Creating configMap with name cm-test-opt-upd-1f0cc390-8c91-4eed-b8fc-63d1813145ad @ 05/21/24 16:56:41.511
  STEP: Creating the pod @ 05/21/24 16:56:41.514
  E0521 16:56:42.303319      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:43.303558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-2dc1e1db-099c-4f78-8a92-1c2263492d9b @ 05/21/24 16:56:43.552
  STEP: Updating configmap cm-test-opt-upd-1f0cc390-8c91-4eed-b8fc-63d1813145ad @ 05/21/24 16:56:43.557
  STEP: Creating configMap with name cm-test-opt-create-2792f0c3-3258-4d34-be4b-ddf18f56c1ec @ 05/21/24 16:56:43.561
  STEP: waiting to observe update in volume @ 05/21/24 16:56:43.564
  E0521 16:56:44.303634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:45.304384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:46.305003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:47.305412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:48.305480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:49.305942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:50.306942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:51.307770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:52.308138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:53.308595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:54.309549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:55.310099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:56.310392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:57.310813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:58.312025      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:56:59.312603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:00.313550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:01.313569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:02.314700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:03.315694      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:04.316256      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:05.316957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:06.317408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:07.318505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:08.319664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:09.320329      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:10.320468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:11.320895      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:12.321309      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:13.322051      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:14.322915      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:15.323860      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:16.324510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:17.325132      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:18.325666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:19.326412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:20.326888      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:21.327873      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:22.328662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:23.328932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:24.329479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:25.330557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:26.331265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:27.331341      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:28.332002      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:29.332380      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:30.332500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:31.332774      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:32.333541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:33.334571      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:34.335286      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:35.335814      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:36.336015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:37.336554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:38.337656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:39.338087      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:40.338496      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:41.339376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:42.340628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:43.340919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:44.341662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:45.342092      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:46.342493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:47.342665      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:48.343831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:49.344429      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:50.344680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:51.345542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:52.346384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:53.346434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:54.347038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:55.347581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:56.347973      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:57.348862      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:58.349524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:57:59.349888      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:00.350701      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:01.350865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:58:01.993429 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5877" for this suite. @ 05/21/24 16:58:01.996
• [80.509 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 05/21/24 16:58:02
  I0521 16:58:02.000132 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 16:58:02
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:58:02.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:58:02.014
  STEP: Setting up server cert @ 05/21/24 16:58:02.026
  E0521 16:58:02.351809      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 16:58:02.433
  STEP: Deploying the webhook pod @ 05/21/24 16:58:02.437
  STEP: Wait for the deployment to be ready @ 05/21/24 16:58:02.445
  I0521 16:58:02.449998 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 16:58:03.353038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:04.353662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 16:58:04.459
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 16:58:04.47
  E0521 16:58:05.353766      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:58:05.471141 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 05/21/24 16:58:05.479
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/21/24 16:58:05.479
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 05/21/24 16:58:05.497
  E0521 16:58:06.354396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 05/21/24 16:58:06.511
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/21/24 16:58:06.511
  E0521 16:58:07.354766      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 05/21/24 16:58:07.531
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/21/24 16:58:07.531
  E0521 16:58:08.355592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:09.356394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:10.357161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:11.357367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:12.358134      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 05/21/24 16:58:12.555
  STEP: Registering slow webhook via the AdmissionRegistration API @ 05/21/24 16:58:12.555
  E0521 16:58:13.358408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:14.359387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:15.360068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:16.360424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:17.361523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:58:17.617764 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5307" for this suite. @ 05/21/24 16:58:17.619
  STEP: Destroying namespace "webhook-markers-2452" for this suite. @ 05/21/24 16:58:17.624
• [15.630 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 05/21/24 16:58:17.63
  I0521 16:58:17.630602 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replicaset @ 05/21/24 16:58:17.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:58:17.638
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:58:17.64
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 05/21/24 16:58:17.642
  E0521 16:58:18.362472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:19.363017      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 05/21/24 16:58:19.656
  STEP: Then the orphan pod is adopted @ 05/21/24 16:58:19.662
  E0521 16:58:20.363166      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 05/21/24 16:58:20.67
  I0521 16:58:20.673547 22 resource.go:87] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/21/24 16:58:20.683
  E0521 16:58:21.363604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 16:58:21.692796 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4357" for this suite. @ 05/21/24 16:58:21.696
• [4.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 05/21/24 16:58:21.701
  I0521 16:58:21.701634 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename gc @ 05/21/24 16:58:21.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:58:21.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:58:21.714
  STEP: create the deployment @ 05/21/24 16:58:21.716
  W0521 16:58:21.720145      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/21/24 16:58:21.72
  STEP: delete the deployment @ 05/21/24 16:58:22.222
  STEP: wait for all rs to be garbage collected @ 05/21/24 16:58:22.225
  STEP: expected 0 rs, got 1 rs @ 05/21/24 16:58:22.228
  STEP: expected 0 pods, got 2 pods @ 05/21/24 16:58:22.229
  E0521 16:58:22.363939      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/21/24 16:58:22.729
  I0521 16:58:22.785623 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0521 16:58:22.785709 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7838" for this suite. @ 05/21/24 16:58:22.787
• [1.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 05/21/24 16:58:22.791
  I0521 16:58:22.791621 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename cronjob @ 05/21/24 16:58:22.792
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 16:58:22.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 16:58:22.799
  STEP: Creating a suspended cronjob @ 05/21/24 16:58:22.8
  STEP: Ensuring no jobs are scheduled @ 05/21/24 16:58:22.804
  E0521 16:58:23.364389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:24.365456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:25.366490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:26.367462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:27.368185      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:28.368355      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:29.368431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:30.369527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:31.369707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:32.370592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:33.371564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:34.373065      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:35.373299      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:36.373324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:37.374369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:38.375385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:39.376385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:40.376602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:41.377485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:42.378344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:43.379343      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:44.379426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:45.380434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:46.381406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:47.381665      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:48.382604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:49.383299      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:50.383681      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:51.384393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:52.384531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:53.385618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:54.386521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:55.387541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:56.388371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:57.388608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:58.389365      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:58:59.390339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:00.390840      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:01.391225      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:02.391534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:03.392389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:04.392764      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:05.393451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:06.393554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:07.394548      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:08.395584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:09.396638      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:10.397001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:11.397340      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:12.397855      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:13.398029      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:14.398585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:15.399629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:16.400139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:17.401128      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:18.401488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:19.401929      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:20.402013      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:21.402375      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:22.402771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:23.402933      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:24.403555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:25.404076      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:26.404529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:27.405412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:28.406391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:29.407390      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:30.407775      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:31.408345      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:32.409383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:33.409695      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:34.409804      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:35.410682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:36.411339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:37.412151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:38.413081      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:39.413397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:40.413813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:41.414493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:42.415394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:43.416522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:44.416898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:45.417835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:46.418057      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:47.418656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:48.419422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:49.420021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:50.421161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:51.421308      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:52.421528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:53.422331      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:54.422770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:55.423397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:56.423923      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:57.424250      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:58.424611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 16:59:59.425271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:00.425708      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:01.426474      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:02.427590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:03.428327      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:04.428865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:05.429828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:06.430531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:07.431602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:08.432510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:09.433602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:10.434096      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:11.434533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:12.435661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:13.436126      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:14.436514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:15.436849      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:16.437088      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:17.438171      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:18.438477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:19.439547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:20.440481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:21.441578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:22.442022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:23.442070      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:24.442624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:25.443544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:26.444039      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:27.444641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:28.445614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:29.446143      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:30.447286      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:31.447719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:32.448500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:33.449371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:34.449395      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:35.450297      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:36.450580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:37.451579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:38.452634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:39.452679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:40.452996      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:41.453601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:42.454024      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:43.454542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:44.454682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:45.455445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:46.456546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:47.457354      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:48.458305      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:49.458576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:50.459346      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:51.459499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:52.459761      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:53.460545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:54.460835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:55.461433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:56.461640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:57.462318      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:58.462871      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:00:59.463305      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:00.464177      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:01.465109      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:02.465580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:03.465694      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:04.466647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:05.467626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:06.467910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:07.468607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:08.469453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:09.469597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:10.469995      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:11.470655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:12.471391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:13.473156      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:14.473353      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:15.473872      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:16.474558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:17.475339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:18.475695      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:19.476242      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:20.477522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:21.478586      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:22.479044      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:23.479683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:24.480130      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:25.480152      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:26.480512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:27.481007      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:28.481336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:29.481468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:30.482106      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:31.483107      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:32.483426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:33.483566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:34.484623      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:35.485603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:36.486022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:37.487228      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:38.487491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:39.487648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:40.488037      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:41.488618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:42.489214      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:43.490244      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:44.490483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:45.491316      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:46.491477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:47.491969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:48.492116      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:49.492812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:50.493762      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:51.494646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:52.495597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:53.496208      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:54.496311      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:55.497097      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:56.497132      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:57.497803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:58.497907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:01:59.499003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:00.499907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:01.500431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:02.501330      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:03.501930      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:04.502658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:05.502884      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:06.503419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:07.504550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:08.505071      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:09.505390      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:10.505748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:11.506437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:12.507060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:13.507626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:14.508606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:15.509694      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:16.509793      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:17.510515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:18.510597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:19.510677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:20.511069      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:21.511805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:22.512311      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:23.512389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:24.512443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:25.513460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:26.513979      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:27.514017      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:28.514509      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:29.515101      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:30.516209      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:31.516705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:32.517511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:33.517933      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:34.518396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:35.519407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:36.519885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:37.520542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:38.521331      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:39.521700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:40.521896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:41.522557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:42.522885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:43.523612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:44.524403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:45.525549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:46.525995      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:47.526751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:48.526877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:49.526740      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:50.526975      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:51.527067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:52.527352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:53.528023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:54.528505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:55.529040      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:56.529455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:57.529783      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:58.530078      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:02:59.530800      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:00.531465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:01.532624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:02.533165      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:03.533277      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:04.533298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:05.533842      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:06.534563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:07.535546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:08.536016      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:09.536829      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:10.537891      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:11.538661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:12.539092      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:13.540219      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:14.540299      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:15.540827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:16.541843      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:17.542820      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:18.543599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:19.544270      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:20.545089      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:21.545995      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:22.546484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 05/21/24 17:03:22.805
  STEP: Removing cronjob @ 05/21/24 17:03:22.809
  I0521 17:03:22.815023 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4461" for this suite. @ 05/21/24 17:03:22.818
• [300.031 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 05/21/24 17:03:22.823
  I0521 17:03:22.823183 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename taint-multiple-pods @ 05/21/24 17:03:22.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:03:22.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:03:22.839
  I0521 17:03:22.842359 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0521 17:03:23.547229      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:24.547581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:25.548119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:26.548667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:27.549080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:28.549516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:29.550306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:30.550987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:31.551215      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:32.551511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:33.551590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:34.552482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:35.552542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:36.553517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:37.554079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:38.554526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:39.555507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:40.556302      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:41.556671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:42.557452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:43.557921      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:44.558427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:45.559063      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:46.559329      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:47.559866      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:48.560096      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:49.560067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:50.560450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:51.561209      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:52.561520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:53.562498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:54.563569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:55.564141      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:56.564582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:57.565426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:58.565897      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:03:59.566449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:00.567446      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:01.567801      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:02.568440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:03.569333      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:04.569506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:05.570419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:06.570822      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:07.571797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:08.572324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:09.572561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:10.573314      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:11.573751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:12.573964      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:13.575014      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:14.575621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:15.576037      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:16.576504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:17.577370      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:18.577515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:19.577586      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:20.578613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:21.579271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:22.579578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:04:22.843386 22 util.go:400] Waiting for terminating namespaces to be deleted...
  I0521 17:04:22.847698 22 taints.go:150] Starting informer...
  STEP: Starting pods... @ 05/21/24 17:04:22.847
  I0521 17:04:23.065957 22 taints.go:469] Pod1 is running on k8sconformance-m02. Tainting Node
  E0521 17:04:23.579903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:24.581033      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:04:25.284868 22 taints.go:477] Pod2 is running on k8sconformance-m02. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/21/24 17:04:25.284
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/21/24 17:04:25.297
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 05/21/24 17:04:25.3
  E0521 17:04:25.581856      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:26.582464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:27.582569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:28.583013      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:29.583240      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:30.583683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:04:31.229491 22 taints.go:498] Noticed Pod "taint-eviction-b1" gets evicted.
  E0521 17:04:31.583950      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:32.584708      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:33.585295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:34.585634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:35.585871      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:36.586344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:37.586530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:38.587075      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:39.587957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:40.588007      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:41.588432      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:42.588810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:43.589394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:44.589689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:45.590038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:46.590584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:47.591603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:48.591959      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:49.592501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:50.592580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:04:51.389388 22 taints.go:498] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/21/24 17:04:51.399
  I0521 17:04:51.402042 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-1134" for this suite. @ 05/21/24 17:04:51.404
• [88.588 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 05/21/24 17:04:51.414
  I0521 17:04:51.414865 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replicaset @ 05/21/24 17:04:51.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:04:51.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:04:51.428
  I0521 17:04:51.430167 22 replica_set.go:191] Creating ReplicaSet my-hostname-basic-1002ec82-a863-42ef-a0b9-c3a2f43e1010
  I0521 17:04:51.435813 22 resource.go:87] Pod name my-hostname-basic-1002ec82-a863-42ef-a0b9-c3a2f43e1010: Found 0 pods out of 1
  E0521 17:04:51.593431      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:52.594438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:53.594468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:54.595452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:55.596547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:04:56.439854 22 resource.go:87] Pod name my-hostname-basic-1002ec82-a863-42ef-a0b9-c3a2f43e1010: Found 1 pods out of 1
  I0521 17:04:56.439914 22 replica_set.go:204] Ensuring a pod for ReplicaSet "my-hostname-basic-1002ec82-a863-42ef-a0b9-c3a2f43e1010" is running
  I0521 17:04:56.442638 22 replica_set.go:220] Pod "my-hostname-basic-1002ec82-a863-42ef-a0b9-c3a2f43e1010-pxlrg" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 17:04:52 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 17:04:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 17:04:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 17:04:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-05-21 17:04:51 +0000 UTC Reason: Message:}])
  I0521 17:04:56.442681 22 replica_set.go:228] Trying to dial the pod
  STEP: trying to dial each unique pod @ 05/21/24 17:04:56.442
  I0521 17:04:56.448498 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-339" for this suite. @ 05/21/24 17:04:56.45
• [5.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1079
  STEP: Creating a kubernetes client @ 05/21/24 17:04:56.454
  I0521 17:04:56.454381 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 17:04:56.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:04:56.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:04:56.468
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/21/24 17:04:56.47
  I0521 17:04:56.471002 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-700 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0521 17:04:56.515731 22 builder.go:146] stderr: ""
  I0521 17:04:56.515763 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 05/21/24 17:04:56.515
  I0521 17:04:56.515831 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-700 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I0521 17:04:56.562692 22 builder.go:146] stderr: ""
  I0521 17:04:56.562728 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/21/24 17:04:56.562
  I0521 17:04:56.563971 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-700 delete pods e2e-test-httpd-pod'
  E0521 17:04:56.597267      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:04:57.598079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:04:58.560006 22 builder.go:146] stderr: ""
  I0521 17:04:58.560076 22 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0521 17:04:58.560212 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-700" for this suite. @ 05/21/24 17:04:58.563
• [2.113 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 05/21/24 17:04:58.568
  I0521 17:04:58.568173 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename proxy @ 05/21/24 17:04:58.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:04:58.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:04:58.582
  STEP: starting an echo server on multiple ports @ 05/21/24 17:04:58.597
  STEP: creating replication controller proxy-service-d96vm in namespace proxy-2485 @ 05/21/24 17:04:58.597
  E0521 17:04:58.598181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:04:58.604150      22 runners.go:198] Created replication controller with name: proxy-service-d96vm, namespace: proxy-2485, replica count: 1
  E0521 17:04:59.599384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:04:59.655825      22 runners.go:198] proxy-service-d96vm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  E0521 17:05:00.599473      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:00.656863      22 runners.go:198] proxy-service-d96vm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0521 17:05:00.661217 22 proxy.go:230] setup took 2.07598183s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 05/21/24 17:05:00.661
  I0521 17:05:00.666110 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 4.744429ms)
  I0521 17:05:00.668317 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 6.921652ms)
  I0521 17:05:00.668409 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 6.919123ms)
  I0521 17:05:00.668447 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 6.902439ms)
  I0521 17:05:00.668777 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 7.244589ms)
  I0521 17:05:00.668788 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 7.376939ms)
  I0521 17:05:00.668836 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 7.2591ms)
  I0521 17:05:00.668897 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 7.382853ms)
  I0521 17:05:00.670297 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 8.741254ms)
  I0521 17:05:00.670347 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 8.736911ms)
  I0521 17:05:00.670521 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 8.974083ms)
  I0521 17:05:00.673996 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 12.427501ms)
  I0521 17:05:00.675122 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 13.639978ms)
  I0521 17:05:00.675122 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 13.75912ms)
  I0521 17:05:00.676330 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 14.830623ms)
  I0521 17:05:00.676420 22 proxy.go:558] (0) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 14.934799ms)
  I0521 17:05:00.682179 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 5.617658ms)
  I0521 17:05:00.682326 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 5.853629ms)
  I0521 17:05:00.682360 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 5.807489ms)
  I0521 17:05:00.683678 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 7.16914ms)
  I0521 17:05:00.683697 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 7.145162ms)
  I0521 17:05:00.683772 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 7.309761ms)
  I0521 17:05:00.683794 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 7.279429ms)
  I0521 17:05:00.683797 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 7.309573ms)
  I0521 17:05:00.683815 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 7.286057ms)
  I0521 17:05:00.683857 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 7.287964ms)
  I0521 17:05:00.683866 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 7.288846ms)
  I0521 17:05:00.684424 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 7.847481ms)
  I0521 17:05:00.684497 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 7.964718ms)
  I0521 17:05:00.684493 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 8.014792ms)
  I0521 17:05:00.684498 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 7.922769ms)
  I0521 17:05:00.684560 22 proxy.go:558] (1) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 8.00079ms)
  I0521 17:05:00.689410 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 4.75645ms)
  I0521 17:05:00.689831 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 5.144994ms)
  I0521 17:05:00.691368 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 6.569445ms)
  I0521 17:05:00.691436 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 6.706838ms)
  I0521 17:05:00.691473 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 6.835704ms)
  I0521 17:05:00.691487 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 6.665128ms)
  I0521 17:05:00.691529 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 6.711973ms)
  I0521 17:05:00.691591 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 6.831546ms)
  I0521 17:05:00.691659 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 6.656981ms)
  I0521 17:05:00.692505 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 7.74148ms)
  I0521 17:05:00.692490 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 7.779104ms)
  I0521 17:05:00.692566 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 7.791638ms)
  I0521 17:05:00.693042 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 8.255872ms)
  I0521 17:05:00.693050 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 8.267546ms)
  I0521 17:05:00.693085 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 8.286259ms)
  I0521 17:05:00.693097 22 proxy.go:558] (2) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 8.264913ms)
  I0521 17:05:00.698223 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 4.936417ms)
  I0521 17:05:00.698384 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 5.082403ms)
  I0521 17:05:00.698629 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 5.231267ms)
  I0521 17:05:00.698815 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 5.411982ms)
  I0521 17:05:00.698847 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 5.489887ms)
  I0521 17:05:00.698932 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 5.758977ms)
  I0521 17:05:00.698959 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 5.556164ms)
  I0521 17:05:00.699820 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 6.380951ms)
  I0521 17:05:00.699876 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 6.436284ms)
  I0521 17:05:00.700344 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 6.883049ms)
  I0521 17:05:00.700352 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 6.893282ms)
  I0521 17:05:00.700377 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 7.041208ms)
  I0521 17:05:00.700406 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 7.167115ms)
  I0521 17:05:00.700427 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 7.035545ms)
  I0521 17:05:00.700426 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 6.95445ms)
  I0521 17:05:00.700435 22 proxy.go:558] (3) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 7.170005ms)
  I0521 17:05:00.705850 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 5.303714ms)
  I0521 17:05:00.706271 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 5.574986ms)
  I0521 17:05:00.706289 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 5.663635ms)
  I0521 17:05:00.706315 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 5.594559ms)
  I0521 17:05:00.706339 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 5.744837ms)
  I0521 17:05:00.706347 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 5.703268ms)
  I0521 17:05:00.706309 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 5.65093ms)
  I0521 17:05:00.706309 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 5.761603ms)
  I0521 17:05:00.706376 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 5.660851ms)
  I0521 17:05:00.706392 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 5.721009ms)
  I0521 17:05:00.706892 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 6.360054ms)
  I0521 17:05:00.706908 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 6.214502ms)
  I0521 17:05:00.706914 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 6.341833ms)
  I0521 17:05:00.706947 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 6.242754ms)
  I0521 17:05:00.706967 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 6.407113ms)
  I0521 17:05:00.707157 22 proxy.go:558] (4) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 6.496586ms)
  I0521 17:05:00.711972 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 4.704162ms)
  I0521 17:05:00.712009 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 4.655051ms)
  I0521 17:05:00.711975 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 4.617298ms)
  I0521 17:05:00.712033 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 4.763345ms)
  I0521 17:05:00.712038 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 4.627375ms)
  I0521 17:05:00.712056 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 4.654642ms)
  I0521 17:05:00.712076 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 4.785017ms)
  I0521 17:05:00.712105 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 4.751048ms)
  I0521 17:05:00.712130 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 4.718533ms)
  I0521 17:05:00.712248 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 4.87111ms)
  I0521 17:05:00.712283 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 5.023827ms)
  I0521 17:05:00.712287 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 4.953126ms)
  I0521 17:05:00.712628 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 5.383597ms)
  I0521 17:05:00.712663 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 5.27046ms)
  I0521 17:05:00.712678 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 5.325468ms)
  I0521 17:05:00.712711 22 proxy.go:558] (5) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 5.452415ms)
  I0521 17:05:00.717359 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 4.578863ms)
  I0521 17:05:00.717430 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 4.52888ms)
  I0521 17:05:00.717454 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 4.55542ms)
  I0521 17:05:00.717480 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 4.598505ms)
  I0521 17:05:00.717500 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 4.686897ms)
  I0521 17:05:00.717486 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 4.69615ms)
  I0521 17:05:00.717536 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 4.730262ms)
  I0521 17:05:00.717567 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 4.704584ms)
  I0521 17:05:00.717581 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 4.663578ms)
  I0521 17:05:00.717824 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 4.937772ms)
  I0521 17:05:00.717826 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 4.894105ms)
  I0521 17:05:00.717846 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 4.946266ms)
  I0521 17:05:00.717848 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 5.018269ms)
  I0521 17:05:00.717857 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 4.975443ms)
  I0521 17:05:00.717888 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 4.981654ms)
  I0521 17:05:00.717896 22 proxy.go:558] (6) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 5.057765ms)
  I0521 17:05:00.721526 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 3.562903ms)
  I0521 17:05:00.721571 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 3.589768ms)
  I0521 17:05:00.721567 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 3.54583ms)
  I0521 17:05:00.721597 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 3.635104ms)
  I0521 17:05:00.721612 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 3.627988ms)
  I0521 17:05:00.722298 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 4.359025ms)
  I0521 17:05:00.722307 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 4.258168ms)
  I0521 17:05:00.722300 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 4.295683ms)
  I0521 17:05:00.722333 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 4.31692ms)
  I0521 17:05:00.722300 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 4.244881ms)
  I0521 17:05:00.722334 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 4.287776ms)
  I0521 17:05:00.722340 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 4.267271ms)
  I0521 17:05:00.722347 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 4.301206ms)
  I0521 17:05:00.722375 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 4.324102ms)
  I0521 17:05:00.722436 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 4.404443ms)
  I0521 17:05:00.722448 22 proxy.go:558] (7) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 4.420731ms)
  I0521 17:05:00.725869 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 3.373214ms)
  I0521 17:05:00.725869 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 3.267841ms)
  I0521 17:05:00.725921 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 3.360482ms)
  I0521 17:05:00.725924 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 3.332518ms)
  I0521 17:05:00.725962 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 3.375943ms)
  I0521 17:05:00.725992 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 3.417945ms)
  I0521 17:05:00.726006 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 3.471034ms)
  I0521 17:05:00.726007 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 3.419845ms)
  I0521 17:05:00.726019 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 3.403984ms)
  I0521 17:05:00.726023 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 3.463755ms)
  I0521 17:05:00.726032 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 3.5185ms)
  I0521 17:05:00.726040 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 3.429059ms)
  I0521 17:05:00.726046 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 3.496117ms)
  I0521 17:05:00.726069 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 3.547099ms)
  I0521 17:05:00.726086 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 3.592855ms)
  I0521 17:05:00.726092 22 proxy.go:558] (8) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 3.487321ms)
  I0521 17:05:00.728660 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.500338ms)
  I0521 17:05:00.728761 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 2.615295ms)
  I0521 17:05:00.728770 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 2.607204ms)
  I0521 17:05:00.728762 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 2.5576ms)
  I0521 17:05:00.728781 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.64668ms)
  I0521 17:05:00.728809 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 2.595344ms)
  I0521 17:05:00.728808 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.597082ms)
  I0521 17:05:00.728811 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.625461ms)
  I0521 17:05:00.728822 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 2.617388ms)
  I0521 17:05:00.728812 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 2.682558ms)
  I0521 17:05:00.729036 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 2.81631ms)
  I0521 17:05:00.729076 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.952936ms)
  I0521 17:05:00.729174 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 3.003344ms)
  I0521 17:05:00.729218 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 3.08785ms)
  I0521 17:05:00.729240 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 3.01486ms)
  I0521 17:05:00.729248 22 proxy.go:558] (9) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 3.056688ms)
  I0521 17:05:00.731757 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.426344ms)
  I0521 17:05:00.731757 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 2.387308ms)
  I0521 17:05:00.731783 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 2.421663ms)
  I0521 17:05:00.731760 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.471585ms)
  I0521 17:05:00.731757 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 2.443231ms)
  I0521 17:05:00.731876 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.539159ms)
  I0521 17:05:00.731894 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 2.543982ms)
  I0521 17:05:00.731931 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.584137ms)
  I0521 17:05:00.731932 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 2.6134ms)
  I0521 17:05:00.731947 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.663052ms)
  I0521 17:05:00.731952 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 2.584101ms)
  I0521 17:05:00.732131 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.832931ms)
  I0521 17:05:00.732147 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 2.791823ms)
  I0521 17:05:00.732151 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.870367ms)
  I0521 17:05:00.732159 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 2.828694ms)
  I0521 17:05:00.732309 22 proxy.go:558] (10) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.971855ms)
  I0521 17:05:00.734608 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 2.250731ms)
  I0521 17:05:00.734649 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 2.29938ms)
  I0521 17:05:00.734676 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.272378ms)
  I0521 17:05:00.734866 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 2.505341ms)
  I0521 17:05:00.734883 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.480639ms)
  I0521 17:05:00.734917 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.492391ms)
  I0521 17:05:00.734931 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.489969ms)
  I0521 17:05:00.734943 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 2.538824ms)
  I0521 17:05:00.734956 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 2.523863ms)
  I0521 17:05:00.734988 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.55116ms)
  I0521 17:05:00.735011 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.583812ms)
  I0521 17:05:00.735023 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 2.586802ms)
  I0521 17:05:00.735054 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.687216ms)
  I0521 17:05:00.735068 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.66824ms)
  I0521 17:05:00.735081 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 2.668963ms)
  I0521 17:05:00.735096 22 proxy.go:558] (11) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 2.675007ms)
  I0521 17:05:00.737038 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.762523ms)
  I0521 17:05:00.737405 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 2.190185ms)
  I0521 17:05:00.737407 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 2.127188ms)
  I0521 17:05:00.737415 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 2.292588ms)
  I0521 17:05:00.737423 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 2.177194ms)
  I0521 17:05:00.737431 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 2.184736ms)
  I0521 17:05:00.737434 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 2.181987ms)
  I0521 17:05:00.737416 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.187387ms)
  I0521 17:05:00.737436 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 2.183686ms)
  I0521 17:05:00.737450 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.189383ms)
  I0521 17:05:00.737488 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.310363ms)
  I0521 17:05:00.737486 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 2.206664ms)
  I0521 17:05:00.737519 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.244327ms)
  I0521 17:05:00.737521 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.236076ms)
  I0521 17:05:00.737554 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.32288ms)
  I0521 17:05:00.737559 22 proxy.go:558] (12) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.294529ms)
  I0521 17:05:00.739407 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 1.767611ms)
  I0521 17:05:00.739420 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 1.798207ms)
  I0521 17:05:00.739419 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 1.804405ms)
  I0521 17:05:00.739417 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 1.759109ms)
  I0521 17:05:00.739446 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.790134ms)
  I0521 17:05:00.739456 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 1.798701ms)
  I0521 17:05:00.739459 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 1.79712ms)
  I0521 17:05:00.739511 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 1.909366ms)
  I0521 17:05:00.739536 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.892859ms)
  I0521 17:05:00.739550 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 1.897946ms)
  I0521 17:05:00.739701 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.05925ms)
  I0521 17:05:00.740096 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.426774ms)
  I0521 17:05:00.740097 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 2.499852ms)
  I0521 17:05:00.740093 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.46521ms)
  I0521 17:05:00.740119 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.478818ms)
  I0521 17:05:00.740123 22 proxy.go:558] (13) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 2.518001ms)
  I0521 17:05:00.742352 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.16195ms)
  I0521 17:05:00.742593 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 2.434239ms)
  I0521 17:05:00.742630 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.400615ms)
  I0521 17:05:00.742649 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 2.449883ms)
  I0521 17:05:00.742663 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.432936ms)
  I0521 17:05:00.742656 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 2.478765ms)
  I0521 17:05:00.742681 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.460911ms)
  I0521 17:05:00.742689 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 2.538349ms)
  I0521 17:05:00.742696 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 2.544258ms)
  I0521 17:05:00.742701 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 2.538901ms)
  I0521 17:05:00.742897 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 2.697373ms)
  I0521 17:05:00.742902 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.671438ms)
  I0521 17:05:00.742905 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 2.679348ms)
  I0521 17:05:00.742906 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.684795ms)
  I0521 17:05:00.742913 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.688142ms)
  I0521 17:05:00.742917 22 proxy.go:558] (14) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.767617ms)
  I0521 17:05:00.744696 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.745725ms)
  I0521 17:05:00.744696 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 1.710881ms)
  I0521 17:05:00.744966 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 1.970624ms)
  I0521 17:05:00.745222 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 2.194322ms)
  I0521 17:05:00.745228 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.225809ms)
  I0521 17:05:00.745244 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 2.205925ms)
  I0521 17:05:00.745249 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 2.213383ms)
  I0521 17:05:00.745254 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 2.230776ms)
  I0521 17:05:00.745267 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 2.219916ms)
  I0521 17:05:00.745269 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 2.248882ms)
  I0521 17:05:00.745274 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 2.239548ms)
  I0521 17:05:00.745514 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 2.524498ms)
  I0521 17:05:00.745517 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.480869ms)
  I0521 17:05:00.745537 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.490278ms)
  I0521 17:05:00.745540 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.522607ms)
  I0521 17:05:00.745545 22 proxy.go:558] (15) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.530918ms)
  I0521 17:05:00.747425 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 1.784146ms)
  I0521 17:05:00.747476 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.80614ms)
  I0521 17:05:00.747482 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 1.823638ms)
  I0521 17:05:00.747489 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 1.907744ms)
  I0521 17:05:00.747487 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 1.854269ms)
  I0521 17:05:00.747499 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.853095ms)
  I0521 17:05:00.747516 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 1.832549ms)
  I0521 17:05:00.747552 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 1.882503ms)
  I0521 17:05:00.747615 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 1.933256ms)
  I0521 17:05:00.747636 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 1.939361ms)
  I0521 17:05:00.747700 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 2.014973ms)
  I0521 17:05:00.748121 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.433175ms)
  I0521 17:05:00.748158 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.458174ms)
  I0521 17:05:00.748168 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 2.471438ms)
  I0521 17:05:00.748261 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.580967ms)
  I0521 17:05:00.748262 22 proxy.go:558] (16) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.567094ms)
  I0521 17:05:00.750163 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 1.839472ms)
  I0521 17:05:00.750214 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 1.86827ms)
  I0521 17:05:00.750244 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 1.956652ms)
  I0521 17:05:00.750255 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 1.921067ms)
  I0521 17:05:00.750250 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 1.873227ms)
  I0521 17:05:00.750264 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 1.893069ms)
  I0521 17:05:00.750275 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.905952ms)
  I0521 17:05:00.750284 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.903474ms)
  I0521 17:05:00.750289 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 1.909484ms)
  I0521 17:05:00.750298 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 1.943472ms)
  I0521 17:05:00.750329 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 1.985795ms)
  I0521 17:05:00.750332 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.005081ms)
  I0521 17:05:00.750427 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.07172ms)
  I0521 17:05:00.750437 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.072041ms)
  I0521 17:05:00.750453 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.086752ms)
  I0521 17:05:00.750441 22 proxy.go:558] (17) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.126171ms)
  I0521 17:05:00.752248 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 1.753612ms)
  I0521 17:05:00.752250 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.709763ms)
  I0521 17:05:00.752276 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 1.789808ms)
  I0521 17:05:00.752294 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 1.744968ms)
  I0521 17:05:00.752294 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.763762ms)
  I0521 17:05:00.752309 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 1.763517ms)
  I0521 17:05:00.752458 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 1.927344ms)
  I0521 17:05:00.752489 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 1.953949ms)
  I0521 17:05:00.752501 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 1.948035ms)
  I0521 17:05:00.752531 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 1.981125ms)
  I0521 17:05:00.752537 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 2.020748ms)
  I0521 17:05:00.752544 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.048355ms)
  I0521 17:05:00.752555 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.028557ms)
  I0521 17:05:00.752572 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.067173ms)
  I0521 17:05:00.752629 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 2.075386ms)
  I0521 17:05:00.752742 22 proxy.go:558] (18) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.255673ms)
  I0521 17:05:00.754680 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.872133ms)
  I0521 17:05:00.754716 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:162/proxy/: bar (200; 1.942155ms)
  I0521 17:05:00.754730 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:460/proxy/: tls baz (200; 1.920094ms)
  I0521 17:05:00.754749 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:1080/proxy/rewriteme">... (200; 1.928613ms)
  I0521 17:05:00.754767 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:462/proxy/: tls qux (200; 1.928066ms)
  I0521 17:05:00.754780 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:1080/proxy/rewriteme">test<... (200; 2.018977ms)
  I0521 17:05:00.754788 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/http:proxy-service-d96vm-4np5n:160/proxy/: foo (200; 1.965635ms)
  I0521 17:05:00.754800 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n/proxy/rewriteme">test</a> (200; 1.993083ms)
  I0521 17:05:00.754862 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname1/proxy/: foo (200; 2.024261ms)
  I0521 17:05:00.754956 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname1/proxy/: foo (200; 2.152973ms)
  I0521 17:05:00.754970 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname1/proxy/: tls baz (200; 2.202325ms)
  I0521 17:05:00.754978 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/services/proxy-service-d96vm:portname2/proxy/: bar (200; 2.218954ms)
  I0521 17:05:00.754984 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/services/https:proxy-service-d96vm:tlsportname2/proxy/: tls qux (200; 2.166756ms)
  I0521 17:05:00.754990 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/: <a href="/api/v1/namespaces/proxy-2485/pods/https:proxy-service-d96vm-4np5n:443/proxy/tlsrewritem... (200; 2.155328ms)
  I0521 17:05:00.754995 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/pods/proxy-service-d96vm-4np5n:162/proxy/: bar (200; 2.210807ms)
  I0521 17:05:00.755015 22 proxy.go:558] (19) /api/v1/namespaces/proxy-2485/services/http:proxy-service-d96vm:portname2/proxy/: bar (200; 2.217546ms)
  STEP: deleting ReplicationController proxy-service-d96vm in namespace proxy-2485, will wait for the garbage collector to delete the pods @ 05/21/24 17:05:00.755
  I0521 17:05:00.816426 22 resources.go:139] Deleting ReplicationController proxy-service-d96vm took: 9.289303ms
  I0521 17:05:00.916613 22 resources.go:163] Terminating ReplicationController proxy-service-d96vm pods took: 100.185562ms
  E0521 17:05:01.601385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:02.602397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:03.602544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:03.616789 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2485" for this suite. @ 05/21/24 17:05:03.617
• [5.054 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 05/21/24 17:05:03.622
  I0521 17:05:03.622014 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 17:05:03.622
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:05:03.63
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:05:03.633
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 17:05:03.635
  E0521 17:05:04.603415      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:05.603878      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:06.604538      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:07.605113      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:05:07.653
  I0521 17:05:07.655931 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-d1c68245-b5f3-444c-a379-6c2fd71d5e12 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 17:05:07.671
  I0521 17:05:07.688269 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5649" for this suite. @ 05/21/24 17:05:07.691
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 05/21/24 17:05:07.697
  I0521 17:05:07.697558 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 17:05:07.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:05:07.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:05:07.712
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 05/21/24 17:05:07.714
  E0521 17:05:08.605646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:09.606354      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:10.607375      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:11.607621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:05:11.731
  I0521 17:05:11.734666 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-19916104-b7c4-4fd0-8f3f-28222e13e2e3 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:05:11.742
  I0521 17:05:11.758673 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2001" for this suite. @ 05/21/24 17:05:11.761
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 05/21/24 17:05:11.766
  I0521 17:05:11.766996 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replicaset @ 05/21/24 17:05:11.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:05:11.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:05:11.779
  I0521 17:05:11.787145 22 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0521 17:05:12.608465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:13.608661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:14.609263      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:15.610471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:16.610941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:16.790943 22 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/21/24 17:05:16.791
  STEP: Scaling up "test-rs" replicaset @ 05/21/24 17:05:16.791
  I0521 17:05:16.799889 22 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 05/21/24 17:05:16.799
  I0521 17:05:16.814484 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-4590 with ReadyReplicas 1, AvailableReplicas 1
  I0521 17:05:16.823534 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-4590 with ReadyReplicas 1, AvailableReplicas 1
  I0521 17:05:16.836051 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-4590 with ReadyReplicas 1, AvailableReplicas 1
  I0521 17:05:16.841590 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-4590 with ReadyReplicas 1, AvailableReplicas 1
  E0521 17:05:17.611587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:17.784165 22 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-4590 with ReadyReplicas 2, AvailableReplicas 2
  I0521 17:05:17.815174 22 replica_set.go:545] observed Replicaset test-rs in namespace replicaset-4590 with ReadyReplicas 3 found true
  I0521 17:05:17.815407 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4590" for this suite. @ 05/21/24 17:05:17.819
• [6.058 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 05/21/24 17:05:17.824
  I0521 17:05:17.824736 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:05:17.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:05:17.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:05:17.839
  STEP: Creating projection with secret that has name projected-secret-test-map-4934fd54-6dd0-4974-9ac5-b32e2bb5017f @ 05/21/24 17:05:17.842
  STEP: Creating a pod to test consume secrets @ 05/21/24 17:05:17.846
  E0521 17:05:18.612347      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:19.612780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:20.613135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:21.613545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:05:21.867
  I0521 17:05:21.870493 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-e52bedc3-401c-474f-ae08-f4fcb93b1465 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 17:05:21.877
  I0521 17:05:21.893681 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9305" for this suite. @ 05/21/24 17:05:21.896
• [4.078 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3656
  STEP: Creating a kubernetes client @ 05/21/24 17:05:21.902
  I0521 17:05:21.902922 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 17:05:21.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:05:21.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:05:21.916
  STEP: creating service multiprotocol-test in namespace services-8726 @ 05/21/24 17:05:21.919
  STEP: creating pod pod1 in namespace services-8726 @ 05/21/24 17:05:21.93
  STEP: Creating pod pod1 in namespace services-8726 @ 05/21/24 17:05:21.93
  E0521 17:05:22.614636      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:23.615120      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-8726 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 05/21/24 17:05:23.95
  I0521 17:05:23.957984 22 service.go:4351] successfully validated that service multiprotocol-test in namespace services-8726 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 05/21/24 17:05:23.958
  I0521 17:05:23.958064 22 resource.go:361] Creating new exec pod
  E0521 17:05:24.615147      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:25.615515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:25.970926 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.150.37 80'
  I0521 17:05:26.057688 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.98.150.37 80\nConnection to 10.98.150.37 80 port [tcp/http] succeeded!\n"
  I0521 17:05:26.057720 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:05:26.057773 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.98.150.37 80'
  E0521 17:05:26.615624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:27.616510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:28.617368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:29.617946      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:30.153482 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.98.150.37 80\nConnection to 10.98.150.37 80 port [udp/*] succeeded!\n"
  I0521 17:05:30.153531 22 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 05/21/24 17:05:30.153
  I0521 17:05:30.162688 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.150.37 80'
  I0521 17:05:30.258507 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.98.150.37 80\nConnection to 10.98.150.37 80 port [tcp/http] succeeded!\n"
  I0521 17:05:30.258556 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:05:30.258663 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.98.150.37 80'
  E0521 17:05:30.617956      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:31.618520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:32.619457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:33.619963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:34.361180 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.98.150.37 80\nConnection to 10.98.150.37 80 port [udp/*] succeeded!\n"
  I0521 17:05:34.361259 22 builder.go:147] stdout: ""
  I0521 17:05:34.361341 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.98.150.37 80'
  E0521 17:05:34.620526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:35.621239      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:36.622028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:37.622688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:38.462786 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.98.150.37 80\nConnection to 10.98.150.37 80 port [udp/*] succeeded!\n"
  I0521 17:05:38.462857 22 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 05/21/24 17:05:38.462
  I0521 17:05:38.471975 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.98.150.37 80'
  E0521 17:05:38.622974      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:39.623683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:40.624582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:41.625021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:42.562415 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.98.150.37 80\nConnection to 10.98.150.37 80 port [udp/*] succeeded!\n"
  I0521 17:05:42.562449 22 builder.go:147] stdout: "pod1"
  I0521 17:05:42.562525 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.150.37 80'
  E0521 17:05:42.625835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:43.626546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:44.626797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:44.662384 22 builder.go:135] rc: 1
  I0521 17:05:44.662481 22 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.150.37 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.98.150.37 80
  nc: connect to 10.98.150.37 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0521 17:05:44.662593 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.150.37 80'
  E0521 17:05:45.627690      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:46.627892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:46.757704 22 builder.go:135] rc: 1
  I0521 17:05:46.757791 22 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.150.37 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.98.150.37 80
  nc: connect to 10.98.150.37 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0521 17:05:46.757898 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.150.37 80'
  E0521 17:05:47.628611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:48.629037      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:48.854989 22 builder.go:135] rc: 1
  I0521 17:05:48.855077 22 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8726 exec execpodck7bs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.98.150.37 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.98.150.37 80
  nc: connect to 10.98.150.37 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0521 17:05:48.855279 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8726" for this suite. @ 05/21/24 17:05:48.858
• [26.962 seconds]
------------------------------
SSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 05/21/24 17:05:48.865
  I0521 17:05:48.865149 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 17:05:48.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:05:48.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:05:48.88
  STEP: creating a secret @ 05/21/24 17:05:48.883
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 05/21/24 17:05:48.887
  STEP: patching the secret @ 05/21/24 17:05:48.89
  STEP: deleting the secret using a LabelSelector @ 05/21/24 17:05:48.898
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 05/21/24 17:05:48.905
  I0521 17:05:48.908233 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5091" for this suite. @ 05/21/24 17:05:48.911
• [0.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 05/21/24 17:05:48.916
  I0521 17:05:48.916588 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 17:05:48.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:05:48.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:05:48.928
  STEP: Creating pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512 @ 05/21/24 17:05:48.93
  E0521 17:05:49.629494      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:50.629966      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/21/24 17:05:50.944
  I0521 17:05:50.946874 22 container_probe.go:1749] Initial restart count of pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 is 0
  I0521 17:05:50.949008 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:05:51.631005      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:52.631338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:52.955322 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:05:53.631765      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:54.632562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:54.961231 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:05:55.633521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:56.633614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:56.966980 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:05:57.633773      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:05:58.634546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:05:58.970075 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:05:59.635000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:00.635130      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:00.975616 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:01.636331      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:02.636907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:02.979823 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:03.637608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:04.638648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:04.983921 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:05.638928      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:06.639476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:06.988336 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:07.639528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:08.640606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:08.994323 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:09.640945      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:10.641333      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:11.000010 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  I0521 17:06:11.000076 22 container_probe.go:1763] Restart count of pod container-probe-2512/liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 is now 1 (20.05316043s elapsed)
  E0521 17:06:11.641689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:12.641763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:13.005662 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:13.642412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:14.643507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:15.011555 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:15.643971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:16.644688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:17.016799 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:17.645438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:18.645621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:19.022164 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:19.645933      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:20.646300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:21.027885 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:21.646662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:22.647111      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:23.034665 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:23.647530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:24.648163      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:25.040470 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:25.648443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:26.648657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:27.046624 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:27.649529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:28.650092      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:29.051715 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:29.650579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:30.651077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:31.057805 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  I0521 17:06:31.057868 22 container_probe.go:1763] Restart count of pod container-probe-2512/liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 is now 2 (40.110952789s elapsed)
  E0521 17:06:31.651648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:32.651881      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:33.061004 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:33.653017      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:34.653666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:35.066938 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:35.653851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:36.654448      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:37.072726 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:37.655475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:38.655990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:39.078236 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:39.656742      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:40.657593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:41.084367 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:41.658020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:42.658717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:43.090470 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:43.659184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:44.659687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:45.096488 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:45.660380      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:46.660595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:47.102436 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:47.661475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:48.661124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:49.107961 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:49.661549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:50.662406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:51.112872 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  I0521 17:06:51.112934 22 container_probe.go:1763] Restart count of pod container-probe-2512/liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 is now 3 (1m0.166017383s elapsed)
  E0521 17:06:51.662667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:52.663182      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:53.117647 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:53.663314      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:54.663377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:55.122919 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:55.663678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:56.664516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:57.127979 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:57.664499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:06:58.664764      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:06:59.132369 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:06:59.664978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:00.665282      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:01.137377 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:01.666262      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:02.666560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:03.143322 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:03.666855      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:04.667129      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:05.149423 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:05.667366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:06.667932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:07.155279 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:07.669002      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:08.669534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:09.161636 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:09.670382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:10.671227      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:11.166815 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  I0521 17:07:11.166879 22 container_probe.go:1763] Restart count of pod container-probe-2512/liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 is now 4 (1m20.219961947s elapsed)
  E0521 17:07:11.672392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:12.672747      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:13.173439 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:13.673048      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:14.673643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:15.179269 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:15.674608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:16.675567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:17.184321 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:17.676560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:18.677053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:19.189539 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:19.677168      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:20.677832      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:21.195354 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:21.678761      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:22.679573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:23.202485 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:23.680154      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:24.680831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:25.207487 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:25.680936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:26.681573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:27.212000 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:27.681760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:28.682324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:29.217590 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:29.683083      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:30.684181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:31.223090 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:31.684981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:32.685524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:33.228131 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:33.685561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:34.686472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:35.233674 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:35.686596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:36.687358      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:37.237334 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:37.687578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:38.688696      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:39.243486 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:39.689000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:40.689382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:41.249294 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:41.689753      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:42.690393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:43.254099 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:43.690526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:44.691044      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:45.259122 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:45.691509      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:46.692054      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:47.265591 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:47.692393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:48.693018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:49.270932 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:49.693561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:50.694482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:51.276725 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:51.695324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:52.695523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:53.281532 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:53.696016      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:54.696521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:55.286578 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:55.697241      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:56.697667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:57.292298 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:57.697827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:07:58.698438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:07:59.297544 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:07:59.699139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:00.700144      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:01.302912 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:08:01.700549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:02.700940      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:03.306624 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:08:03.700977      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:04.701851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:05.313039 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:08:05.702736      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:06.703589      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:07.318055 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:08:07.703897      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:08.704504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:09.322036 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:08:09.704611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:10.705598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:11.327464 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:08:11.706032      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:12.706907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:13.333528 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  E0521 17:08:13.707893      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:14.708285      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:15.338616 22 container_probe.go:1759] Get pod liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 in namespace container-probe-2512
  I0521 17:08:15.338672 22 container_probe.go:1763] Restart count of pod container-probe-2512/liveness-4b2d24c9-ec9f-4a69-869a-cf00ac148ac5 is now 5 (2m24.391757261s elapsed)
  STEP: deleting the pod @ 05/21/24 17:08:15.338
  I0521 17:08:15.347965 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2512" for this suite. @ 05/21/24 17:08:15.351
• [146.444 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 05/21/24 17:08:15.36
  I0521 17:08:15.360763 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/21/24 17:08:15.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:15.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:15.375
  I0521 17:08:15.377719 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:08:15.708442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:16.709422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:17.709780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:18.710475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:19.711387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:20.712619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:21.576154 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6965" for this suite. @ 05/21/24 17:08:21.58
• [6.227 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 05/21/24 17:08:21.588
  I0521 17:08:21.588293 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/21/24 17:08:21.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:21.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:21.607
  STEP: create the container to handle the HTTPGet hook request. @ 05/21/24 17:08:21.61
  E0521 17:08:21.713247      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:22.713635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/21/24 17:08:23.626
  E0521 17:08:23.714211      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:24.714758      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 05/21/24 17:08:25.643
  STEP: delete the pod with lifecycle hook @ 05/21/24 17:08:25.656
  E0521 17:08:25.715160      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:26.715388      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:27.671813 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-7500" for this suite. @ 05/21/24 17:08:27.674
• [6.093 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 05/21/24 17:08:27.68
  I0521 17:08:27.681020 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename runtimeclass @ 05/21/24 17:08:27.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:27.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:27.695
  E0521 17:08:27.715943      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:28.717038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:29.717404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:29.720069 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5101" for this suite. @ 05/21/24 17:08:29.723
• [2.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 05/21/24 17:08:29.729
  I0521 17:08:29.729256 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl-logs @ 05/21/24 17:08:29.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:29.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:29.747
  STEP: creating an pod @ 05/21/24 17:08:29.751
  I0521 17:08:29.751349 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-logs-9977 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I0521 17:08:29.799571 22 builder.go:146] stderr: ""
  I0521 17:08:29.799635 22 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 05/21/24 17:08:29.799
  I0521 17:08:29.799793 22 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0521 17:08:30.718533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:31.718984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:31.812011 22 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 05/21/24 17:08:31.812
  I0521 17:08:31.812147 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-logs-9977 logs logs-generator logs-generator'
  I0521 17:08:31.861276 22 builder.go:146] stderr: ""
  I0521 17:08:31.861331 22 builder.go:147] stdout: "I0521 17:08:30.431143       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/rhzx 340\nI0521 17:08:30.631416       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/zm4 281\nI0521 17:08:30.831806       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/zxvg 560\nI0521 17:08:31.031331       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/5js 589\nI0521 17:08:31.231844       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/szm4 533\nI0521 17:08:31.432361       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/9gp 205\nI0521 17:08:31.631832       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/xhtw 381\nI0521 17:08:31.832145       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/48tb 488\n"
  STEP: limiting log lines @ 05/21/24 17:08:31.861
  I0521 17:08:31.861411 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-logs-9977 logs logs-generator logs-generator --tail=1'
  I0521 17:08:31.900246 22 builder.go:146] stderr: ""
  I0521 17:08:31.900272 22 builder.go:147] stdout: "I0521 17:08:31.832145       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/48tb 488\n"
  I0521 17:08:31.900279 22 logs.go:127] got output "I0521 17:08:31.832145       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/48tb 488\n"
  STEP: limiting log bytes @ 05/21/24 17:08:31.9
  I0521 17:08:31.900324 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-logs-9977 logs logs-generator logs-generator --limit-bytes=1'
  I0521 17:08:31.939044 22 builder.go:146] stderr: ""
  I0521 17:08:31.939079 22 builder.go:147] stdout: "I"
  I0521 17:08:31.939089 22 logs.go:133] got output "I"
  STEP: exposing timestamps @ 05/21/24 17:08:31.939
  I0521 17:08:31.939156 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-logs-9977 logs logs-generator logs-generator --tail=1 --timestamps'
  I0521 17:08:31.977385 22 builder.go:146] stderr: ""
  I0521 17:08:31.977422 22 builder.go:147] stdout: "2024-05-21T17:08:31.832322457Z I0521 17:08:31.832145       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/48tb 488\n"
  I0521 17:08:31.977434 22 logs.go:139] got output "2024-05-21T17:08:31.832322457Z I0521 17:08:31.832145       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/48tb 488\n"
  STEP: restricting to a time range @ 05/21/24 17:08:31.977
  E0521 17:08:32.719748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:33.720366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:34.478454 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-logs-9977 logs logs-generator logs-generator --since=1s'
  I0521 17:08:34.528470 22 builder.go:146] stderr: ""
  I0521 17:08:34.528509 22 builder.go:147] stdout: "I0521 17:08:33.631633       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/r82f 241\nI0521 17:08:33.832031       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/2cbd 356\nI0521 17:08:34.031377       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/p9t9 545\nI0521 17:08:34.231797       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/mwv 426\nI0521 17:08:34.432303       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/xj9n 390\n"
  I0521 17:08:34.528552 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-logs-9977 logs logs-generator logs-generator --since=24h'
  I0521 17:08:34.574159 22 builder.go:146] stderr: ""
  I0521 17:08:34.574246 22 builder.go:147] stdout: "I0521 17:08:30.431143       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/rhzx 340\nI0521 17:08:30.631416       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/zm4 281\nI0521 17:08:30.831806       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/zxvg 560\nI0521 17:08:31.031331       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/5js 589\nI0521 17:08:31.231844       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/szm4 533\nI0521 17:08:31.432361       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/9gp 205\nI0521 17:08:31.631832       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/xhtw 381\nI0521 17:08:31.832145       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/48tb 488\nI0521 17:08:32.031553       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/swx 272\nI0521 17:08:32.232120       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/dv8 268\nI0521 17:08:32.431452       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/brp 510\nI0521 17:08:32.631918       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/src 306\nI0521 17:08:32.832143       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/ldlz 366\nI0521 17:08:33.031499       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/zg8 496\nI0521 17:08:33.231976       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/v5zx 513\nI0521 17:08:33.431375       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/2564 259\nI0521 17:08:33.631633       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/r82f 241\nI0521 17:08:33.832031       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/2cbd 356\nI0521 17:08:34.031377       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/p9t9 545\nI0521 17:08:34.231797       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/mwv 426\nI0521 17:08:34.432303       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/xj9n 390\n"
  I0521 17:08:34.574335 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-logs-9977 delete pod logs-generator'
  E0521 17:08:34.720658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:35.721910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:35.804996 22 builder.go:146] stderr: ""
  I0521 17:08:35.805028 22 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I0521 17:08:35.805120 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-9977" for this suite. @ 05/21/24 17:08:35.807
• [6.081 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 05/21/24 17:08:35.809
  I0521 17:08:35.809894 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:08:35.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:35.817
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:35.819
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 17:08:35.821
  E0521 17:08:36.722361      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:37.722678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:38.722841      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:39.723382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:08:39.834
  I0521 17:08:39.837118 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-ed1487d3-9cd2-4319-ac4a-4f8689bb3d95 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 17:08:39.844
  I0521 17:08:39.855692 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2039" for this suite. @ 05/21/24 17:08:39.857
• [4.052 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 05/21/24 17:08:39.861
  I0521 17:08:39.861689 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 17:08:39.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:39.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:39.874
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/21/24 17:08:39.876
  E0521 17:08:40.723758      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:41.724621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:42.725480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:43.725969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:08:43.893
  I0521 17:08:43.896350 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-a3bac87d-77d7-4c85-83d1-75408b110403 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:08:43.902
  I0521 17:08:43.916899 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-583" for this suite. @ 05/21/24 17:08:43.919
• [4.063 seconds]
------------------------------
SSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 05/21/24 17:08:43.925
  I0521 17:08:43.925370 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename podtemplate @ 05/21/24 17:08:43.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:43.936
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:43.939
  I0521 17:08:43.964929 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-1156" for this suite. @ 05/21/24 17:08:43.967
• [0.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 05/21/24 17:08:43.972
  I0521 17:08:43.972415 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 17:08:43.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:43.983
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:43.986
  STEP: Creating a ResourceQuota @ 05/21/24 17:08:43.989
  STEP: Getting a ResourceQuota @ 05/21/24 17:08:43.993
  STEP: Listing all ResourceQuotas with LabelSelector @ 05/21/24 17:08:43.995
  STEP: Patching the ResourceQuota @ 05/21/24 17:08:43.998
  STEP: Deleting a Collection of ResourceQuotas @ 05/21/24 17:08:44.005
  STEP: Verifying the deleted ResourceQuota @ 05/21/24 17:08:44.021
  I0521 17:08:44.025597 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9882" for this suite. @ 05/21/24 17:08:44.03
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 05/21/24 17:08:44.033
  I0521 17:08:44.033980 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename events @ 05/21/24 17:08:44.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:44.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:44.043
  STEP: Create set of events @ 05/21/24 17:08:44.044
  STEP: get a list of Events with a label in the current namespace @ 05/21/24 17:08:44.053
  STEP: delete a list of events @ 05/21/24 17:08:44.054
  I0521 17:08:44.054799 22 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 05/21/24 17:08:44.062
  I0521 17:08:44.063708 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-71" for this suite. @ 05/21/24 17:08:44.065
• [0.034 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 05/21/24 17:08:44.068
  I0521 17:08:44.068638 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 17:08:44.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:44.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:44.078
  STEP: Setting up server cert @ 05/21/24 17:08:44.091
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 17:08:44.204
  STEP: Deploying the webhook pod @ 05/21/24 17:08:44.208
  STEP: Wait for the deployment to be ready @ 05/21/24 17:08:44.215
  I0521 17:08:44.218413 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 17:08:44.725927      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:45.726167      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 17:08:46.229
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 17:08:46.241
  E0521 17:08:46.727234      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:08:47.241709 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 05/21/24 17:08:47.248
  STEP: create a namespace for the webhook @ 05/21/24 17:08:47.263
  STEP: create a configmap should be unconditionally rejected by the webhook @ 05/21/24 17:08:47.274
  I0521 17:08:47.316677 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5024" for this suite. @ 05/21/24 17:08:47.318
  STEP: Destroying namespace "webhook-markers-7907" for this suite. @ 05/21/24 17:08:47.323
  STEP: Destroying namespace "fail-closed-namespace-4853" for this suite. @ 05/21/24 17:08:47.326
• [3.262 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 05/21/24 17:08:47.33
  I0521 17:08:47.330647 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 17:08:47.331
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:08:47.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:08:47.338
  E0521 17:08:47.727320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:48.728634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:49.729533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:50.730092      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:51.730434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:52.730797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:53.730899      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:54.731254      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:55.731573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:56.731988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:57.732108      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:58.732553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:08:59.733025      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:00.733071      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:01.734022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:02.734610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:03.734821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/21/24 17:09:04.346
  E0521 17:09:04.735629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:05.736293      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:06.736469      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:07.736749      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:08.737846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/21/24 17:09:09.351
  STEP: Ensuring resource quota status is calculated @ 05/21/24 17:09:09.356
  E0521 17:09:09.738939      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:10.739141      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 05/21/24 17:09:11.36
  STEP: Ensuring resource quota status captures configMap creation @ 05/21/24 17:09:11.371
  E0521 17:09:11.739475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:12.740503      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 05/21/24 17:09:13.377
  STEP: Ensuring resource quota status released usage @ 05/21/24 17:09:13.382
  E0521 17:09:13.741091      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:14.741744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:09:15.385824 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9152" for this suite. @ 05/21/24 17:09:15.389
• [28.063 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 05/21/24 17:09:15.393
  I0521 17:09:15.393327 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 17:09:15.393
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:09:15.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:09:15.401
  I0521 17:09:15.402789 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: creating the pod @ 05/21/24 17:09:15.403
  STEP: submitting the pod to kubernetes @ 05/21/24 17:09:15.403
  E0521 17:09:15.742368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:16.743312      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:09:17.496984 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5800" for this suite. @ 05/21/24 17:09:17.498
• [2.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 05/21/24 17:09:17.501
  I0521 17:09:17.501879 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename endpointslicemirroring @ 05/21/24 17:09:17.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:09:17.509
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:09:17.511
  STEP: mirroring a new custom Endpoint @ 05/21/24 17:09:17.52
  I0521 17:09:17.528270 22 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  E0521 17:09:17.743805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:18.744416      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 05/21/24 17:09:19.533
  I0521 17:09:19.540676 22 endpointslicemirroring.go:171] Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0521 17:09:19.745496      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:20.745693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 05/21/24 17:09:21.545
  I0521 17:09:21.554472 22 endpointslicemirroring.go:194] Waiting for 0 EndpointSlices to exist, got 1
  E0521 17:09:21.745642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:22.746780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:09:23.557864 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-2910" for this suite. @ 05/21/24 17:09:23.56
• [6.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:420
  STEP: Creating a kubernetes client @ 05/21/24 17:09:23.565
  I0521 17:09:23.565225 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename job @ 05/21/24 17:09:23.566
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:09:23.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:09:23.582
  STEP: Creating Indexed job @ 05/21/24 17:09:23.585
  STEP: Ensuring job reaches completions @ 05/21/24 17:09:23.589
  E0521 17:09:23.746947      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:24.747746      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:25.747852      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:26.748640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:27.749493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:28.749927      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:29.750336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:30.750466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 05/21/24 17:09:31.595
  I0521 17:09:31.599349 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8413" for this suite. @ 05/21/24 17:09:31.601
• [8.041 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 05/21/24 17:09:31.606
  I0521 17:09:31.606211 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename disruption @ 05/21/24 17:09:31.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:09:31.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:09:31.621
  STEP: creating the pdb @ 05/21/24 17:09:31.623
  STEP: Waiting for the pdb to be processed @ 05/21/24 17:09:31.627
  E0521 17:09:31.750885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:32.751488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 05/21/24 17:09:33.632
  STEP: Waiting for the pdb to be processed @ 05/21/24 17:09:33.639
  E0521 17:09:33.752400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:34.752519      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 05/21/24 17:09:35.643
  STEP: Waiting for the pdb to be processed @ 05/21/24 17:09:35.652
  E0521 17:09:35.752449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:36.753359      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 05/21/24 17:09:37.657
  I0521 17:09:37.659566 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9934" for this suite. @ 05/21/24 17:09:37.661
• [6.058 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 05/21/24 17:09:37.663
  I0521 17:09:37.664000 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename limitrange @ 05/21/24 17:09:37.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:09:37.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:09:37.672
  STEP: Creating LimitRange "e2e-limitrange-hqx95" in namespace "limitrange-9464" @ 05/21/24 17:09:37.674
  STEP: Creating another limitRange in another namespace @ 05/21/24 17:09:37.678
  I0521 17:09:37.685985 22 limit_range.go:299] Namespace "e2e-limitrange-hqx95-5302" created
  I0521 17:09:37.686028 22 limit_range.go:300] Creating LimitRange "e2e-limitrange-hqx95" in namespace "e2e-limitrange-hqx95-5302"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-hqx95" @ 05/21/24 17:09:37.689
  I0521 17:09:37.691045 22 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-hqx95" in "limitrange-9464" namespace @ 05/21/24 17:09:37.691
  I0521 17:09:37.695971 22 limit_range.go:335] LimitRange "e2e-limitrange-hqx95" has been patched
  STEP: Delete LimitRange "e2e-limitrange-hqx95" by Collection with labelSelector: "e2e-limitrange-hqx95=patched" @ 05/21/24 17:09:37.696
  STEP: Confirm that the limitRange "e2e-limitrange-hqx95" has been deleted @ 05/21/24 17:09:37.699
  I0521 17:09:37.699687 22 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I0521 17:09:37.700704 22 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-hqx95=patched"
  I0521 17:09:37.700736 22 limit_range.go:344] LimitRange "e2e-limitrange-hqx95" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-hqx95" @ 05/21/24 17:09:37.7
  I0521 17:09:37.701734 22 limit_range.go:350] Found 1 limitRange
  I0521 17:09:37.701819 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-9464" for this suite. @ 05/21/24 17:09:37.703
  STEP: Destroying namespace "e2e-limitrange-hqx95-5302" for this suite. @ 05/21/24 17:09:37.706
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 05/21/24 17:09:37.709
  I0521 17:09:37.709091 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 17:09:37.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:09:37.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:09:37.719
  STEP: Setting up server cert @ 05/21/24 17:09:37.735
  E0521 17:09:37.754124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 17:09:37.84
  STEP: Deploying the webhook pod @ 05/21/24 17:09:37.844
  STEP: Wait for the deployment to be ready @ 05/21/24 17:09:37.85
  I0521 17:09:37.854357 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 17:09:38.754562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:39.754841      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 17:09:39.866
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 17:09:39.878
  E0521 17:09:40.755404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:09:40.878855 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/21/24 17:09:40.946
  STEP: Creating a configMap that should be mutated @ 05/21/24 17:09:40.957
  STEP: Deleting the collection of validation webhooks @ 05/21/24 17:09:40.981
  STEP: Creating a configMap that should not be mutated @ 05/21/24 17:09:41.012
  I0521 17:09:41.046835 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8607" for this suite. @ 05/21/24 17:09:41.049
  STEP: Destroying namespace "webhook-markers-229" for this suite. @ 05/21/24 17:09:41.053
• [3.349 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 05/21/24 17:09:41.058
  I0521 17:09:41.058509 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename subpath @ 05/21/24 17:09:41.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:09:41.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:09:41.072
  STEP: Setting up data @ 05/21/24 17:09:41.074
  STEP: Creating pod pod-subpath-test-configmap-mhsn @ 05/21/24 17:09:41.081
  STEP: Creating a pod to test atomic-volume-subpath @ 05/21/24 17:09:41.081
  E0521 17:09:41.755831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:42.756384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:43.757451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:44.757903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:45.758674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:46.759630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:47.760489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:48.760633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:49.761387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:50.761735      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:51.761910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:52.762323      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:53.763384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:54.763708      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:55.764479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:56.765620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:57.766360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:58.766789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:09:59.767466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:00.768614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:01.768820      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:02.769275      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:10:03.145
  I0521 17:10:03.148040 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-configmap-mhsn container test-container-subpath-configmap-mhsn: <nil>
  STEP: delete the pod @ 05/21/24 17:10:03.156
  STEP: Deleting pod pod-subpath-test-configmap-mhsn @ 05/21/24 17:10:03.171
  I0521 17:10:03.171087 22 delete.go:62] Deleting pod "pod-subpath-test-configmap-mhsn" in namespace "subpath-9921"
  I0521 17:10:03.175786 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9921" for this suite. @ 05/21/24 17:10:03.179
• [22.127 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 05/21/24 17:10:03.186
  I0521 17:10:03.186158 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replication-controller @ 05/21/24 17:10:03.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:10:03.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:10:03.2
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 05/21/24 17:10:03.203
  E0521 17:10:03.769217      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:04.769465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 05/21/24 17:10:05.221
  STEP: Then the orphan pod is adopted @ 05/21/24 17:10:05.227
  E0521 17:10:05.770031      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:10:06.236061 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-796" for this suite. @ 05/21/24 17:10:06.239
• [3.059 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 05/21/24 17:10:06.245
  I0521 17:10:06.245507 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename subpath @ 05/21/24 17:10:06.246
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:10:06.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:10:06.261
  STEP: Setting up data @ 05/21/24 17:10:06.263
  STEP: Creating pod pod-subpath-test-projected-jc4d @ 05/21/24 17:10:06.271
  STEP: Creating a pod to test atomic-volume-subpath @ 05/21/24 17:10:06.271
  E0521 17:10:06.770232      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:07.771006      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:08.771137      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:09.771744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:10.772609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:11.773061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:12.773645      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:13.774106      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:14.775051      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:15.775280      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:16.775468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:17.775965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:18.776821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:19.777425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:20.777653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:21.778248      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:22.778407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:23.779587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:24.780353      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:25.780470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:26.780568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:27.780591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:10:28.339
  I0521 17:10:28.341676 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-projected-jc4d container test-container-subpath-projected-jc4d: <nil>
  STEP: delete the pod @ 05/21/24 17:10:28.35
  STEP: Deleting pod pod-subpath-test-projected-jc4d @ 05/21/24 17:10:28.361
  I0521 17:10:28.361358 22 delete.go:62] Deleting pod "pod-subpath-test-projected-jc4d" in namespace "subpath-5474"
  I0521 17:10:28.363541 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5474" for this suite. @ 05/21/24 17:10:28.366
• [22.126 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 05/21/24 17:10:28.371
  I0521 17:10:28.371736 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 17:10:28.372
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:10:28.383
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:10:28.386
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 05/21/24 17:10:28.389
  E0521 17:10:28.781507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:29.782525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:10:30.402
  I0521 17:10:30.405574 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-4ee2c0cf-d133-4bd8-8f26-aaf9a9b33773 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:10:30.412
  I0521 17:10:30.423251 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9225" for this suite. @ 05/21/24 17:10:30.426
• [2.059 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 05/21/24 17:10:30.43
  I0521 17:10:30.430951 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename gc @ 05/21/24 17:10:30.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:10:30.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:10:30.447
  STEP: create the rc @ 05/21/24 17:10:30.452
  W0521 17:10:30.456109      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0521 17:10:30.783383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:31.783560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:32.783653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:33.783903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:34.785245      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:35.785318      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/21/24 17:10:36.461
  STEP: wait for the rc to be deleted @ 05/21/24 17:10:36.47
  E0521 17:10:36.786139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:37.786397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:38.787463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:39.787615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:40.788619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 05/21/24 17:10:41.475
  E0521 17:10:41.789484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:42.790064      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:43.790704      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:44.790833      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:45.791443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:46.791757      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:47.792762      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:48.792323      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:49.792744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:50.793493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:51.794540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:52.794738      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:53.795137      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:54.795516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:55.796221      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:56.796317      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:57.796495      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:58.796595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:10:59.797626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:00.797915      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:01.798391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:02.798919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:03.799309      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:04.799490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:05.800215      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:06.800512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:07.801082      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:08.801320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:09.801577      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:10.802518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/21/24 17:11:11.484
  I0521 17:11:11.568654 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0521 17:11:11.568699 22 delete.go:95] Deleting pod "simpletest.rc-28c2q" in namespace "gc-6359"
  I0521 17:11:11.578574 22 delete.go:95] Deleting pod "simpletest.rc-2fff9" in namespace "gc-6359"
  I0521 17:11:11.588428 22 delete.go:95] Deleting pod "simpletest.rc-2mlrg" in namespace "gc-6359"
  I0521 17:11:11.598313 22 delete.go:95] Deleting pod "simpletest.rc-2rqxv" in namespace "gc-6359"
  I0521 17:11:11.607702 22 delete.go:95] Deleting pod "simpletest.rc-46f8g" in namespace "gc-6359"
  I0521 17:11:11.622956 22 delete.go:95] Deleting pod "simpletest.rc-4ddnz" in namespace "gc-6359"
  I0521 17:11:11.636346 22 delete.go:95] Deleting pod "simpletest.rc-56l9b" in namespace "gc-6359"
  I0521 17:11:11.651640 22 delete.go:95] Deleting pod "simpletest.rc-5nzsv" in namespace "gc-6359"
  I0521 17:11:11.664978 22 delete.go:95] Deleting pod "simpletest.rc-5qj5h" in namespace "gc-6359"
  I0521 17:11:11.677266 22 delete.go:95] Deleting pod "simpletest.rc-5xlnm" in namespace "gc-6359"
  I0521 17:11:11.687133 22 delete.go:95] Deleting pod "simpletest.rc-698f6" in namespace "gc-6359"
  I0521 17:11:11.697686 22 delete.go:95] Deleting pod "simpletest.rc-6c8ld" in namespace "gc-6359"
  I0521 17:11:11.708613 22 delete.go:95] Deleting pod "simpletest.rc-6cq62" in namespace "gc-6359"
  I0521 17:11:11.720559 22 delete.go:95] Deleting pod "simpletest.rc-6jcjs" in namespace "gc-6359"
  I0521 17:11:11.736388 22 delete.go:95] Deleting pod "simpletest.rc-6tcjt" in namespace "gc-6359"
  I0521 17:11:11.750671 22 delete.go:95] Deleting pod "simpletest.rc-6x9ks" in namespace "gc-6359"
  I0521 17:11:11.763576 22 delete.go:95] Deleting pod "simpletest.rc-6ztzt" in namespace "gc-6359"
  I0521 17:11:11.774826 22 delete.go:95] Deleting pod "simpletest.rc-7dk56" in namespace "gc-6359"
  I0521 17:11:11.788000 22 delete.go:95] Deleting pod "simpletest.rc-7fgdp" in namespace "gc-6359"
  I0521 17:11:11.797000 22 delete.go:95] Deleting pod "simpletest.rc-7pk44" in namespace "gc-6359"
  E0521 17:11:11.803283      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:11:11.811547 22 delete.go:95] Deleting pod "simpletest.rc-7qrr5" in namespace "gc-6359"
  I0521 17:11:11.824036 22 delete.go:95] Deleting pod "simpletest.rc-7srwp" in namespace "gc-6359"
  I0521 17:11:11.844215 22 delete.go:95] Deleting pod "simpletest.rc-7tmqm" in namespace "gc-6359"
  I0521 17:11:11.857208 22 delete.go:95] Deleting pod "simpletest.rc-884mv" in namespace "gc-6359"
  I0521 17:11:11.878159 22 delete.go:95] Deleting pod "simpletest.rc-8h69n" in namespace "gc-6359"
  I0521 17:11:11.896311 22 delete.go:95] Deleting pod "simpletest.rc-8ldnn" in namespace "gc-6359"
  I0521 17:11:11.926851 22 delete.go:95] Deleting pod "simpletest.rc-8zb5d" in namespace "gc-6359"
  I0521 17:11:11.956442 22 delete.go:95] Deleting pod "simpletest.rc-97gfs" in namespace "gc-6359"
  I0521 17:11:11.978774 22 delete.go:95] Deleting pod "simpletest.rc-9d72g" in namespace "gc-6359"
  I0521 17:11:11.994847 22 delete.go:95] Deleting pod "simpletest.rc-9jt5s" in namespace "gc-6359"
  I0521 17:11:12.014595 22 delete.go:95] Deleting pod "simpletest.rc-9ts45" in namespace "gc-6359"
  I0521 17:11:12.037880 22 delete.go:95] Deleting pod "simpletest.rc-bxvbp" in namespace "gc-6359"
  I0521 17:11:12.063644 22 delete.go:95] Deleting pod "simpletest.rc-bzhjw" in namespace "gc-6359"
  I0521 17:11:12.082525 22 delete.go:95] Deleting pod "simpletest.rc-cmpqs" in namespace "gc-6359"
  I0521 17:11:12.093647 22 delete.go:95] Deleting pod "simpletest.rc-cnkpz" in namespace "gc-6359"
  I0521 17:11:12.110434 22 delete.go:95] Deleting pod "simpletest.rc-d92sl" in namespace "gc-6359"
  I0521 17:11:12.133425 22 delete.go:95] Deleting pod "simpletest.rc-dfsk5" in namespace "gc-6359"
  I0521 17:11:12.162608 22 delete.go:95] Deleting pod "simpletest.rc-dxz4n" in namespace "gc-6359"
  I0521 17:11:12.179361 22 delete.go:95] Deleting pod "simpletest.rc-f5sq7" in namespace "gc-6359"
  I0521 17:11:12.196545 22 delete.go:95] Deleting pod "simpletest.rc-fk6mx" in namespace "gc-6359"
  I0521 17:11:12.213399 22 delete.go:95] Deleting pod "simpletest.rc-fqctn" in namespace "gc-6359"
  I0521 17:11:12.232097 22 delete.go:95] Deleting pod "simpletest.rc-fszcf" in namespace "gc-6359"
  I0521 17:11:12.250905 22 delete.go:95] Deleting pod "simpletest.rc-g264l" in namespace "gc-6359"
  I0521 17:11:12.265477 22 delete.go:95] Deleting pod "simpletest.rc-gf6sv" in namespace "gc-6359"
  I0521 17:11:12.290016 22 delete.go:95] Deleting pod "simpletest.rc-hchgf" in namespace "gc-6359"
  I0521 17:11:12.307731 22 delete.go:95] Deleting pod "simpletest.rc-hqgfv" in namespace "gc-6359"
  I0521 17:11:12.324478 22 delete.go:95] Deleting pod "simpletest.rc-hr5zj" in namespace "gc-6359"
  I0521 17:11:12.341878 22 delete.go:95] Deleting pod "simpletest.rc-hsfn5" in namespace "gc-6359"
  I0521 17:11:12.355672 22 delete.go:95] Deleting pod "simpletest.rc-hvl7v" in namespace "gc-6359"
  I0521 17:11:12.368045 22 delete.go:95] Deleting pod "simpletest.rc-hwkdk" in namespace "gc-6359"
  I0521 17:11:12.390049 22 delete.go:95] Deleting pod "simpletest.rc-jcm9q" in namespace "gc-6359"
  I0521 17:11:12.401931 22 delete.go:95] Deleting pod "simpletest.rc-jgw8h" in namespace "gc-6359"
  I0521 17:11:12.423522 22 delete.go:95] Deleting pod "simpletest.rc-jk9dz" in namespace "gc-6359"
  I0521 17:11:12.440782 22 delete.go:95] Deleting pod "simpletest.rc-jnbhp" in namespace "gc-6359"
  I0521 17:11:12.452454 22 delete.go:95] Deleting pod "simpletest.rc-jsdrq" in namespace "gc-6359"
  I0521 17:11:12.469689 22 delete.go:95] Deleting pod "simpletest.rc-k8695" in namespace "gc-6359"
  I0521 17:11:12.486901 22 delete.go:95] Deleting pod "simpletest.rc-kvjh7" in namespace "gc-6359"
  I0521 17:11:12.503949 22 delete.go:95] Deleting pod "simpletest.rc-kzvbl" in namespace "gc-6359"
  I0521 17:11:12.520106 22 delete.go:95] Deleting pod "simpletest.rc-l6rcb" in namespace "gc-6359"
  I0521 17:11:12.537239 22 delete.go:95] Deleting pod "simpletest.rc-m7rnf" in namespace "gc-6359"
  I0521 17:11:12.564155 22 delete.go:95] Deleting pod "simpletest.rc-mbrp4" in namespace "gc-6359"
  I0521 17:11:12.582474 22 delete.go:95] Deleting pod "simpletest.rc-mc564" in namespace "gc-6359"
  I0521 17:11:12.598293 22 delete.go:95] Deleting pod "simpletest.rc-n2hgq" in namespace "gc-6359"
  I0521 17:11:12.617315 22 delete.go:95] Deleting pod "simpletest.rc-n88pz" in namespace "gc-6359"
  I0521 17:11:12.630388 22 delete.go:95] Deleting pod "simpletest.rc-ntlb4" in namespace "gc-6359"
  I0521 17:11:12.651091 22 delete.go:95] Deleting pod "simpletest.rc-nx9l2" in namespace "gc-6359"
  I0521 17:11:12.668261 22 delete.go:95] Deleting pod "simpletest.rc-p2p8v" in namespace "gc-6359"
  I0521 17:11:12.684906 22 delete.go:95] Deleting pod "simpletest.rc-p57f4" in namespace "gc-6359"
  I0521 17:11:12.702553 22 delete.go:95] Deleting pod "simpletest.rc-p9w2q" in namespace "gc-6359"
  I0521 17:11:12.724029 22 delete.go:95] Deleting pod "simpletest.rc-plmnd" in namespace "gc-6359"
  I0521 17:11:12.738405 22 delete.go:95] Deleting pod "simpletest.rc-pmb58" in namespace "gc-6359"
  I0521 17:11:12.753671 22 delete.go:95] Deleting pod "simpletest.rc-psqkw" in namespace "gc-6359"
  I0521 17:11:12.791042 22 delete.go:95] Deleting pod "simpletest.rc-q5w8n" in namespace "gc-6359"
  E0521 17:11:12.804294      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:11:12.839112 22 delete.go:95] Deleting pod "simpletest.rc-qb4k2" in namespace "gc-6359"
  I0521 17:11:12.904900 22 delete.go:95] Deleting pod "simpletest.rc-qgdmt" in namespace "gc-6359"
  I0521 17:11:12.941673 22 delete.go:95] Deleting pod "simpletest.rc-qnnqv" in namespace "gc-6359"
  I0521 17:11:12.994346 22 delete.go:95] Deleting pod "simpletest.rc-qzkdd" in namespace "gc-6359"
  I0521 17:11:13.035151 22 delete.go:95] Deleting pod "simpletest.rc-rgshg" in namespace "gc-6359"
  I0521 17:11:13.086749 22 delete.go:95] Deleting pod "simpletest.rc-rtsvp" in namespace "gc-6359"
  I0521 17:11:13.138617 22 delete.go:95] Deleting pod "simpletest.rc-rvf5d" in namespace "gc-6359"
  I0521 17:11:13.187717 22 delete.go:95] Deleting pod "simpletest.rc-s5jrv" in namespace "gc-6359"
  I0521 17:11:13.237270 22 delete.go:95] Deleting pod "simpletest.rc-ss5cr" in namespace "gc-6359"
  I0521 17:11:13.284321 22 delete.go:95] Deleting pod "simpletest.rc-ssbvw" in namespace "gc-6359"
  I0521 17:11:13.335536 22 delete.go:95] Deleting pod "simpletest.rc-t4xjz" in namespace "gc-6359"
  I0521 17:11:13.391555 22 delete.go:95] Deleting pod "simpletest.rc-tf95g" in namespace "gc-6359"
  I0521 17:11:13.437526 22 delete.go:95] Deleting pod "simpletest.rc-thhrv" in namespace "gc-6359"
  I0521 17:11:13.485792 22 delete.go:95] Deleting pod "simpletest.rc-tl8k5" in namespace "gc-6359"
  I0521 17:11:13.537480 22 delete.go:95] Deleting pod "simpletest.rc-tlj96" in namespace "gc-6359"
  I0521 17:11:13.585515 22 delete.go:95] Deleting pod "simpletest.rc-tpdtm" in namespace "gc-6359"
  I0521 17:11:13.636275 22 delete.go:95] Deleting pod "simpletest.rc-tvww4" in namespace "gc-6359"
  I0521 17:11:13.687470 22 delete.go:95] Deleting pod "simpletest.rc-v88nn" in namespace "gc-6359"
  I0521 17:11:13.734111 22 delete.go:95] Deleting pod "simpletest.rc-v99vm" in namespace "gc-6359"
  I0521 17:11:13.786385 22 delete.go:95] Deleting pod "simpletest.rc-vs8kg" in namespace "gc-6359"
  E0521 17:11:13.805260      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:11:13.834614 22 delete.go:95] Deleting pod "simpletest.rc-wl7lw" in namespace "gc-6359"
  I0521 17:11:13.886405 22 delete.go:95] Deleting pod "simpletest.rc-wlz68" in namespace "gc-6359"
  I0521 17:11:13.939899 22 delete.go:95] Deleting pod "simpletest.rc-x8thl" in namespace "gc-6359"
  I0521 17:11:13.986439 22 delete.go:95] Deleting pod "simpletest.rc-x9vl9" in namespace "gc-6359"
  I0521 17:11:14.038114 22 delete.go:95] Deleting pod "simpletest.rc-xzzfd" in namespace "gc-6359"
  I0521 17:11:14.087147 22 delete.go:95] Deleting pod "simpletest.rc-z46c4" in namespace "gc-6359"
  I0521 17:11:14.139069 22 delete.go:95] Deleting pod "simpletest.rc-zxc9q" in namespace "gc-6359"
  I0521 17:11:14.186767 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6359" for this suite. @ 05/21/24 17:11:14.23
• [43.854 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 05/21/24 17:11:14.285
  I0521 17:11:14.285160 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 17:11:14.286
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:11:14.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:11:14.297
  STEP: Creating secret with name secret-test-map-a0466070-274b-4069-9bca-e1013ba27ae2 @ 05/21/24 17:11:14.3
  STEP: Creating a pod to test consume secrets @ 05/21/24 17:11:14.306
  E0521 17:11:14.805710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:15.806426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:11:16.318
  I0521 17:11:16.321282 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-secrets-8906ac85-b5d4-4013-ae75-e0318978b65d container secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 17:11:16.33
  I0521 17:11:16.342394 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-63" for this suite. @ 05/21/24 17:11:16.344
• [2.064 seconds]
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 05/21/24 17:11:16.349
  I0521 17:11:16.349317 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename cronjob @ 05/21/24 17:11:16.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:11:16.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:11:16.36
  STEP: Creating a cronjob @ 05/21/24 17:11:16.362
  STEP: Ensuring more than one job is running at a time @ 05/21/24 17:11:16.365
  E0521 17:11:16.806461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:17.807099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:18.807336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:19.807373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:20.808460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:21.809557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:22.810630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:23.811004      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:24.811733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:25.811698      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:26.811858      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:27.812336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:28.812328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:29.812367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:30.813524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:31.813771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:32.814453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:33.815399      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:34.816396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:35.817422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:36.817926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:37.818450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:38.818771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:39.819437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:40.820642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:41.821789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:42.822869      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:43.823646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:44.824491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:45.825004      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:46.825476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:47.825401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:48.826445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:49.826515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:50.827055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:51.827994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:52.828929      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:53.829539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:54.830605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:55.830841      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:56.830958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:57.831369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:58.831640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:11:59.832707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:00.833020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:01.833614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:02.834478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:03.835417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:04.835944      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:05.836323      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:06.837045      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:07.837656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:08.838608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:09.838787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:10.839056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:11.839739      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:12.840625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:13.841624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:14.842421      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:15.843115      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:16.843551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:17.843942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:18.844422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:19.844446      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:20.845277      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:21.846364      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:22.847021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:23.847328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:24.848389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:25.849510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:26.849472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:27.850488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:28.850582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:29.851603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:30.852436      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:31.853444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:32.853815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:33.854611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:34.855553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:35.856274      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:36.857161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:37.857477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:38.857748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:39.858682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:40.858706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:41.859810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:42.860547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:43.861400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:44.861831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:45.862327      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:46.863026      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:47.864223      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:48.864600      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:49.865417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:50.865590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:51.866482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:52.867348      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:53.867322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:54.867611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:55.868046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:56.868694      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:57.869466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:58.870657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:12:59.871073      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 05/21/24 17:13:00.371
  STEP: Removing cronjob @ 05/21/24 17:13:00.374
  I0521 17:13:00.380327 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1466" for this suite. @ 05/21/24 17:13:00.383
• [104.039 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 05/21/24 17:13:00.388
  I0521 17:13:00.388756 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename statefulset @ 05/21/24 17:13:00.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:00.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:00.402
  STEP: Creating service test in namespace statefulset-8770 @ 05/21/24 17:13:00.404
  STEP: Looking for a node to schedule stateful set and pod @ 05/21/24 17:13:00.41
  STEP: Creating pod with conflicting port in namespace statefulset-8770 @ 05/21/24 17:13:00.415
  STEP: Waiting until pod test-pod will start running in namespace statefulset-8770 @ 05/21/24 17:13:00.425
  E0521 17:13:00.871423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:01.872566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-8770 @ 05/21/24 17:13:02.431
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8770 @ 05/21/24 17:13:02.438
  I0521 17:13:02.461393 22 statefulset.go:866] Observed stateful pod in namespace: statefulset-8770, name: ss-0, uid: 8f336b97-f1b8-43ce-a9cc-6705489b9202, status phase: Pending. Waiting for statefulset controller to delete.
  I0521 17:13:02.471891 22 statefulset.go:866] Observed stateful pod in namespace: statefulset-8770, name: ss-0, uid: 8f336b97-f1b8-43ce-a9cc-6705489b9202, status phase: Failed. Waiting for statefulset controller to delete.
  I0521 17:13:02.480566 22 statefulset.go:866] Observed stateful pod in namespace: statefulset-8770, name: ss-0, uid: 8f336b97-f1b8-43ce-a9cc-6705489b9202, status phase: Failed. Waiting for statefulset controller to delete.
  I0521 17:13:02.484993 22 statefulset.go:860] Observed delete event for stateful pod ss-0 in namespace statefulset-8770
  STEP: Removing pod with conflicting port in namespace statefulset-8770 @ 05/21/24 17:13:02.485
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8770 and will be in running state @ 05/21/24 17:13:02.501
  E0521 17:13:02.872617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:03.873148      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:04.508612 22 statefulset.go:135] Deleting all statefulset in ns statefulset-8770
  I0521 17:13:04.510611 22 rest.go:150] Scaling statefulset ss to 0
  E0521 17:13:04.873513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:05.874416      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:06.875572      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:07.876562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:08.876905      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:09.877028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:10.877977      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:11.878112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:12.878705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:13.879294      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:14.522679 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0521 17:13:14.525425 22 rest.go:88] Deleting statefulset ss
  I0521 17:13:14.536245 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8770" for this suite. @ 05/21/24 17:13:14.539
• [14.155 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 05/21/24 17:13:14.544
  I0521 17:13:14.544176 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename certificates @ 05/21/24 17:13:14.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:14.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:14.559
  STEP: getting /apis @ 05/21/24 17:13:14.865
  STEP: getting /apis/certificates.k8s.io @ 05/21/24 17:13:14.868
  STEP: getting /apis/certificates.k8s.io/v1 @ 05/21/24 17:13:14.868
  STEP: creating @ 05/21/24 17:13:14.869
  STEP: getting @ 05/21/24 17:13:14.877
  STEP: listing @ 05/21/24 17:13:14.879
  E0521 17:13:14.879233      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: watching @ 05/21/24 17:13:14.88
  I0521 17:13:14.880374 22 certificates.go:316] starting watch
  STEP: patching @ 05/21/24 17:13:14.881
  STEP: updating @ 05/21/24 17:13:14.885
  I0521 17:13:14.888246 22 certificates.go:332] waiting for watch events with expected annotations
  I0521 17:13:14.888283 22 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 05/21/24 17:13:14.888
  STEP: patching /approval @ 05/21/24 17:13:14.889
  STEP: updating /approval @ 05/21/24 17:13:14.893
  STEP: getting /status @ 05/21/24 17:13:14.897
  STEP: patching /status @ 05/21/24 17:13:14.898
  STEP: updating /status @ 05/21/24 17:13:14.903
  STEP: deleting @ 05/21/24 17:13:14.908
  STEP: deleting a collection @ 05/21/24 17:13:14.914
  I0521 17:13:14.919883 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-5420" for this suite. @ 05/21/24 17:13:14.921
• [0.381 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 05/21/24 17:13:14.925
  I0521 17:13:14.925117 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename gc @ 05/21/24 17:13:14.925
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:14.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:14.934
  STEP: create the deployment @ 05/21/24 17:13:14.936
  W0521 17:13:14.940681      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 05/21/24 17:13:14.94
  STEP: delete the deployment @ 05/21/24 17:13:15.444
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 05/21/24 17:13:15.451
  E0521 17:13:15.879591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/21/24 17:13:15.965
  I0521 17:13:16.048235 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0521 17:13:16.048372 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1911" for this suite. @ 05/21/24 17:13:16.05
• [1.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 05/21/24 17:13:16.056
  I0521 17:13:16.056135 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 17:13:16.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:16.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:16.064
  STEP: Creating a pod to test downward api env vars @ 05/21/24 17:13:16.065
  E0521 17:13:16.880482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:17.881139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:18.881533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:19.882480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:13:20.084
  I0521 17:13:20.087813 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downward-api-6811da49-ac1a-4cdb-a103-bb3f49c265d0 container dapi-container: <nil>
  STEP: delete the pod @ 05/21/24 17:13:20.103
  I0521 17:13:20.116807 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-98" for this suite. @ 05/21/24 17:13:20.122
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 05/21/24 17:13:20.127
  I0521 17:13:20.128014 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename var-expansion @ 05/21/24 17:13:20.129
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:20.138
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:20.141
  STEP: Creating a pod to test env composition @ 05/21/24 17:13:20.144
  E0521 17:13:20.883047      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:21.883935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:22.884767      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:23.884898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:13:24.162
  I0521 17:13:24.166302 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod var-expansion-88d26dba-1a26-448d-bc15-ab42b4ce4e4b container dapi-container: <nil>
  STEP: delete the pod @ 05/21/24 17:13:24.176
  I0521 17:13:24.193986 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4597" for this suite. @ 05/21/24 17:13:24.196
• [4.073 seconds]
------------------------------
SSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 05/21/24 17:13:24.201
  I0521 17:13:24.201456 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename disruption @ 05/21/24 17:13:24.202
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:24.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:24.212
  STEP: Waiting for the pdb to be processed @ 05/21/24 17:13:24.218
  E0521 17:13:24.884896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:25.885225      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 05/21/24 17:13:26.247
  I0521 17:13:26.252990 22 disruption.go:578] running pods: 0 < 3
  E0521 17:13:26.885629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:27.886698      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:28.255585 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2952" for this suite. @ 05/21/24 17:13:28.258
• [4.064 seconds]
------------------------------
S
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 05/21/24 17:13:28.265
  I0521 17:13:28.265581 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename subjectreview @ 05/21/24 17:13:28.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:28.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:28.28
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-7166" @ 05/21/24 17:13:28.282
  I0521 17:13:28.285572 22 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-7166:e2e"
  I0521 17:13:28.285612 22 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-7166"}
  I0521 17:13:28.285626 22 subjectreviews.go:71] saUID: "d729b8f2-325d-47df-864c-69fbaf276856"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-7166:e2e" @ 05/21/24 17:13:28.285
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-7166:e2e" @ 05/21/24 17:13:28.285
  I0521 17:13:28.287328 22 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-7166:e2e" api 'list' configmaps in "subjectreview-7166" namespace @ 05/21/24 17:13:28.287
  I0521 17:13:28.288118 22 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-7166:e2e" @ 05/21/24 17:13:28.288
  I0521 17:13:28.290199 22 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0521 17:13:28.290218 22 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0521 17:13:28.290281 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-7166" for this suite. @ 05/21/24 17:13:28.293
• [0.031 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 05/21/24 17:13:28.297
  I0521 17:13:28.297014 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename svcaccounts @ 05/21/24 17:13:28.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:28.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:28.31
  STEP: Creating a pod to test service account token:  @ 05/21/24 17:13:28.313
  E0521 17:13:28.887246      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:29.887740      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:30.888590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:31.888702      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:13:32.331
  I0521 17:13:32.335334 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod test-pod-3b80be46-6193-432d-a920-859570a3d127 container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:13:32.348
  I0521 17:13:32.362564 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2302" for this suite. @ 05/21/24 17:13:32.364
• [4.071 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2240
  STEP: Creating a kubernetes client @ 05/21/24 17:13:32.368
  I0521 17:13:32.368332 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 17:13:32.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:32.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:32.381
  STEP: creating service in namespace services-7575 @ 05/21/24 17:13:32.383
  STEP: creating service affinity-nodeport-transition in namespace services-7575 @ 05/21/24 17:13:32.383
  STEP: creating replication controller affinity-nodeport-transition in namespace services-7575 @ 05/21/24 17:13:32.395
  I0521 17:13:32.402517      22 runners.go:198] Created replication controller with name: affinity-nodeport-transition, namespace: services-7575, replica count: 3
  E0521 17:13:32.889454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:33.889661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:34.890467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:35.453273      22 runners.go:198] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0521 17:13:35.463957 22 resource.go:361] Creating new exec pod
  E0521 17:13:35.890608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:36.891704      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:37.892719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:38.481387 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-7575 exec execpod-affinityjrjrf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I0521 17:13:38.561074 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  I0521 17:13:38.561117 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:13:38.561197 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-7575 exec execpod-affinityjrjrf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.97.64.3 80'
  I0521 17:13:38.643231 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.97.64.3 80\nConnection to 10.97.64.3 80 port [tcp/http] succeeded!\n"
  I0521 17:13:38.643283 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:13:38.643374 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-7575 exec execpod-affinityjrjrf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.2 31075'
  I0521 17:13:38.737079 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.2 31075\nConnection to 192.168.67.2 31075 port [tcp/*] succeeded!\n"
  I0521 17:13:38.737131 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:13:38.737258 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-7575 exec execpod-affinityjrjrf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.3 31075'
  I0521 17:13:38.837883 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.3 31075\nConnection to 192.168.67.3 31075 port [tcp/*] succeeded!\n"
  I0521 17:13:38.837934 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:13:38.845108 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-7575 exec execpod-affinityjrjrf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.67.2:31075/ ; done'
  E0521 17:13:38.893610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:38.994231 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n"
  I0521 17:13:38.994275 22 builder.go:147] stdout: "\naffinity-nodeport-transition-hdbxm\naffinity-nodeport-transition-8hw6t\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-8hw6t\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-hdbxm\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-hdbxm\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-hdbxm\naffinity-nodeport-transition-hdbxm\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-8hw6t"
  I0521 17:13:38.994292 22 service.go:242] Received response from host: affinity-nodeport-transition-hdbxm
  I0521 17:13:38.994302 22 service.go:242] Received response from host: affinity-nodeport-transition-8hw6t
  I0521 17:13:38.994309 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:38.994316 22 service.go:242] Received response from host: affinity-nodeport-transition-8hw6t
  I0521 17:13:38.994335 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:38.994343 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:38.994350 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:38.994357 22 service.go:242] Received response from host: affinity-nodeport-transition-hdbxm
  I0521 17:13:38.994366 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:38.994373 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:38.994381 22 service.go:242] Received response from host: affinity-nodeport-transition-hdbxm
  I0521 17:13:38.994388 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:38.994397 22 service.go:242] Received response from host: affinity-nodeport-transition-hdbxm
  I0521 17:13:38.994403 22 service.go:242] Received response from host: affinity-nodeport-transition-hdbxm
  I0521 17:13:38.994412 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:38.994418 22 service.go:242] Received response from host: affinity-nodeport-transition-8hw6t
  I0521 17:13:38.998673 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-7575 exec execpod-affinityjrjrf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.67.2:31075/ ; done'
  I0521 17:13:39.156688 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.67.2:31075/\n"
  I0521 17:13:39.156747 22 builder.go:147] stdout: "\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9\naffinity-nodeport-transition-xj5d9"
  I0521 17:13:39.156774 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156785 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156794 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156802 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156810 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156819 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156826 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156839 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156848 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156858 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156868 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156877 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156891 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156898 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156905 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156912 22 service.go:242] Received response from host: affinity-nodeport-transition-xj5d9
  I0521 17:13:39.156977 22 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-7575, will wait for the garbage collector to delete the pods @ 05/21/24 17:13:39.166
  I0521 17:13:39.223891 22 resources.go:139] Deleting ReplicationController affinity-nodeport-transition took: 4.424519ms
  I0521 17:13:39.325014 22 resources.go:163] Terminating ReplicationController affinity-nodeport-transition pods took: 101.12002ms
  E0521 17:13:39.894298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:40.894595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:41.839596 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7575" for this suite. @ 05/21/24 17:13:41.841
• [9.477 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 05/21/24 17:13:41.845
  I0521 17:13:41.845481 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 17:13:41.846
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:41.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:41.858
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/21/24 17:13:41.86
  E0521 17:13:41.894874      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:42.895594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:13:43.871
  I0521 17:13:43.874107 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-27d9862a-9629-41ec-ab0f-a054e5216aff container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:13:43.881
  E0521 17:13:43.896153      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:43.897482 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8058" for this suite. @ 05/21/24 17:13:43.9
• [2.061 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1497
  STEP: Creating a kubernetes client @ 05/21/24 17:13:43.907
  I0521 17:13:43.907138 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 17:13:43.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:43.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:43.921
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7969 @ 05/21/24 17:13:43.924
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/21/24 17:13:43.935
  STEP: creating service externalsvc in namespace services-7969 @ 05/21/24 17:13:43.935
  STEP: creating replication controller externalsvc in namespace services-7969 @ 05/21/24 17:13:43.948
  I0521 17:13:43.952454      22 runners.go:198] Created replication controller with name: externalsvc, namespace: services-7969, replica count: 2
  E0521 17:13:44.897158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:45.897774      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:46.898364      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:47.003656      22 runners.go:198] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 05/21/24 17:13:47.005
  I0521 17:13:47.016071 22 resource.go:361] Creating new exec pod
  E0521 17:13:47.898699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:48.899234      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:49.027209 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-7969 exec execpod78v8c -- /bin/sh -x -c nslookup clusterip-service.services-7969.svc.cluster.local'
  I0521 17:13:49.145105 22 builder.go:146] stderr: "+ nslookup clusterip-service.services-7969.svc.cluster.local\n"
  I0521 17:13:49.145161 22 builder.go:147] stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-7969.svc.cluster.local\tcanonical name = externalsvc.services-7969.svc.cluster.local.\nName:\texternalsvc.services-7969.svc.cluster.local\nAddress: 10.98.163.60\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-7969, will wait for the garbage collector to delete the pods @ 05/21/24 17:13:49.145
  I0521 17:13:49.207808 22 resources.go:139] Deleting ReplicationController externalsvc took: 9.11802ms
  I0521 17:13:49.308349 22 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.536429ms
  E0521 17:13:49.899478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:50.899517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:51.900243      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:51.926027 22 service.go:1506] Cleaning up the ClusterIP to ExternalName test service
  I0521 17:13:51.934737 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7969" for this suite. @ 05/21/24 17:13:51.938
• [8.036 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 05/21/24 17:13:51.943
  I0521 17:13:51.943289 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename aggregator @ 05/21/24 17:13:51.943
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:13:51.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:13:51.956
  I0521 17:13:51.958880 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Registering the sample API server. @ 05/21/24 17:13:51.959
  I0521 17:13:52.129060 22 helpers.go:161] Found ClusterRoles; assuming RBAC is enabled.
  I0521 17:13:52.141695 22 deployment.go:222] deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0521 17:13:52.900370      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:53.901391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:54.181971 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:13:54.901620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:55.902486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:56.187917 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:13:56.902502      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:57.902646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:13:58.186661 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:13:58.902792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:13:59.903640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:00.186706 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:00.904406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:01.904533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:02.189343 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:02.905629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:03.906253      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:04.188597 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:04.906906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:05.906999      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:06.187608 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:06.907724      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:07.908691      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:08.187608 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:08.908696      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:09.909510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:10.187121 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:10.910525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:11.910570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:12.187605 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:12.911383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:13.911662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:14.188069 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:14.911706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:15.912631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:16.187013 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:16.913565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:17.914746      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:18.187305 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 13, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-9fd5bd597\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:14:18.915523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:19.916649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:20.304047 22 aggregator.go:749] Waited 114.214123ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 05/21/24 17:14:20.342
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 05/21/24 17:14:20.343
  STEP: List APIServices @ 05/21/24 17:14:20.349
  I0521 17:14:20.353676 22 aggregator.go:550] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 05/21/24 17:14:20.353
  I0521 17:14:20.365213 22 aggregator.go:575] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 05/21/24 17:14:20.365
  I0521 17:14:20.372464 22 aggregator.go:601] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.May, 21, 17, 14, 20, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 05/21/24 17:14:20.372
  I0521 17:14:20.375486 22 aggregator.go:619] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-05-21 17:14:20 +0000 UTC Passed all checks passed}
  I0521 17:14:20.375524 22 aggregator.go:615] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0521 17:14:20.375540 22 aggregator.go:625] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 05/21/24 17:14:20.375
  I0521 17:14:20.382460 22 aggregator.go:641] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-117783879" @ 05/21/24 17:14:20.382
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 05/21/24 17:14:20.393
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 05/21/24 17:14:20.399
  STEP: Patch APIService Status @ 05/21/24 17:14:20.401
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 05/21/24 17:14:20.409
  I0521 17:14:20.413935 22 aggregator.go:719] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-05-21 17:14:20 +0000 UTC Passed all checks passed}
  I0521 17:14:20.413985 22 aggregator.go:719] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0521 17:14:20.414011 22 aggregator.go:715] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0521 17:14:20.414040 22 aggregator.go:725] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 05/21/24 17:14:20.414
  STEP: Confirm that the generated APIService has been deleted @ 05/21/24 17:14:20.42
  I0521 17:14:20.420347 22 aggregator.go:786] Requesting list of APIServices to confirm quantity
  I0521 17:14:20.423021 22 aggregator.go:796] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0521 17:14:20.423058 22 aggregator.go:738] APIService v1alpha1.wardle.example.com has been deleted.
  I0521 17:14:20.481626 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-1735" for this suite. @ 05/21/24 17:14:20.483
• [28.544 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 05/21/24 17:14:20.487
  I0521 17:14:20.487874 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 17:14:20.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:14:20.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:14:20.497
  STEP: Setting up server cert @ 05/21/24 17:14:20.507
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 17:14:20.741
  STEP: Deploying the webhook pod @ 05/21/24 17:14:20.744
  STEP: Wait for the deployment to be ready @ 05/21/24 17:14:20.75
  I0521 17:14:20.753982 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 17:14:20.917172      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:21.918170      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 17:14:22.764
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 17:14:22.777
  E0521 17:14:22.918889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:23.778046 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 05/21/24 17:14:23.784
  STEP: Creating a custom resource definition that should be denied by the webhook @ 05/21/24 17:14:23.804
  I0521 17:14:23.804469 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:14:23.844602 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9678" for this suite. @ 05/21/24 17:14:23.846
  STEP: Destroying namespace "webhook-markers-3478" for this suite. @ 05/21/24 17:14:23.853
• [3.369 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 05/21/24 17:14:23.856
  I0521 17:14:23.856958 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubelet-test @ 05/21/24 17:14:23.857
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:14:23.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:14:23.865
  E0521 17:14:23.919398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:24.919607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:25.884326 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7391" for this suite. @ 05/21/24 17:14:25.886
• [2.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 05/21/24 17:14:25.892
  I0521 17:14:25.892349 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubelet-test @ 05/21/24 17:14:25.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:14:25.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:14:25.904
  E0521 17:14:25.920266      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:26.921206      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:27.922082      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:27.930816 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-304" for this suite. @ 05/21/24 17:14:27.933
• [2.046 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 05/21/24 17:14:27.942
  I0521 17:14:27.942606 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename gc @ 05/21/24 17:14:27.943
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:14:27.951
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:14:27.952
  STEP: create the rc1 @ 05/21/24 17:14:27.955
  STEP: create the rc2 @ 05/21/24 17:14:27.959
  E0521 17:14:28.923738      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:29.924434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:30.926197      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:31.926508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:32.926642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:33.926686      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 05/21/24 17:14:33.966
  STEP: delete the rc simpletest-rc-to-be-deleted @ 05/21/24 17:14:34.234
  STEP: wait for the rc to be deleted @ 05/21/24 17:14:34.238
  E0521 17:14:34.927754      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:35.928182      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:36.928384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:37.929468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:38.930351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:39.250266 22 garbage_collector.go:762] 66 pods remaining
  I0521 17:14:39.250315 22 garbage_collector.go:769] 66 pods has nil DeletionTimestamp
  I0521 17:14:39.250331 22 garbage_collector.go:770] 
  E0521 17:14:39.931465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:40.932249      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:41.932328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:42.932415      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:43.933552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/21/24 17:14:44.249
  I0521 17:14:44.303961 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0521 17:14:44.303999 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2958m" in namespace "gc-6666"
  I0521 17:14:44.316241 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2hf4x" in namespace "gc-6666"
  I0521 17:14:44.324924 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2hgs5" in namespace "gc-6666"
  I0521 17:14:44.335139 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2m9zk" in namespace "gc-6666"
  I0521 17:14:44.345068 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2pb5l" in namespace "gc-6666"
  I0521 17:14:44.360114 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2tvtr" in namespace "gc-6666"
  I0521 17:14:44.369338 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2vfmr" in namespace "gc-6666"
  I0521 17:14:44.379505 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4cnjn" in namespace "gc-6666"
  I0521 17:14:44.390371 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4g6hh" in namespace "gc-6666"
  I0521 17:14:44.398878 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4pfcx" in namespace "gc-6666"
  I0521 17:14:44.407853 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4pmtz" in namespace "gc-6666"
  I0521 17:14:44.421802 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-557vs" in namespace "gc-6666"
  I0521 17:14:44.432303 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5c9w7" in namespace "gc-6666"
  I0521 17:14:44.449292 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5j569" in namespace "gc-6666"
  I0521 17:14:44.462246 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5jqwj" in namespace "gc-6666"
  I0521 17:14:44.473300 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5k89x" in namespace "gc-6666"
  I0521 17:14:44.496691 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5nn2h" in namespace "gc-6666"
  I0521 17:14:44.511900 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5rtng" in namespace "gc-6666"
  I0521 17:14:44.522458 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5x75l" in namespace "gc-6666"
  I0521 17:14:44.535624 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-66p2x" in namespace "gc-6666"
  I0521 17:14:44.556417 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-672x4" in namespace "gc-6666"
  I0521 17:14:44.579468 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6r5v6" in namespace "gc-6666"
  I0521 17:14:44.598948 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7kgxq" in namespace "gc-6666"
  I0521 17:14:44.628312 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7rcvv" in namespace "gc-6666"
  I0521 17:14:44.647677 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7rz8p" in namespace "gc-6666"
  I0521 17:14:44.661426 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-85hrm" in namespace "gc-6666"
  I0521 17:14:44.678750 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-886pd" in namespace "gc-6666"
  I0521 17:14:44.697496 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8fjc4" in namespace "gc-6666"
  I0521 17:14:44.723175 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8jhjj" in namespace "gc-6666"
  I0521 17:14:44.744588 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8m9vb" in namespace "gc-6666"
  I0521 17:14:44.761389 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-98pzn" in namespace "gc-6666"
  I0521 17:14:44.774799 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-99zrw" in namespace "gc-6666"
  I0521 17:14:44.796991 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9j8gx" in namespace "gc-6666"
  I0521 17:14:44.811123 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9k7c2" in namespace "gc-6666"
  I0521 17:14:44.832978 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9wrq8" in namespace "gc-6666"
  I0521 17:14:44.850526 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bdbkk" in namespace "gc-6666"
  I0521 17:14:44.866854 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bk4ww" in namespace "gc-6666"
  I0521 17:14:44.892692 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-brzcj" in namespace "gc-6666"
  I0521 17:14:44.906946 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bsrnm" in namespace "gc-6666"
  I0521 17:14:44.923416 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cjctk" in namespace "gc-6666"
  E0521 17:14:44.934372      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:14:44.941642 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cx55g" in namespace "gc-6666"
  I0521 17:14:44.953995 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-d2pgp" in namespace "gc-6666"
  I0521 17:14:44.970874 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-d46vb" in namespace "gc-6666"
  I0521 17:14:44.992123 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-d59lf" in namespace "gc-6666"
  I0521 17:14:45.005789 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dqtbk" in namespace "gc-6666"
  I0521 17:14:45.022351 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dv9q8" in namespace "gc-6666"
  I0521 17:14:45.037336 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dwfq9" in namespace "gc-6666"
  I0521 17:14:45.048536 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-f888d" in namespace "gc-6666"
  I0521 17:14:45.058386 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fpdj5" in namespace "gc-6666"
  I0521 17:14:45.077939 22 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-ftfdl" in namespace "gc-6666"
  I0521 17:14:45.089275 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6666" for this suite. @ 05/21/24 17:14:45.096
• [17.162 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 05/21/24 17:14:45.104
  I0521 17:14:45.104802 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-watch @ 05/21/24 17:14:45.105
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:14:45.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:14:45.124
  I0521 17:14:45.127387 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:14:45.935477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:46.936587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 05/21/24 17:14:47.683
  I0521 17:14:47.688268 22 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-21T17:14:47Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-21T17:14:47Z]] name:name1 resourceVersion:14012 uid:f29da0b7-8dfb-4a81-9b86-238d474ada45] num:map[num1:9223372036854775807 num2:1000000]]}
  E0521 17:14:47.937527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:48.938605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:49.939468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:50.940454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:51.940596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:52.940865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:53.941522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:54.941847      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:55.942266      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:56.942467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 05/21/24 17:14:57.688
  I0521 17:14:57.699028 22 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-21T17:14:57Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-21T17:14:57Z]] name:name2 resourceVersion:14537 uid:79e3b184-5899-4020-b135-03c2430f7a32] num:map[num1:9223372036854775807 num2:1000000]]}
  E0521 17:14:57.943288      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:58.943720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:14:59.943816      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:00.944444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:01.945604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:02.946050      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:03.946742      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:04.948540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:05.948754      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:06.949493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 05/21/24 17:15:07.699
  I0521 17:15:07.709394 22 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-21T17:14:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-21T17:15:07Z]] name:name1 resourceVersion:14555 uid:f29da0b7-8dfb-4a81-9b86-238d474ada45] num:map[num1:9223372036854775807 num2:1000000]]}
  E0521 17:15:07.950627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:08.950872      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:09.951527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:10.952277      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:11.952403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:12.952580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:13.953688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:14.954778      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:15.955430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:16.955665      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 05/21/24 17:15:17.71
  I0521 17:15:17.720564 22 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-21T17:14:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-21T17:15:17Z]] name:name2 resourceVersion:14569 uid:79e3b184-5899-4020-b135-03c2430f7a32] num:map[num1:9223372036854775807 num2:1000000]]}
  E0521 17:15:17.956606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:18.957507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:19.957610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:20.958616      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:21.958787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:22.959697      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:23.960549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:24.960810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:25.961630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:26.962589      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 05/21/24 17:15:27.721
  I0521 17:15:27.731030 22 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-21T17:14:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-21T17:15:07Z]] name:name1 resourceVersion:14579 uid:f29da0b7-8dfb-4a81-9b86-238d474ada45] num:map[num1:9223372036854775807 num2:1000000]]}
  E0521 17:15:27.963683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:28.964722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:29.965435      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:30.965661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:31.966118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:32.966516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:33.967599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:34.968129      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:35.969015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:36.970045      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 05/21/24 17:15:37.732
  I0521 17:15:37.742181 22 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-05-21T17:14:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-05-21T17:15:17Z]] name:name2 resourceVersion:14589 uid:79e3b184-5899-4020-b135-03c2430f7a32] num:map[num1:9223372036854775807 num2:1000000]]}
  E0521 17:15:37.970671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:38.971639      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:39.972720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:40.973373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:41.973532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:42.974507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:43.976015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:44.976967      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:45.977482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:46.978911      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:47.980063      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:15:48.256036 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-1589" for this suite. @ 05/21/24 17:15:48.26
• [63.161 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 05/21/24 17:15:48.266
  I0521 17:15:48.266558 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 17:15:48.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:15:48.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:15:48.284
  STEP: creating the pod @ 05/21/24 17:15:48.287
  STEP: submitting the pod to kubernetes @ 05/21/24 17:15:48.287
  E0521 17:15:48.980499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:49.981440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/21/24 17:15:50.304
  STEP: updating the pod @ 05/21/24 17:15:50.307
  I0521 17:15:50.824328 22 pod_client.go:141] Successfully updated pod "pod-update-4271fca3-38a0-45c7-a746-1bfda0f3eeb1"
  STEP: verifying the updated pod is in kubernetes @ 05/21/24 17:15:50.827
  I0521 17:15:50.830153 22 pods.go:391] Pod update OK
  I0521 17:15:50.830274 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7256" for this suite. @ 05/21/24 17:15:50.832
• [2.574 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 05/21/24 17:15:50.841
  I0521 17:15:50.841136 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename hostport @ 05/21/24 17:15:50.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:15:50.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:15:50.855
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 05/21/24 17:15:50.86
  E0521 17:15:50.982172      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:51.982970      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.67.3 on the node which pod1 resides and expect scheduled @ 05/21/24 17:15:52.878
  E0521 17:15:52.983154      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:53.983385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:54.984381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:55.984306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:56.984578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:57.985551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:58.985935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:15:59.986546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:00.987367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:01.987553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:02.987903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:03.988352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.67.3 but use UDP protocol on the node which pod2 resides @ 05/21/24 17:16:04.916
  E0521 17:16:04.988541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:05.988793      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:06.989377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:07.989779      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 05/21/24 17:16:08.946
  I0521 17:16:08.946343 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.67.3 http://127.0.0.1:54323/hostname] Namespace:hostport-8700 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 17:16:08.946366 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:16:08.946948 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 17:16:08.947002 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8700/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.67.3+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0521 17:16:08.990121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.67.3, port: 54323 @ 05/21/24 17:16:09.007
  I0521 17:16:09.007383 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.67.3:54323/hostname] Namespace:hostport-8700 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 17:16:09.007424 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:16:09.008486 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 17:16:09.008610 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8700/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.67.3%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.67.3, port: 54323 UDP @ 05/21/24 17:16:09.06
  I0521 17:16:09.060353 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.67.3 54323] Namespace:hostport-8700 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 17:16:09.060364 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:16:09.060886 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 17:16:09.060943 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-8700/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.67.3+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0521 17:16:09.990473      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:10.991624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:11.992461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:12.992570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:13.993573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:16:14.122233 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-8700" for this suite. @ 05/21/24 17:16:14.126
• [23.291 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 05/21/24 17:16:14.131
  I0521 17:16:14.131946 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename deployment @ 05/21/24 17:16:14.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:16:14.144
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:16:14.147
  I0521 17:16:14.148643 22 deployment.go:792] Creating deployment "test-recreate-deployment"
  I0521 17:16:14.151888 22 deployment.go:798] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0521 17:16:14.157038 22 deployment.go:222] deployment "test-recreate-deployment" doesn't have the required revision set
  E0521 17:16:14.993890      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:15.994397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:16:16.165538 22 deployment.go:802] Waiting deployment "test-recreate-deployment" to complete
  I0521 17:16:16.167871 22 deployment.go:807] Triggering a new rollout for deployment "test-recreate-deployment"
  I0521 17:16:16.176768 22 deployment.go:313] Updating deployment test-recreate-deployment
  I0521 17:16:16.176832 22 deployment.go:814] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0521 17:16:16.241323 22 deployment.go:633] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5962",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b97378bb-02c0-40bc-812a-2a2c3e74bf5f",
      ResourceVersion: (string) (len=5) "14733",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851908574,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908574,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=64) "ReplicaSet \"test-recreate-deployment-66b65d9f8f\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0521 17:16:16.244967 22 deployment.go:39] New ReplicaSet "test-recreate-deployment-66b65d9f8f" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-66b65d9f8f",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5962",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e618f191-4b90-43b9-8442-9d09a5c4e520",
      ResourceVersion: (string) (len=5) "14731",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851908576,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "b97378bb-02c0-40bc-812a-2a2c3e74bf5f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 39 37 33 37 38  62 62 2d 30 32 63 30 2d  |\"b97378bb-02c0-|
              00000120  34 30 62 63 2d 38 31 32  61 2d 32 61 32 63 33 65  |40bc-812a-2a2c3e|
              00000130  37 34 62 66 35 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |74bf5f\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 17:16:16.245503 22 deployment.go:44] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0521 17:16:16.245678 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-6b6d9cd7b6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5962",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "66245226-24c4-4da8-9e4d-da836d371cca",
      ResourceVersion: (string) (len=5) "14722",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851908574,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "b97378bb-02c0-40bc-812a-2a2c3e74bf5f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 39 37 33 37 38  62 62 2d 30 32 63 30 2d  |\"b97378bb-02c0-|
              00000120  34 30 62 63 2d 38 31 32  61 2d 32 61 32 63 33 65  |40bc-812a-2a2c3e|
              00000130  37 34 62 66 35 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |74bf5f\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6b6d9cd7b6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 17:16:16.248724 22 deployment.go:67] Pod "test-recreate-deployment-66b65d9f8f-hq767" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-recreate-deployment-66b65d9f8f-hq767",
      GenerateName: (string) (len=36) "test-recreate-deployment-66b65d9f8f-",
      Namespace: (string) (len=15) "deployment-5962",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "222c4634-f6ab-4022-9fbe-90a301b35521",
      ResourceVersion: (string) (len=5) "14734",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851908576,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "66b65d9f8f"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-recreate-deployment-66b65d9f8f",
          UID: (types.UID) (len=36) "e618f191-4b90-43b9-8442-9d09a5c4e520",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 38 66 31 39 31 2d 34  |d\":\"e618f191-4|
              00000090  62 39 30 2d 34 33 62 39  2d 38 34 34 32 2d 39 64  |b90-43b9-8442-9d|
              000000a0  30 39 61 35 63 34 65 35  32 30 5c 22 7d 22 3a 7b  |09a5c4e520\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9v4xs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9v4xs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851908576,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851908576,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 17:16:16.249967 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5962" for this suite. @ 05/21/24 17:16:16.252
• [2.124 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 05/21/24 17:16:16.255
  I0521 17:16:16.255700 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename var-expansion @ 05/21/24 17:16:16.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:16:16.265
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:16:16.267
  STEP: creating the pod @ 05/21/24 17:16:16.269
  STEP: waiting for pod running @ 05/21/24 17:16:16.273
  E0521 17:16:16.994985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:17.995301      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 05/21/24 17:16:18.282
  I0521 17:16:18.284958 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4596 PodName:var-expansion-055a4261-e3b4-4a25-8aca-6752c19a6da2 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 17:16:18.284997 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:16:18.285626 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 17:16:18.285687 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-4596/pods/var-expansion-055a4261-e3b4-4a25-8aca-6752c19a6da2/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 05/21/24 17:16:18.355
  I0521 17:16:18.357276 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4596 PodName:var-expansion-055a4261-e3b4-4a25-8aca-6752c19a6da2 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 17:16:18.357305 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:16:18.357741 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 17:16:18.357790 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-4596/pods/var-expansion-055a4261-e3b4-4a25-8aca-6752c19a6da2/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 05/21/24 17:16:18.402
  I0521 17:16:18.918429 22 pod_client.go:141] Successfully updated pod "var-expansion-055a4261-e3b4-4a25-8aca-6752c19a6da2"
  STEP: waiting for annotated pod running @ 05/21/24 17:16:18.918
  STEP: deleting the pod gracefully @ 05/21/24 17:16:18.921
  I0521 17:16:18.921589 22 delete.go:62] Deleting pod "var-expansion-055a4261-e3b4-4a25-8aca-6752c19a6da2" in namespace "var-expansion-4596"
  I0521 17:16:18.928402 22 delete.go:70] Wait up to 5m0s for pod "var-expansion-055a4261-e3b4-4a25-8aca-6752c19a6da2" to be fully deleted
  E0521 17:16:18.995919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:19.996030      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:20.996397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:21.996434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:22.997439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:23.997773      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:24.997993      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:25.998485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:26.999302      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:27.999634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:29.000008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:30.000607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:31.000740      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:32.001184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:33.001790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:34.002598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:35.002792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:36.003417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:37.004208      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:38.004505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:39.005302      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:40.005609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:41.006325      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:42.006806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:43.007355      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:44.007825      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:45.008233      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:46.009069      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:47.009419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:48.009473      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:49.010354      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:50.010776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:51.011667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:16:51.014527 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4596" for this suite. @ 05/21/24 17:16:51.018
• [34.770 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 05/21/24 17:16:51.026
  I0521 17:16:51.026063 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 17:16:51.027
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:16:51.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:16:51.038
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 17:16:51.041
  E0521 17:16:52.012155      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:53.012858      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:54.012979      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:55.013371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:16:55.057
  I0521 17:16:55.060895 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-b2cb40e0-18ee-4ee4-a845-9d4e401db082 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 17:16:55.078
  I0521 17:16:55.088684 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7229" for this suite. @ 05/21/24 17:16:55.09
• [4.069 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 05/21/24 17:16:55.095
  I0521 17:16:55.095069 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename namespaces @ 05/21/24 17:16:55.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:16:55.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:16:55.105
  STEP: creating a Namespace @ 05/21/24 17:16:55.107
  STEP: patching the Namespace @ 05/21/24 17:16:55.114
  STEP: get the Namespace and ensuring it has the label @ 05/21/24 17:16:55.118
  I0521 17:16:55.120084 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8369" for this suite. @ 05/21/24 17:16:55.121
  STEP: Destroying namespace "nspatchtest-13ef9257-71bb-40e1-8ab8-ba8fe6d126c7-7966" for this suite. @ 05/21/24 17:16:55.127
• [0.036 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 05/21/24 17:16:55.131
  I0521 17:16:55.131540 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename statefulset @ 05/21/24 17:16:55.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:16:55.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:16:55.143
  STEP: Creating service test in namespace statefulset-8135 @ 05/21/24 17:16:55.145
  STEP: Creating statefulset ss in namespace statefulset-8135 @ 05/21/24 17:16:55.152
  I0521 17:16:55.156984 22 wait.go:40] Found 0 stateful pods, waiting for 1
  E0521 17:16:56.013249      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:57.013465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:58.013931      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:16:59.014558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:00.015568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:01.015928      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:02.016976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:03.017231      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:04.017504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:05.018112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:17:05.160356 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 05/21/24 17:17:05.166
  STEP: Getting /status @ 05/21/24 17:17:05.18
  I0521 17:17:05.183616 22 statefulset.go:1067] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 05/21/24 17:17:05.183
  I0521 17:17:05.189439 22 statefulset.go:1087] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 05/21/24 17:17:05.189
  I0521 17:17:05.190879 22 statefulset.go:1115] Observed &StatefulSet event: ADDED
  I0521 17:17:05.190930 22 statefulset.go:1108] Found Statefulset ss in namespace statefulset-8135 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0521 17:17:05.190954 22 statefulset.go:1119] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 05/21/24 17:17:05.19
  I0521 17:17:05.191006 22 statefulset.go:1123] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0521 17:17:05.198679 22 statefulset.go:1127] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 05/21/24 17:17:05.198
  I0521 17:17:05.200661 22 statefulset.go:1152] Observed &StatefulSet event: ADDED
  I0521 17:17:05.200738 22 statefulset.go:135] Deleting all statefulset in ns statefulset-8135
  I0521 17:17:05.202817 22 rest.go:150] Scaling statefulset ss to 0
  E0521 17:17:06.018490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:07.019502      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:08.019767      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:09.019752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:10.020557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:11.021458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:12.022454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:13.023543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:14.024511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:15.024662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:17:15.214760 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0521 17:17:15.217278 22 rest.go:88] Deleting statefulset ss
  I0521 17:17:15.229809 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8135" for this suite. @ 05/21/24 17:17:15.232
• [20.108 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 05/21/24 17:17:15.239
  I0521 17:17:15.239919 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename ingressclass @ 05/21/24 17:17:15.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:17:15.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:17:15.25
  STEP: getting /apis @ 05/21/24 17:17:15.251
  STEP: getting /apis/networking.k8s.io @ 05/21/24 17:17:15.253
  STEP: getting /apis/networking.k8s.iov1 @ 05/21/24 17:17:15.254
  STEP: creating @ 05/21/24 17:17:15.254
  STEP: getting @ 05/21/24 17:17:15.263
  STEP: listing @ 05/21/24 17:17:15.265
  STEP: watching @ 05/21/24 17:17:15.266
  I0521 17:17:15.266360 22 ingressclass.go:348] starting watch
  STEP: patching @ 05/21/24 17:17:15.266
  STEP: updating @ 05/21/24 17:17:15.269
  I0521 17:17:15.272086 22 ingressclass.go:364] waiting for watch events with expected annotations
  I0521 17:17:15.272111 22 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 05/21/24 17:17:15.272
  STEP: deleting a collection @ 05/21/24 17:17:15.277
  I0521 17:17:15.284155 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-4385" for this suite. @ 05/21/24 17:17:15.285
• [0.050 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:850
  STEP: Creating a kubernetes client @ 05/21/24 17:17:15.29
  I0521 17:17:15.290290 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 17:17:15.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:17:15.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:17:15.3
  STEP: creating service multi-endpoint-test in namespace services-1257 @ 05/21/24 17:17:15.301
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1257 to expose endpoints map[] @ 05/21/24 17:17:15.308
  I0521 17:17:15.312472 22 service.go:4226] Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  E0521 17:17:16.025518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:17:16.323354 22 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-1257 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-1257 @ 05/21/24 17:17:16.323
  E0521 17:17:17.026442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:18.026486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1257 to expose endpoints map[pod1:[100]] @ 05/21/24 17:17:18.344
  I0521 17:17:18.351722 22 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-1257 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-1257 @ 05/21/24 17:17:18.351
  E0521 17:17:19.027481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:20.028629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1257 to expose endpoints map[pod1:[100] pod2:[101]] @ 05/21/24 17:17:20.367
  I0521 17:17:20.374399 22 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-1257 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 05/21/24 17:17:20.374
  I0521 17:17:20.374457 22 resource.go:361] Creating new exec pod
  E0521 17:17:21.029486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:22.029758      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:23.030067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:17:23.385706 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1257 exec execpodb9sxn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I0521 17:17:23.471826 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  I0521 17:17:23.471862 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:17:23.471913 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1257 exec execpodb9sxn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.129.93 80'
  I0521 17:17:23.548060 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.129.93 80\nConnection to 10.108.129.93 80 port [tcp/http] succeeded!\n"
  I0521 17:17:23.548090 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:17:23.548139 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1257 exec execpodb9sxn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0521 17:17:23.633298 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  I0521 17:17:23.633356 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:17:23.633460 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1257 exec execpodb9sxn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.129.93 81'
  I0521 17:17:23.713797 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.129.93 81\nConnection to 10.108.129.93 81 port [tcp/*] succeeded!\n"
  I0521 17:17:23.713844 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-1257 @ 05/21/24 17:17:23.713
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1257 to expose endpoints map[pod2:[101]] @ 05/21/24 17:17:23.725
  I0521 17:17:23.737681 22 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-1257 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-1257 @ 05/21/24 17:17:23.737
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1257 to expose endpoints map[] @ 05/21/24 17:17:23.745
  I0521 17:17:23.752945 22 service.go:4258] successfully validated that service multi-endpoint-test in namespace services-1257 exposes endpoints map[]
  I0521 17:17:23.767384 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1257" for this suite. @ 05/21/24 17:17:23.77
• [8.484 seconds]
------------------------------
S
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 05/21/24 17:17:23.774
  I0521 17:17:23.774258 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 17:17:23.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:17:23.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:17:23.784
  STEP: Creating a pod to test downward api env vars @ 05/21/24 17:17:23.786
  E0521 17:17:24.030365      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:25.031553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:17:25.803
  I0521 17:17:25.806139 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downward-api-c115b5ae-fd73-4d75-ae6c-add6791c5d32 container dapi-container: <nil>
  STEP: delete the pod @ 05/21/24 17:17:25.813
  I0521 17:17:25.827449 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4295" for this suite. @ 05/21/24 17:17:25.834
• [2.074 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 05/21/24 17:17:25.848
  I0521 17:17:25.848953 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename var-expansion @ 05/21/24 17:17:25.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:17:25.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:17:25.869
  E0521 17:17:26.032553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:27.032926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:17:27.882158 22 delete.go:62] Deleting pod "var-expansion-bb625df0-91e3-4e8f-9654-dc728ea0de32" in namespace "var-expansion-6651"
  I0521 17:17:27.890090 22 delete.go:70] Wait up to 5m0s for pod "var-expansion-bb625df0-91e3-4e8f-9654-dc728ea0de32" to be fully deleted
  E0521 17:17:28.033151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:29.033396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:17:29.898839 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6651" for this suite. @ 05/21/24 17:17:29.902
• [4.060 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 05/21/24 17:17:29.908
  I0521 17:17:29.908617 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 17:17:29.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:17:29.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:17:29.926
  STEP: Setting up server cert @ 05/21/24 17:17:29.944
  E0521 17:17:30.034305      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 17:17:30.048
  STEP: Deploying the webhook pod @ 05/21/24 17:17:30.052
  STEP: Wait for the deployment to be ready @ 05/21/24 17:17:30.059
  I0521 17:17:30.062862 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 17:17:31.034542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:32.035471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 17:17:32.072
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 17:17:32.081
  E0521 17:17:33.035715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:17:33.082348 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 05/21/24 17:17:33.09
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/21/24 17:17:33.106
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 05/21/24 17:17:33.113
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/21/24 17:17:33.118
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 05/21/24 17:17:33.124
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/21/24 17:17:33.129
  I0521 17:17:33.160852 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6730" for this suite. @ 05/21/24 17:17:33.162
  STEP: Destroying namespace "webhook-markers-8579" for this suite. @ 05/21/24 17:17:33.167
• [3.267 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 05/21/24 17:17:33.175
  I0521 17:17:33.175679 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename var-expansion @ 05/21/24 17:17:33.176
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:17:33.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:17:33.187
  STEP: creating the pod with failed condition @ 05/21/24 17:17:33.189
  E0521 17:17:34.036394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:35.037067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:36.037630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:37.038672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:38.039558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:39.039745      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:40.039773      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:41.040633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:42.041446      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:43.041919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:44.042433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:45.043065      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:46.043710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:47.044138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:48.044368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:49.044695      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:50.045584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:51.046996      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:52.047477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:53.047728      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:54.047936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:55.048875      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:56.049583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:57.050654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:58.050959      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:17:59.051803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:00.052696      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:01.053737      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:02.054717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:03.055173      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:04.055506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:05.055491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:06.055680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:07.056269      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:08.056645      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:09.057129      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:10.058163      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:11.058395      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:12.059319      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:13.059601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:14.060655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:15.061377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:16.061795      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:17.062374      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:18.062910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:19.062988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:20.063387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:21.064011      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:22.063789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:23.064628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:24.064984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:25.065844      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:26.066613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:27.066910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:28.067795      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:29.068875      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:30.069706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:31.070486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:32.071234      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:33.071562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:34.072646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:35.073457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:36.073678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:37.074360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:38.074957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:39.075178      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:40.075493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:41.075541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:42.076070      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:43.076512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:44.077130      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:45.077368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:46.077498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:47.077790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:48.078598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:49.079660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:50.080251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:51.080278      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:52.081020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:53.081457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:54.082568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:55.083485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:56.084424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:57.084507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:58.084753      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:18:59.085416      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:00.085496      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:01.085731      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:02.086380      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:03.086626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:04.087555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:05.088423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:06.088450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:07.088741      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:08.089421      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:09.089586      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:10.089677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:11.089791      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:12.090527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:13.091643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:14.092599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:15.093067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:16.093269      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:17.093458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:18.094453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:19.094784      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:20.095547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:21.096564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:22.097356      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:23.097907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:24.098700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:25.099689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:26.100144      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:27.100669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:28.101653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:29.102245      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:30.102347      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:31.103323      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:32.103342      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:33.103822      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 05/21/24 17:19:33.196
  I0521 17:19:33.712893 22 pod_client.go:141] Successfully updated pod "var-expansion-bb17e21e-48cb-494c-bf37-15a52703f559"
  STEP: waiting for pod running @ 05/21/24 17:19:33.712
  E0521 17:19:34.104352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:35.105336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 05/21/24 17:19:35.722
  I0521 17:19:35.722791 22 delete.go:62] Deleting pod "var-expansion-bb17e21e-48cb-494c-bf37-15a52703f559" in namespace "var-expansion-5433"
  I0521 17:19:35.731428 22 delete.go:70] Wait up to 5m0s for pod "var-expansion-bb17e21e-48cb-494c-bf37-15a52703f559" to be fully deleted
  E0521 17:19:36.105615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:37.106607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:38.106746      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:39.107703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:40.108146      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:41.108498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:42.108796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:43.109126      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:44.109459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:45.110443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:46.110831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:47.111256      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:48.112314      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:49.113060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:50.113819      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:51.114517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:52.115311      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:53.115525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:54.115657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:55.116537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:56.116959      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:57.117805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:58.118647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:19:59.119244      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:00.120001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:01.120765      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:02.121279      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:03.121787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:04.122147      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:05.123103      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:06.123734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:07.124620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:20:07.821237 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5433" for this suite. @ 05/21/24 17:20:07.824
• [154.655 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3136
  STEP: Creating a kubernetes client @ 05/21/24 17:20:07.831
  I0521 17:20:07.831402 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 17:20:07.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:20:07.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:20:07.845
  STEP: fetching services @ 05/21/24 17:20:07.848
  I0521 17:20:07.851430 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7193" for this suite. @ 05/21/24 17:20:07.854
• [0.027 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 05/21/24 17:20:07.858
  I0521 17:20:07.859006 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:20:07.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:20:07.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:20:07.874
  STEP: Creating secret with name s-test-opt-del-230fc0b4-9d17-4681-ab4a-4fef207ea1e3 @ 05/21/24 17:20:07.879
  STEP: Creating secret with name s-test-opt-upd-53e72327-14ed-4d71-b828-6bb485d5597e @ 05/21/24 17:20:07.882
  STEP: Creating the pod @ 05/21/24 17:20:07.885
  E0521 17:20:08.124945      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:09.125479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-230fc0b4-9d17-4681-ab4a-4fef207ea1e3 @ 05/21/24 17:20:09.933
  STEP: Updating secret s-test-opt-upd-53e72327-14ed-4d71-b828-6bb485d5597e @ 05/21/24 17:20:09.938
  STEP: Creating secret with name s-test-opt-create-fa0aeb8d-91c7-479d-bf6f-69df1bd360b0 @ 05/21/24 17:20:09.943
  STEP: waiting to observe update in volume @ 05/21/24 17:20:09.949
  E0521 17:20:10.126489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:11.127257      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:12.127840      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:13.128293      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:14.128894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:15.129547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:16.130477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:17.130993      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:18.131826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:19.132264      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:20.132898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:21.133477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:22.134175      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:23.134701      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:24.134843      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:25.135017      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:26.135538      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:27.136023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:28.136422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:29.136993      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:30.137002      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:31.137539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:32.137835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:33.137994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:34.138157      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:35.138990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:36.139110      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:37.140055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:38.140175      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:39.140572      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:40.141127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:41.141480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:42.142459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:43.142826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:44.143423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:45.144056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:46.144801      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:47.145118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:48.145575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:49.146184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:50.146606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:51.147686      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:52.148097      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:53.149159      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:54.149785      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:55.150570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:56.150745      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:57.151525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:58.151740      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:20:59.152527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:00.152670      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:01.153072      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:02.153780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:03.154504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:04.154584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:05.155311      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:06.155508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:07.156021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:08.156513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:09.157129      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:10.157571      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:11.158450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:12.158551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:13.158919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:14.159550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:15.160718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:16.160958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:17.161608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:18.162135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:19.162917      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:20.163416      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:21.163974      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:22.164729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:23.165633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:24.166256      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:25.167266      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:26.167376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:26.406440 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3408" for this suite. @ 05/21/24 17:21:26.409
• [78.557 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 05/21/24 17:21:26.416
  I0521 17:21:26.416768 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename field-validation @ 05/21/24 17:21:26.417
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:21:26.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:21:26.433
  I0521 17:21:26.436545 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  W0521 17:21:26.437368      22 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc005e4e030 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0521 17:21:27.167637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:28.168027      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0521 17:21:28.986777      22 warnings.go:70] unknown field "alpha"
  W0521 17:21:28.986810      22 warnings.go:70] unknown field "beta"
  W0521 17:21:28.986819      22 warnings.go:70] unknown field "delta"
  W0521 17:21:28.986828      22 warnings.go:70] unknown field "epsilon"
  W0521 17:21:28.986837      22 warnings.go:70] unknown field "gamma"
  E0521 17:21:29.168610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:29.522285 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3566" for this suite. @ 05/21/24 17:21:29.525
• [3.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 05/21/24 17:21:29.532
  I0521 17:21:29.532585 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename conformance-tests @ 05/21/24 17:21:29.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:21:29.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:21:29.55
  STEP: Getting node addresses @ 05/21/24 17:21:29.553
  I0521 17:21:29.553245 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I0521 17:21:29.556599 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-7553" for this suite. @ 05/21/24 17:21:29.558
• [0.029 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 05/21/24 17:21:29.561
  I0521 17:21:29.561983 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-webhook @ 05/21/24 17:21:29.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:21:29.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:21:29.579
  STEP: Setting up server cert @ 05/21/24 17:21:29.582
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 05/21/24 17:21:29.805
  STEP: Deploying the custom resource conversion webhook pod @ 05/21/24 17:21:29.809
  STEP: Wait for the deployment to be ready @ 05/21/24 17:21:29.816
  I0521 17:21:29.820818 22 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0521 17:21:30.169522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:31.170127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 17:21:31.831
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 17:21:31.841
  E0521 17:21:32.170683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:32.842543 22 util.go:427] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0521 17:21:32.850681 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:21:33.170822      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:34.171904      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:35.172598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 05/21/24 17:21:35.419
  STEP: Create a v2 custom resource @ 05/21/24 17:21:35.432
  STEP: List CRs in v1 @ 05/21/24 17:21:35.459
  STEP: List CRs in v2 @ 05/21/24 17:21:35.462
  I0521 17:21:36.008776 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-7308" for this suite. @ 05/21/24 17:21:36.011
• [6.456 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 05/21/24 17:21:36.018
  I0521 17:21:36.018071 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename endpointslice @ 05/21/24 17:21:36.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:21:36.027
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:21:36.031
  STEP: getting /apis @ 05/21/24 17:21:36.033
  STEP: getting /apis/discovery.k8s.io @ 05/21/24 17:21:36.037
  STEP: getting /apis/discovery.k8s.iov1 @ 05/21/24 17:21:36.037
  STEP: creating @ 05/21/24 17:21:36.038
  STEP: getting @ 05/21/24 17:21:36.047
  STEP: listing @ 05/21/24 17:21:36.049
  STEP: watching @ 05/21/24 17:21:36.05
  I0521 17:21:36.050832 22 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 05/21/24 17:21:36.051
  STEP: cluster-wide watching @ 05/21/24 17:21:36.053
  I0521 17:21:36.053268 22 endpointslice.go:459] starting watch
  STEP: patching @ 05/21/24 17:21:36.053
  STEP: updating @ 05/21/24 17:21:36.06
  I0521 17:21:36.064155 22 endpointslice.go:482] waiting for watch events with expected annotations
  I0521 17:21:36.064216 22 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 05/21/24 17:21:36.064
  STEP: deleting a collection @ 05/21/24 17:21:36.085
  I0521 17:21:36.093053 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-5453" for this suite. @ 05/21/24 17:21:36.094
• [0.079 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1394
  STEP: Creating a kubernetes client @ 05/21/24 17:21:36.097
  I0521 17:21:36.097083 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 17:21:36.097
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:21:36.105
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:21:36.106
  I0521 17:21:36.108106 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-2613 create -f -'
  E0521 17:21:36.173424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:36.180985 22 builder.go:146] stderr: ""
  I0521 17:21:36.181017 22 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I0521 17:21:36.181059 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-2613 create -f -'
  I0521 17:21:36.264264 22 builder.go:146] stderr: ""
  I0521 17:21:36.264299 22 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/21/24 17:21:36.264
  E0521 17:21:37.174539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:37.270467 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 17:21:37.270529 22 framework.go:733] Found 0 / 1
  E0521 17:21:38.175519      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:38.270073 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 17:21:38.270128 22 framework.go:733] Found 1 / 1
  I0521 17:21:38.270155 22 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0521 17:21:38.273057 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 17:21:38.273092 22 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0521 17:21:38.273140 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-2613 describe pod agnhost-primary-gxhpb'
  I0521 17:21:38.323072 22 builder.go:146] stderr: ""
  I0521 17:21:38.323158 22 builder.go:147] stdout: "Name:             agnhost-primary-gxhpb\nNamespace:        kubectl-2613\nPriority:         0\nService Account:  default\nNode:             k8sconformance-m02/192.168.67.3\nStart Time:       Tue, 21 May 2024 17:21:36 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.1.32\nIPs:\n  IP:           10.244.1.32\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://4b043ecc8d3aec9ac8c66bdd39540753e0f22dfcbe7b20aeb6375d01407cc0a9\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 21 May 2024 17:21:36 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-sqbtf (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-sqbtf:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-2613/agnhost-primary-gxhpb to k8sconformance-m02\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
  I0521 17:21:38.323219 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-2613 describe rc agnhost-primary'
  I0521 17:21:38.367720 22 builder.go:146] stderr: ""
  I0521 17:21:38.367773 22 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2613\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-gxhpb\n"
  I0521 17:21:38.367820 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-2613 describe service agnhost-primary'
  I0521 17:21:38.407801 22 builder.go:146] stderr: ""
  I0521 17:21:38.407833 22 builder.go:147] stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2613\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.97.214.94\nIPs:               10.97.214.94\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.1.32:6379\nSession Affinity:  None\nEvents:            <none>\n"
  I0521 17:21:38.409475 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-2613 describe node k8sconformance'
  I0521 17:21:38.463179 22 builder.go:146] stderr: ""
  I0521 17:21:38.463243 22 builder.go:147] stdout: "Name:               k8sconformance\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8sconformance\n                    kubernetes.io/os=linux\n                    minikube.k8s.io/commit=de22f1f905d451689e279b5dc15299144faf7a59-dirty\n                    minikube.k8s.io/name=k8sconformance\n                    minikube.k8s.io/primary=true\n                    minikube.k8s.io/updated_at=2024_05_21T12_34_03_0700\n                    minikube.k8s.io/version=v1.33.1\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 21 May 2024 16:34:00 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  k8sconformance\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 21 May 2024 17:21:31 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 21 May 2024 17:18:15 +0000   Tue, 21 May 2024 16:33:59 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 21 May 2024 17:18:15 +0000   Tue, 21 May 2024 16:33:59 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 21 May 2024 17:18:15 +0000   Tue, 21 May 2024 16:33:59 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 21 May 2024 17:18:15 +0000   Tue, 21 May 2024 16:34:00 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.67.2\n  Hostname:    k8sconformance\nCapacity:\n  cpu:                12\n  ephemeral-storage:  954434220Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             32480668Ki\n  pods:               110\nAllocatable:\n  cpu:                12\n  ephemeral-storage:  954434220Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             32480668Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 8778a130db8b40b88b1b6eebb4b0729a\n  System UUID:                4ec57889-c3c1-456a-bb22-4d508ec84b3e\n  Boot ID:                    5f5421f7-c2ed-49bc-a6de-59d40c5ed8cf\n  Kernel Version:             6.8.0-31-generic\n  OS Image:                   Ubuntu 22.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://26.1.2\n  Kubelet Version:            v1.30.1\n  Kube-Proxy Version:         v1.30.1\nPodCIDR:                      10.244.0.0/24\nPodCIDRs:                     10.244.0.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-7db6d8ff4d-5h9wx                                   100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     47m\n  kube-system                 etcd-k8sconformance                                        100m (0%)     0 (0%)      100Mi (0%)       0 (0%)         47m\n  kube-system                 kindnet-x4z6c                                              100m (0%)     100m (0%)   50Mi (0%)        50Mi (0%)      47m\n  kube-system                 kube-apiserver-k8sconformance                              250m (2%)     0 (0%)      0 (0%)           0 (0%)         47m\n  kube-system                 kube-controller-manager-k8sconformance                     200m (1%)     0 (0%)      0 (0%)           0 (0%)         47m\n  kube-system                 kube-proxy-bk2bg                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         47m\n  kube-system                 kube-scheduler-k8sconformance                              100m (0%)     0 (0%)      0 (0%)           0 (0%)         47m\n  kube-system                 storage-provisioner                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         47m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-05530e69374c4820-8kzzl    0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (7%)   100m (0%)\n  memory             220Mi (0%)  220Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age   From             Message\n  ----    ------                   ----  ----             -------\n  Normal  Starting                 47m   kube-proxy       \n  Normal  Starting                 47m   kubelet          Starting kubelet.\n  Normal  NodeAllocatableEnforced  47m   kubelet          Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientMemory  47m   kubelet          Node k8sconformance status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    47m   kubelet          Node k8sconformance status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     47m   kubelet          Node k8sconformance status is now: NodeHasSufficientPID\n  Normal  RegisteredNode           47m   node-controller  Node k8sconformance event: Registered Node k8sconformance in Controller\n"
  I0521 17:21:38.463285 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-2613 describe namespace kubectl-2613'
  I0521 17:21:38.502089 22 builder.go:146] stderr: ""
  I0521 17:21:38.502132 22 builder.go:147] stdout: "Name:         kubectl-2613\nLabels:       e2e-framework=kubectl\n              e2e-run=2e7e1833-6abb-47fa-bc98-ecd17b7a0354\n              kubernetes.io/metadata.name=kubectl-2613\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0521 17:21:38.502240 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2613" for this suite. @ 05/21/24 17:21:38.503
• [2.411 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:789
  STEP: Creating a kubernetes client @ 05/21/24 17:21:38.508
  I0521 17:21:38.508583 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 17:21:38.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:21:38.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:21:38.516
  STEP: creating service endpoint-test2 in namespace services-1696 @ 05/21/24 17:21:38.517
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1696 to expose endpoints map[] @ 05/21/24 17:21:38.524
  I0521 17:21:38.526103 22 service.go:4226] Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0521 17:21:39.176107      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:39.536484 22 service.go:4258] successfully validated that service endpoint-test2 in namespace services-1696 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-1696 @ 05/21/24 17:21:39.536
  E0521 17:21:40.176594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:41.176612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1696 to expose endpoints map[pod1:[80]] @ 05/21/24 17:21:41.555
  I0521 17:21:41.564548 22 service.go:4258] successfully validated that service endpoint-test2 in namespace services-1696 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 05/21/24 17:21:41.564
  I0521 17:21:41.564642 22 resource.go:361] Creating new exec pod
  E0521 17:21:42.177669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:43.178169      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:44.178971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:44.579851 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1696 exec execpod42ncg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0521 17:21:44.675943 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0521 17:21:44.675973 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:21:44.676018 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1696 exec execpod42ncg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.99.111.78 80'
  I0521 17:21:44.758664 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.99.111.78 80\nConnection to 10.99.111.78 80 port [tcp/http] succeeded!\n"
  I0521 17:21:44.758715 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-1696 @ 05/21/24 17:21:44.758
  E0521 17:21:45.179000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:46.179700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1696 to expose endpoints map[pod1:[80] pod2:[80]] @ 05/21/24 17:21:46.779
  I0521 17:21:46.788859 22 service.go:4258] successfully validated that service endpoint-test2 in namespace services-1696 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 05/21/24 17:21:46.788
  E0521 17:21:47.180590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:47.789706 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1696 exec execpod42ncg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0521 17:21:47.903474 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0521 17:21:47.903541 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:21:47.903657 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1696 exec execpod42ncg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.99.111.78 80'
  I0521 17:21:48.011324 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.99.111.78 80\nConnection to 10.99.111.78 80 port [tcp/http] succeeded!\n"
  I0521 17:21:48.011387 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-1696 @ 05/21/24 17:21:48.011
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1696 to expose endpoints map[pod2:[80]] @ 05/21/24 17:21:48.025
  I0521 17:21:48.037357 22 service.go:4258] successfully validated that service endpoint-test2 in namespace services-1696 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 05/21/24 17:21:48.037
  E0521 17:21:48.181508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:49.038286 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1696 exec execpod42ncg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0521 17:21:49.140272 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I0521 17:21:49.140337 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:21:49.140462 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1696 exec execpod42ncg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.99.111.78 80'
  E0521 17:21:49.181794      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:49.228262 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.99.111.78 80\nConnection to 10.99.111.78 80 port [tcp/http] succeeded!\n"
  I0521 17:21:49.228322 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-1696 @ 05/21/24 17:21:49.228
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1696 to expose endpoints map[] @ 05/21/24 17:21:49.24
  I0521 17:21:49.250430 22 service.go:4258] successfully validated that service endpoint-test2 in namespace services-1696 exposes endpoints map[]
  I0521 17:21:49.264746 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1696" for this suite. @ 05/21/24 17:21:49.267
• [10.763 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 05/21/24 17:21:49.271
  I0521 17:21:49.271734 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename dns @ 05/21/24 17:21:49.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:21:49.28
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:21:49.281
  STEP: Creating a test headless service @ 05/21/24 17:21:49.283
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5062.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5062.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5062.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5062.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5062.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5062.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5062.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5062.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5062.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 230.248.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.248.230_udp@PTR;check="$$(dig +tcp +noall +answer +search 230.248.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.248.230_tcp@PTR;sleep 1; done
   @ 05/21/24 17:21:49.297
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5062.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5062.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5062.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5062.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5062.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5062.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5062.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5062.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5062.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5062.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 230.248.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.248.230_udp@PTR;check="$$(dig +tcp +noall +answer +search 230.248.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.248.230_tcp@PTR;sleep 1; done
   @ 05/21/24 17:21:49.297
  STEP: creating a pod to probe DNS @ 05/21/24 17:21:49.297
  STEP: submitting the pod to kubernetes @ 05/21/24 17:21:49.297
  E0521 17:21:50.182404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:51.182524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/21/24 17:21:51.311
  STEP: looking for the results for each expected name from probers @ 05/21/24 17:21:51.314
  I0521 17:21:51.318415 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:51.321247 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:51.323886 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:51.326391 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:51.337760 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:51.339752 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:51.341791 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:51.344038 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:51.352262 22 dns_common.go:489] Lookups using dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7 failed for: [wheezy_udp@dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_udp@dns-test-service.dns-5062.svc.cluster.local jessie_tcp@dns-test-service.dns-5062.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local]

  I0521 17:21:51.357526 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:21:51.362276 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:21:51.367353 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:21:52.183543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:53.183957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:54.184864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:55.185747      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:56.186220      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:21:56.321638 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:56.324710 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:56.327352 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:56.329938 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:56.340817 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:56.342970 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:56.345030 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:56.347081 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:21:56.355560 22 dns_common.go:489] Lookups using dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7 failed for: [wheezy_udp@dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_udp@dns-test-service.dns-5062.svc.cluster.local jessie_tcp@dns-test-service.dns-5062.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local]

  I0521 17:21:56.363574 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:21:56.368921 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:21:56.374141 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:21:57.186433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:58.186334      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:21:59.186544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:00.186896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:01.187372      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:22:01.319746 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:01.322358 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:01.324460 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:01.326503 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:01.336252 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:01.338291 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:01.340589 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:01.342578 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:01.350713 22 dns_common.go:489] Lookups using dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7 failed for: [wheezy_udp@dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_udp@dns-test-service.dns-5062.svc.cluster.local jessie_tcp@dns-test-service.dns-5062.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local]

  I0521 17:22:01.355949 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:22:01.360380 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:22:01.365017 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:22:02.187633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:03.188583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:04.189447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:05.190303      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:06.190468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:22:06.321694 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:06.324979 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:06.327362 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:06.329782 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:06.341212 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:06.343438 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:06.345575 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:06.347812 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:06.357178 22 dns_common.go:489] Lookups using dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7 failed for: [wheezy_udp@dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_udp@dns-test-service.dns-5062.svc.cluster.local jessie_tcp@dns-test-service.dns-5062.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local]

  I0521 17:22:06.361364 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:22:06.365353 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:22:06.369452 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:22:07.190385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:08.190751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:09.191673      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:10.192142      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:11.192623      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:22:11.319992 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:11.322753 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:11.325201 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:11.327391 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:11.338199 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:11.340344 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:11.342554 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:11.344731 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:11.352855 22 dns_common.go:489] Lookups using dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7 failed for: [wheezy_udp@dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_udp@dns-test-service.dns-5062.svc.cluster.local jessie_tcp@dns-test-service.dns-5062.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local]

  I0521 17:22:11.358295 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:22:11.364051 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:22:11.370365 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:22:12.193270      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:13.193600      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:14.193752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:15.194797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:16.195549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:22:16.321615 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:16.324739 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:16.327339 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:16.329559 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:16.341239 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:16.343353 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:16.345649 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:16.347876 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local from pod dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7: the server could not find the requested resource (get pods dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7)
  I0521 17:22:16.360224 22 dns_common.go:489] Lookups using dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7 failed for: [wheezy_udp@dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@dns-test-service.dns-5062.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_udp@dns-test-service.dns-5062.svc.cluster.local jessie_tcp@dns-test-service.dns-5062.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5062.svc.cluster.local]

  I0521 17:22:16.366313 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:22:16.372927 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:22:16.378808 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:22:17.195888      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:18.196400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:19.197560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:20.198477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:21.199421      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:22:21.356036 22 dns_common.go:527] DNS probes using dns-5062/dns-test-a05a55af-6955-4090-811f-1f7ccc30e6a7 succeeded

  STEP: deleting the pod @ 05/21/24 17:22:21.356
  STEP: deleting the test service @ 05/21/24 17:22:21.367
  STEP: deleting the test headless service @ 05/21/24 17:22:21.39
  I0521 17:22:21.401426 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5062" for this suite. @ 05/21/24 17:22:21.404
• [32.138 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 05/21/24 17:22:21.409
  I0521 17:22:21.409397 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:22:21.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:22:21.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:22:21.425
  STEP: Creating configMap with name cm-test-opt-del-584709a8-dade-44dc-9fb7-c28688ed3189 @ 05/21/24 17:22:21.428
  STEP: Creating configMap with name cm-test-opt-upd-238cd328-7efb-454e-8777-f3b07178a7e1 @ 05/21/24 17:22:21.43
  STEP: Creating the pod @ 05/21/24 17:22:21.432
  E0521 17:22:22.199903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:23.200461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-584709a8-dade-44dc-9fb7-c28688ed3189 @ 05/21/24 17:22:23.456
  STEP: Updating configmap cm-test-opt-upd-238cd328-7efb-454e-8777-f3b07178a7e1 @ 05/21/24 17:22:23.459
  STEP: Creating configMap with name cm-test-opt-create-b9c03fa2-5e4a-4ae4-8d39-5cfd3bf14582 @ 05/21/24 17:22:23.461
  STEP: waiting to observe update in volume @ 05/21/24 17:22:23.464
  E0521 17:22:24.200665      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:25.201643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:26.202403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:27.202629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:28.202874      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:29.203672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:30.204177      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:31.204600      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:32.205344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:33.205483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:34.206126      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:35.207183      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:36.207296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:37.207476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:38.207608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:39.208630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:40.208901      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:41.209467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:42.210409      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:43.210588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:44.210598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:45.211535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:46.211703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:47.212351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:48.212534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:49.212890      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:50.213414      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:51.213879      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:52.214342      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:53.214536      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:54.215014      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:55.215780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:56.216258      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:57.216531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:58.217223      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:22:59.217530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:00.217824      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:01.218460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:02.218587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:03.219111      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:04.219496      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:05.220445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:06.220965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:07.221697      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:08.222162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:09.222711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:10.223288      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:11.223551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:12.224155      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:13.224784      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:14.225151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:15.225408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:16.225676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:17.226478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:18.226924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:19.227842      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:20.228462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:21.229012      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:22.229304      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:23.229542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:24.229567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:25.230484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:26.231154      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:27.231399      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:28.232377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:29.232810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:30.233443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:31.233805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:32.234713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:33.235706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:34.236285      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:35.237032      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:36.237655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:37.238697      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:38.239286      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:39.239388      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:40.240003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:41.240544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:42.240904      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:43.241518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:23:43.935176 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4819" for this suite. @ 05/21/24 17:23:43.937
• [82.536 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 05/21/24 17:23:43.945
  I0521 17:23:43.945992 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename containers @ 05/21/24 17:23:43.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:23:43.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:23:43.962
  STEP: Creating a pod to test override all @ 05/21/24 17:23:43.964
  E0521 17:23:44.241884      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:45.242748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:46.243596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:47.244533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:23:47.984
  I0521 17:23:47.987350 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod client-containers-deaea581-b6bc-4b52-8e39-b67ade8af8d4 container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:23:47.994
  I0521 17:23:48.007244 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4192" for this suite. @ 05/21/24 17:23:48.01
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 05/21/24 17:23:48.014
  I0521 17:23:48.014900 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:23:48.015
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:23:48.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:23:48.028
  STEP: Creating configMap with name projected-configmap-test-volume-map-54558157-11b5-45d1-aeda-2a885f6307bd @ 05/21/24 17:23:48.03
  STEP: Creating a pod to test consume configMaps @ 05/21/24 17:23:48.033
  E0521 17:23:48.245583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:49.245733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:50.246451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:51.246296      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:23:52.049
  I0521 17:23:52.052131 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-85cb1b93-276f-49b7-bda5-8b7b6352bb9e container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:23:52.058
  I0521 17:23:52.071206 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4010" for this suite. @ 05/21/24 17:23:52.073
• [4.064 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:697
  STEP: Creating a kubernetes client @ 05/21/24 17:23:52.078
  I0521 17:23:52.078851 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename job @ 05/21/24 17:23:52.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:23:52.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:23:52.094
  STEP: Creating a job @ 05/21/24 17:23:52.096
  STEP: Ensuring active pods == parallelism @ 05/21/24 17:23:52.101
  E0521 17:23:52.247382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:53.247779      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 05/21/24 17:23:54.107
  E0521 17:23:54.248324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:23:54.618659 22 pod_client.go:141] Successfully updated pod "adopt-release-799fv"
  STEP: Checking that the Job readopts the Pod @ 05/21/24 17:23:54.618
  E0521 17:23:55.248978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:56.249581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 05/21/24 17:23:56.626
  I0521 17:23:57.134164 22 pod_client.go:141] Successfully updated pod "adopt-release-799fv"
  STEP: Checking that the Job releases the Pod @ 05/21/24 17:23:57.134
  E0521 17:23:57.249851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:23:58.250962      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:23:59.141642 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9554" for this suite. @ 05/21/24 17:23:59.144
• [7.072 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 05/21/24 17:23:59.151
  I0521 17:23:59.151353 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 17:23:59.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:23:59.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:23:59.167
  STEP: Discovering how many secrets are in namespace by default @ 05/21/24 17:23:59.171
  E0521 17:23:59.251036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:00.251955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:01.252710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:02.253115      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:03.253575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 05/21/24 17:24:04.173
  E0521 17:24:04.254273      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:05.255316      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:06.256121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:07.256604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:08.257383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/21/24 17:24:09.177
  STEP: Ensuring resource quota status is calculated @ 05/21/24 17:24:09.184
  E0521 17:24:09.258116      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:10.258123      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 05/21/24 17:24:11.189
  STEP: Ensuring resource quota status captures secret creation @ 05/21/24 17:24:11.203
  E0521 17:24:11.258376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:12.258500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 05/21/24 17:24:13.21
  STEP: Ensuring resource quota status released usage @ 05/21/24 17:24:13.217
  E0521 17:24:13.258626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:14.259609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:24:15.222183 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8883" for this suite. @ 05/21/24 17:24:15.225
• [16.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 05/21/24 17:24:15.229
  I0521 17:24:15.229869 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename namespaces @ 05/21/24 17:24:15.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:24:15.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:24:15.245
  STEP: Creating namespace "e2e-ns-hmjkh" @ 05/21/24 17:24:15.247
  I0521 17:24:15.258243 22 namespace.go:411] Namespace "e2e-ns-hmjkh-4781" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-hmjkh-4781" @ 05/21/24 17:24:15.258
  E0521 17:24:15.259693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:24:15.263385 22 namespace.go:434] Namespace "e2e-ns-hmjkh-4781" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-hmjkh-4781" @ 05/21/24 17:24:15.263
  I0521 17:24:15.268323 22 namespace.go:463] Namespace "e2e-ns-hmjkh-4781" has []v1.FinalizerName{"kubernetes"}
  I0521 17:24:15.268412 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2695" for this suite. @ 05/21/24 17:24:15.27
  STEP: Destroying namespace "e2e-ns-hmjkh-4781" for this suite. @ 05/21/24 17:24:15.275
• [0.049 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 05/21/24 17:24:15.279
  I0521 17:24:15.279293 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 17:24:15.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:24:15.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:24:15.294
  STEP: Counting existing ResourceQuota @ 05/21/24 17:24:15.297
  E0521 17:24:16.260163      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:17.260567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:18.261631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:19.262559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:20.262619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/21/24 17:24:20.299
  STEP: Ensuring resource quota status is calculated @ 05/21/24 17:24:20.303
  E0521 17:24:21.263558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:22.263670      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 05/21/24 17:24:22.308
  STEP: Creating a NodePort Service @ 05/21/24 17:24:22.327
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 05/21/24 17:24:22.35
  STEP: Ensuring resource quota status captures service creation @ 05/21/24 17:24:22.371
  E0521 17:24:23.264699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:24.265568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 05/21/24 17:24:24.378
  STEP: Ensuring resource quota status released usage @ 05/21/24 17:24:24.409
  E0521 17:24:25.266451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:26.266531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:24:26.412653 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2597" for this suite. @ 05/21/24 17:24:26.413
• [11.140 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 05/21/24 17:24:26.419
  I0521 17:24:26.419113 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename watch @ 05/21/24 17:24:26.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:24:26.428
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:24:26.431
  STEP: creating a watch on configmaps with label A @ 05/21/24 17:24:26.434
  STEP: creating a watch on configmaps with label B @ 05/21/24 17:24:26.435
  STEP: creating a watch on configmaps with label A or B @ 05/21/24 17:24:26.436
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 05/21/24 17:24:26.437
  I0521 17:24:26.441352 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7837  2c5e56c3-c952-44d7-b1b9-733f9c76f6b2 16196 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 17:24:26.441452 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7837  2c5e56c3-c952-44d7-b1b9-733f9c76f6b2 16196 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 05/21/24 17:24:26.441
  I0521 17:24:26.447492 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7837  2c5e56c3-c952-44d7-b1b9-733f9c76f6b2 16197 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 17:24:26.447563 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7837  2c5e56c3-c952-44d7-b1b9-733f9c76f6b2 16197 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 05/21/24 17:24:26.447
  I0521 17:24:26.453842 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7837  2c5e56c3-c952-44d7-b1b9-733f9c76f6b2 16198 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 17:24:26.453964 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7837  2c5e56c3-c952-44d7-b1b9-733f9c76f6b2 16198 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 05/21/24 17:24:26.454
  I0521 17:24:26.457631 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7837  2c5e56c3-c952-44d7-b1b9-733f9c76f6b2 16199 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 17:24:26.457700 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7837  2c5e56c3-c952-44d7-b1b9-733f9c76f6b2 16199 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 05/21/24 17:24:26.457
  I0521 17:24:26.461030 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7837  600604fb-aaaa-493c-a3be-7cb029914c92 16200 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 17:24:26.461100 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7837  600604fb-aaaa-493c-a3be-7cb029914c92 16200 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0521 17:24:27.267067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:28.267445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:29.267527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:30.268176      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:31.268568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:32.269359      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:33.269643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:34.270048      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:35.270104      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:36.270391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 05/21/24 17:24:36.461
  I0521 17:24:36.470505 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7837  600604fb-aaaa-493c-a3be-7cb029914c92 16215 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 17:24:36.470592 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7837  600604fb-aaaa-493c-a3be-7cb029914c92 16215 0 2024-05-21 17:24:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-05-21 17:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0521 17:24:37.271351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:38.271331      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:39.271696      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:40.272088      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:41.272148      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:42.273410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:43.273558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:44.274092      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:45.274337      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:46.274480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:24:46.471098 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7837" for this suite. @ 05/21/24 17:24:46.477
• [20.065 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:779
  STEP: Creating a kubernetes client @ 05/21/24 17:24:46.484
  I0521 17:24:46.484064 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 17:24:46.485
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:24:46.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:24:46.499
  I0521 17:24:46.504703 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-600" for this suite. @ 05/21/24 17:24:46.507
• [0.027 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 05/21/24 17:24:46.511
  I0521 17:24:46.511566 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir-wrapper @ 05/21/24 17:24:46.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:24:46.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:24:46.522
  STEP: Creating 50 configmaps @ 05/21/24 17:24:46.524
  STEP: Creating RC which spawns configmap-volume pods @ 05/21/24 17:24:46.767
  I0521 17:24:46.888961 22 resource.go:87] Pod name wrapped-volume-race-64f79038-1169-4e87-bb53-9d401ae6895f: Found 3 pods out of 5
  E0521 17:24:47.275476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:48.276553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:49.277692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:50.277808      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:51.278547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:24:51.902434 22 resource.go:87] Pod name wrapped-volume-race-64f79038-1169-4e87-bb53-9d401ae6895f: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/21/24 17:24:51.902
  STEP: Creating RC which spawns configmap-volume pods @ 05/21/24 17:24:51.911
  I0521 17:24:51.921658 22 resource.go:87] Pod name wrapped-volume-race-f13255cf-2d05-4ea4-9602-f3d40b024694: Found 0 pods out of 5
  E0521 17:24:52.278942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:53.279608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:54.279670      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:55.280482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:56.281680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:24:56.929757 22 resource.go:87] Pod name wrapped-volume-race-f13255cf-2d05-4ea4-9602-f3d40b024694: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/21/24 17:24:56.929
  STEP: Creating RC which spawns configmap-volume pods @ 05/21/24 17:24:56.943
  I0521 17:24:56.956246 22 resource.go:87] Pod name wrapped-volume-race-f5451ea7-4430-4dc0-bd1b-6269ed57d1e1: Found 0 pods out of 5
  E0521 17:24:57.282393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:58.282425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:24:59.283506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:00.283865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:01.284937      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:25:01.960979 22 resource.go:87] Pod name wrapped-volume-race-f5451ea7-4430-4dc0-bd1b-6269ed57d1e1: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 05/21/24 17:25:01.961
  STEP: deleting ReplicationController wrapped-volume-race-f5451ea7-4430-4dc0-bd1b-6269ed57d1e1 in namespace emptydir-wrapper-4721, will wait for the garbage collector to delete the pods @ 05/21/24 17:25:01.968
  I0521 17:25:02.030837 22 resources.go:139] Deleting ReplicationController wrapped-volume-race-f5451ea7-4430-4dc0-bd1b-6269ed57d1e1 took: 10.297692ms
  I0521 17:25:02.131395 22 resources.go:163] Terminating ReplicationController wrapped-volume-race-f5451ea7-4430-4dc0-bd1b-6269ed57d1e1 pods took: 100.564541ms
  E0521 17:25:02.285521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-f13255cf-2d05-4ea4-9602-f3d40b024694 in namespace emptydir-wrapper-4721, will wait for the garbage collector to delete the pods @ 05/21/24 17:25:03.032
  I0521 17:25:03.097716 22 resources.go:139] Deleting ReplicationController wrapped-volume-race-f13255cf-2d05-4ea4-9602-f3d40b024694 took: 9.371855ms
  I0521 17:25:03.198948 22 resources.go:163] Terminating ReplicationController wrapped-volume-race-f13255cf-2d05-4ea4-9602-f3d40b024694 pods took: 101.236618ms
  E0521 17:25:03.286226      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-64f79038-1169-4e87-bb53-9d401ae6895f in namespace emptydir-wrapper-4721, will wait for the garbage collector to delete the pods @ 05/21/24 17:25:04.1
  I0521 17:25:04.164180 22 resources.go:139] Deleting ReplicationController wrapped-volume-race-64f79038-1169-4e87-bb53-9d401ae6895f took: 7.849231ms
  I0521 17:25:04.264910 22 resources.go:163] Terminating ReplicationController wrapped-volume-race-64f79038-1169-4e87-bb53-9d401ae6895f pods took: 100.731218ms
  E0521 17:25:04.287100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 05/21/24 17:25:05.065
  I0521 17:25:05.217037 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-4721" for this suite. @ 05/21/24 17:25:05.219
• [18.712 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 05/21/24 17:25:05.224
  I0521 17:25:05.224205 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-preemption @ 05/21/24 17:25:05.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:25:05.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:25:05.236
  I0521 17:25:05.250918 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0521 17:25:05.288312      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:06.289101      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:07.290037      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:08.290599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:09.290760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:10.290650      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:11.291594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:12.292745      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:13.293251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:14.293483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:15.294035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:16.294694      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:17.295315      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:18.295524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:19.296537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:20.297525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:21.297789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:22.298625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:23.299759      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:24.300452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:25.300482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:26.300997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:27.301499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:28.302614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:29.303570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:30.304393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:31.305058      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:32.305604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:33.306677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:34.307707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:35.308686      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:36.309393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:37.309620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:38.310526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:39.311450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:40.311948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:41.312994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:42.313711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:43.314569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:44.314894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:45.315443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:46.316429      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:47.316922      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:48.317620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:49.318529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:50.319214      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:51.319427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:52.320410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:53.320546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:54.321657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:55.321997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:56.322242      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:57.323278      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:58.323671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:25:59.323994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:00.325144      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:01.326237      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:02.326634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:03.327513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:04.327751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:26:05.256986 22 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 05/21/24 17:26:05.262
  I0521 17:26:05.262540 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-preemption-path @ 05/21/24 17:26:05.263
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:26:05.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:26:05.28
  STEP: Finding an available node @ 05/21/24 17:26:05.285
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/21/24 17:26:05.285
  E0521 17:26:05.328697      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:06.328795      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/21/24 17:26:07.299
  I0521 17:26:07.309011 22 preemption.go:583] found a healthy node: k8sconformance-m02
  E0521 17:26:07.329368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:08.329699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:09.330650      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:10.331134      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:11.331491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:12.331720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:13.331927      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:26:13.370458 22 preemption.go:706] pods created so far: [1 1 1]
  I0521 17:26:13.370511 22 preemption.go:707] length of pods created so far: 3
  E0521 17:26:14.332167      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:15.332792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:26:15.380918 22 preemption.go:724] pods created so far: [2 2 1]
  E0521 17:26:16.333640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:17.334302      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:18.335254      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:19.335573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:20.336120      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:21.336603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:22.336729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:26:22.438263 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-7511" for this suite. @ 05/21/24 17:26:22.44
  I0521 17:26:22.444634 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3994" for this suite. @ 05/21/24 17:26:22.447
• [77.227 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 05/21/24 17:26:22.451
  I0521 17:26:22.451655 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 17:26:22.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:26:22.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:26:22.464
  I0521 17:26:22.497358 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7796" for this suite. @ 05/21/24 17:26:22.5
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 05/21/24 17:26:22.505
  I0521 17:26:22.505524 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename containers @ 05/21/24 17:26:22.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:26:22.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:26:22.52
  STEP: Creating a pod to test override command @ 05/21/24 17:26:22.522
  E0521 17:26:23.337534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:24.338440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:25.339419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:26.339574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:26:26.542
  I0521 17:26:26.545683 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod client-containers-9a8913b0-77ef-4c02-a72f-7c52d506e13c container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:26:26.562
  I0521 17:26:26.575890 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4791" for this suite. @ 05/21/24 17:26:26.578
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 05/21/24 17:26:26.582
  I0521 17:26:26.582727 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 17:26:26.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:26:26.592
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:26:26.594
  STEP: Creating projection with secret that has name secret-emptykey-test-bc451624-ab84-4c26-9e78-c74fcf40957f @ 05/21/24 17:26:26.596
  I0521 17:26:26.597892 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6255" for this suite. @ 05/21/24 17:26:26.6
• [0.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 05/21/24 17:26:26.604
  I0521 17:26:26.604606 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 17:26:26.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:26:26.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:26:26.618
  STEP: creating the pod @ 05/21/24 17:26:26.62
  STEP: submitting the pod to kubernetes @ 05/21/24 17:26:26.621
  W0521 17:26:26.627808      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0521 17:26:27.340546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:28.340565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 05/21/24 17:26:28.64
  STEP: updating the pod @ 05/21/24 17:26:28.643
  I0521 17:26:29.159949 22 pod_client.go:141] Successfully updated pod "pod-update-activedeadlineseconds-105df262-a7be-4491-a171-b2901593942d"
  E0521 17:26:29.341382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:30.342015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:31.342527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:32.343515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:26:33.174178 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8467" for this suite. @ 05/21/24 17:26:33.177
• [6.579 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 05/21/24 17:26:33.184
  I0521 17:26:33.184277 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 17:26:33.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:26:33.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:26:33.203
  STEP: Counting existing ResourceQuota @ 05/21/24 17:26:33.206
  E0521 17:26:33.344376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:34.345052      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:35.345979      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:36.346158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:37.346421      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/21/24 17:26:38.209
  STEP: Ensuring resource quota status is calculated @ 05/21/24 17:26:38.213
  E0521 17:26:38.346889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:39.347029      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 05/21/24 17:26:40.219
  STEP: Ensuring resource quota status captures replication controller creation @ 05/21/24 17:26:40.234
  E0521 17:26:40.347878      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:41.348620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 05/21/24 17:26:42.238
  STEP: Ensuring resource quota status released usage @ 05/21/24 17:26:42.244
  E0521 17:26:42.349002      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:43.349565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:26:44.250704 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2318" for this suite. @ 05/21/24 17:26:44.253
• [11.076 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 05/21/24 17:26:44.259
  I0521 17:26:44.259973 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 17:26:44.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:26:44.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:26:44.277
  STEP: Creating resourceQuota "e2e-rq-status-sgnvw" @ 05/21/24 17:26:44.283
  I0521 17:26:44.289486 22 resource_quota.go:1051] Resource quota "e2e-rq-status-sgnvw" reports spec: hard cpu limit of 500m
  I0521 17:26:44.289538 22 resource_quota.go:1053] Resource quota "e2e-rq-status-sgnvw" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-sgnvw" /status @ 05/21/24 17:26:44.289
  STEP: Confirm /status for "e2e-rq-status-sgnvw" resourceQuota via watch @ 05/21/24 17:26:44.297
  I0521 17:26:44.299119 22 resource_quota.go:1080] observed resourceQuota "e2e-rq-status-sgnvw" in namespace "resourcequota-5085" with hard status: v1.ResourceList(nil)
  I0521 17:26:44.299232 22 resource_quota.go:1083] Found resourceQuota "e2e-rq-status-sgnvw" in namespace "resourcequota-5085" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0521 17:26:44.299259 22 resource_quota.go:1090] ResourceQuota "e2e-rq-status-sgnvw" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 05/21/24 17:26:44.301
  I0521 17:26:44.305957 22 resource_quota.go:1101] Resource quota "e2e-rq-status-sgnvw" reports spec: hard cpu limit of 1
  I0521 17:26:44.306000 22 resource_quota.go:1102] Resource quota "e2e-rq-status-sgnvw" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-sgnvw" /status @ 05/21/24 17:26:44.306
  STEP: Confirm /status for "e2e-rq-status-sgnvw" resourceQuota via watch @ 05/21/24 17:26:44.311
  I0521 17:26:44.312777 22 resource_quota.go:1124] observed resourceQuota "e2e-rq-status-sgnvw" in namespace "resourcequota-5085" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0521 17:26:44.312808 22 resource_quota.go:1127] Found resourceQuota "e2e-rq-status-sgnvw" in namespace "resourcequota-5085" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0521 17:26:44.312823 22 resource_quota.go:1134] ResourceQuota "e2e-rq-status-sgnvw" /status was patched
  STEP: Get "e2e-rq-status-sgnvw" /status @ 05/21/24 17:26:44.312
  I0521 17:26:44.314556 22 resource_quota.go:1145] Resourcequota "e2e-rq-status-sgnvw" reports status: hard cpu of 1
  I0521 17:26:44.314577 22 resource_quota.go:1147] Resourcequota "e2e-rq-status-sgnvw" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-sgnvw" /status before checking Spec is unchanged @ 05/21/24 17:26:44.316
  I0521 17:26:44.320079 22 resource_quota.go:1167] Resourcequota "e2e-rq-status-sgnvw" reports status: hard cpu of 2
  I0521 17:26:44.320120 22 resource_quota.go:1169] Resourcequota "e2e-rq-status-sgnvw" reports status: hard memory of 2Gi
  I0521 17:26:44.320961 22 resource_quota.go:1181] Found resourceQuota "e2e-rq-status-sgnvw" in namespace "resourcequota-5085" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0521 17:26:44.322492 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1c2a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1c318), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1c3a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:26:44.349752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:45.350162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:46.350675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:47.351643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:48.352575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:26:49.323624 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1c5d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1c630), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1c6a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:26:49.352685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:50.353376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:51.353639      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:52.353986      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:53.354890      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:26:54.326004 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1c8d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1c900), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1c930), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:26:54.355286      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:55.355745      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:56.356537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:57.356591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:26:58.356862      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:26:59.326474 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1ca98), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1cb28), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1cb88), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:26:59.357513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:00.357834      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:01.358540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:02.359521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:03.360414      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:04.326497 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049844b0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049844e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984528), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:04.361439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:05.362374      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:06.362432      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:07.362477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:08.363545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:09.325307 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1cf30), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1cfa8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1d020), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:09.364582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:10.364945      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:11.365107      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:12.365563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:13.365806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:14.326097 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c1e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c240), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c300), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:14.366233      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:15.366925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:16.367373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:17.367570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:18.368052      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:19.325728 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049847f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984870), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049848b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:19.368917      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:20.369916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:21.370912      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:22.371375      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:23.371688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:24.326487 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1d5c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1d5f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1d620), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:24.372713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:25.373622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:26.374751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:27.375732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:28.376553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:29.323628 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1d860), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1d8c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1d908), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:29.376920      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:30.376981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:31.377564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:32.377651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:33.377937      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:34.325113 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1da88), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1dad0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1db00), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:34.378161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:35.378948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:36.379548      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:37.379883      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:38.380833      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:39.325480 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984c18), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984c48), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984cc0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:39.381853      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:40.381953      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:41.382458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:42.383434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:43.384471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:44.325587 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1dd88), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1ddb8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004b1dde8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:44.384980      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:45.386008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:46.386634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:47.387578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:48.388141      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:49.324695 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c840), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c888), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c8d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:49.388889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:50.389739      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:51.391312      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:52.390734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:53.391135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:54.326015 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c0f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c138), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c1b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:54.391280      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:55.391482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:56.391834      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:57.392347      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:27:58.392585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:27:59.326685 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984060), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049840a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049840d8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:27:59.392861      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:00.393970      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:01.394560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:02.395638      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:03.396086      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:04.324795 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a82e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a8360), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a8390), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:04.397022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:05.397156      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:06.397472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:07.398666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:08.398896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:09.326083 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a86d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a8750), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a88a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:09.399383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:10.400358      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:11.400510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:12.400602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:13.401568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:14.325405 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984420), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984468), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984498), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:14.402430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:15.403323      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:16.403498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:17.403578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:18.404590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:19.325844 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a8cf0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a8d80), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a8e10), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:19.405075      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:20.406000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:21.406453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:22.406699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:23.407576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:24.326731 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a9170), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a9200), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a92a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:24.407931      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:25.408882      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:26.409471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:27.409557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:28.410625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:29.325667 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c4e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c540), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c5a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:29.411706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:30.412011      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:31.412172      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:32.412472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:33.413490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:34.326703 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049848b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049849a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984a20), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:34.413811      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:35.414893      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:36.415927      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:37.416620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:38.416986      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:39.324476 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984c00), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984c30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984c90), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:39.417587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:40.417944      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:41.418418      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:42.418495      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:43.419619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:44.327109 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984ed0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984f30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004984f78), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:44.420470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:45.420524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:46.420785      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:47.421654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:48.422330      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:49.323041 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004985110), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004985188), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049851d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:49.422427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:50.423114      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:51.423360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:52.423797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:53.424078      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:54.326044 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a9668), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a96e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a9710), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:54.424267      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:55.424358      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:56.424479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:57.425001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:28:58.425612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:28:59.325676 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c9a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414c9d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414ca50), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:28:59.425842      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:00.426247      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:01.426851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:02.427055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:03.427790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:29:04.326217 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a9b00), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a9b90), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045a9c20), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:29:04.428508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:05.429627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:06.430628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:07.431127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:08.431227      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:29:09.326296 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414cc90), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414ccf0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00414cd20), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:29:09.431358      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:10.432343      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:11.432642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:12.432916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:13.433596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:29:14.326156 22 resource_quota.go:1212] ResourceQuota "e2e-rq-status-sgnvw" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-sgnvw", GenerateName:"", Namespace:"resourcequota-5085", SelfLink:"", UID:"4e078e4d-2af3-4106-b167-e426e37eb21c", ResourceVersion:"17072", Generation:0, CreationTimestamp:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-sgnvw"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0049855d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004985608), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.May, 21, 17, 26, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004985668), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0521 17:29:14.434607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:15.434668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:16.435243      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:17.435483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:18.435796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:29:19.326177 22 resource_quota.go:1209] ResourceQuota "e2e-rq-status-sgnvw" Spec was unchanged and /status reset
  I0521 17:29:19.326373 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5085" for this suite. @ 05/21/24 17:29:19.329
• [155.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 05/21/24 17:29:19.335
  I0521 17:29:19.335570 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 17:29:19.336
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:29:19.348
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:29:19.352
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 05/21/24 17:29:19.355
  E0521 17:29:19.436942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:20.437847      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:29:21.369
  I0521 17:29:21.371661 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-928a4551-ffaf-44c5-9cb9-ce51593db7f9 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:29:21.389
  I0521 17:29:21.403725 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3376" for this suite. @ 05/21/24 17:29:21.406
• [2.075 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 05/21/24 17:29:21.41
  I0521 17:29:21.410483 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename init-container @ 05/21/24 17:29:21.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:29:21.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:29:21.422
  STEP: creating the pod @ 05/21/24 17:29:21.423
  I0521 17:29:21.423324 22 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E0521 17:29:21.438003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:22.438476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:23.439291      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:24.439869      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:29:25.328157 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2231" for this suite. @ 05/21/24 17:29:25.331
• [3.925 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:601
  STEP: Creating a kubernetes client @ 05/21/24 17:29:25.335
  I0521 17:29:25.335637 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename job @ 05/21/24 17:29:25.336
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:29:25.347
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:29:25.348
  STEP: Creating a job @ 05/21/24 17:29:25.35
  STEP: Ensuring job reaches completions @ 05/21/24 17:29:25.355
  E0521 17:29:25.440425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:26.441538      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:27.442340      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:28.442400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:29.442966      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:30.443060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:31.444250      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:32.444416      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:33.445535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:34.446625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:29:35.358452 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8824" for this suite. @ 05/21/24 17:29:35.36
• [10.031 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 05/21/24 17:29:35.366
  I0521 17:29:35.366988 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename prestop @ 05/21/24 17:29:35.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:29:35.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:29:35.381
  STEP: Creating server pod server in namespace prestop-2045 @ 05/21/24 17:29:35.384
  STEP: Waiting for pods to come up. @ 05/21/24 17:29:35.39
  E0521 17:29:35.447379      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:36.447609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-2045 @ 05/21/24 17:29:37.401
  E0521 17:29:37.448345      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:38.448497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 05/21/24 17:29:39.419
  E0521 17:29:39.449016      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:40.449462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:41.450539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:42.451506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:43.451950      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:29:44.430998 22 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 05/21/24 17:29:44.431
  I0521 17:29:44.444562 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-2045" for this suite. @ 05/21/24 17:29:44.448
  E0521 17:29:44.452226      22 retrywatcher.go:129] "Watch failed" err="context canceled"
• [9.088 seconds]
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:334
  STEP: Creating a kubernetes client @ 05/21/24 17:29:44.454
  I0521 17:29:44.454948 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-pred @ 05/21/24 17:29:44.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:29:44.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:29:44.471
  I0521 17:29:44.472719 22 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0521 17:29:44.475517 22 util.go:400] Waiting for terminating namespaces to be deleted...
  I0521 17:29:44.476834 22 predicates.go:121] 
  Logging pods the apiserver thinks is on node k8sconformance before test
  I0521 17:29:44.480803 22 predicates.go:887] coredns-7db6d8ff4d-5h9wx from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.480833 22 predicates.go:889] 	Container coredns ready: true, restart count 1
  I0521 17:29:44.480844 22 predicates.go:887] etcd-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.480851 22 predicates.go:889] 	Container etcd ready: true, restart count 0
  I0521 17:29:44.480859 22 predicates.go:887] kindnet-x4z6c from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.480865 22 predicates.go:889] 	Container kindnet-cni ready: true, restart count 0
  I0521 17:29:44.480873 22 predicates.go:887] kube-apiserver-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.480879 22 predicates.go:889] 	Container kube-apiserver ready: true, restart count 0
  I0521 17:29:44.480888 22 predicates.go:887] kube-controller-manager-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.480895 22 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 0
  I0521 17:29:44.480902 22 predicates.go:887] kube-proxy-bk2bg from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.480909 22 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0521 17:29:44.480916 22 predicates.go:887] kube-scheduler-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.480922 22 predicates.go:889] 	Container kube-scheduler ready: true, restart count 0
  I0521 17:29:44.480930 22 predicates.go:887] storage-provisioner from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.480937 22 predicates.go:889] 	Container storage-provisioner ready: true, restart count 1
  I0521 17:29:44.480944 22 predicates.go:887] sonobuoy-systemd-logs-daemon-set-05530e69374c4820-8kzzl from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 17:29:44.480951 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 17:29:44.480957 22 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0521 17:29:44.480964 22 predicates.go:121] 
  Logging pods the apiserver thinks is on node k8sconformance-m02 before test
  I0521 17:29:44.483469 22 predicates.go:887] kindnet-bnm9k from kube-system started at 2024-05-21 17:04:51 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.483485 22 predicates.go:889] 	Container kindnet-cni ready: true, restart count 0
  I0521 17:29:44.483491 22 predicates.go:887] kube-proxy-8nnv4 from kube-system started at 2024-05-21 16:34:28 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.483496 22 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0521 17:29:44.483502 22 predicates.go:887] tester from prestop-2045 started at 2024-05-21 17:29:37 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.483506 22 predicates.go:889] 	Container tester ready: true, restart count 0
  I0521 17:29:44.483512 22 predicates.go:887] sonobuoy from sonobuoy started at 2024-05-21 16:38:41 +0000 UTC (1 container statuses recorded)
  I0521 17:29:44.483516 22 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0521 17:29:44.483522 22 predicates.go:887] sonobuoy-e2e-job-6986495216344806 from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 17:29:44.483527 22 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0521 17:29:44.483532 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 17:29:44.483540 22 predicates.go:887] sonobuoy-systemd-logs-daemon-set-05530e69374c4820-9t6gh from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 17:29:44.483545 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 17:29:44.483550 22 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node k8sconformance @ 05/21/24 17:29:44.494
  STEP: verifying the node has the label node k8sconformance-m02 @ 05/21/24 17:29:44.509
  I0521 17:29:44.521068 22 predicates.go:374] Pod coredns-7db6d8ff4d-5h9wx requesting resource cpu=100m on Node k8sconformance
  I0521 17:29:44.521116 22 predicates.go:374] Pod etcd-k8sconformance requesting resource cpu=100m on Node k8sconformance
  I0521 17:29:44.521135 22 predicates.go:374] Pod kindnet-bnm9k requesting resource cpu=100m on Node k8sconformance-m02
  I0521 17:29:44.521151 22 predicates.go:374] Pod kindnet-x4z6c requesting resource cpu=100m on Node k8sconformance
  I0521 17:29:44.521164 22 predicates.go:374] Pod kube-apiserver-k8sconformance requesting resource cpu=250m on Node k8sconformance
  I0521 17:29:44.521178 22 predicates.go:374] Pod kube-controller-manager-k8sconformance requesting resource cpu=200m on Node k8sconformance
  I0521 17:29:44.521206 22 predicates.go:374] Pod kube-proxy-8nnv4 requesting resource cpu=0m on Node k8sconformance-m02
  I0521 17:29:44.521221 22 predicates.go:374] Pod kube-proxy-bk2bg requesting resource cpu=0m on Node k8sconformance
  I0521 17:29:44.521235 22 predicates.go:374] Pod kube-scheduler-k8sconformance requesting resource cpu=100m on Node k8sconformance
  I0521 17:29:44.521247 22 predicates.go:374] Pod storage-provisioner requesting resource cpu=0m on Node k8sconformance
  I0521 17:29:44.521260 22 predicates.go:374] Pod tester requesting resource cpu=0m on Node k8sconformance-m02
  I0521 17:29:44.521273 22 predicates.go:374] Pod sonobuoy requesting resource cpu=0m on Node k8sconformance-m02
  I0521 17:29:44.521287 22 predicates.go:374] Pod sonobuoy-e2e-job-6986495216344806 requesting resource cpu=0m on Node k8sconformance-m02
  I0521 17:29:44.521299 22 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-05530e69374c4820-8kzzl requesting resource cpu=0m on Node k8sconformance
  I0521 17:29:44.521314 22 predicates.go:374] Pod sonobuoy-systemd-logs-daemon-set-05530e69374c4820-9t6gh requesting resource cpu=0m on Node k8sconformance-m02
  STEP: Starting Pods to consume most of the cluster CPU. @ 05/21/24 17:29:44.521
  I0521 17:29:44.521371 22 predicates.go:384] Creating a pod which consumes cpu=7805m on Node k8sconformance
  I0521 17:29:44.529613 22 predicates.go:384] Creating a pod which consumes cpu=8330m on Node k8sconformance-m02
  E0521 17:29:45.452564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:46.452629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 05/21/24 17:29:46.552
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-16140eda-0667-4a10-b6b3-67d7738a22fb.17d19133c537e255], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3121/filler-pod-16140eda-0667-4a10-b6b3-67d7738a22fb to k8sconformance-m02] @ 05/21/24 17:29:46.555
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-16140eda-0667-4a10-b6b3-67d7738a22fb.17d19133e2ffa1e9], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/21/24 17:29:46.555
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-16140eda-0667-4a10-b6b3-67d7738a22fb.17d19133e5143b0b], Reason = [Created], Message = [Created container filler-pod-16140eda-0667-4a10-b6b3-67d7738a22fb] @ 05/21/24 17:29:46.555
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-16140eda-0667-4a10-b6b3-67d7738a22fb.17d19133e90f8d22], Reason = [Started], Message = [Started container filler-pod-16140eda-0667-4a10-b6b3-67d7738a22fb] @ 05/21/24 17:29:46.555
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9d16772b-9866-403a-9486-f94b17985425.17d19133c4ba26bd], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3121/filler-pod-9d16772b-9866-403a-9486-f94b17985425 to k8sconformance] @ 05/21/24 17:29:46.555
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9d16772b-9866-403a-9486-f94b17985425.17d19133e2fdaf48], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 05/21/24 17:29:46.555
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9d16772b-9866-403a-9486-f94b17985425.17d19133e52c38c9], Reason = [Created], Message = [Created container filler-pod-9d16772b-9866-403a-9486-f94b17985425] @ 05/21/24 17:29:46.555
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-9d16772b-9866-403a-9486-f94b17985425.17d19133e8ff1362], Reason = [Started], Message = [Started container filler-pod-9d16772b-9866-403a-9486-f94b17985425] @ 05/21/24 17:29:46.555
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17d191343da3e577], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] @ 05/21/24 17:29:46.567
  E0521 17:29:47.453663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node k8sconformance-m02 @ 05/21/24 17:29:47.568
  STEP: verifying the node doesn't have the label node @ 05/21/24 17:29:47.581
  STEP: removing the label node off the node k8sconformance @ 05/21/24 17:29:47.585
  STEP: verifying the node doesn't have the label node @ 05/21/24 17:29:47.597
  I0521 17:29:47.601635 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3121" for this suite. @ 05/21/24 17:29:47.606
• [3.159 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:70
  STEP: Creating a kubernetes client @ 05/21/24 17:29:47.614
  I0521 17:29:47.614665 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/21/24 17:29:47.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:29:47.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:29:47.638
  I0521 17:29:47.642114 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:29:48.454676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 05/21/24 17:29:48.798
  I0521 17:29:48.798080 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 --namespace=crd-publish-openapi-5692 create -f -'
  E0521 17:29:49.455608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:50.456290      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:29:50.852548 22 builder.go:146] stderr: ""
  I0521 17:29:50.852621 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5716-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0521 17:29:50.852725 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 --namespace=crd-publish-openapi-5692 delete e2e-test-crd-publish-openapi-5716-crds test-foo'
  I0521 17:29:50.902714 22 builder.go:146] stderr: ""
  I0521 17:29:50.902754 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5716-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I0521 17:29:50.902801 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 --namespace=crd-publish-openapi-5692 apply -f -'
  I0521 17:29:50.955304 22 builder.go:146] stderr: ""
  I0521 17:29:50.955338 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5716-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0521 17:29:50.955391 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 --namespace=crd-publish-openapi-5692 delete e2e-test-crd-publish-openapi-5716-crds test-foo'
  I0521 17:29:51.004812 22 builder.go:146] stderr: ""
  I0521 17:29:51.004837 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5716-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 05/21/24 17:29:51.004
  I0521 17:29:51.004885 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 --namespace=crd-publish-openapi-5692 create -f -'
  I0521 17:29:51.041678 22 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 05/21/24 17:29:51.041
  I0521 17:29:51.041752 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 --namespace=crd-publish-openapi-5692 create -f -'
  I0521 17:29:51.078301 22 builder.go:135] rc: 1
  I0521 17:29:51.078376 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 --namespace=crd-publish-openapi-5692 apply -f -'
  I0521 17:29:51.115776 22 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 05/21/24 17:29:51.115
  I0521 17:29:51.115901 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 --namespace=crd-publish-openapi-5692 create -f -'
  I0521 17:29:51.154851 22 builder.go:135] rc: 1
  I0521 17:29:51.154921 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 --namespace=crd-publish-openapi-5692 apply -f -'
  I0521 17:29:51.195085 22 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 05/21/24 17:29:51.195
  I0521 17:29:51.195194 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 explain e2e-test-crd-publish-openapi-5716-crds'
  I0521 17:29:51.229179 22 builder.go:146] stderr: ""
  I0521 17:29:51.229235 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5716-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 05/21/24 17:29:51.229
  I0521 17:29:51.229485 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 explain e2e-test-crd-publish-openapi-5716-crds.metadata'
  I0521 17:29:51.264304 22 builder.go:146] stderr: ""
  I0521 17:29:51.264429 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5716-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0521 17:29:51.265231 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 explain e2e-test-crd-publish-openapi-5716-crds.spec'
  I0521 17:29:51.302453 22 builder.go:146] stderr: ""
  I0521 17:29:51.302491 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5716-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0521 17:29:51.302610 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 explain e2e-test-crd-publish-openapi-5716-crds.spec.bars'
  I0521 17:29:51.338713 22 builder.go:146] stderr: ""
  I0521 17:29:51.338753 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5716-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 05/21/24 17:29:51.338
  I0521 17:29:51.338933 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-5692 explain e2e-test-crd-publish-openapi-5716-crds.spec.bars2'
  I0521 17:29:51.375159 22 builder.go:135] rc: 1
  E0521 17:29:51.457354      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:52.457352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:29:52.506448 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5692" for this suite. @ 05/21/24 17:29:52.511
• [4.899 seconds]
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 05/21/24 17:29:52.513
  I0521 17:29:52.514008 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-preemption @ 05/21/24 17:29:52.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:29:52.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:29:52.523
  I0521 17:29:52.535497 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0521 17:29:53.458677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:54.459591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:55.459844      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:56.460752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:57.461731      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:58.462281      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:29:59.462450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:00.463232      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:01.463590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:02.463846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:03.464101      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:04.464555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:05.465472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:06.465756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:07.466251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:08.466709      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:09.467235      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:10.468160      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:11.468583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:12.468783      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:13.469718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:14.470328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:15.471152      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:16.471468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:17.471721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:18.472710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:19.473175      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:20.473831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:21.473948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:22.474844      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:23.475606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:24.475982      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:25.476158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:26.476592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:27.476683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:28.477269      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:29.478248      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:30.479098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:31.479407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:32.479397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:33.480405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:34.481552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:35.482559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:36.482990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:37.483451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:38.483519      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:39.484576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:40.485417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:41.486129      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:42.486591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:43.487475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:44.488560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:45.488676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:46.489169      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:47.490373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:48.490803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:49.491462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:50.492372      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:51.492519      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:52.492579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:30:52.541647 22 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/21/24 17:30:52.544
  I0521 17:30:52.564019 22 preemption.go:178] Created pod: pod0-0-sched-preemption-low-priority
  I0521 17:30:52.572124 22 preemption.go:178] Created pod: pod0-1-sched-preemption-medium-priority
  I0521 17:30:52.591772 22 preemption.go:178] Created pod: pod1-0-sched-preemption-medium-priority
  I0521 17:30:52.597945 22 preemption.go:178] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/21/24 17:30:52.597
  E0521 17:30:53.493658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:54.493872      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 05/21/24 17:30:54.617
  E0521 17:30:55.494899      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:56.495359      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:57.495485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:58.496605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:30:59.497638      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:00.498486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:31:00.676642 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2152" for this suite. @ 05/21/24 17:31:00.679
• [68.170 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1793
  STEP: Creating a kubernetes client @ 05/21/24 17:31:00.683
  I0521 17:31:00.683987 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 17:31:00.684
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:00.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:00.701
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/21/24 17:31:00.703
  I0521 17:31:00.704071 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-5527 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0521 17:31:00.748693 22 builder.go:146] stderr: ""
  I0521 17:31:00.748716 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 05/21/24 17:31:00.748
  E0521 17:31:01.499003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:02.499071      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:03.499521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:04.500023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:05.501090      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/21/24 17:31:05.8
  I0521 17:31:05.800466 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-5527 get pod e2e-test-httpd-pod -o json'
  I0521 17:31:05.880289 22 builder.go:146] stderr: ""
  I0521 17:31:05.880362 22 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-05-21T17:31:00Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5527\",\n        \"resourceVersion\": \"17686\",\n        \"uid\": \"6d52cafb-da2b-4780-bf8b-f6c676e70920\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-mmmqn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8sconformance-m02\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-mmmqn\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-21T17:31:02Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-21T17:31:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-21T17:31:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-21T17:31:02Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-05-21T17:31:00Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://2f0ee77a3f34ad9f9eb7b3ee365988042c30187b3fb28b9b1adad7dda8e4a615\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-05-21T17:31:01Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.67.3\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"192.168.67.3\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.65\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.1.65\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-05-21T17:31:00Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 05/21/24 17:31:05.88
  I0521 17:31:05.880430 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-5527 replace -f -'
  I0521 17:31:05.976472 22 builder.go:146] stderr: ""
  I0521 17:31:05.976514 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 05/21/24 17:31:05.976
  I0521 17:31:05.978142 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-5527 delete pods e2e-test-httpd-pod'
  E0521 17:31:06.502339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:31:07.491013 22 builder.go:146] stderr: ""
  I0521 17:31:07.491057 22 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0521 17:31:07.491179 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5527" for this suite. @ 05/21/24 17:31:07.493
• [6.815 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 05/21/24 17:31:07.498
  I0521 17:31:07.498953 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 17:31:07.5
  E0521 17:31:07.502459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:07.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:07.509
  STEP: Creating configMap with name configmap-test-volume-612c2268-8d0a-41b9-9624-b5780046f723 @ 05/21/24 17:31:07.511
  STEP: Creating a pod to test consume configMaps @ 05/21/24 17:31:07.515
  E0521 17:31:08.503525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:09.504432      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:10.504582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:11.505650      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:31:11.533
  I0521 17:31:11.536481 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-ba872adb-aeec-4323-bc5b-77e49f581dbb container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:31:11.548
  I0521 17:31:11.559388 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2020" for this suite. @ 05/21/24 17:31:11.561
• [4.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 05/21/24 17:31:11.566
  I0521 17:31:11.566860 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename limitrange @ 05/21/24 17:31:11.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:11.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:11.58
  STEP: Creating a LimitRange @ 05/21/24 17:31:11.582
  STEP: Setting up watch @ 05/21/24 17:31:11.582
  STEP: Submitting a LimitRange @ 05/21/24 17:31:11.686
  STEP: Verifying LimitRange creation was observed @ 05/21/24 17:31:11.695
  STEP: Fetching the LimitRange to ensure it has proper values @ 05/21/24 17:31:11.695
  I0521 17:31:11.698539 22 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0521 17:31:11.698599 22 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 05/21/24 17:31:11.698
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 05/21/24 17:31:11.704
  I0521 17:31:11.708282 22 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0521 17:31:11.708351 22 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 05/21/24 17:31:11.708
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 05/21/24 17:31:11.713
  I0521 17:31:11.716983 22 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0521 17:31:11.717065 22 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 05/21/24 17:31:11.717
  STEP: Failing to create a Pod with more than max resources @ 05/21/24 17:31:11.72
  STEP: Updating a LimitRange @ 05/21/24 17:31:11.722
  STEP: Verifying LimitRange updating is effective @ 05/21/24 17:31:11.726
  E0521 17:31:12.505889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:13.506404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 05/21/24 17:31:13.732
  STEP: Failing to create a Pod with more than max resources @ 05/21/24 17:31:13.74
  STEP: Deleting a LimitRange @ 05/21/24 17:31:13.744
  STEP: Verifying the LimitRange was deleted @ 05/21/24 17:31:13.749
  E0521 17:31:14.507607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:15.508716      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:16.509444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:17.509664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:18.510255      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:31:18.754449 22 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 05/21/24 17:31:18.754
  I0521 17:31:18.763453 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-6410" for this suite. @ 05/21/24 17:31:18.767
• [7.205 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 05/21/24 17:31:18.772
  I0521 17:31:18.772599 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:31:18.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:18.785
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:18.788
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 17:31:18.79
  E0521 17:31:19.510554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:20.511040      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:31:20.803
  I0521 17:31:20.806492 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-587b7c41-97bf-479a-8606-ebb432006f36 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 17:31:20.813
  I0521 17:31:20.823789 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4852" for this suite. @ 05/21/24 17:31:20.825
• [2.055 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 05/21/24 17:31:20.828
  I0521 17:31:20.828060 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:31:20.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:20.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:20.839
  STEP: Creating projection with secret that has name projected-secret-test-map-8bb862f1-cca9-4301-8acc-77141ad79f9b @ 05/21/24 17:31:20.841
  STEP: Creating a pod to test consume secrets @ 05/21/24 17:31:20.845
  E0521 17:31:21.511304      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:22.511668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:31:22.861
  I0521 17:31:22.864935 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-448cdd15-e5b7-485f-8eeb-f9f505765b34 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 17:31:22.871
  I0521 17:31:22.886336 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1393" for this suite. @ 05/21/24 17:31:22.889
• [2.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 05/21/24 17:31:22.894
  I0521 17:31:22.894525 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/21/24 17:31:22.895
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:22.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:22.91
  STEP: creating the policy @ 05/21/24 17:31:22.916
  STEP: waiting until the marker is denied @ 05/21/24 17:31:22.928
  E0521 17:31:23.511733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 05/21/24 17:31:23.535
  STEP: testing a non-replicated ReplicaSet not to be denied @ 05/21/24 17:31:23.547
  I0521 17:31:23.587389 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-810" for this suite. @ 05/21/24 17:31:23.591
• [0.703 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 05/21/24 17:31:23.597
  I0521 17:31:23.597576 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename discovery @ 05/21/24 17:31:23.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:23.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:23.606
  STEP: Setting up server cert @ 05/21/24 17:31:23.607
  STEP: Requesting APIResourceList from "/api/v1" @ 05/21/24 17:31:23.914
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 05/21/24 17:31:23.915
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 05/21/24 17:31:23.916
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 05/21/24 17:31:23.916
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 05/21/24 17:31:23.917
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 05/21/24 17:31:23.917
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 05/21/24 17:31:23.918
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 05/21/24 17:31:23.918
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 05/21/24 17:31:23.919
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 05/21/24 17:31:23.92
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 05/21/24 17:31:23.921
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 05/21/24 17:31:23.921
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 05/21/24 17:31:23.922
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 05/21/24 17:31:23.922
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 05/21/24 17:31:23.923
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 05/21/24 17:31:23.924
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 05/21/24 17:31:23.925
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 05/21/24 17:31:23.925
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 05/21/24 17:31:23.926
  I0521 17:31:23.927647 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-8612" for this suite. @ 05/21/24 17:31:23.93
• [0.337 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 05/21/24 17:31:23.936
  I0521 17:31:23.936933 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 05/21/24 17:31:23.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:23.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:23.948
  STEP: create the container to handle the HTTPGet hook request. @ 05/21/24 17:31:23.952
  E0521 17:31:24.512526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:25.513636      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 05/21/24 17:31:25.965
  E0521 17:31:26.514493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:27.515730      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 05/21/24 17:31:27.975
  E0521 17:31:28.516447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:29.517245      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 05/21/24 17:31:29.987
  I0521 17:31:30.005138 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4046" for this suite. @ 05/21/24 17:31:30.007
• [6.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 05/21/24 17:31:30.014
  I0521 17:31:30.014114 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 17:31:30.015
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:30.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:30.032
  STEP: Counting existing ResourceQuota @ 05/21/24 17:31:30.035
  E0521 17:31:30.517670      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:31.518751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:32.519574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:33.520319      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:34.520964      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/21/24 17:31:35.037
  STEP: Ensuring resource quota status is calculated @ 05/21/24 17:31:35.043
  E0521 17:31:35.522033      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:36.522536      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:31:37.049415 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2229" for this suite. @ 05/21/24 17:31:37.052
• [7.045 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1759
  STEP: Creating a kubernetes client @ 05/21/24 17:31:37.059
  I0521 17:31:37.059306 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 17:31:37.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:37.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:37.074
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 05/21/24 17:31:37.077
  I0521 17:31:37.077307 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8756 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I0521 17:31:37.123180 22 builder.go:146] stderr: ""
  I0521 17:31:37.123226 22 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 05/21/24 17:31:37.123
  I0521 17:31:37.124629 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8756 delete pods e2e-test-httpd-pod'
  E0521 17:31:37.522960      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:38.523646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:31:38.898665 22 builder.go:146] stderr: ""
  I0521 17:31:38.898719 22 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0521 17:31:38.898898 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8756" for this suite. @ 05/21/24 17:31:38.903
• [1.850 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 05/21/24 17:31:38.908
  I0521 17:31:38.908984 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/21/24 17:31:38.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:38.92
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:38.923
  STEP: Creating two CSIDrivers @ 05/21/24 17:31:38.926
  STEP: Getting "inline-driver-8e31b1c6-0b61-470b-a71c-8fda9df8018e" & "inline-driver-4bd02857-f792-4748-b9bc-ae3b8d9e567f" @ 05/21/24 17:31:38.939
  STEP: Patching the CSIDriver "inline-driver-4bd02857-f792-4748-b9bc-ae3b8d9e567f" @ 05/21/24 17:31:38.944
  STEP: Updating the CSIDriver "inline-driver-4bd02857-f792-4748-b9bc-ae3b8d9e567f" @ 05/21/24 17:31:38.951
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-9259" @ 05/21/24 17:31:38.957
  STEP: Deleting CSIDriver "inline-driver-8e31b1c6-0b61-470b-a71c-8fda9df8018e" @ 05/21/24 17:31:38.959
  STEP: Confirm deletion of CSIDriver "inline-driver-8e31b1c6-0b61-470b-a71c-8fda9df8018e" @ 05/21/24 17:31:38.963
  STEP: Deleting CSIDriver "inline-driver-4bd02857-f792-4748-b9bc-ae3b8d9e567f" via DeleteCollection @ 05/21/24 17:31:38.965
  STEP: Confirm deletion of CSIDriver "inline-driver-4bd02857-f792-4748-b9bc-ae3b8d9e567f" @ 05/21/24 17:31:38.97
  I0521 17:31:38.972591 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-9259" for this suite. @ 05/21/24 17:31:38.974
• [0.070 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 05/21/24 17:31:38.979
  I0521 17:31:38.979291 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename discovery @ 05/21/24 17:31:38.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:38.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:38.988
  STEP: Setting up server cert @ 05/21/24 17:31:38.99
  I0521 17:31:39.080586 22 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0521 17:31:39.081339 22 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0521 17:31:39.081393 22 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0521 17:31:39.081399 22 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0521 17:31:39.081404 22 discovery.go:139] Checking APIGroup: apps
  I0521 17:31:39.081865 22 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0521 17:31:39.081886 22 discovery.go:148] Versions found [{apps/v1 v1}]
  I0521 17:31:39.081893 22 discovery.go:154] apps/v1 matches apps/v1
  I0521 17:31:39.081900 22 discovery.go:139] Checking APIGroup: events.k8s.io
  I0521 17:31:39.082378 22 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0521 17:31:39.082389 22 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0521 17:31:39.082393 22 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0521 17:31:39.082395 22 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0521 17:31:39.082848 22 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0521 17:31:39.082866 22 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0521 17:31:39.082871 22 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0521 17:31:39.082877 22 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0521 17:31:39.083411 22 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0521 17:31:39.083417 22 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0521 17:31:39.083420 22 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0521 17:31:39.083424 22 discovery.go:139] Checking APIGroup: autoscaling
  I0521 17:31:39.083813 22 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0521 17:31:39.083830 22 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0521 17:31:39.083837 22 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0521 17:31:39.083843 22 discovery.go:139] Checking APIGroup: batch
  I0521 17:31:39.084255 22 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0521 17:31:39.084260 22 discovery.go:148] Versions found [{batch/v1 v1}]
  I0521 17:31:39.084263 22 discovery.go:154] batch/v1 matches batch/v1
  I0521 17:31:39.084266 22 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0521 17:31:39.084641 22 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0521 17:31:39.084658 22 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0521 17:31:39.084665 22 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0521 17:31:39.084671 22 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0521 17:31:39.085078 22 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0521 17:31:39.085083 22 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0521 17:31:39.085085 22 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0521 17:31:39.085088 22 discovery.go:139] Checking APIGroup: policy
  I0521 17:31:39.085464 22 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0521 17:31:39.085481 22 discovery.go:148] Versions found [{policy/v1 v1}]
  I0521 17:31:39.085488 22 discovery.go:154] policy/v1 matches policy/v1
  I0521 17:31:39.085493 22 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0521 17:31:39.085889 22 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0521 17:31:39.085894 22 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0521 17:31:39.085897 22 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0521 17:31:39.085900 22 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0521 17:31:39.086256 22 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0521 17:31:39.086261 22 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0521 17:31:39.086264 22 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0521 17:31:39.086267 22 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0521 17:31:39.086655 22 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0521 17:31:39.086672 22 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0521 17:31:39.086678 22 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0521 17:31:39.086684 22 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0521 17:31:39.087080 22 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0521 17:31:39.087086 22 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0521 17:31:39.087088 22 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0521 17:31:39.087098 22 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0521 17:31:39.087487 22 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0521 17:31:39.087504 22 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0521 17:31:39.087511 22 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0521 17:31:39.087529 22 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0521 17:31:39.087954 22 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0521 17:31:39.087958 22 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0521 17:31:39.087961 22 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0521 17:31:39.087963 22 discovery.go:139] Checking APIGroup: node.k8s.io
  I0521 17:31:39.088414 22 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0521 17:31:39.088428 22 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0521 17:31:39.088433 22 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0521 17:31:39.088440 22 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0521 17:31:39.088858 22 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0521 17:31:39.088863 22 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0521 17:31:39.088866 22 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0521 17:31:39.088872 22 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0521 17:31:39.089283 22 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0521 17:31:39.089300 22 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  I0521 17:31:39.089306 22 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0521 17:31:39.089365 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-6063" for this suite. @ 05/21/24 17:31:39.09
• [0.116 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 05/21/24 17:31:39.094
  I0521 17:31:39.094839 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:31:39.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:39.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:39.102
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 17:31:39.103
  E0521 17:31:39.524425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:40.525348      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:31:41.116
  I0521 17:31:41.119027 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-03bbaf76-5a6b-4a6a-8f0c-89a9c48a0310 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 17:31:41.125
  I0521 17:31:41.140243 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4575" for this suite. @ 05/21/24 17:31:41.143
• [2.053 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 05/21/24 17:31:41.148
  I0521 17:31:41.148381 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename deployment @ 05/21/24 17:31:41.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:41.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:41.166
  I0521 17:31:41.168158 22 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0521 17:31:41.173284 22 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0521 17:31:41.525982      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:42.527039      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:43.527426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:44.527890      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:45.528556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:31:46.176374 22 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/21/24 17:31:46.176
  I0521 17:31:46.176459 22 deployment.go:763] Creating deployment "test-rolling-update-deployment"
  I0521 17:31:46.181352 22 deployment.go:769] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0521 17:31:46.185645 22 deployment.go:222] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0521 17:31:46.529136      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:47.529660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:31:48.195238 22 deployment.go:773] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0521 17:31:48.197734 22 deployment.go:778] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0521 17:31:48.206632 22 deployment.go:633] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-905",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5dac93a9-fe05-4ef1-9e27-d551ea9cbc3c",
      ResourceVersion: (string) (len=5) "18272",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851909506,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-6f4b778cd6\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0521 17:31:48.211921 22 deployment.go:39] New ReplicaSet "test-rolling-update-deployment-6f4b778cd6" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-6f4b778cd6",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-905",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3251bf8f-8bf5-4533-b378-f5c1cd0b0d03",
      ResourceVersion: (string) (len=5) "18262",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851909506,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "5dac93a9-fe05-4ef1-9e27-d551ea9cbc3c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 64 61 63 39 33  61 39 2d 66 65 30 35 2d  |\"5dac93a9-fe05-|
              00000120  34 65 66 31 2d 39 65 32  37 2d 64 35 35 31 65 61  |4ef1-9e27-d551ea|
              00000130  39 63 62 63 33 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |9cbc3c\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 17:31:48.213040 22 deployment.go:44] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0521 17:31:48.213366 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-905",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7ce3aacd-517f-4d10-865b-9dff1ea78507",
      ResourceVersion: (string) (len=5) "18271",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851909501,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "5dac93a9-fe05-4ef1-9e27-d551ea9cbc3c",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909501,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 35 64 61 63 39 33 61  |"uid\":\"5dac93a|
              000000b0  39 2d 66 65 30 35 2d 34  65 66 31 2d 39 65 32 37  |9-fe05-4ef1-9e27|
              000000c0  2d 64 35 35 31 65 61 39  63 62 63 33 63 5c 22 7d  |-d551ea9cbc3c\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909507,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 17:31:48.216921 22 deployment.go:67] Pod "test-rolling-update-deployment-6f4b778cd6-gv6r7" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-6f4b778cd6-gv6r7",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-6f4b778cd6-",
      Namespace: (string) (len=14) "deployment-905",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "815eb073-d53e-4da4-a57f-d786ee8f42b8",
      ResourceVersion: (string) (len=5) "18261",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851909506,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f4b778cd6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-6f4b778cd6",
          UID: (types.UID) (len=36) "3251bf8f-8bf5-4533-b378-f5c1cd0b0d03",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 32  35 31 62 66 38 66 2d 38  |d\":\"3251bf8f-8|
              00000090  62 66 35 2d 34 35 33 33  2d 62 33 37 38 2d 66 35  |bf5-4533-b378-f5|
              000000a0  63 31 63 64 30 62 30 64  30 33 5c 22 7d 22 3a 7b  |c1cd0b0d03\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 37  35 5c 22 7d 22 3a 7b 22  |.244.1.75\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mxtxt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mxtxt",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851909506,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=11) "10.244.1.75",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.244.1.75"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851909506,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851909506,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=129) "docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=73) "docker://56a18a81b254fbfe55f411170fe5c82ca6703e65f7ca3009582f1825f3d7dbc2",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 17:31:48.218202 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-905" for this suite. @ 05/21/24 17:31:48.22
• [7.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 05/21/24 17:31:48.225
  I0521 17:31:48.225580 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 17:31:48.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:48.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:48.24
  STEP: creating secret secrets-6560/secret-test-19efd050-adbc-4f90-bb92-a4604f25a9c7 @ 05/21/24 17:31:48.243
  STEP: Creating a pod to test consume secrets @ 05/21/24 17:31:48.247
  E0521 17:31:48.529749      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:49.530407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:31:50.26
  I0521 17:31:50.262590 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-ddb7f3b7-3ff2-4665-afba-a6a51332b2f9 container env-test: <nil>
  STEP: delete the pod @ 05/21/24 17:31:50.269
  I0521 17:31:50.281868 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6560" for this suite. @ 05/21/24 17:31:50.284
• [2.063 seconds]
------------------------------
SSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:57
  STEP: Creating a kubernetes client @ 05/21/24 17:31:50.289
  I0521 17:31:50.289032 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename volumeattachment @ 05/21/24 17:31:50.289
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:50.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:50.302
  STEP: Create VolumeAttachment "va-e2e-zcq84" on node "k8sconformance" @ 05/21/24 17:31:50.307
  STEP: Get VolumeAttachment "va-e2e-zcq84" on node "k8sconformance" @ 05/21/24 17:31:50.311
  STEP: Patch VolumeAttachment "va-e2e-zcq84" on node "k8sconformance" @ 05/21/24 17:31:50.313
  STEP: List VolumeAttachments with "va-e2e-zcq84=patched" label @ 05/21/24 17:31:50.317
  STEP: Delete VolumeAttachment "va-e2e-zcq84" on node "k8sconformance" @ 05/21/24 17:31:50.32
  STEP: Confirm deletion of VolumeAttachment "va-e2e-zcq84" on node "k8sconformance" @ 05/21/24 17:31:50.324
  STEP: Create VolumeAttachment "va-e2e-jjg4q" on node "k8sconformance-m02" @ 05/21/24 17:31:50.329
  STEP: Update the VolumeAttachment "va-e2e-jjg4q" on node "k8sconformance-m02" with label "va-e2e=updated" @ 05/21/24 17:31:50.332
  STEP: Create VolumeAttachment "va-e2e-jrgdj" on node "k8sconformance" @ 05/21/24 17:31:50.343
  STEP: Update the VolumeAttachment "va-e2e-jrgdj" on node "k8sconformance" with label "va-e2e=updated" @ 05/21/24 17:31:50.347
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 05/21/24 17:31:50.356
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 05/21/24 17:31:50.362
  I0521 17:31:50.364278 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-2674" for this suite. @ 05/21/24 17:31:50.366
• [0.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 05/21/24 17:31:50.369
  I0521 17:31:50.369775 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename svcaccounts @ 05/21/24 17:31:50.37
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:31:50.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:31:50.379
  I0521 17:31:50.395012 22 service_accounts.go:618] created pod
  E0521 17:31:50.530823      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:51.531458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:52.532271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:53.532396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:31:54.404
  E0521 17:31:54.532489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:55.533375      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:56.533559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:57.534703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:58.535651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:31:59.536433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:00.537442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:01.537920      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:02.538765      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:03.539780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:04.540802      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:05.541737      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:06.542053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:07.542448      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:08.542818      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:09.543627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:10.544173      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:11.544763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:12.544840      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:13.545334      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:14.545381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:15.545577      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:16.546085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:17.546699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:18.547529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:19.548652      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:20.549303      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:21.549814      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:22.550384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:23.550514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:24.404634 22 service_accounts.go:624] polling logs
  I0521 17:32:24.415493 22 service_accounts.go:634] Pod logs: 
  I0521 17:31:51.001447       1 log.go:245] OK: Got token
  I0521 17:31:51.001524       1 log.go:245] validating with in-cluster discovery
  I0521 17:31:51.001720       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0521 17:31:51.001739       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-1791:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000326f80), NotBefore:(*jwt.NumericDate)(0xc000327070), IssuedAt:(*jwt.NumericDate)(0xc000326f90), ID:"767ae9a3-3bdd-4454-a901-cb73c75fab56"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1791", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"70168ed8-bea3-4b87-a4e6-f4a4178efa5c"}}}
  I0521 17:31:51.008060       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0521 17:31:51.012867       1 log.go:245] OK: Validated signature on JWT
  I0521 17:31:51.012946       1 log.go:245] OK: Got valid claims from token!
  I0521 17:31:51.012974       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-1791:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0006a8a40), NotBefore:(*jwt.NumericDate)(0xc0006a8a68), IssuedAt:(*jwt.NumericDate)(0xc0006a8a48), ID:"767ae9a3-3bdd-4454-a901-cb73c75fab56"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1791", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"70168ed8-bea3-4b87-a4e6-f4a4178efa5c"}}}

  I0521 17:32:24.415550 22 service_accounts.go:638] completed pod
  I0521 17:32:24.421597 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1791" for this suite. @ 05/21/24 17:32:24.425
• [34.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1627
  STEP: Creating a kubernetes client @ 05/21/24 17:32:24.43
  I0521 17:32:24.430424 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 17:32:24.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:32:24.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:32:24.447
  STEP: creating the pod @ 05/21/24 17:32:24.45
  I0521 17:32:24.450810 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8752 create -f -'
  I0521 17:32:24.522059 22 builder.go:146] stderr: ""
  I0521 17:32:24.522096 22 builder.go:147] stdout: "pod/pause created\n"
  E0521 17:32:24.550771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:25.551788      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 05/21/24 17:32:26.53
  I0521 17:32:26.530543 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8752 label pods pause testing-label=testing-label-value'
  E0521 17:32:26.551863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:26.576244 22 builder.go:146] stderr: ""
  I0521 17:32:26.576272 22 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 05/21/24 17:32:26.576
  I0521 17:32:26.576319 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8752 get pod pause -L testing-label'
  I0521 17:32:26.615743 22 builder.go:146] stderr: ""
  I0521 17:32:26.615769 22 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 05/21/24 17:32:26.615
  I0521 17:32:26.615820 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8752 label pods pause testing-label-'
  I0521 17:32:26.655967 22 builder.go:146] stderr: ""
  I0521 17:32:26.655992 22 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 05/21/24 17:32:26.656
  I0521 17:32:26.656038 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8752 get pod pause -L testing-label'
  I0521 17:32:26.693134 22 builder.go:146] stderr: ""
  I0521 17:32:26.693172 22 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 05/21/24 17:32:26.693
  I0521 17:32:26.693306 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8752 delete --grace-period=0 --force -f -'
  I0521 17:32:26.735556 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0521 17:32:26.735596 22 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I0521 17:32:26.735638 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8752 get rc,svc -l name=pause --no-headers'
  I0521 17:32:26.773763 22 builder.go:146] stderr: "No resources found in kubectl-8752 namespace.\n"
  I0521 17:32:26.773796 22 builder.go:147] stdout: ""
  I0521 17:32:26.773847 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8752 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0521 17:32:26.809163 22 builder.go:146] stderr: ""
  I0521 17:32:26.809213 22 builder.go:147] stdout: ""
  I0521 17:32:26.809321 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8752" for this suite. @ 05/21/24 17:32:26.81
• [2.383 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 05/21/24 17:32:26.813
  I0521 17:32:26.813697 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:32:26.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:32:26.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:32:26.821
  STEP: Creating projection with secret that has name projected-secret-test-beda1e66-6f73-4f90-a551-67e66b1d4214 @ 05/21/24 17:32:26.823
  STEP: Creating a pod to test consume secrets @ 05/21/24 17:32:26.825
  E0521 17:32:27.552418      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:28.552454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:29.553510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:30.554290      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:32:30.842
  I0521 17:32:30.845282 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-a1d3e38a-7397-4447-9809-6fa979eefd18 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 17:32:30.852
  I0521 17:32:30.868133 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3267" for this suite. @ 05/21/24 17:32:30.87
• [4.062 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 05/21/24 17:32:30.875
  I0521 17:32:30.875611 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 17:32:30.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:32:30.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:32:30.889
  STEP: Creating the pod @ 05/21/24 17:32:30.892
  E0521 17:32:31.554556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:32.554848      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:33.430304 22 pod_client.go:141] Successfully updated pod "annotationupdateb25b149b-ca2e-403f-878b-6302f9f65ebb"
  E0521 17:32:33.555608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:34.556427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:35.556492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:36.557458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:37.459794 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9739" for this suite. @ 05/21/24 17:32:37.462
• [6.591 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 05/21/24 17:32:37.467
  I0521 17:32:37.467549 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename daemonsets @ 05/21/24 17:32:37.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:32:37.479
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:32:37.483
  I0521 17:32:37.498255 22 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 05/21/24 17:32:37.502
  I0521 17:32:37.503908 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 17:32:37.503946 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 05/21/24 17:32:37.503
  I0521 17:32:37.516120 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 17:32:37.516178 22 fixtures.go:130] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0521 17:32:37.558241      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:38.518070 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 17:32:38.518131 22 fixtures.go:130] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0521 17:32:38.559363      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:39.517750 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 17:32:39.517820 22 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 05/21/24 17:32:39.52
  I0521 17:32:39.535310 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 17:32:39.535365 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0521 17:32:39.560206      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:40.537459 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 17:32:40.537515 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 05/21/24 17:32:40.537
  I0521 17:32:40.548716 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 17:32:40.548761 22 fixtures.go:130] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0521 17:32:40.560876      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:41.551294 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 17:32:41.551346 22 fixtures.go:130] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0521 17:32:41.561280      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:42.551253 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 17:32:42.551303 22 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/21/24 17:32:42.556
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3464, will wait for the garbage collector to delete the pods @ 05/21/24 17:32:42.556
  E0521 17:32:42.561277      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:42.616436 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 6.404744ms
  I0521 17:32:42.717088 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.641122ms
  E0521 17:32:43.562443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:43.822645 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 17:32:43.822707 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0521 17:32:43.825432 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18542"},"items":null}

  I0521 17:32:43.827656 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18542"},"items":null}

  I0521 17:32:43.840949 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3464" for this suite. @ 05/21/24 17:32:43.844
• [6.382 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 05/21/24 17:32:43.849
  I0521 17:32:43.849957 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename var-expansion @ 05/21/24 17:32:43.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:32:43.861
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:32:43.863
  STEP: Creating a pod to test substitution in container's args @ 05/21/24 17:32:43.865
  E0521 17:32:44.563508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:45.564419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:32:45.876
  I0521 17:32:45.879183 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod var-expansion-3d294d6f-60d9-4aa7-8dd8-eb7f3d7cb614 container dapi-container: <nil>
  STEP: delete the pod @ 05/21/24 17:32:45.885
  I0521 17:32:45.898723 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3669" for this suite. @ 05/21/24 17:32:45.901
• [2.058 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 05/21/24 17:32:45.908
  I0521 17:32:45.908929 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 17:32:45.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:32:45.92
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:32:45.928
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 17:32:45.941
  E0521 17:32:46.564799      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:47.565771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:32:47.965
  I0521 17:32:47.968921 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-23c6c70d-5242-40a4-a1b5-ddd9b0b45322 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 17:32:47.976
  I0521 17:32:47.988748 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1867" for this suite. @ 05/21/24 17:32:47.991
• [2.087 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 05/21/24 17:32:47.996
  I0521 17:32:47.996308 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename gc @ 05/21/24 17:32:47.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:32:48.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:32:48.008
  I0521 17:32:48.039277 22 garbage_collector.go:840] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"63ce7ec4-e2ca-4ab1-93eb-201b512c2746", Controller:(*bool)(0xc00552443a), BlockOwnerDeletion:(*bool)(0xc00552443b)}}
  I0521 17:32:48.048728 22 garbage_collector.go:844] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"9a49a553-b0de-4cd6-a812-b77d4f0de566", Controller:(*bool)(0xc001dd44ee), BlockOwnerDeletion:(*bool)(0xc001dd44ef)}}
  I0521 17:32:48.055655 22 garbage_collector.go:848] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fee85d2b-a8ea-4a8a-8b44-178e774d4f0d", Controller:(*bool)(0xc0055246ce), BlockOwnerDeletion:(*bool)(0xc0055246cf)}}
  E0521 17:32:48.566402      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:49.566487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:50.567428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:51.567423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:52.567603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:32:53.060553 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2582" for this suite. @ 05/21/24 17:32:53.062
• [5.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 05/21/24 17:32:53.066
  I0521 17:32:53.066388 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 17:32:53.067
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:32:53.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:32:53.076
  STEP: Creating secret with name secret-test-e580cf5d-6ddc-453a-af76-77bab1227d31 @ 05/21/24 17:32:53.077
  STEP: Creating a pod to test consume secrets @ 05/21/24 17:32:53.08
  E0521 17:32:53.568393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:54.568971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:32:55.09
  I0521 17:32:55.092505 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-secrets-e9740b4b-639b-4d2e-ac1e-1ea3a760db18 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 17:32:55.099
  I0521 17:32:55.109717 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8748" for this suite. @ 05/21/24 17:32:55.112
• [2.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 05/21/24 17:32:55.119
  I0521 17:32:55.119457 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replication-controller @ 05/21/24 17:32:55.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:32:55.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:32:55.133
  STEP: Given a ReplicationController is created @ 05/21/24 17:32:55.135
  STEP: When the matched label of one of its pods change @ 05/21/24 17:32:55.14
  I0521 17:32:55.142709 22 resource.go:87] Pod name pod-release: Found 0 pods out of 1
  E0521 17:32:55.569520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:56.570045      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:57.571058      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:58.571527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:32:59.571562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:00.145920 22 resource.go:87] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 05/21/24 17:33:00.156
  E0521 17:33:00.572327      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:01.164551 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8021" for this suite. @ 05/21/24 17:33:01.167
• [6.054 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 05/21/24 17:33:01.173
  I0521 17:33:01.173951 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 17:33:01.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:33:01.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:33:01.19
  STEP: Creating pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080 @ 05/21/24 17:33:01.193
  E0521 17:33:01.572504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:02.573562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/21/24 17:33:03.208
  I0521 17:33:03.211794 22 container_probe.go:1749] Initial restart count of pod liveness-d759449f-c97c-487b-8c67-4027d307267a is 0
  I0521 17:33:03.214293 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:03.574543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:04.575038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:05.219151 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:05.575721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:06.576653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:07.224368 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:07.576835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:08.577368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:09.229467 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:09.577892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:10.578530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:11.236244 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:11.579671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:12.580703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:13.241451 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:13.581099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:14.581546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:15.246340 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:15.582554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:16.583647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:17.251658 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:17.584312      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:18.584547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:19.257478 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:19.584906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:20.585389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:21.263926 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  E0521 17:33:21.586300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:22.586666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:23.269605 22 container_probe.go:1759] Get pod liveness-d759449f-c97c-487b-8c67-4027d307267a in namespace container-probe-2080
  I0521 17:33:23.269670 22 container_probe.go:1763] Restart count of pod container-probe-2080/liveness-d759449f-c97c-487b-8c67-4027d307267a is now 1 (20.057832292s elapsed)
  STEP: deleting the pod @ 05/21/24 17:33:23.269
  I0521 17:33:23.282965 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2080" for this suite. @ 05/21/24 17:33:23.287
• [22.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 05/21/24 17:33:23.293
  I0521 17:33:23.293615 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename var-expansion @ 05/21/24 17:33:23.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:33:23.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:33:23.312
  STEP: Creating a pod to test substitution in volume subpath @ 05/21/24 17:33:23.314
  E0521 17:33:23.587371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:24.588149      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:33:25.326
  I0521 17:33:25.329437 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod var-expansion-a4abcc3c-dc7e-4b7d-a4ba-41442ca4c18e container dapi-container: <nil>
  STEP: delete the pod @ 05/21/24 17:33:25.336
  I0521 17:33:25.348944 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-889" for this suite. @ 05/21/24 17:33:25.351
• [2.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1858
  STEP: Creating a kubernetes client @ 05/21/24 17:33:25.361
  I0521 17:33:25.361713 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 17:33:25.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:33:25.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:33:25.375
  STEP: Starting the proxy @ 05/21/24 17:33:25.377
  I0521 17:33:25.377356 22 util.go:592] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8302 proxy --unix-socket=/tmp/kubectl-proxy-unix2300797446/test'
  STEP: retrieving proxy /api/ output @ 05/21/24 17:33:25.407
  I0521 17:33:25.408126 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8302" for this suite. @ 05/21/24 17:33:25.41
• [0.053 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:531
  STEP: Creating a kubernetes client @ 05/21/24 17:33:25.414
  I0521 17:33:25.414453 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename security-context-test @ 05/21/24 17:33:25.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:33:25.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:33:25.42
  E0521 17:33:25.589433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:26.590335      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:27.441572 22 security_context.go:538] Got logs for pod "busybox-privileged-false-5111ac6a-8c61-4def-a347-72f006f6f465": "ip: RTNETLINK answers: Operation not permitted\n"
  I0521 17:33:27.441685 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6735" for this suite. @ 05/21/24 17:33:27.444
• [2.034 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 05/21/24 17:33:27.449
  I0521 17:33:27.449246 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 17:33:27.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:33:27.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:33:27.468
  STEP: Creating pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394 @ 05/21/24 17:33:27.47
  E0521 17:33:27.591131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:28.592212      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/21/24 17:33:29.485
  I0521 17:33:29.488031 22 container_probe.go:1749] Initial restart count of pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 is 0
  I0521 17:33:29.490382 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:29.592582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:30.593401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:31.495943 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:31.594309      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:32.594455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:33.501446 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:33.594628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:34.594850      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:35.507434 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:35.595587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:36.596593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:37.513335 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:37.597558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:38.598110      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:39.520007 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:39.599218      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:40.600156      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:41.525412 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:41.600432      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:42.601564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:43.531927 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:43.602376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:44.602782      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:45.537513 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:45.603612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:46.604642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:47.543432 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:47.605799      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:48.606597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:49.548711 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:49.606877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:50.607591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:51.551526 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:51.608000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:52.609052      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:53.556403 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:53.609604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:54.610133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:55.559671 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:55.611004      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:56.611445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:57.564364 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:57.612529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:33:58.613581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:33:59.570347 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:33:59.614440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:00.615438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:01.575902 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:01.616013      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:02.616542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:03.581719 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:03.617001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:04.617135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:05.586020 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:05.618165      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:06.618506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:07.591262 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:07.619428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:08.619768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:09.596958 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:09.620128      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:10.621155      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:11.603327 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:11.621364      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:12.621575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:13.608724 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:13.622055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:14.622214      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:15.613718 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:15.622853      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:16.623226      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:17.619603 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:17.623487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:18.624441      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:19.625248      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:19.625607 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:20.625522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:21.626481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:21.631371 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:22.627319      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:23.627465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:23.635944 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:24.627930      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:25.628316      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:25.640564 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:26.628564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:27.628931      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:27.645961 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:28.629135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:29.629377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:29.652157 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:30.630098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:31.630584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:31.658129 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:32.631314      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:33.631828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:33.662804 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:34.632618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:35.633383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:35.669036 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:36.633594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:37.634084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:37.674272 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:38.634406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:39.634955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:39.680178 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:40.635687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:41.636115      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:41.686256 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:42.636695      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:43.637324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:43.691600 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:44.637896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:45.638504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:45.696872 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:46.638757      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:47.639305      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:47.702759 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:48.639817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:49.639861      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:49.708015 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:50.640177      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:51.640525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:51.710997 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:52.640555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:53.641471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:53.717433 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:54.642488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:55.642436      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:55.723125 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:56.643593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:57.643911      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:57.728486 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:34:58.644506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:34:59.644763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:34:59.735041 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:00.645506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:01.646085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:01.741144 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:02.646947      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:03.647461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:03.746900 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:04.648541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:05.648585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:05.753052 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:06.649541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:07.650428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:07.758178 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:08.651542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:09.652656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:09.764273 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:10.652978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:11.653441      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:11.769797 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:12.653749      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:13.654568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:13.774586 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:14.654730      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:15.655856      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:15.780683 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:16.656419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:17.656652      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:17.785674 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:18.656714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:19.657584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:19.790756 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:20.657597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:21.657966      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:21.796937 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:22.658700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:23.659212      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:23.803053 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:24.660080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:25.660257      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:25.807092 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:26.660824      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:27.661720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:27.812367 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:28.662713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:29.663141      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:29.817514 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:30.664306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:31.665099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:31.823239 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:32.665218      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:33.665998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:33.828690 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:34.666748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:35.667140      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:35.834428 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:36.667560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:37.667618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:37.836949 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:38.667985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:39.668402      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:39.840246 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:40.668602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:41.669547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:41.846582 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:42.669572      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:43.670671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:43.849070 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:44.671797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:45.672579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:45.854609 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:46.672743      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:47.673013      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:47.860652 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:48.673675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:49.674346      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:49.866026 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:50.675082      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:51.674941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:51.871995 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:52.675768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:53.676237      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:53.877432 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:54.677035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:55.677362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:55.883263 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:56.677403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:57.677825      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:57.888893 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:35:58.678531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:35:59.678763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:35:59.894118 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:00.679458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:01.680001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:01.900275 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:02.680364      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:03.680889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:03.906303 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:04.681540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:05.681781      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:05.912301 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:06.681989      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:07.682713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:07.918970 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:08.683851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:09.684577      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:09.924478 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:10.685622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:11.686119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:11.931037 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:12.686693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:13.687161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:13.936766 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:14.687587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:15.688100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:15.942215 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:16.688176      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:17.688714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:17.948181 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:18.688895      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:19.689961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:19.952446 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:20.690458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:21.691184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:21.958107 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:22.691956      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:23.692524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:23.963883 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:24.692772      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:25.693898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:25.968800 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:26.695014      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:27.695401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:27.974733 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:28.695760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:29.696500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:29.976758 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:30.697119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:31.697611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:31.983129 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:32.697902      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:33.698464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:33.988290 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:34.698761      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:35.699714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:35.994779 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:36.700428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:37.700494      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:38.000041 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:38.700529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:39.701507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:40.005728 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:40.701970      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:41.702654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:42.011519 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:42.703307      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:43.703710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:44.017051 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:44.704499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:45.705620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:46.021745 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:46.705689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:47.706239      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:48.026909 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:48.706584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:49.707338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:50.032673 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:50.707975      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:51.708579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:52.037912 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:52.709727      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:53.710276      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:54.042337 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:54.711032      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:55.711455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:56.047889 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:56.711755      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:57.711845      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:36:58.052621 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:36:58.712478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:36:59.712991      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:00.059233 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:00.713952      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:01.714152      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:02.065480 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:02.715270      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:03.715460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:04.069585 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:04.716447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:05.716747      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:06.075700 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:06.717306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:07.717551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:08.081352 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:08.718683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:09.719242      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:10.085775 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:10.719898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:11.720454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:12.091387 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:12.721091      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:13.721567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:14.097909 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:14.722626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:15.723077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:16.103941 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:16.723565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:17.724145      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:18.109237 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:18.724772      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:19.725362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:20.115221 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:20.726395      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:21.726611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:22.119984 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:22.727569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:23.728548      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:24.125009 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:24.728853      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:25.729154      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:26.131704 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:26.729965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:27.730900      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:28.137358 22 container_probe.go:1759] Get pod test-grpc-7dbd42b5-3bce-4653-a2c4-419a80937b04 in namespace container-probe-2394
  E0521 17:37:28.731726      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:29.732658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/21/24 17:37:30.138
  I0521 17:37:30.156249 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2394" for this suite. @ 05/21/24 17:37:30.163
• [242.720 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 05/21/24 17:37:30.169
  I0521 17:37:30.169629 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename svc-latency @ 05/21/24 17:37:30.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:37:30.18
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:37:30.182
  I0521 17:37:30.183753 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-4457 @ 05/21/24 17:37:30.184
  I0521 17:37:30.187686      22 runners.go:198] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4457, replica count: 1
  E0521 17:37:30.732955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:31.238407      22 runners.go:198] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0521 17:37:31.733180      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:32.238997      22 runners.go:198] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0521 17:37:32.347845 22 service_latency.go:356] Created: latency-svc-zrlbr
  I0521 17:37:32.355860 22 service_latency.go:363] Got endpoints: latency-svc-zrlbr [16.214596ms]
  I0521 17:37:32.369560 22 service_latency.go:356] Created: latency-svc-fd5zn
  I0521 17:37:32.376571 22 service_latency.go:363] Got endpoints: latency-svc-fd5zn [20.043906ms]
  I0521 17:37:32.379378 22 service_latency.go:356] Created: latency-svc-d8wsj
  I0521 17:37:32.384532 22 service_latency.go:363] Got endpoints: latency-svc-d8wsj [28.211267ms]
  I0521 17:37:32.389603 22 service_latency.go:356] Created: latency-svc-czj54
  I0521 17:37:32.397555 22 service_latency.go:363] Got endpoints: latency-svc-czj54 [40.913158ms]
  I0521 17:37:32.399588 22 service_latency.go:356] Created: latency-svc-mc4gs
  I0521 17:37:32.405362 22 service_latency.go:363] Got endpoints: latency-svc-mc4gs [48.797697ms]
  I0521 17:37:32.408313 22 service_latency.go:356] Created: latency-svc-mr75b
  I0521 17:37:32.416139 22 service_latency.go:363] Got endpoints: latency-svc-mr75b [60.027943ms]
  I0521 17:37:32.418800 22 service_latency.go:356] Created: latency-svc-qnwjv
  I0521 17:37:32.426511 22 service_latency.go:363] Got endpoints: latency-svc-qnwjv [70.024346ms]
  I0521 17:37:32.429687 22 service_latency.go:356] Created: latency-svc-p7xqr
  I0521 17:37:32.436266 22 service_latency.go:363] Got endpoints: latency-svc-p7xqr [79.60307ms]
  I0521 17:37:32.439609 22 service_latency.go:356] Created: latency-svc-4st2n
  I0521 17:37:32.446951 22 service_latency.go:363] Got endpoints: latency-svc-4st2n [90.586862ms]
  I0521 17:37:32.448777 22 service_latency.go:356] Created: latency-svc-w76d5
  I0521 17:37:32.452717 22 service_latency.go:363] Got endpoints: latency-svc-w76d5 [96.573362ms]
  I0521 17:37:32.459626 22 service_latency.go:356] Created: latency-svc-8jwh9
  I0521 17:37:32.463011 22 service_latency.go:363] Got endpoints: latency-svc-8jwh9 [106.455708ms]
  I0521 17:37:32.468971 22 service_latency.go:356] Created: latency-svc-gptp6
  I0521 17:37:32.499734 22 service_latency.go:363] Got endpoints: latency-svc-gptp6 [143.501262ms]
  I0521 17:37:32.500807 22 service_latency.go:356] Created: latency-svc-gnqr5
  I0521 17:37:32.506534 22 service_latency.go:363] Got endpoints: latency-svc-gnqr5 [149.897749ms]
  I0521 17:37:32.514115 22 service_latency.go:356] Created: latency-svc-5g7q7
  I0521 17:37:32.522666 22 service_latency.go:363] Got endpoints: latency-svc-5g7q7 [166.007489ms]
  I0521 17:37:32.525844 22 service_latency.go:356] Created: latency-svc-dw7qb
  I0521 17:37:32.529493 22 service_latency.go:363] Got endpoints: latency-svc-dw7qb [173.448556ms]
  I0521 17:37:32.537688 22 service_latency.go:356] Created: latency-svc-mfg7n
  I0521 17:37:32.544178 22 service_latency.go:363] Got endpoints: latency-svc-mfg7n [187.711996ms]
  I0521 17:37:32.551578 22 service_latency.go:356] Created: latency-svc-76c65
  I0521 17:37:32.557531 22 service_latency.go:363] Got endpoints: latency-svc-76c65 [180.906546ms]
  I0521 17:37:32.560317 22 service_latency.go:356] Created: latency-svc-zp5q2
  I0521 17:37:32.564731 22 service_latency.go:363] Got endpoints: latency-svc-zp5q2 [180.082577ms]
  I0521 17:37:32.572636 22 service_latency.go:356] Created: latency-svc-drc44
  I0521 17:37:32.577733 22 service_latency.go:363] Got endpoints: latency-svc-drc44 [180.140181ms]
  I0521 17:37:32.580466 22 service_latency.go:356] Created: latency-svc-plp6k
  I0521 17:37:32.587396 22 service_latency.go:363] Got endpoints: latency-svc-plp6k [181.869626ms]
  I0521 17:37:32.589895 22 service_latency.go:356] Created: latency-svc-9gnrf
  I0521 17:37:32.593238 22 service_latency.go:363] Got endpoints: latency-svc-9gnrf [176.905898ms]
  I0521 17:37:32.627482 22 service_latency.go:356] Created: latency-svc-9qllf
  I0521 17:37:32.632570 22 service_latency.go:356] Created: latency-svc-225gh
  I0521 17:37:32.633105 22 service_latency.go:363] Got endpoints: latency-svc-9qllf [206.470958ms]
  I0521 17:37:32.640622 22 service_latency.go:363] Got endpoints: latency-svc-225gh [204.302383ms]
  I0521 17:37:32.643672 22 service_latency.go:356] Created: latency-svc-k5slq
  I0521 17:37:32.652214 22 service_latency.go:363] Got endpoints: latency-svc-k5slq [205.183694ms]
  I0521 17:37:32.655641 22 service_latency.go:356] Created: latency-svc-x7vqm
  I0521 17:37:32.659284 22 service_latency.go:363] Got endpoints: latency-svc-x7vqm [206.439311ms]
  I0521 17:37:32.666413 22 service_latency.go:356] Created: latency-svc-v54g4
  I0521 17:37:32.673970 22 service_latency.go:363] Got endpoints: latency-svc-v54g4 [210.90913ms]
  I0521 17:37:32.678143 22 service_latency.go:356] Created: latency-svc-h2m9d
  I0521 17:37:32.685038 22 service_latency.go:363] Got endpoints: latency-svc-h2m9d [185.178274ms]
  I0521 17:37:32.688834 22 service_latency.go:356] Created: latency-svc-bp7wm
  I0521 17:37:32.692176 22 service_latency.go:363] Got endpoints: latency-svc-bp7wm [185.586805ms]
  I0521 17:37:32.699099 22 service_latency.go:356] Created: latency-svc-6vfhx
  I0521 17:37:32.710753 22 service_latency.go:363] Got endpoints: latency-svc-6vfhx [187.995358ms]
  I0521 17:37:32.713569 22 service_latency.go:356] Created: latency-svc-swpzm
  I0521 17:37:32.721035 22 service_latency.go:363] Got endpoints: latency-svc-swpzm [191.495465ms]
  I0521 17:37:32.723339 22 service_latency.go:356] Created: latency-svc-rp6fv
  E0521 17:37:32.733830      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:32.747887 22 service_latency.go:363] Got endpoints: latency-svc-rp6fv [203.594489ms]
  I0521 17:37:32.752423 22 service_latency.go:356] Created: latency-svc-lzklc
  I0521 17:37:32.761673 22 service_latency.go:363] Got endpoints: latency-svc-lzklc [204.046871ms]
  I0521 17:37:32.765815 22 service_latency.go:356] Created: latency-svc-h9dfj
  I0521 17:37:32.773436 22 service_latency.go:363] Got endpoints: latency-svc-h9dfj [208.659667ms]
  I0521 17:37:32.778099 22 service_latency.go:356] Created: latency-svc-nmfg5
  I0521 17:37:32.785624 22 service_latency.go:363] Got endpoints: latency-svc-nmfg5 [207.711798ms]
  I0521 17:37:32.788693 22 service_latency.go:356] Created: latency-svc-c4pjd
  I0521 17:37:32.796487 22 service_latency.go:363] Got endpoints: latency-svc-c4pjd [208.973213ms]
  I0521 17:37:32.799650 22 service_latency.go:356] Created: latency-svc-fplsn
  I0521 17:37:32.802876 22 service_latency.go:363] Got endpoints: latency-svc-fplsn [209.602335ms]
  I0521 17:37:32.810559 22 service_latency.go:356] Created: latency-svc-tprbh
  I0521 17:37:32.817046 22 service_latency.go:363] Got endpoints: latency-svc-tprbh [183.830308ms]
  I0521 17:37:32.820701 22 service_latency.go:356] Created: latency-svc-t645h
  I0521 17:37:32.823717 22 service_latency.go:363] Got endpoints: latency-svc-t645h [183.005134ms]
  I0521 17:37:32.831409 22 service_latency.go:356] Created: latency-svc-4scwp
  I0521 17:37:32.839494 22 service_latency.go:363] Got endpoints: latency-svc-4scwp [187.170683ms]
  I0521 17:37:32.842778 22 service_latency.go:356] Created: latency-svc-9sz42
  I0521 17:37:32.866921 22 service_latency.go:363] Got endpoints: latency-svc-9sz42 [207.528394ms]
  I0521 17:37:32.870367 22 service_latency.go:356] Created: latency-svc-rxxfn
  I0521 17:37:32.881532 22 service_latency.go:356] Created: latency-svc-j4hs5
  I0521 17:37:32.892229 22 service_latency.go:356] Created: latency-svc-77n22
  I0521 17:37:32.901764 22 service_latency.go:356] Created: latency-svc-g25vg
  I0521 17:37:32.904473 22 service_latency.go:363] Got endpoints: latency-svc-rxxfn [230.395003ms]
  I0521 17:37:32.910008 22 service_latency.go:356] Created: latency-svc-qg5fr
  I0521 17:37:32.916240 22 service_latency.go:356] Created: latency-svc-4hdjc
  I0521 17:37:32.923777 22 service_latency.go:356] Created: latency-svc-wgq28
  I0521 17:37:32.932071 22 service_latency.go:356] Created: latency-svc-2rrxg
  I0521 17:37:32.942406 22 service_latency.go:356] Created: latency-svc-2mzrm
  I0521 17:37:32.953273 22 service_latency.go:356] Created: latency-svc-j7cfj
  I0521 17:37:32.954100 22 service_latency.go:363] Got endpoints: latency-svc-j4hs5 [268.937556ms]
  I0521 17:37:32.963568 22 service_latency.go:356] Created: latency-svc-zkpsw
  I0521 17:37:32.991882 22 service_latency.go:356] Created: latency-svc-lnzf6
  I0521 17:37:33.000562 22 service_latency.go:356] Created: latency-svc-f8lpv
  I0521 17:37:33.012858 22 service_latency.go:363] Got endpoints: latency-svc-77n22 [320.616505ms]
  I0521 17:37:33.032912 22 service_latency.go:356] Created: latency-svc-9sg78
  I0521 17:37:33.040045 22 service_latency.go:356] Created: latency-svc-cfsbb
  I0521 17:37:33.044234 22 service_latency.go:356] Created: latency-svc-69qn4
  I0521 17:37:33.048334 22 service_latency.go:356] Created: latency-svc-f4dqk
  I0521 17:37:33.054779 22 service_latency.go:363] Got endpoints: latency-svc-g25vg [343.934727ms]
  I0521 17:37:33.055957 22 service_latency.go:356] Created: latency-svc-2bsqf
  I0521 17:37:33.065598 22 service_latency.go:356] Created: latency-svc-xcfc9
  I0521 17:37:33.112394 22 service_latency.go:363] Got endpoints: latency-svc-qg5fr [391.303731ms]
  I0521 17:37:33.125770 22 service_latency.go:356] Created: latency-svc-gkgzg
  I0521 17:37:33.153939 22 service_latency.go:363] Got endpoints: latency-svc-4hdjc [405.920351ms]
  I0521 17:37:33.167611 22 service_latency.go:356] Created: latency-svc-s8b9h
  I0521 17:37:33.205714 22 service_latency.go:363] Got endpoints: latency-svc-wgq28 [443.925189ms]
  I0521 17:37:33.225960 22 service_latency.go:356] Created: latency-svc-v85sq
  I0521 17:37:33.254845 22 service_latency.go:363] Got endpoints: latency-svc-2rrxg [481.308053ms]
  I0521 17:37:33.267324 22 service_latency.go:356] Created: latency-svc-npj4m
  I0521 17:37:33.303593 22 service_latency.go:363] Got endpoints: latency-svc-2mzrm [517.820472ms]
  I0521 17:37:33.322588 22 service_latency.go:356] Created: latency-svc-9q48l
  I0521 17:37:33.357464 22 service_latency.go:363] Got endpoints: latency-svc-j7cfj [560.8654ms]
  I0521 17:37:33.368275 22 service_latency.go:356] Created: latency-svc-tls2g
  I0521 17:37:33.404472 22 service_latency.go:363] Got endpoints: latency-svc-zkpsw [601.536754ms]
  I0521 17:37:33.416641 22 service_latency.go:356] Created: latency-svc-m8ts5
  I0521 17:37:33.453027 22 service_latency.go:363] Got endpoints: latency-svc-lnzf6 [635.916465ms]
  I0521 17:37:33.464852 22 service_latency.go:356] Created: latency-svc-zx7mt
  I0521 17:37:33.505608 22 service_latency.go:363] Got endpoints: latency-svc-f8lpv [681.857929ms]
  I0521 17:37:33.516382 22 service_latency.go:356] Created: latency-svc-9ghb5
  I0521 17:37:33.554949 22 service_latency.go:363] Got endpoints: latency-svc-9sg78 [715.35685ms]
  I0521 17:37:33.566816 22 service_latency.go:356] Created: latency-svc-gt5k2
  I0521 17:37:33.605680 22 service_latency.go:363] Got endpoints: latency-svc-cfsbb [738.647168ms]
  I0521 17:37:33.619165 22 service_latency.go:356] Created: latency-svc-pxxrm
  I0521 17:37:33.655224 22 service_latency.go:363] Got endpoints: latency-svc-69qn4 [750.681105ms]
  I0521 17:37:33.669375 22 service_latency.go:356] Created: latency-svc-n9l6m
  I0521 17:37:33.704651 22 service_latency.go:363] Got endpoints: latency-svc-f4dqk [750.479559ms]
  I0521 17:37:33.718002 22 service_latency.go:356] Created: latency-svc-wwnhh
  E0521 17:37:33.735044      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:33.754365 22 service_latency.go:363] Got endpoints: latency-svc-2bsqf [741.377897ms]
  I0521 17:37:33.768283 22 service_latency.go:356] Created: latency-svc-4kh5w
  I0521 17:37:33.803566 22 service_latency.go:363] Got endpoints: latency-svc-xcfc9 [748.738094ms]
  I0521 17:37:33.815947 22 service_latency.go:356] Created: latency-svc-vknvs
  I0521 17:37:33.857693 22 service_latency.go:363] Got endpoints: latency-svc-gkgzg [745.201948ms]
  I0521 17:37:33.871227 22 service_latency.go:356] Created: latency-svc-z5959
  I0521 17:37:33.906499 22 service_latency.go:363] Got endpoints: latency-svc-s8b9h [752.451836ms]
  I0521 17:37:33.918659 22 service_latency.go:356] Created: latency-svc-2svrc
  I0521 17:37:33.952234 22 service_latency.go:363] Got endpoints: latency-svc-v85sq [746.413329ms]
  I0521 17:37:33.967863 22 service_latency.go:356] Created: latency-svc-vfm7b
  I0521 17:37:34.004410 22 service_latency.go:363] Got endpoints: latency-svc-npj4m [749.313718ms]
  I0521 17:37:34.017960 22 service_latency.go:356] Created: latency-svc-gxpsn
  I0521 17:37:34.052819 22 service_latency.go:363] Got endpoints: latency-svc-9q48l [749.107872ms]
  I0521 17:37:34.066518 22 service_latency.go:356] Created: latency-svc-gmtzd
  I0521 17:37:34.104802 22 service_latency.go:363] Got endpoints: latency-svc-tls2g [747.217045ms]
  I0521 17:37:34.116686 22 service_latency.go:356] Created: latency-svc-g48fw
  I0521 17:37:34.155427 22 service_latency.go:363] Got endpoints: latency-svc-m8ts5 [750.869988ms]
  I0521 17:37:34.171934 22 service_latency.go:356] Created: latency-svc-rrq2k
  I0521 17:37:34.204594 22 service_latency.go:363] Got endpoints: latency-svc-zx7mt [751.456027ms]
  I0521 17:37:34.216678 22 service_latency.go:356] Created: latency-svc-spvr7
  I0521 17:37:34.255858 22 service_latency.go:363] Got endpoints: latency-svc-9ghb5 [750.186947ms]
  I0521 17:37:34.266809 22 service_latency.go:356] Created: latency-svc-nfrm6
  I0521 17:37:34.305464 22 service_latency.go:363] Got endpoints: latency-svc-gt5k2 [750.449582ms]
  I0521 17:37:34.319289 22 service_latency.go:356] Created: latency-svc-2s9kg
  I0521 17:37:34.353716 22 service_latency.go:363] Got endpoints: latency-svc-pxxrm [747.948917ms]
  I0521 17:37:34.366837 22 service_latency.go:356] Created: latency-svc-848jp
  I0521 17:37:34.402712 22 service_latency.go:363] Got endpoints: latency-svc-n9l6m [747.355821ms]
  I0521 17:37:34.412344 22 service_latency.go:356] Created: latency-svc-shrrj
  I0521 17:37:34.454406 22 service_latency.go:363] Got endpoints: latency-svc-wwnhh [749.67596ms]
  I0521 17:37:34.466645 22 service_latency.go:356] Created: latency-svc-l87r2
  I0521 17:37:34.504978 22 service_latency.go:363] Got endpoints: latency-svc-4kh5w [750.537262ms]
  I0521 17:37:34.516659 22 service_latency.go:356] Created: latency-svc-gj7r8
  I0521 17:37:34.555789 22 service_latency.go:363] Got endpoints: latency-svc-vknvs [752.137815ms]
  I0521 17:37:34.566753 22 service_latency.go:356] Created: latency-svc-cd6q9
  I0521 17:37:34.604327 22 service_latency.go:363] Got endpoints: latency-svc-z5959 [746.549272ms]
  I0521 17:37:34.616920 22 service_latency.go:356] Created: latency-svc-hc8rd
  I0521 17:37:34.653690 22 service_latency.go:363] Got endpoints: latency-svc-2svrc [747.104719ms]
  I0521 17:37:34.667424 22 service_latency.go:356] Created: latency-svc-kjprr
  I0521 17:37:34.705161 22 service_latency.go:363] Got endpoints: latency-svc-vfm7b [752.82224ms]
  I0521 17:37:34.720168 22 service_latency.go:356] Created: latency-svc-r5nk7
  E0521 17:37:34.735086      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:34.754001 22 service_latency.go:363] Got endpoints: latency-svc-gxpsn [749.49261ms]
  I0521 17:37:34.769015 22 service_latency.go:356] Created: latency-svc-vrvk8
  I0521 17:37:34.804270 22 service_latency.go:363] Got endpoints: latency-svc-gmtzd [751.373814ms]
  I0521 17:37:34.818298 22 service_latency.go:356] Created: latency-svc-nccsr
  I0521 17:37:34.854653 22 service_latency.go:363] Got endpoints: latency-svc-g48fw [749.760465ms]
  I0521 17:37:34.868091 22 service_latency.go:356] Created: latency-svc-9x8fq
  I0521 17:37:34.909103 22 service_latency.go:363] Got endpoints: latency-svc-rrq2k [753.604264ms]
  I0521 17:37:34.922348 22 service_latency.go:356] Created: latency-svc-59lrm
  I0521 17:37:34.955813 22 service_latency.go:363] Got endpoints: latency-svc-spvr7 [751.147461ms]
  I0521 17:37:34.967840 22 service_latency.go:356] Created: latency-svc-lkgq9
  I0521 17:37:35.003990 22 service_latency.go:363] Got endpoints: latency-svc-nfrm6 [748.054991ms]
  I0521 17:37:35.017294 22 service_latency.go:356] Created: latency-svc-xhg6f
  I0521 17:37:35.056056 22 service_latency.go:363] Got endpoints: latency-svc-2s9kg [750.515139ms]
  I0521 17:37:35.068882 22 service_latency.go:356] Created: latency-svc-jtx5r
  I0521 17:37:35.104607 22 service_latency.go:363] Got endpoints: latency-svc-848jp [750.829568ms]
  I0521 17:37:35.120770 22 service_latency.go:356] Created: latency-svc-7676m
  I0521 17:37:35.153961 22 service_latency.go:363] Got endpoints: latency-svc-shrrj [751.189765ms]
  I0521 17:37:35.166673 22 service_latency.go:356] Created: latency-svc-hklvq
  I0521 17:37:35.201310 22 service_latency.go:363] Got endpoints: latency-svc-l87r2 [746.817175ms]
  I0521 17:37:35.212344 22 service_latency.go:356] Created: latency-svc-zbd96
  I0521 17:37:35.251521 22 service_latency.go:363] Got endpoints: latency-svc-gj7r8 [746.476547ms]
  I0521 17:37:35.262260 22 service_latency.go:356] Created: latency-svc-h7sf8
  I0521 17:37:35.300542 22 service_latency.go:363] Got endpoints: latency-svc-cd6q9 [744.686514ms]
  I0521 17:37:35.310555 22 service_latency.go:356] Created: latency-svc-zpjvt
  I0521 17:37:35.358412 22 service_latency.go:363] Got endpoints: latency-svc-hc8rd [754.000239ms]
  I0521 17:37:35.369464 22 service_latency.go:356] Created: latency-svc-8h2m4
  I0521 17:37:35.406528 22 service_latency.go:363] Got endpoints: latency-svc-kjprr [752.772527ms]
  I0521 17:37:35.416365 22 service_latency.go:356] Created: latency-svc-2qjks
  I0521 17:37:35.453620 22 service_latency.go:363] Got endpoints: latency-svc-r5nk7 [748.317863ms]
  I0521 17:37:35.468159 22 service_latency.go:356] Created: latency-svc-fwb8d
  I0521 17:37:35.502163 22 service_latency.go:363] Got endpoints: latency-svc-vrvk8 [748.051134ms]
  I0521 17:37:35.510754 22 service_latency.go:356] Created: latency-svc-jdj6b
  I0521 17:37:35.555357 22 service_latency.go:363] Got endpoints: latency-svc-nccsr [751.004332ms]
  I0521 17:37:35.567857 22 service_latency.go:356] Created: latency-svc-bvwqp
  I0521 17:37:35.604999 22 service_latency.go:363] Got endpoints: latency-svc-9x8fq [750.277579ms]
  I0521 17:37:35.617584 22 service_latency.go:356] Created: latency-svc-mcvnc
  I0521 17:37:35.654104 22 service_latency.go:363] Got endpoints: latency-svc-59lrm [744.787016ms]
  I0521 17:37:35.666886 22 service_latency.go:356] Created: latency-svc-p2cz5
  I0521 17:37:35.704916 22 service_latency.go:363] Got endpoints: latency-svc-lkgq9 [749.020804ms]
  I0521 17:37:35.717397 22 service_latency.go:356] Created: latency-svc-s844d
  E0521 17:37:35.735291      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:35.755695 22 service_latency.go:363] Got endpoints: latency-svc-xhg6f [751.642537ms]
  I0521 17:37:35.767103 22 service_latency.go:356] Created: latency-svc-bpsvm
  I0521 17:37:35.806916 22 service_latency.go:363] Got endpoints: latency-svc-jtx5r [750.727947ms]
  I0521 17:37:35.817879 22 service_latency.go:356] Created: latency-svc-g9kbc
  I0521 17:37:35.855634 22 service_latency.go:363] Got endpoints: latency-svc-7676m [750.952377ms]
  I0521 17:37:35.869790 22 service_latency.go:356] Created: latency-svc-fk2vl
  I0521 17:37:35.905916 22 service_latency.go:363] Got endpoints: latency-svc-hklvq [751.777112ms]
  I0521 17:37:35.918167 22 service_latency.go:356] Created: latency-svc-wtl67
  I0521 17:37:35.959832 22 service_latency.go:363] Got endpoints: latency-svc-zbd96 [758.452146ms]
  I0521 17:37:35.974464 22 service_latency.go:356] Created: latency-svc-khl44
  I0521 17:37:36.005548 22 service_latency.go:363] Got endpoints: latency-svc-h7sf8 [753.96248ms]
  I0521 17:37:36.019153 22 service_latency.go:356] Created: latency-svc-jjdwh
  I0521 17:37:36.053964 22 service_latency.go:363] Got endpoints: latency-svc-zpjvt [753.382695ms]
  I0521 17:37:36.066401 22 service_latency.go:356] Created: latency-svc-9trl4
  I0521 17:37:36.105702 22 service_latency.go:363] Got endpoints: latency-svc-8h2m4 [747.21537ms]
  I0521 17:37:36.116421 22 service_latency.go:356] Created: latency-svc-gfvxr
  I0521 17:37:36.154742 22 service_latency.go:363] Got endpoints: latency-svc-2qjks [748.144099ms]
  I0521 17:37:36.168599 22 service_latency.go:356] Created: latency-svc-wnd5t
  I0521 17:37:36.206391 22 service_latency.go:363] Got endpoints: latency-svc-fwb8d [752.689022ms]
  I0521 17:37:36.218705 22 service_latency.go:356] Created: latency-svc-ffvxr
  I0521 17:37:36.256488 22 service_latency.go:363] Got endpoints: latency-svc-jdj6b [754.284149ms]
  I0521 17:37:36.273844 22 service_latency.go:356] Created: latency-svc-cpmpb
  I0521 17:37:36.305518 22 service_latency.go:363] Got endpoints: latency-svc-bvwqp [750.084291ms]
  I0521 17:37:36.316616 22 service_latency.go:356] Created: latency-svc-tf76h
  I0521 17:37:36.351627 22 service_latency.go:363] Got endpoints: latency-svc-mcvnc [746.559535ms]
  I0521 17:37:36.366786 22 service_latency.go:356] Created: latency-svc-xf5sm
  I0521 17:37:36.402836 22 service_latency.go:363] Got endpoints: latency-svc-p2cz5 [748.650512ms]
  I0521 17:37:36.414106 22 service_latency.go:356] Created: latency-svc-sjq4m
  I0521 17:37:36.452637 22 service_latency.go:363] Got endpoints: latency-svc-s844d [747.632612ms]
  I0521 17:37:36.466444 22 service_latency.go:356] Created: latency-svc-l8wsk
  I0521 17:37:36.506980 22 service_latency.go:363] Got endpoints: latency-svc-bpsvm [751.216539ms]
  I0521 17:37:36.519465 22 service_latency.go:356] Created: latency-svc-szb8x
  I0521 17:37:36.554027 22 service_latency.go:363] Got endpoints: latency-svc-g9kbc [747.020835ms]
  I0521 17:37:36.567123 22 service_latency.go:356] Created: latency-svc-m4j65
  I0521 17:37:36.605587 22 service_latency.go:363] Got endpoints: latency-svc-fk2vl [749.847508ms]
  I0521 17:37:36.618888 22 service_latency.go:356] Created: latency-svc-6wbv6
  I0521 17:37:36.653466 22 service_latency.go:363] Got endpoints: latency-svc-wtl67 [747.47589ms]
  I0521 17:37:36.664741 22 service_latency.go:356] Created: latency-svc-x75cx
  I0521 17:37:36.704899 22 service_latency.go:363] Got endpoints: latency-svc-khl44 [744.968444ms]
  I0521 17:37:36.718164 22 service_latency.go:356] Created: latency-svc-xtwtk
  E0521 17:37:36.736061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:36.753408 22 service_latency.go:363] Got endpoints: latency-svc-jjdwh [747.779274ms]
  I0521 17:37:36.766477 22 service_latency.go:356] Created: latency-svc-5xxtm
  I0521 17:37:36.804315 22 service_latency.go:363] Got endpoints: latency-svc-9trl4 [750.278018ms]
  I0521 17:37:36.817132 22 service_latency.go:356] Created: latency-svc-r4jhn
  I0521 17:37:36.854517 22 service_latency.go:363] Got endpoints: latency-svc-gfvxr [748.733651ms]
  I0521 17:37:36.866068 22 service_latency.go:356] Created: latency-svc-flpb5
  I0521 17:37:36.905414 22 service_latency.go:363] Got endpoints: latency-svc-wnd5t [750.580832ms]
  I0521 17:37:36.916076 22 service_latency.go:356] Created: latency-svc-vtz7f
  I0521 17:37:36.955318 22 service_latency.go:363] Got endpoints: latency-svc-ffvxr [748.8494ms]
  I0521 17:37:36.968461 22 service_latency.go:356] Created: latency-svc-w86ss
  I0521 17:37:37.003737 22 service_latency.go:363] Got endpoints: latency-svc-cpmpb [747.169676ms]
  I0521 17:37:37.015015 22 service_latency.go:356] Created: latency-svc-x46nj
  I0521 17:37:37.054655 22 service_latency.go:363] Got endpoints: latency-svc-tf76h [749.061507ms]
  I0521 17:37:37.067484 22 service_latency.go:356] Created: latency-svc-wdr9q
  I0521 17:37:37.109467 22 service_latency.go:363] Got endpoints: latency-svc-xf5sm [757.769288ms]
  I0521 17:37:37.123252 22 service_latency.go:356] Created: latency-svc-mptxx
  I0521 17:37:37.153833 22 service_latency.go:363] Got endpoints: latency-svc-sjq4m [750.906344ms]
  I0521 17:37:37.167018 22 service_latency.go:356] Created: latency-svc-7sgv6
  I0521 17:37:37.205378 22 service_latency.go:363] Got endpoints: latency-svc-l8wsk [752.645142ms]
  I0521 17:37:37.222784 22 service_latency.go:356] Created: latency-svc-6lq6r
  I0521 17:37:37.254415 22 service_latency.go:363] Got endpoints: latency-svc-szb8x [747.351797ms]
  I0521 17:37:37.266321 22 service_latency.go:356] Created: latency-svc-99zbc
  I0521 17:37:37.306520 22 service_latency.go:363] Got endpoints: latency-svc-m4j65 [752.411176ms]
  I0521 17:37:37.320674 22 service_latency.go:356] Created: latency-svc-fc7nm
  I0521 17:37:37.355375 22 service_latency.go:363] Got endpoints: latency-svc-6wbv6 [749.699996ms]
  I0521 17:37:37.367137 22 service_latency.go:356] Created: latency-svc-82z5b
  I0521 17:37:37.405486 22 service_latency.go:363] Got endpoints: latency-svc-x75cx [751.941749ms]
  I0521 17:37:37.420565 22 service_latency.go:356] Created: latency-svc-47vxg
  I0521 17:37:37.454046 22 service_latency.go:363] Got endpoints: latency-svc-xtwtk [749.073895ms]
  I0521 17:37:37.469538 22 service_latency.go:356] Created: latency-svc-7z4qg
  I0521 17:37:37.504333 22 service_latency.go:363] Got endpoints: latency-svc-5xxtm [750.825858ms]
  I0521 17:37:37.517662 22 service_latency.go:356] Created: latency-svc-dm78s
  I0521 17:37:37.554777 22 service_latency.go:363] Got endpoints: latency-svc-r4jhn [750.376361ms]
  I0521 17:37:37.566863 22 service_latency.go:356] Created: latency-svc-m9hs5
  I0521 17:37:37.606826 22 service_latency.go:363] Got endpoints: latency-svc-flpb5 [752.236046ms]
  I0521 17:37:37.620433 22 service_latency.go:356] Created: latency-svc-n28q4
  I0521 17:37:37.654040 22 service_latency.go:363] Got endpoints: latency-svc-vtz7f [748.547452ms]
  I0521 17:37:37.665770 22 service_latency.go:356] Created: latency-svc-lqcvk
  I0521 17:37:37.704878 22 service_latency.go:363] Got endpoints: latency-svc-w86ss [749.437439ms]
  I0521 17:37:37.718085 22 service_latency.go:356] Created: latency-svc-np5f5
  E0521 17:37:37.737111      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:37.756959 22 service_latency.go:363] Got endpoints: latency-svc-x46nj [753.120511ms]
  I0521 17:37:37.771092 22 service_latency.go:356] Created: latency-svc-dtrpj
  I0521 17:37:37.804701 22 service_latency.go:363] Got endpoints: latency-svc-wdr9q [749.972241ms]
  I0521 17:37:37.816291 22 service_latency.go:356] Created: latency-svc-7fmfv
  I0521 17:37:37.854300 22 service_latency.go:363] Got endpoints: latency-svc-mptxx [744.749063ms]
  I0521 17:37:37.865565 22 service_latency.go:356] Created: latency-svc-m5hnq
  I0521 17:37:37.904339 22 service_latency.go:363] Got endpoints: latency-svc-7sgv6 [750.407654ms]
  I0521 17:37:37.916995 22 service_latency.go:356] Created: latency-svc-7b2wp
  I0521 17:37:37.953910 22 service_latency.go:363] Got endpoints: latency-svc-6lq6r [748.452815ms]
  I0521 17:37:37.965955 22 service_latency.go:356] Created: latency-svc-xtk8k
  I0521 17:37:38.003838 22 service_latency.go:363] Got endpoints: latency-svc-99zbc [749.321653ms]
  I0521 17:37:38.016397 22 service_latency.go:356] Created: latency-svc-n8rc4
  I0521 17:37:38.054261 22 service_latency.go:363] Got endpoints: latency-svc-fc7nm [747.658338ms]
  I0521 17:37:38.066294 22 service_latency.go:356] Created: latency-svc-nk56d
  I0521 17:37:38.106063 22 service_latency.go:363] Got endpoints: latency-svc-82z5b [750.615386ms]
  I0521 17:37:38.118567 22 service_latency.go:356] Created: latency-svc-l6b9q
  I0521 17:37:38.155513 22 service_latency.go:363] Got endpoints: latency-svc-47vxg [749.95812ms]
  I0521 17:37:38.192334 22 service_latency.go:356] Created: latency-svc-l8sr2
  I0521 17:37:38.202049 22 service_latency.go:363] Got endpoints: latency-svc-7z4qg [747.919297ms]
  I0521 17:37:38.209450 22 service_latency.go:356] Created: latency-svc-zcbc5
  I0521 17:37:38.259838 22 service_latency.go:363] Got endpoints: latency-svc-dm78s [755.409635ms]
  I0521 17:37:38.272922 22 service_latency.go:356] Created: latency-svc-tr89w
  I0521 17:37:38.303157 22 service_latency.go:363] Got endpoints: latency-svc-m9hs5 [748.303349ms]
  I0521 17:37:38.314447 22 service_latency.go:356] Created: latency-svc-rcjh4
  I0521 17:37:38.355418 22 service_latency.go:363] Got endpoints: latency-svc-n28q4 [748.488911ms]
  I0521 17:37:38.368212 22 service_latency.go:356] Created: latency-svc-vhcqf
  I0521 17:37:38.403433 22 service_latency.go:363] Got endpoints: latency-svc-lqcvk [749.314609ms]
  I0521 17:37:38.410920 22 service_latency.go:356] Created: latency-svc-c59xm
  I0521 17:37:38.454779 22 service_latency.go:363] Got endpoints: latency-svc-np5f5 [749.774181ms]
  I0521 17:37:38.470668 22 service_latency.go:356] Created: latency-svc-xrcwc
  I0521 17:37:38.503657 22 service_latency.go:363] Got endpoints: latency-svc-dtrpj [746.6192ms]
  I0521 17:37:38.515739 22 service_latency.go:356] Created: latency-svc-t8cfm
  I0521 17:37:38.554492 22 service_latency.go:363] Got endpoints: latency-svc-7fmfv [749.729221ms]
  I0521 17:37:38.574571 22 service_latency.go:356] Created: latency-svc-vvq7m
  I0521 17:37:38.605353 22 service_latency.go:363] Got endpoints: latency-svc-m5hnq [750.975714ms]
  I0521 17:37:38.618371 22 service_latency.go:356] Created: latency-svc-9r6cd
  I0521 17:37:38.653537 22 service_latency.go:363] Got endpoints: latency-svc-7b2wp [749.101152ms]
  I0521 17:37:38.664181 22 service_latency.go:356] Created: latency-svc-nf6q4
  I0521 17:37:38.705888 22 service_latency.go:363] Got endpoints: latency-svc-xtk8k [751.887879ms]
  I0521 17:37:38.718584 22 service_latency.go:356] Created: latency-svc-kzh6p
  E0521 17:37:38.737721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:38.755531 22 service_latency.go:363] Got endpoints: latency-svc-n8rc4 [751.60666ms]
  I0521 17:37:38.768808 22 service_latency.go:356] Created: latency-svc-svrw8
  I0521 17:37:38.805344 22 service_latency.go:363] Got endpoints: latency-svc-nk56d [750.981967ms]
  I0521 17:37:38.817481 22 service_latency.go:356] Created: latency-svc-n4vmz
  I0521 17:37:38.854270 22 service_latency.go:363] Got endpoints: latency-svc-l6b9q [748.103329ms]
  I0521 17:37:38.867153 22 service_latency.go:356] Created: latency-svc-mk29h
  I0521 17:37:38.904371 22 service_latency.go:363] Got endpoints: latency-svc-l8sr2 [748.754837ms]
  I0521 17:37:38.916138 22 service_latency.go:356] Created: latency-svc-5x2hc
  I0521 17:37:38.956256 22 service_latency.go:363] Got endpoints: latency-svc-zcbc5 [754.167873ms]
  I0521 17:37:38.967561 22 service_latency.go:356] Created: latency-svc-mcbwv
  I0521 17:37:39.004394 22 service_latency.go:363] Got endpoints: latency-svc-tr89w [744.466182ms]
  I0521 17:37:39.018477 22 service_latency.go:356] Created: latency-svc-gjqg9
  I0521 17:37:39.052784 22 service_latency.go:363] Got endpoints: latency-svc-rcjh4 [749.495648ms]
  I0521 17:37:39.063399 22 service_latency.go:356] Created: latency-svc-88dtd
  I0521 17:37:39.105543 22 service_latency.go:363] Got endpoints: latency-svc-vhcqf [750.013456ms]
  I0521 17:37:39.116924 22 service_latency.go:356] Created: latency-svc-bsmww
  I0521 17:37:39.156803 22 service_latency.go:363] Got endpoints: latency-svc-c59xm [753.32395ms]
  I0521 17:37:39.168510 22 service_latency.go:356] Created: latency-svc-lqskf
  I0521 17:37:39.203679 22 service_latency.go:363] Got endpoints: latency-svc-xrcwc [748.79213ms]
  I0521 17:37:39.214990 22 service_latency.go:356] Created: latency-svc-n5h45
  I0521 17:37:39.254255 22 service_latency.go:363] Got endpoints: latency-svc-t8cfm [750.512085ms]
  I0521 17:37:39.266095 22 service_latency.go:356] Created: latency-svc-2g42f
  I0521 17:37:39.306805 22 service_latency.go:363] Got endpoints: latency-svc-vvq7m [752.226444ms]
  I0521 17:37:39.318710 22 service_latency.go:356] Created: latency-svc-tc2cf
  I0521 17:37:39.355042 22 service_latency.go:363] Got endpoints: latency-svc-9r6cd [749.585192ms]
  I0521 17:37:39.367558 22 service_latency.go:356] Created: latency-svc-7nv5k
  I0521 17:37:39.402727 22 service_latency.go:363] Got endpoints: latency-svc-nf6q4 [749.130797ms]
  I0521 17:37:39.411726 22 service_latency.go:356] Created: latency-svc-hj99n
  I0521 17:37:39.455340 22 service_latency.go:363] Got endpoints: latency-svc-kzh6p [749.373671ms]
  I0521 17:37:39.468096 22 service_latency.go:356] Created: latency-svc-7tzhp
  I0521 17:37:39.503775 22 service_latency.go:363] Got endpoints: latency-svc-svrw8 [748.158717ms]
  I0521 17:37:39.517540 22 service_latency.go:356] Created: latency-svc-sp4sh
  I0521 17:37:39.555731 22 service_latency.go:363] Got endpoints: latency-svc-n4vmz [750.324104ms]
  I0521 17:37:39.567876 22 service_latency.go:356] Created: latency-svc-5nwww
  I0521 17:37:39.604721 22 service_latency.go:363] Got endpoints: latency-svc-mk29h [750.370434ms]
  I0521 17:37:39.619526 22 service_latency.go:356] Created: latency-svc-cp5tw
  I0521 17:37:39.655614 22 service_latency.go:363] Got endpoints: latency-svc-5x2hc [751.161472ms]
  I0521 17:37:39.667482 22 service_latency.go:356] Created: latency-svc-wlpws
  I0521 17:37:39.705946 22 service_latency.go:363] Got endpoints: latency-svc-mcbwv [749.617887ms]
  I0521 17:37:39.723712 22 service_latency.go:356] Created: latency-svc-8w8xn
  E0521 17:37:39.738666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:39.754275 22 service_latency.go:363] Got endpoints: latency-svc-gjqg9 [749.793068ms]
  I0521 17:37:39.764959 22 service_latency.go:356] Created: latency-svc-5bvhx
  I0521 17:37:39.803676 22 service_latency.go:363] Got endpoints: latency-svc-88dtd [750.757151ms]
  I0521 17:37:39.815168 22 service_latency.go:356] Created: latency-svc-xjzth
  I0521 17:37:39.856329 22 service_latency.go:363] Got endpoints: latency-svc-bsmww [750.699798ms]
  I0521 17:37:39.868361 22 service_latency.go:356] Created: latency-svc-hp522
  I0521 17:37:39.904688 22 service_latency.go:363] Got endpoints: latency-svc-lqskf [747.793563ms]
  I0521 17:37:39.916153 22 service_latency.go:356] Created: latency-svc-7gc5q
  I0521 17:37:39.954463 22 service_latency.go:363] Got endpoints: latency-svc-n5h45 [750.684603ms]
  I0521 17:37:39.966234 22 service_latency.go:356] Created: latency-svc-jvmh5
  I0521 17:37:40.006580 22 service_latency.go:363] Got endpoints: latency-svc-2g42f [752.223752ms]
  I0521 17:37:40.019529 22 service_latency.go:356] Created: latency-svc-fjrd7
  I0521 17:37:40.054630 22 service_latency.go:363] Got endpoints: latency-svc-tc2cf [747.745302ms]
  I0521 17:37:40.066459 22 service_latency.go:356] Created: latency-svc-8qst9
  I0521 17:37:40.105053 22 service_latency.go:363] Got endpoints: latency-svc-7nv5k [749.91845ms]
  I0521 17:37:40.117472 22 service_latency.go:356] Created: latency-svc-9vd74
  I0521 17:37:40.156237 22 service_latency.go:363] Got endpoints: latency-svc-hj99n [753.449977ms]
  I0521 17:37:40.169112 22 service_latency.go:356] Created: latency-svc-hbptg
  I0521 17:37:40.204449 22 service_latency.go:363] Got endpoints: latency-svc-7tzhp [749.017939ms]
  I0521 17:37:40.255179 22 service_latency.go:363] Got endpoints: latency-svc-sp4sh [751.341231ms]
  I0521 17:37:40.304754 22 service_latency.go:363] Got endpoints: latency-svc-5nwww [748.948144ms]
  I0521 17:37:40.351230 22 service_latency.go:363] Got endpoints: latency-svc-cp5tw [746.438257ms]
  I0521 17:37:40.401341 22 service_latency.go:363] Got endpoints: latency-svc-wlpws [745.664873ms]
  I0521 17:37:40.454030 22 service_latency.go:363] Got endpoints: latency-svc-8w8xn [748.012279ms]
  I0521 17:37:40.505262 22 service_latency.go:363] Got endpoints: latency-svc-5bvhx [750.909783ms]
  I0521 17:37:40.556506 22 service_latency.go:363] Got endpoints: latency-svc-xjzth [752.762673ms]
  I0521 17:37:40.603928 22 service_latency.go:363] Got endpoints: latency-svc-hp522 [747.52913ms]
  I0521 17:37:40.652122 22 service_latency.go:363] Got endpoints: latency-svc-7gc5q [747.351536ms]
  I0521 17:37:40.703993 22 service_latency.go:363] Got endpoints: latency-svc-jvmh5 [749.454281ms]
  E0521 17:37:40.739121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:40.755489 22 service_latency.go:363] Got endpoints: latency-svc-fjrd7 [748.815073ms]
  I0521 17:37:40.802954 22 service_latency.go:363] Got endpoints: latency-svc-8qst9 [748.251337ms]
  I0521 17:37:40.854613 22 service_latency.go:363] Got endpoints: latency-svc-9vd74 [749.484071ms]
  I0521 17:37:40.904362 22 service_latency.go:363] Got endpoints: latency-svc-hbptg [748.036423ms]
  I0521 17:37:40.904520 22 service_latency.go:114] Latencies: [20.043906ms 28.211267ms 40.913158ms 48.797697ms 60.027943ms 70.024346ms 79.60307ms 90.586862ms 96.573362ms 106.455708ms 143.501262ms 149.897749ms 166.007489ms 173.448556ms 176.905898ms 180.082577ms 180.140181ms 180.906546ms 181.869626ms 183.005134ms 183.830308ms 185.178274ms 185.586805ms 187.170683ms 187.711996ms 187.995358ms 191.495465ms 203.594489ms 204.046871ms 204.302383ms 205.183694ms 206.439311ms 206.470958ms 207.528394ms 207.711798ms 208.659667ms 208.973213ms 209.602335ms 210.90913ms 230.395003ms 268.937556ms 320.616505ms 343.934727ms 391.303731ms 405.920351ms 443.925189ms 481.308053ms 517.820472ms 560.8654ms 601.536754ms 635.916465ms 681.857929ms 715.35685ms 738.647168ms 741.377897ms 744.466182ms 744.686514ms 744.749063ms 744.787016ms 744.968444ms 745.201948ms 745.664873ms 746.413329ms 746.438257ms 746.476547ms 746.549272ms 746.559535ms 746.6192ms 746.817175ms 747.020835ms 747.104719ms 747.169676ms 747.21537ms 747.217045ms 747.351536ms 747.351797ms 747.355821ms 747.47589ms 747.52913ms 747.632612ms 747.658338ms 747.745302ms 747.779274ms 747.793563ms 747.919297ms 747.948917ms 748.012279ms 748.036423ms 748.051134ms 748.054991ms 748.103329ms 748.144099ms 748.158717ms 748.251337ms 748.303349ms 748.317863ms 748.452815ms 748.488911ms 748.547452ms 748.650512ms 748.733651ms 748.738094ms 748.754837ms 748.79213ms 748.815073ms 748.8494ms 748.948144ms 749.017939ms 749.020804ms 749.061507ms 749.073895ms 749.101152ms 749.107872ms 749.130797ms 749.313718ms 749.314609ms 749.321653ms 749.373671ms 749.437439ms 749.454281ms 749.484071ms 749.49261ms 749.495648ms 749.585192ms 749.617887ms 749.67596ms 749.699996ms 749.729221ms 749.760465ms 749.774181ms 749.793068ms 749.847508ms 749.91845ms 749.95812ms 749.972241ms 750.013456ms 750.084291ms 750.186947ms 750.277579ms 750.278018ms 750.324104ms 750.370434ms 750.376361ms 750.407654ms 750.449582ms 750.479559ms 750.512085ms 750.515139ms 750.537262ms 750.580832ms 750.615386ms 750.681105ms 750.684603ms 750.699798ms 750.727947ms 750.757151ms 750.825858ms 750.829568ms 750.869988ms 750.906344ms 750.909783ms 750.952377ms 750.975714ms 750.981967ms 751.004332ms 751.147461ms 751.161472ms 751.189765ms 751.216539ms 751.341231ms 751.373814ms 751.456027ms 751.60666ms 751.642537ms 751.777112ms 751.887879ms 751.941749ms 752.137815ms 752.223752ms 752.226444ms 752.236046ms 752.411176ms 752.451836ms 752.645142ms 752.689022ms 752.762673ms 752.772527ms 752.82224ms 753.120511ms 753.32395ms 753.382695ms 753.449977ms 753.604264ms 753.96248ms 754.000239ms 754.167873ms 754.284149ms 755.409635ms 757.769288ms 758.452146ms]
  I0521 17:37:40.904541 22 service_latency.go:118] 50 %ile: 748.733651ms
  I0521 17:37:40.904553 22 service_latency.go:119] 90 %ile: 752.236046ms
  I0521 17:37:40.904565 22 service_latency.go:120] 99 %ile: 757.769288ms
  I0521 17:37:40.904576 22 service_latency.go:121] Total sample count: 200
  I0521 17:37:40.904679 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-4457" for this suite. @ 05/21/24 17:37:40.909
• [10.745 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 05/21/24 17:37:40.915
  I0521 17:37:40.915058 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 17:37:40.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:37:40.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:37:40.928
  STEP: Creating configMap with name configmap-test-volume-aa121ba4-1234-4a10-8a30-d70ff1421f18 @ 05/21/24 17:37:40.93
  STEP: Creating a pod to test consume configMaps @ 05/21/24 17:37:40.933
  E0521 17:37:41.739174      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:42.739744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:43.739921      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:44.740623      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:37:44.95
  I0521 17:37:44.952963 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-cbeec1a5-7cbf-4f37-8391-fa600f77fe23 container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:37:44.97
  I0521 17:37:44.980681 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3566" for this suite. @ 05/21/24 17:37:44.983
• [4.073 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 05/21/24 17:37:44.988
  I0521 17:37:44.988471 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 17:37:44.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:37:45.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:37:45.005
  STEP: Creating pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351 @ 05/21/24 17:37:45.007
  E0521 17:37:45.740916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:46.741272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/21/24 17:37:47.029
  I0521 17:37:47.038652 22 container_probe.go:1749] Initial restart count of pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 is 0
  I0521 17:37:47.041618 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:37:47.741430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:48.742526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:49.043905 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:37:49.743545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:50.745240      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:51.048691 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:37:51.744590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:52.745583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:53.054104 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:37:53.745963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:54.746512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:55.059560 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:37:55.746915      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:56.747545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:57.064791 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:37:57.748675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:37:58.749537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:37:59.070323 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:37:59.750679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:00.751674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:01.075592 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:01.752315      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:02.752896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:03.081776 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:03.753491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:04.753993      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:05.087739 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:05.754704      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:06.755357      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:07.092134 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:07.755921      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:08.756158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:09.098041 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:09.756358      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:10.756486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:11.104996 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:11.756691      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:12.757036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:13.111880 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:13.757582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:14.758085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:15.117663 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:15.758750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:16.759724      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:17.123469 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:17.760152      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:18.760627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:19.128932 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:19.761293      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:20.762469      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:21.133718 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:21.763407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:22.763849      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:23.140538 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:23.764326      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:24.764740      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:25.145686 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:25.764966      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:26.766051      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:27.150813 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:27.766511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:28.766591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:29.154614 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:29.767454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:30.768514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:31.160333 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:31.769624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:32.769760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:33.166376 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:33.769911      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:34.770146      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:35.172108 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:35.770617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:36.771103      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:37.178137 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:37.771555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:38.771623      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:39.182348 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:39.772088      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:40.772659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:41.188261 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:41.773575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:42.774064      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:43.194512 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:43.774171      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:44.774434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:45.199785 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:45.775451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:46.775726      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:47.205481 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:47.776088      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:48.776804      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:49.208893 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  E0521 17:38:49.777574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:50.777579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:51.214867 22 container_probe.go:1759] Get pod test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 in namespace container-probe-4351
  I0521 17:38:51.214936 22 container_probe.go:1763] Restart count of pod container-probe-4351/test-grpc-9e5f6597-10de-4ba9-98c1-d23f8f7aee05 is now 1 (1m4.176235524s elapsed)
  STEP: deleting the pod @ 05/21/24 17:38:51.215
  I0521 17:38:51.228240 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4351" for this suite. @ 05/21/24 17:38:51.232
• [66.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 05/21/24 17:38:51.238
  I0521 17:38:51.238710 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:38:51.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:38:51.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:38:51.254
  STEP: Creating the pod @ 05/21/24 17:38:51.257
  E0521 17:38:51.778369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:52.778646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:53.779602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:53.798445 22 pod_client.go:141] Successfully updated pod "labelsupdate2606bf91-7397-4d7a-8da5-bb19e99d27db"
  E0521 17:38:54.780711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:55.781508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:55.817706 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9731" for this suite. @ 05/21/24 17:38:55.821
• [4.587 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 05/21/24 17:38:55.826
  I0521 17:38:55.826666 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename containers @ 05/21/24 17:38:55.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:38:55.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:38:55.843
  E0521 17:38:56.781900      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:57.782053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:38:57.869673 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3035" for this suite. @ 05/21/24 17:38:57.872
• [2.052 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:766
  STEP: Creating a kubernetes client @ 05/21/24 17:38:57.878
  I0521 17:38:57.878923 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 17:38:57.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:38:57.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:38:57.895
  STEP: Setting up server cert @ 05/21/24 17:38:57.912
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 17:38:58.12
  STEP: Deploying the webhook pod @ 05/21/24 17:38:58.124
  STEP: Wait for the deployment to be ready @ 05/21/24 17:38:58.131
  I0521 17:38:58.133932 22 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0521 17:38:58.782376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:38:59.782837      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 17:39:00.141
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 17:39:00.15
  E0521 17:39:00.783237      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:39:01.151052 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 05/21/24 17:39:01.159
  STEP: verifying the mutating webhook match conditions @ 05/21/24 17:39:01.166
  STEP: updating the mutating webhook match conditions @ 05/21/24 17:39:01.168
  STEP: verifying the mutating webhook match conditions @ 05/21/24 17:39:01.175
  I0521 17:39:01.211419 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1896" for this suite. @ 05/21/24 17:39:01.213
  STEP: Destroying namespace "webhook-markers-4946" for this suite. @ 05/21/24 17:39:01.217
• [3.344 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 05/21/24 17:39:01.222
  I0521 17:39:01.222428 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename svcaccounts @ 05/21/24 17:39:01.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:39:01.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:39:01.243
  E0521 17:39:01.783635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:02.784318      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 05/21/24 17:39:03.258
  I0521 17:39:03.258674 22 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7640 pod-service-account-4d8bffca-644b-4260-982c-6f5cd8a9d6dd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 05/21/24 17:39:03.358
  I0521 17:39:03.358794 22 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7640 pod-service-account-4d8bffca-644b-4260-982c-6f5cd8a9d6dd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 05/21/24 17:39:03.441
  I0521 17:39:03.441308 22 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7640 pod-service-account-4d8bffca-644b-4260-982c-6f5cd8a9d6dd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I0521 17:39:03.518331 22 service_accounts.go:114] Got root ca configmap in namespace "svcaccounts-7640"
  I0521 17:39:03.519736 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7640" for this suite. @ 05/21/24 17:39:03.521
• [2.304 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 05/21/24 17:39:03.527
  I0521 17:39:03.527260 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 17:39:03.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:39:03.537
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:39:03.539
  STEP: Creating configMap with name configmap-test-volume-map-e4e6941f-3227-44b1-8e18-873982a89825 @ 05/21/24 17:39:03.54
  STEP: Creating a pod to test consume configMaps @ 05/21/24 17:39:03.544
  E0521 17:39:03.784537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:04.784677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:39:05.555
  I0521 17:39:05.558411 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-bfb6b56f-0821-449c-a80a-00370e4db4cb container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:39:05.565
  I0521 17:39:05.580256 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-457" for this suite. @ 05/21/24 17:39:05.583
• [2.061 seconds]
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:489
  STEP: Creating a kubernetes client @ 05/21/24 17:39:05.588
  I0521 17:39:05.588652 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename security-context-test @ 05/21/24 17:39:05.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:39:05.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:39:05.602
  E0521 17:39:05.785126      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:06.785651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:39:07.618905 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9797" for this suite. @ 05/21/24 17:39:07.622
• [2.038 seconds]
------------------------------
S
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 05/21/24 17:39:07.626
  I0521 17:39:07.626874 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename taint-single-pod @ 05/21/24 17:39:07.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:39:07.638
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:39:07.642
  I0521 17:39:07.644875 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0521 17:39:07.785955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:08.786918      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:09.787037      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:10.787543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:11.788022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:12.788158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:13.789079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:14.789684      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:15.790655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:16.790984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:17.791684      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:18.792309      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:19.792429      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:20.792404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:21.792515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:22.793050      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:23.793749      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:24.794756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:25.795376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:26.795835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:27.796541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:28.796581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:29.797436      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:30.797478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:31.797599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:32.797739      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:33.798085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:34.798681      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:35.798827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:36.799274      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:37.799665      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:38.799987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:39.800821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:40.800974      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:41.801451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:42.801935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:43.802984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:44.803511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:45.804696      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:46.805720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:47.806260      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:48.806837      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:49.807707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:50.808649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:51.809015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:52.809576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:53.810543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:54.811110      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:55.811183      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:56.811567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:57.812079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:58.812625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:39:59.813353      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:00.814160      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:01.814884      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:02.815459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:03.816476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:04.816917      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:05.817036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:06.817117      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:40:07.645504 22 util.go:400] Waiting for terminating namespaces to be deleted...
  I0521 17:40:07.650031 22 taints.go:150] Starting informer...
  STEP: Starting pod... @ 05/21/24 17:40:07.65
  E0521 17:40:07.817547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:40:07.867459 22 taints.go:300] Pod is running on k8sconformance-m02. Tainting Node
  STEP: Trying to apply a taint on the Node @ 05/21/24 17:40:07.867
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/21/24 17:40:07.878
  STEP: Waiting short time to make sure Pod is queued for deletion @ 05/21/24 17:40:07.882
  I0521 17:40:07.882119 22 taints.go:319] Pod wasn't evicted. Proceeding
  I0521 17:40:07.882146 22 taints.go:326] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 05/21/24 17:40:07.897
  STEP: Waiting some time to make sure that toleration time passed. @ 05/21/24 17:40:07.9
  E0521 17:40:08.818284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:09.818621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:10.819677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:11.820807      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:12.821349      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:13.821516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:14.821972      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:15.822569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:16.822732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:17.823562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:18.824063      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:19.824532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:20.824739      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:21.825631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:22.826173      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:23.826575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:24.827103      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:25.827486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:26.827773      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:27.828361      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:28.828812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:29.829379      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:30.829549      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:31.829682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:32.830303      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:33.830705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:34.831553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:35.832524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:36.833088      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:37.833686      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:38.834666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:39.835561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:40.836437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:41.836983      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:42.837100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:43.838000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:44.838334      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:45.838531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:46.839070      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:47.839512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:48.839594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:49.840479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:50.841251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:51.841438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:52.841737      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:53.842369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:54.842533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:55.843575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:56.844651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:57.845501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:58.846626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:40:59.846702      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:00.847657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:01.848533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:02.848735      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:03.849164      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:04.849457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:05.850364      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:06.850441      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:07.851597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:08.851729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:09.851850      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:10.852420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:11.853505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:12.854076      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:13.854518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:14.854648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:15.855397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:16.855781      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:17.856593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:18.856766      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:19.857576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:20.857702      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:21.858365      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:22.858603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:22.901977 22 taints.go:335] Pod wasn't evicted. Test successful
  I0521 17:41:22.902330 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-9382" for this suite. @ 05/21/24 17:41:22.907
• [135.286 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 05/21/24 17:41:22.913
  I0521 17:41:22.913248 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/21/24 17:41:22.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:41:22.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:41:22.929
  STEP: fetching the /apis discovery document @ 05/21/24 17:41:22.932
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 05/21/24 17:41:22.933
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 05/21/24 17:41:22.933
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 05/21/24 17:41:22.933
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 05/21/24 17:41:22.934
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 05/21/24 17:41:22.934
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 05/21/24 17:41:22.935
  I0521 17:41:22.935464 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3228" for this suite. @ 05/21/24 17:41:22.938
• [0.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 05/21/24 17:41:22.943
  I0521 17:41:22.943667 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename server-version @ 05/21/24 17:41:22.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:41:22.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:41:22.956
  STEP: Request ServerVersion @ 05/21/24 17:41:22.958
  STEP: Confirm major version @ 05/21/24 17:41:22.959
  I0521 17:41:22.959500 22 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 05/21/24 17:41:22.959
  I0521 17:41:22.959541 22 server_version.go:58] cleanMinorVersion: 30
  I0521 17:41:22.959562 22 server_version.go:62] Minor version: 30
  I0521 17:41:22.959630 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-2401" for this suite. @ 05/21/24 17:41:22.961
• [0.022 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:841
  STEP: Creating a kubernetes client @ 05/21/24 17:41:22.965
  I0521 17:41:22.965836 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 17:41:22.967
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:41:22.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:41:22.98
  STEP: Setting up server cert @ 05/21/24 17:41:22.991
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 17:41:23.205
  STEP: Deploying the webhook pod @ 05/21/24 17:41:23.208
  STEP: Wait for the deployment to be ready @ 05/21/24 17:41:23.215
  I0521 17:41:23.219605 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 17:41:23.859207      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:24.860229      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 17:41:25.23
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 17:41:25.242
  E0521 17:41:25.861162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:26.242885 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 05/21/24 17:41:26.25
  I0521 17:41:26.286367 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3584" for this suite. @ 05/21/24 17:41:26.289
  STEP: Destroying namespace "webhook-markers-2284" for this suite. @ 05/21/24 17:41:26.293
• [3.333 seconds]
------------------------------
S
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 05/21/24 17:41:26.299
  I0521 17:41:26.299340 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename runtimeclass @ 05/21/24 17:41:26.299
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:41:26.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:41:26.308
  STEP: Deleting RuntimeClass runtimeclass-8240-delete-me @ 05/21/24 17:41:26.314
  STEP: Waiting for the RuntimeClass to disappear @ 05/21/24 17:41:26.317
  I0521 17:41:26.324378 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8240" for this suite. @ 05/21/24 17:41:26.326
• [0.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 05/21/24 17:41:26.331
  I0521 17:41:26.331048 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 17:41:26.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:41:26.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:41:26.341
  STEP: Creating pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916 @ 05/21/24 17:41:26.343
  E0521 17:41:26.861336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:27.862056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/21/24 17:41:28.358
  I0521 17:41:28.360389 22 container_probe.go:1749] Initial restart count of pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 is 0
  I0521 17:41:28.362296 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:28.862603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:29.863166      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:30.366650 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:30.863310      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:31.863834      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:32.371745 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:32.864644      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:33.864925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:34.377384 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:34.865411      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:35.866068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:36.380760 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:36.866389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:37.866931      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:38.386656 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:38.867464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:39.867951      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:40.391667 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:40.868419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:41.868614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:42.397322 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:42.869826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:43.870386      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:44.403216 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:44.870415      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:45.870467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:46.407560 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:46.871303      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:47.871483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:48.412842 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:48.872420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:49.873047      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:50.418173 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:50.874022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:51.874978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:52.423728 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:52.875297      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:53.875650      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:54.429284 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:54.876407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:55.876980      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:56.435527 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:56.877061      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:57.877615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:41:58.440917 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:41:58.878616      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:41:59.879581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:00.447108 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:00.880559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:01.880705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:02.452602 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:02.881039      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:03.881495      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:04.458185 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:04.881993      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:05.882474      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:06.463056 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:06.882398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:07.882689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:08.469054 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:08.883576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:09.884049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:10.475977 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:10.884463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:11.885647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:12.481278 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:12.886505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:13.886935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:14.487074 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:14.887825      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:15.888488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:16.492114 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:16.888379      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:17.888743      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:18.497736 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:18.889249      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:19.889486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:20.504470 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:20.890671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:21.890672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:22.509182 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:22.891567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:23.892010      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:24.515313 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:24.892777      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:25.893654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:26.519954 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:26.894643      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:27.895140      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:28.523382 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:28.895987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:29.896576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:30.528546 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:30.897010      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:31.897630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:32.533339 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:32.897904      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:33.898641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:34.538615 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:34.899642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:35.900362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:36.544296 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:36.900554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:37.901656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:38.548899 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:38.902526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:39.903575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:40.554490 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:40.904507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:41.905474      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:42.557089 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:42.906532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:43.907580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:44.560428 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:44.908170      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:45.908571      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:46.565056 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:46.909661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:47.910135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:48.570236 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:48.910498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:49.911662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:50.575429 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:50.911827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:51.912760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:52.581146 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:52.913458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:53.914582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:54.585414 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:54.914806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:55.914928      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:56.589592 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:56.915001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:57.915446      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:42:58.595361 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:42:58.916422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:42:59.916666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:00.601444 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:00.916723      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:01.916978      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:02.607443 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:02.917881      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:03.918932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:04.613035 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:04.919825      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:05.920528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:06.618786 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:06.921164      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:07.921564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:08.625107 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:08.922663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:09.922808      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:10.631399 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:10.923504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:11.924085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:12.637515 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:12.924478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:13.924844      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:14.642161 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:14.924941      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:15.925601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:16.647780 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:16.926249      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:17.926671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:18.653675 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:18.927036      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:19.928104      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:20.659840 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:20.928393      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:21.928860      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:22.665093 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:22.929448      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:23.929893      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:24.670331 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:24.930273      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:25.931028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:26.676294 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:26.931656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:27.932620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:28.681400 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:28.933674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:29.934087      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:30.686929 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:30.934049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:31.934306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:32.691579 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:32.935109      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:33.935349      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:34.697276 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:34.936001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:35.936540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:36.702597 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:36.936682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:37.937768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:38.707936 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:38.938468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:39.939527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:40.712279 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:40.939664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:41.940582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:42.715406 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:42.941639      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:43.941986      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:44.719055 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:44.942742      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:45.943570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:46.722534 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:46.943905      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:47.946419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:48.727602 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:48.944986      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:49.945383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:50.729469 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:50.945529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:51.946284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:52.735131 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:52.946453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:53.946824      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:54.738184 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:54.947812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:55.948720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:56.741546 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:56.949108      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:57.949392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:43:58.745557 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:43:58.949956      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:43:59.950379      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:00.750719 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:00.951065      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:01.951942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:02.753492 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:02.952018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:03.952571      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:04.758352 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:04.953021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:05.953728      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:06.760975 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:06.954659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:07.954714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:08.763478 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:08.954919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:09.955595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:10.766439 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:10.955828      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:11.956425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:12.769708 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:12.957405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:13.957720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:14.773857 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:14.958667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:15.959027      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:16.777805 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:16.959083      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:17.959635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:18.781247 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:18.959711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:19.960101      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:20.785556 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:20.960987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:21.961436      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:22.790467 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:22.961821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:23.962131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:24.795172 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:24.962778      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:25.963515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:26.800407 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:26.963619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:27.964563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:28.805161 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:28.965612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:29.966518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:30.810839 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:30.967135      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:31.967673      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:32.815403 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:32.968731      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:33.968801      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:34.821520 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:34.969141      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:35.969551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:36.827274 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:36.969655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:37.970687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:38.832869 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:38.971407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:39.971376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:40.839276 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:40.972558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:41.973046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:42.845499 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:42.973638      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:43.974720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:44.850947 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:44.975572      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:45.976483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:46.856132 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:46.977365      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:47.977583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:48.862013 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:48.978075      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:49.978164      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:50.867022 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:50.978205      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:51.978628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:52.873119 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:52.979276      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:53.979528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:54.879115 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:54.980158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:55.980593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:56.882611 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:56.980935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:57.981438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:44:58.889009 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:44:58.982165      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:44:59.982648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:00.895263 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:00.983419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:01.983639      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:02.899684 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:02.983949      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:03.984748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:04.905604 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:04.984790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:05.985348      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:06.911430 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:06.985490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:07.985563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:08.914721 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:08.986096      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:09.986989      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:10.920178 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:10.987557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:11.988033      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:12.926023 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:12.988158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:13.988668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:14.931473 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:14.988734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:15.989461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:16.937468 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:16.989585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:17.990701      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:18.943127 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:18.991245      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:19.991592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:20.949494 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:20.991858      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:21.992652      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:22.954782 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:22.993085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:23.993778      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:24.960736 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:24.993877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:25.994449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:26.965145 22 container_probe.go:1759] Get pod liveness-61153028-d1f7-4ff6-bbd2-b456b43d0716 in namespace container-probe-8916
  E0521 17:45:26.995498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:27.995958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/21/24 17:45:28.966
  I0521 17:45:28.980536 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8916" for this suite. @ 05/21/24 17:45:28.983
• [242.658 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 05/21/24 17:45:28.988
  I0521 17:45:28.988962 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pod-network-test @ 05/21/24 17:45:28.99
  E0521 17:45:28.995975      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:45:29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:45:29.002
  STEP: Performing setup for networking test in namespace pod-network-test-3233 @ 05/21/24 17:45:29.003
  STEP: creating a selector @ 05/21/24 17:45:29.003
  STEP: Creating the service pods in kubernetes @ 05/21/24 17:45:29.003
  I0521 17:45:29.003281 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0521 17:45:29.996584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:30.997417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:31.997515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:32.998570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:33.999447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:35.000217      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:36.000520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:37.000583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:38.001092      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:39.001535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:40.001969      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:41.002219      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/21/24 17:45:41.062
  E0521 17:45:42.003068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:43.003661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:43.090425 22 utils.go:779] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0521 17:45:43.090473 22 utils.go:472] Going to poll 10.244.0.154 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  I0521 17:45:43.092697 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.154:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3233 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 17:45:43.092735 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:45:43.093399 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 17:45:43.093465 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3233/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.0.154%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0521 17:45:43.171280 22 utils.go:489] Found all 1 expected endpoints: [netserver-0]
  I0521 17:45:43.171344 22 utils.go:472] Going to poll 10.244.1.104 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  I0521 17:45:43.174057 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.104:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3233 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 17:45:43.174097 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:45:43.174770 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 17:45:43.174845 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3233/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.1.104%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I0521 17:45:43.239555 22 utils.go:489] Found all 1 expected endpoints: [netserver-1]
  I0521 17:45:43.239698 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3233" for this suite. @ 05/21/24 17:45:43.242
• [14.259 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 05/21/24 17:45:43.248
  I0521 17:45:43.248531 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename svcaccounts @ 05/21/24 17:45:43.249
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:45:43.26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:45:43.263
  I0521 17:45:43.284433 22 service_accounts.go:253] created pod pod-service-account-defaultsa
  I0521 17:45:43.284504 22 service_accounts.go:267] pod pod-service-account-defaultsa service account token volume mount: true
  I0521 17:45:43.290725 22 service_accounts.go:253] created pod pod-service-account-mountsa
  I0521 17:45:43.290797 22 service_accounts.go:267] pod pod-service-account-mountsa service account token volume mount: true
  I0521 17:45:43.297898 22 service_accounts.go:253] created pod pod-service-account-nomountsa
  I0521 17:45:43.297961 22 service_accounts.go:267] pod pod-service-account-nomountsa service account token volume mount: false
  I0521 17:45:43.305272 22 service_accounts.go:253] created pod pod-service-account-defaultsa-mountspec
  I0521 17:45:43.305344 22 service_accounts.go:267] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0521 17:45:43.312760 22 service_accounts.go:253] created pod pod-service-account-mountsa-mountspec
  I0521 17:45:43.312834 22 service_accounts.go:267] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0521 17:45:43.322236 22 service_accounts.go:253] created pod pod-service-account-nomountsa-mountspec
  I0521 17:45:43.322329 22 service_accounts.go:267] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0521 17:45:43.335757 22 service_accounts.go:253] created pod pod-service-account-defaultsa-nomountspec
  I0521 17:45:43.335812 22 service_accounts.go:267] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0521 17:45:43.343433 22 service_accounts.go:253] created pod pod-service-account-mountsa-nomountspec
  I0521 17:45:43.343460 22 service_accounts.go:267] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0521 17:45:43.348423 22 service_accounts.go:253] created pod pod-service-account-nomountsa-nomountspec
  I0521 17:45:43.348482 22 service_accounts.go:267] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0521 17:45:43.348604 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5248" for this suite. @ 05/21/24 17:45:43.351
• [0.113 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 05/21/24 17:45:43.361
  I0521 17:45:43.361668 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:45:43.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:45:43.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:45:43.373
  STEP: Creating configMap with name projected-configmap-test-volume-aa5ae50d-1d02-498c-8456-90cb7151d53a @ 05/21/24 17:45:43.375
  STEP: Creating a pod to test consume configMaps @ 05/21/24 17:45:43.378
  E0521 17:45:44.004456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:45.004853      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:46.005698      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:47.006595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:45:47.398
  I0521 17:45:47.401020 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-914bb09e-9b41-4e63-8ae3-83f000225994 container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:45:47.416
  I0521 17:45:47.432587 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9649" for this suite. @ 05/21/24 17:45:47.435
• [4.079 seconds]
------------------------------
SSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 05/21/24 17:45:47.44
  I0521 17:45:47.440720 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename events @ 05/21/24 17:45:47.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:45:47.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:45:47.451
  STEP: creating a test event @ 05/21/24 17:45:47.453
  STEP: listing events in all namespaces @ 05/21/24 17:45:47.459
  STEP: listing events in test namespace @ 05/21/24 17:45:47.462
  STEP: listing events with field selection filtering on source @ 05/21/24 17:45:47.463
  STEP: listing events with field selection filtering on reportingController @ 05/21/24 17:45:47.465
  STEP: getting the test event @ 05/21/24 17:45:47.467
  STEP: patching the test event @ 05/21/24 17:45:47.469
  STEP: getting the test event @ 05/21/24 17:45:47.478
  STEP: updating the test event @ 05/21/24 17:45:47.48
  STEP: getting the test event @ 05/21/24 17:45:47.483
  STEP: deleting the test event @ 05/21/24 17:45:47.484
  STEP: listing events in all namespaces @ 05/21/24 17:45:47.486
  STEP: listing events in test namespace @ 05/21/24 17:45:47.488
  I0521 17:45:47.489678 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2369" for this suite. @ 05/21/24 17:45:47.491
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 05/21/24 17:45:47.494
  I0521 17:45:47.494247 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/21/24 17:45:47.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:45:47.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:45:47.506
  I0521 17:45:47.509613 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:45:48.007269      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:48.531208 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7692" for this suite. @ 05/21/24 17:45:48.537
• [1.049 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 05/21/24 17:45:48.542
  I0521 17:45:48.542859 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:45:48.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:45:48.557
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:45:48.559
  STEP: Creating configMap with name projected-configmap-test-volume-52fccf83-8f9b-46ec-91b7-ab3a2cbb76e2 @ 05/21/24 17:45:48.561
  STEP: Creating a pod to test consume configMaps @ 05/21/24 17:45:48.564
  E0521 17:45:49.007148      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:50.007830      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:51.008950      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:52.008343      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:45:52.581
  I0521 17:45:52.583399 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-acd6af98-b547-4851-8b41-825216a4fabe container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:45:52.589
  I0521 17:45:52.601140 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3609" for this suite. @ 05/21/24 17:45:52.603
• [4.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 05/21/24 17:45:52.608
  I0521 17:45:52.608662 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename dns @ 05/21/24 17:45:52.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:45:52.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:45:52.622
  STEP: Creating a test headless service @ 05/21/24 17:45:52.625
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local;sleep 1; done
   @ 05/21/24 17:45:52.629
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local;sleep 1; done
   @ 05/21/24 17:45:52.629
  STEP: creating a pod to probe DNS @ 05/21/24 17:45:52.629
  STEP: submitting the pod to kubernetes @ 05/21/24 17:45:52.629
  E0521 17:45:53.009225      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:54.009630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/21/24 17:45:54.646
  STEP: looking for the results for each expected name from probers @ 05/21/24 17:45:54.649
  I0521 17:45:54.653104 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:54.655602 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:54.657846 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:54.660137 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:54.662289 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:54.664457 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:54.666514 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:54.668556 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:54.668590 22 dns_common.go:489] Lookups using dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local]

  I0521 17:45:54.674807 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:45:54.681558 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:45:54.687752 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:45:55.009781      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:56.010683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:57.011666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:58.012666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:45:59.012939      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:45:59.656569 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:59.659711 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:59.662123 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:59.664255 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:59.666565 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:59.668600 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:59.670715 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:59.672816 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:45:59.672853 22 dns_common.go:489] Lookups using dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local]

  I0521 17:45:59.678897 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:45:59.685124 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:45:59.691440 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:46:00.013039      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:01.013480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:02.014483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:03.015551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:04.016618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:04.654108 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:04.656962 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:04.659284 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:04.661797 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:04.664117 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:04.665836 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:04.667579 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:04.669537 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:04.669584 22 dns_common.go:489] Lookups using dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local]

  I0521 17:46:04.676411 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:46:04.682583 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:46:04.688291 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:46:05.017156      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:06.018256      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:07.018676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:08.019440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:09.020433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:09.654164 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:09.656764 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:09.659017 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:09.661334 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:09.663298 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:09.665105 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:09.666540 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:09.667843 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:09.667867 22 dns_common.go:489] Lookups using dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local]

  I0521 17:46:09.671660 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:46:09.675132 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:46:09.679085 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:46:10.021471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:11.021715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:12.022617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:13.023606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:14.024453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:14.656056 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:14.659537 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:14.662092 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:14.664332 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:14.666529 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:14.668603 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:14.670507 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:14.672462 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:14.672501 22 dns_common.go:489] Lookups using dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local]

  I0521 17:46:14.678560 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:46:14.684645 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:46:14.690131 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:46:15.025021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:16.025520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:17.026587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:18.027538      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:19.027563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:19.655556 22 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:19.658830 22 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:19.661662 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:19.664138 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:19.666370 22 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:19.668677 22 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:19.670822 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:19.672948 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local from pod dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0: the server could not find the requested resource (get pods dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0)
  I0521 17:46:19.672994 22 dns_common.go:489] Lookups using dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local wheezy_udp@dns-test-service-2.dns-566.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-566.svc.cluster.local jessie_udp@dns-test-service-2.dns-566.svc.cluster.local jessie_tcp@dns-test-service-2.dns-566.svc.cluster.local]

  I0521 17:46:19.679397 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 17:46:19.686093 22 dns_common.go:495] Pod client logs for querier: 
  I0521 17:46:19.691754 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 17:46:20.028284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:21.029176      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:22.029620      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:23.030646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:24.031586      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:24.672347 22 dns_common.go:527] DNS probes using dns-566/dns-test-3c6bdd47-5d94-410e-b8fa-c9bb99b834a0 succeeded

  STEP: deleting the pod @ 05/21/24 17:46:24.672
  STEP: deleting the test headless service @ 05/21/24 17:46:24.682
  I0521 17:46:24.702868 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-566" for this suite. @ 05/21/24 17:46:24.71
• [32.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 05/21/24 17:46:24.716
  I0521 17:46:24.716890 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename daemonsets @ 05/21/24 17:46:24.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:46:24.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:46:24.729
  STEP: Creating simple DaemonSet "daemon-set" @ 05/21/24 17:46:24.74
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/21/24 17:46:24.743
  I0521 17:46:24.747182 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 17:46:24.747221 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  E0521 17:46:25.032128      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:25.751584 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 17:46:25.751625 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  E0521 17:46:26.032980      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:26.748380 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0521 17:46:26.748425 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 05/21/24 17:46:26.75
  STEP: DeleteCollection of the DaemonSets @ 05/21/24 17:46:26.751
  STEP: Verify that ReplicaSets have been deleted @ 05/21/24 17:46:26.754
  I0521 17:46:26.764080 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22023"},"items":null}

  I0521 17:46:26.766634 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22023"},"items":[{"metadata":{"name":"daemon-set-6nqjf","generateName":"daemon-set-","namespace":"daemonsets-3487","uid":"bea30c02-b0a8-460e-a383-9d8cd8507ea5","resourceVersion":"22023","creationTimestamp":"2024-05-21T17:46:24Z","deletionTimestamp":"2024-05-21T17:46:56Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"2a3ea1ab-9291-4cbb-a90d-a8a8c22b9cb7","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-21T17:46:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2a3ea1ab-9291-4cbb-a90d-a8a8c22b9cb7\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-21T17:46:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.157\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-lv2mb","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-lv2mb","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8sconformance","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8sconformance"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:26Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:24Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:26Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:26Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:24Z"}],"hostIP":"192.168.67.2","hostIPs":[{"ip":"192.168.67.2"}],"podIP":"10.244.0.157","podIPs":[{"ip":"10.244.0.157"}],"startTime":"2024-05-21T17:46:24Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-21T17:46:25Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"docker://cece30cd37fdc51c0d404c6da660aa952fd604a69a485d6063b3e608df3a7954","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-wgn6l","generateName":"daemon-set-","namespace":"daemonsets-3487","uid":"3a6b4cb0-9f28-4014-a23b-1c8cade21e0c","resourceVersion":"22022","creationTimestamp":"2024-05-21T17:46:24Z","deletionTimestamp":"2024-05-21T17:46:56Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7d79bd845c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"2a3ea1ab-9291-4cbb-a90d-a8a8c22b9cb7","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-05-21T17:46:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2a3ea1ab-9291-4cbb-a90d-a8a8c22b9cb7\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-05-21T17:46:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.111\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vfbs7","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vfbs7","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"k8sconformance-m02","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["k8sconformance-m02"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:26Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:24Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:26Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:26Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-05-21T17:46:24Z"}],"hostIP":"192.168.67.3","hostIPs":[{"ip":"192.168.67.3"}],"podIP":"10.244.1.111","podIPs":[{"ip":"10.244.1.111"}],"startTime":"2024-05-21T17:46:24Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-05-21T17:46:25Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"docker://c5dd9366bbf667cf947d7cc10ebfade0e987d75928e634cb00137b067f2acab6","started":true}],"qosClass":"BestEffort"}}]}

  I0521 17:46:26.770726 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3487" for this suite. @ 05/21/24 17:46:26.772
• [2.058 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:927
  STEP: Creating a kubernetes client @ 05/21/24 17:46:26.775
  I0521 17:46:26.775055 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename job @ 05/21/24 17:46:26.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:46:26.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:46:26.784
  STEP: Creating a suspended job @ 05/21/24 17:46:26.786
  STEP: Patching the Job @ 05/21/24 17:46:26.789
  STEP: Watching for Job to be patched @ 05/21/24 17:46:26.822
  I0521 17:46:26.823636 22 job.go:1109] Event ADDED observed for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh] and annotations: map[]
  I0521 17:46:26.823668 22 job.go:1109] Event MODIFIED observed for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh] and annotations: map[]
  I0521 17:46:26.823684 22 job.go:1112] Event MODIFIED found for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh e2e-rhmvh:patched] and annotations: map[]
  STEP: Updating the job @ 05/21/24 17:46:26.823
  STEP: Watching for Job to be updated @ 05/21/24 17:46:26.83
  I0521 17:46:26.831776 22 job.go:1112] Event MODIFIED found for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh e2e-rhmvh:patched] and annotations: map[updated:true]
  I0521 17:46:26.831807 22 job.go:1005] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 05/21/24 17:46:26.831
  I0521 17:46:26.832912 22 job.go:1012] Job: e2e-rhmvh as labels: map[e2e-job-label:e2e-rhmvh e2e-rhmvh:patched]
  STEP: Waiting for job to complete @ 05/21/24 17:46:26.832
  E0521 17:46:27.033247      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:28.033839      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:29.034894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:30.035836      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:31.036759      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:32.037208      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:33.037678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:34.038336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 05/21/24 17:46:34.838
  STEP: Watching for Job to be deleted @ 05/21/24 17:46:34.845
  I0521 17:46:34.847562 22 job.go:1109] Event MODIFIED observed for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh e2e-rhmvh:patched] and annotations: map[updated:true]
  I0521 17:46:34.847776 22 job.go:1109] Event MODIFIED observed for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh e2e-rhmvh:patched] and annotations: map[updated:true]
  I0521 17:46:34.847811 22 job.go:1109] Event MODIFIED observed for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh e2e-rhmvh:patched] and annotations: map[updated:true]
  I0521 17:46:34.848096 22 job.go:1109] Event MODIFIED observed for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh e2e-rhmvh:patched] and annotations: map[updated:true]
  I0521 17:46:34.848218 22 job.go:1109] Event MODIFIED observed for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh e2e-rhmvh:patched] and annotations: map[updated:true]
  I0521 17:46:34.848356 22 job.go:1112] Event DELETED found for Job e2e-rhmvh in namespace job-4866 with labels: map[e2e-job-label:e2e-rhmvh e2e-rhmvh:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 05/21/24 17:46:34.848
  I0521 17:46:34.851088 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4866" for this suite. @ 05/21/24 17:46:34.854
• [8.084 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 05/21/24 17:46:34.859
  I0521 17:46:34.859503 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename gc @ 05/21/24 17:46:34.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:46:34.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:46:34.875
  STEP: create the rc @ 05/21/24 17:46:34.879
  W0521 17:46:34.883692      22 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0521 17:46:35.038967      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:36.039945      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:37.040444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:38.040976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:39.041685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:40.041905      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 05/21/24 17:46:40.887
  STEP: wait for the rc to be deleted @ 05/21/24 17:46:40.894
  E0521 17:46:41.042596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:41.909466 22 garbage_collector.go:670] 80 pods remaining
  I0521 17:46:41.909503 22 garbage_collector.go:677] 80 pods has nil DeletionTimestamp
  I0521 17:46:41.909514 22 garbage_collector.go:678] 
  E0521 17:46:42.043405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:42.910991 22 garbage_collector.go:670] 71 pods remaining
  I0521 17:46:42.911032 22 garbage_collector.go:677] 70 pods has nil DeletionTimestamp
  I0521 17:46:42.911042 22 garbage_collector.go:678] 
  E0521 17:46:43.044052      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:43.906692 22 garbage_collector.go:670] 60 pods remaining
  I0521 17:46:43.906731 22 garbage_collector.go:677] 60 pods has nil DeletionTimestamp
  I0521 17:46:43.906745 22 garbage_collector.go:678] 
  E0521 17:46:44.044600      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:44.904792 22 garbage_collector.go:670] 40 pods remaining
  I0521 17:46:44.904852 22 garbage_collector.go:677] 40 pods has nil DeletionTimestamp
  I0521 17:46:44.904868 22 garbage_collector.go:678] 
  E0521 17:46:45.044679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:45.902309 22 garbage_collector.go:670] 31 pods remaining
  I0521 17:46:45.902340 22 garbage_collector.go:677] 30 pods has nil DeletionTimestamp
  I0521 17:46:45.902348 22 garbage_collector.go:678] 
  E0521 17:46:46.045669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:46.904594 22 garbage_collector.go:670] 20 pods remaining
  I0521 17:46:46.904641 22 garbage_collector.go:677] 20 pods has nil DeletionTimestamp
  I0521 17:46:46.904657 22 garbage_collector.go:678] 
  E0521 17:46:47.046252      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 05/21/24 17:46:47.899
  E0521 17:46:48.046758      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:46:48.052345 22 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0521 17:46:48.052553 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9135" for this suite. @ 05/21/24 17:46:48.056
• [13.202 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 05/21/24 17:46:48.061
  I0521 17:46:48.061687 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 17:46:48.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:46:48.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:46:48.08
  STEP: Creating a ResourceQuota with terminating scope @ 05/21/24 17:46:48.082
  STEP: Ensuring ResourceQuota status is calculated @ 05/21/24 17:46:48.085
  E0521 17:46:49.047860      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:50.048484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 05/21/24 17:46:50.091
  STEP: Ensuring ResourceQuota status is calculated @ 05/21/24 17:46:50.097
  E0521 17:46:51.048560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:52.049659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 05/21/24 17:46:52.103
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 05/21/24 17:46:52.119
  E0521 17:46:53.049973      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:54.050944      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 05/21/24 17:46:54.123
  E0521 17:46:55.052110      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:56.053118      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/21/24 17:46:56.127
  STEP: Ensuring resource quota status released the pod usage @ 05/21/24 17:46:56.135
  E0521 17:46:57.054284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:46:58.054518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 05/21/24 17:46:58.141
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 05/21/24 17:46:58.154
  E0521 17:46:59.054482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:00.054582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 05/21/24 17:47:00.16
  E0521 17:47:01.055103      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:02.055676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/21/24 17:47:02.165
  STEP: Ensuring resource quota status released the pod usage @ 05/21/24 17:47:02.175
  E0521 17:47:03.056517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:04.057362      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:47:04.180216 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7267" for this suite. @ 05/21/24 17:47:04.183
• [16.128 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:673
  STEP: Creating a kubernetes client @ 05/21/24 17:47:04.189
  I0521 17:47:04.189893 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/21/24 17:47:04.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:47:04.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:47:04.203
  STEP: getting /apis @ 05/21/24 17:47:04.21
  STEP: getting /apis/admissionregistration.k8s.io @ 05/21/24 17:47:04.213
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 05/21/24 17:47:04.214
  STEP: creating @ 05/21/24 17:47:04.215
  STEP: getting @ 05/21/24 17:47:04.226
  STEP: listing @ 05/21/24 17:47:04.229
  STEP: watching @ 05/21/24 17:47:04.231
  I0521 17:47:04.231722 22 validatingadmissionpolicy.go:768] starting watch
  STEP: patching @ 05/21/24 17:47:04.232
  STEP: updating @ 05/21/24 17:47:04.238
  I0521 17:47:04.245532 22 validatingadmissionpolicy.go:796] waiting for watch events with expected annotations
  STEP: deleting @ 05/21/24 17:47:04.245
  STEP: deleting a collection @ 05/21/24 17:47:04.251
  I0521 17:47:04.257812 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-9034" for this suite. @ 05/21/24 17:47:04.258
• [0.072 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 05/21/24 17:47:04.261
  I0521 17:47:04.261487 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename deployment @ 05/21/24 17:47:04.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:47:04.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:47:04.27
  STEP: creating a Deployment @ 05/21/24 17:47:04.273
  I0521 17:47:04.273779 22 deployment.go:507] Creating simple deployment test-deployment-6vfx2
  I0521 17:47:04.281806 22 deployment.go:222] deployment "test-deployment-6vfx2" doesn't have the required revision set
  E0521 17:47:05.057991      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:06.058404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 05/21/24 17:47:06.294
  I0521 17:47:06.297391 22 deployment.go:532] Deployment test-deployment-6vfx2 has Conditions: [{Available True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6vfx2-c8586b885" has successfully progressed.}]
  STEP: updating Deployment Status @ 05/21/24 17:47:06.297
  I0521 17:47:06.307594 22 deployment.go:552] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 47, 5, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 47, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 47, 5, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 47, 4, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-6vfx2-c8586b885\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 05/21/24 17:47:06.307
  I0521 17:47:06.309759 22 deployment.go:579] Observed &Deployment event: ADDED
  I0521 17:47:06.309804 22 deployment.go:575] Observed Deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-6vfx2-c8586b885"}
  I0521 17:47:06.309922 22 deployment.go:579] Observed &Deployment event: MODIFIED
  I0521 17:47:06.309946 22 deployment.go:575] Observed Deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-6vfx2-c8586b885"}
  I0521 17:47:06.309961 22 deployment.go:575] Observed Deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0521 17:47:06.310087 22 deployment.go:579] Observed &Deployment event: MODIFIED
  I0521 17:47:06.310108 22 deployment.go:575] Observed Deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0521 17:47:06.310144 22 deployment.go:575] Observed Deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-6vfx2-c8586b885" is progressing.}
  I0521 17:47:06.310284 22 deployment.go:579] Observed &Deployment event: MODIFIED
  I0521 17:47:06.310310 22 deployment.go:575] Observed Deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0521 17:47:06.310325 22 deployment.go:575] Observed Deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6vfx2-c8586b885" has successfully progressed.}
  I0521 17:47:06.310422 22 deployment.go:579] Observed &Deployment event: MODIFIED
  I0521 17:47:06.310440 22 deployment.go:575] Observed Deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0521 17:47:06.310455 22 deployment.go:575] Observed Deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6vfx2-c8586b885" has successfully progressed.}
  I0521 17:47:06.310471 22 deployment.go:572] Found Deployment test-deployment-6vfx2 in namespace deployment-7565 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0521 17:47:06.310487 22 deployment.go:583] Deployment test-deployment-6vfx2 has an updated status
  STEP: patching the Statefulset Status @ 05/21/24 17:47:06.31
  I0521 17:47:06.310530 22 deployment.go:587] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0521 17:47:06.316573 22 deployment.go:591] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 05/21/24 17:47:06.316
  I0521 17:47:06.318597 22 deployment.go:616] Observed &Deployment event: ADDED
  I0521 17:47:06.318661 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-6vfx2-c8586b885"}
  I0521 17:47:06.318820 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0521 17:47:06.318868 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-6vfx2-c8586b885"}
  I0521 17:47:06.318884 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0521 17:47:06.318993 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0521 17:47:06.319019 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0521 17:47:06.319034 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:04 +0000 UTC 2024-05-21 17:47:04 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-6vfx2-c8586b885" is progressing.}
  I0521 17:47:06.319134 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0521 17:47:06.319154 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0521 17:47:06.319168 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6vfx2-c8586b885" has successfully progressed.}
  I0521 17:47:06.319289 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0521 17:47:06.319309 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0521 17:47:06.319325 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-05-21 17:47:05 +0000 UTC 2024-05-21 17:47:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-6vfx2-c8586b885" has successfully progressed.}
  I0521 17:47:06.319339 22 deployment.go:612] Observed deployment test-deployment-6vfx2 in namespace deployment-7565 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0521 17:47:06.319464 22 deployment.go:616] Observed &Deployment event: MODIFIED
  I0521 17:47:06.319491 22 deployment.go:609] Found deployment test-deployment-6vfx2 in namespace deployment-7565 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0521 17:47:06.319505 22 deployment.go:620] Deployment test-deployment-6vfx2 has a patched status
  I0521 17:47:06.325158 22 deployment.go:633] Deployment "test-deployment-6vfx2":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-6vfx2",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7565",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9ca67f87-e3e1-4e86-b430-7c42ee33e68b",
      ResourceVersion: (string) (len=5) "24021",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910424,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910424,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910426,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910426,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910426,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910426,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=55) "Found new replica set \"test-deployment-6vfx2-c8586b885\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0521 17:47:06.330269 22 deployment.go:39] New ReplicaSet "test-deployment-6vfx2-c8586b885" of Deployment "test-deployment-6vfx2":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-6vfx2-c8586b885",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7565",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "097d97d5-5237-4e06-a0a7-1072c3064ba1",
      ResourceVersion: (string) (len=5) "24017",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910424,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-6vfx2",
          UID: (types.UID) (len=36) "9ca67f87-e3e1-4e86-b430-7c42ee33e68b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910424,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 39 63 61  |k:{\"uid\":\"9ca|
              00000120  36 37 66 38 37 2d 65 33  65 31 2d 34 65 38 36 2d  |67f87-e3e1-4e86-|
              00000130  62 34 33 30 2d 37 63 34  32 65 65 33 33 65 36 38  |b430-7c42ee33e68|
              00000140  62 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |b\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910425,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 17:47:06.334047 22 deployment.go:67] Pod "test-deployment-6vfx2-c8586b885-gjh8m" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "test-deployment-6vfx2-c8586b885-gjh8m",
      GenerateName: (string) (len=32) "test-deployment-6vfx2-c8586b885-",
      Namespace: (string) (len=15) "deployment-7565",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9b0b19f0-376c-4bdb-9f25-f735df9b0fb7",
      ResourceVersion: (string) (len=5) "24016",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910424,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "c8586b885"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "test-deployment-6vfx2-c8586b885",
          UID: (types.UID) (len=36) "097d97d5-5237-4e06-a0a7-1072c3064ba1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910424,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 30 39 37 64 39 37 64  35 2d 35 32 33 37 2d 34  |"097d97d5-5237-4|
              000000a0  65 30 36 2d 61 30 61 37  2d 31 30 37 32 63 33 30  |e06-a0a7-1072c30|
              000000b0  36 34 62 61 31 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |64ba1\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910425,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  36 37 5c 22 7d 22 3a 7b  |.244.1.167\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t4gxs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t4gxs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910425,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910424,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910425,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910425,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910424,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=12) "10.244.1.167",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.167"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910424,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851910424,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://5bd247f7579480d2020b2fc446270550f974a8c36375b8afb114b3f58a25ffa1",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 17:47:06.336161 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7565" for this suite. @ 05/21/24 17:47:06.338
• [2.082 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 05/21/24 17:47:06.344
  I0521 17:47:06.344371 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename endpointslice @ 05/21/24 17:47:06.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:47:06.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:47:06.357
  E0521 17:47:07.059152      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:08.060151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 05/21/24 17:47:08.416
  STEP: referencing matching pods with named port @ 05/21/24 17:47:08.42
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 05/21/24 17:47:08.424
  STEP: recreating EndpointSlices after they've been deleted @ 05/21/24 17:47:08.428
  I0521 17:47:08.441475 22 endpointslice.go:938] EndpointSlice for Service endpointslice-545/example-named-port not found
  E0521 17:47:09.060871      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:10.061494      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:47:10.446709 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-545" for this suite. @ 05/21/24 17:47:10.449
• [4.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 05/21/24 17:47:10.458
  I0521 17:47:10.458031 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pod-network-test @ 05/21/24 17:47:10.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:47:10.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:47:10.471
  STEP: Performing setup for networking test in namespace pod-network-test-9507 @ 05/21/24 17:47:10.474
  STEP: creating a selector @ 05/21/24 17:47:10.474
  STEP: Creating the service pods in kubernetes @ 05/21/24 17:47:10.474
  I0521 17:47:10.474930 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0521 17:47:11.061870      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:12.062352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:13.062560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:14.063126      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:15.064023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:16.064901      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:17.065916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:18.066750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:19.067756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:20.068472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:21.068465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:22.069372      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:23.070066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:24.070400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:25.071644      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:26.072307      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:27.072641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:28.073139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:29.073301      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:30.073989      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:31.074422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:32.074719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/21/24 17:47:32.55
  E0521 17:47:33.075533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:34.076469      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:47:34.578326 22 utils.go:779] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0521 17:47:34.578383 22 utils.go:472] Going to poll 10.244.0.207 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  I0521 17:47:34.580477 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.207 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9507 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 17:47:34.580511 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:47:34.581084 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 17:47:34.581144 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9507/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.0.207+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0521 17:47:35.076696      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:47:35.652662 22 utils.go:489] Found all 1 expected endpoints: [netserver-0]
  I0521 17:47:35.652735 22 utils.go:472] Going to poll 10.244.1.170 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  I0521 17:47:35.656565 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.170 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9507 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 17:47:35.656622 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 17:47:35.657518 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 17:47:35.657628 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9507/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.1.170+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0521 17:47:36.077719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:47:36.726363 22 utils.go:489] Found all 1 expected endpoints: [netserver-1]
  I0521 17:47:36.726556 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9507" for this suite. @ 05/21/24 17:47:36.73
• [26.279 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 05/21/24 17:47:36.737
  I0521 17:47:36.737130 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 17:47:36.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:47:36.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:47:36.752
  STEP: Counting existing ResourceQuota @ 05/21/24 17:47:36.755
  E0521 17:47:37.078528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:38.078555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:39.078946      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:40.079785      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:41.079991      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 05/21/24 17:47:41.758
  STEP: Ensuring resource quota status is calculated @ 05/21/24 17:47:41.763
  E0521 17:47:42.080723      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:43.081038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 05/21/24 17:47:43.77
  STEP: Ensuring ResourceQuota status captures the pod usage @ 05/21/24 17:47:43.788
  E0521 17:47:44.081517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:45.081727      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 05/21/24 17:47:45.79
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 05/21/24 17:47:45.793
  STEP: Ensuring a pod cannot update its resource requirements @ 05/21/24 17:47:45.794
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 05/21/24 17:47:45.797
  E0521 17:47:46.082461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:47.083385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 05/21/24 17:47:47.8
  STEP: Ensuring resource quota status released the pod usage @ 05/21/24 17:47:47.807
  E0521 17:47:48.083548      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:49.083747      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:47:49.810165 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1899" for this suite. @ 05/21/24 17:47:49.812
• [13.078 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 05/21/24 17:47:49.815
  I0521 17:47:49.815284 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename statefulset @ 05/21/24 17:47:49.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:47:49.824
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:47:49.825
  STEP: Creating service test in namespace statefulset-1681 @ 05/21/24 17:47:49.826
  I0521 17:47:49.834943 22 wait.go:40] Found 0 stateful pods, waiting for 1
  E0521 17:47:50.084655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:51.085551      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:52.085800      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:53.085855      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:54.086633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:55.086827      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:56.087523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:57.087631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:58.088263      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:47:59.088562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:47:59.838344 22 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 05/21/24 17:47:59.842
  W0521 17:47:59.850490      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  I0521 17:47:59.855994 22 wait.go:40] Found 1 stateful pods, waiting for 2
  E0521 17:48:00.089542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:01.090559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:02.091379      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:03.092539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:04.092782      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:05.093722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:06.093804      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:07.094040      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:08.094123      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:09.094596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:09.859589 22 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0521 17:48:09.859652 22 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 05/21/24 17:48:09.864
  STEP: Delete all of the StatefulSets @ 05/21/24 17:48:09.867
  STEP: Verify that StatefulSets have been deleted @ 05/21/24 17:48:09.872
  I0521 17:48:09.874850 22 statefulset.go:135] Deleting all statefulset in ns statefulset-1681
  I0521 17:48:09.881555 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1681" for this suite. @ 05/21/24 17:48:09.889
• [20.083 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 05/21/24 17:48:09.898
  I0521 17:48:09.899000 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename statefulset @ 05/21/24 17:48:09.9
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:48:09.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:48:09.925
  STEP: Creating service test in namespace statefulset-4493 @ 05/21/24 17:48:09.928
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 05/21/24 17:48:09.931
  STEP: Creating stateful set ss in namespace statefulset-4493 @ 05/21/24 17:48:09.934
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4493 @ 05/21/24 17:48:09.941
  I0521 17:48:09.944036 22 wait.go:40] Found 0 stateful pods, waiting for 1
  E0521 17:48:10.095139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:11.095294      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:12.095511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:13.095891      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:14.096898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:15.097455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:16.098601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:17.099400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:18.100394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:19.100520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:19.945871 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 05/21/24 17:48:19.945
  I0521 17:48:19.950231 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4493 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 17:48:20.035807 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 17:48:20.035854 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 17:48:20.035872 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0521 17:48:20.038165 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0521 17:48:20.101684      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:21.101945      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:22.102533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:23.102644      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:24.103703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:25.104125      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:26.104780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:27.105623      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:28.105787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:29.105903      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:30.042659 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0521 17:48:30.042720 22 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0521 17:48:30.057607 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 9.999999474s
  E0521 17:48:30.106554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:31.063849 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 8.996274805s
  E0521 17:48:31.107123      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:32.069724 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 7.990297732s
  E0521 17:48:32.107944      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:33.075320 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 6.984194945s
  E0521 17:48:33.108581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:34.080771 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 5.978788491s
  E0521 17:48:34.109035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:35.086919 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 4.973271334s
  E0521 17:48:35.110119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:36.093642 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 3.966856663s
  E0521 17:48:36.110702      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:37.099334 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 2.960892909s
  E0521 17:48:37.111438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:38.104833 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 1.95508917s
  E0521 17:48:38.111857      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:39.110053 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 1 for another 949.531832ms
  E0521 17:48:39.112069      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4493 @ 05/21/24 17:48:40.11
  E0521 17:48:40.112747      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:40.116579 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4493 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0521 17:48:40.219332 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0521 17:48:40.219376 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0521 17:48:40.219402 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0521 17:48:40.221626 22 wait.go:40] Found 1 stateful pods, waiting for 3
  E0521 17:48:41.113835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:42.114069      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:43.114719      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:44.115523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:45.116182      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:46.116534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:47.117497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:48.117866      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:49.118485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:50.118910      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:48:50.225957 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0521 17:48:50.226022 22 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0521 17:48:50.226042 22 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 05/21/24 17:48:50.226
  STEP: Scale down will halt with unhealthy stateful pod @ 05/21/24 17:48:50.226
  I0521 17:48:50.232903 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4493 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 17:48:50.310712 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 17:48:50.310759 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 17:48:50.310779 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0521 17:48:50.310831 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4493 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 17:48:50.402680 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 17:48:50.402726 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 17:48:50.402748 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0521 17:48:50.402804 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4493 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 17:48:50.501326 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 17:48:50.501360 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 17:48:50.501373 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0521 17:48:50.501383 22 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0521 17:48:50.503080 22 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0521 17:48:51.119619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:52.120618      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:53.121184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:54.121405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:55.122112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:56.122392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:57.122779      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:58.123475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:48:59.123598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:00.124627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:00.510429 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0521 17:49:00.510483 22 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0521 17:49:00.510500 22 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0521 17:49:00.525105 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 9.999999473s
  E0521 17:49:01.125619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:01.532446 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 8.995176623s
  E0521 17:49:02.126002      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:02.539129 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 7.988077182s
  E0521 17:49:03.126935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:03.545261 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 6.982148334s
  E0521 17:49:04.127964      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:04.551086 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 5.975955318s
  E0521 17:49:05.128797      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:05.556086 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 4.969431211s
  E0521 17:49:06.129513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:06.561005 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 3.96425158s
  E0521 17:49:07.129760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:07.565521 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 2.96015653s
  E0521 17:49:08.130316      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:08.570990 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 1.955434545s
  E0521 17:49:09.130552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:09.576530 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 950.029115ms
  E0521 17:49:10.131312      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4493 @ 05/21/24 17:49:10.577
  I0521 17:49:10.582530 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4493 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0521 17:49:10.668181 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0521 17:49:10.668256 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0521 17:49:10.668285 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0521 17:49:10.668338 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4493 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0521 17:49:10.762975 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0521 17:49:10.763027 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0521 17:49:10.763047 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0521 17:49:10.763105 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4493 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0521 17:49:10.849132 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0521 17:49:10.849177 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0521 17:49:10.849208 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0521 17:49:10.849220 22 rest.go:150] Scaling statefulset ss to 0
  E0521 17:49:11.131360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:12.131619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:13.132305      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:14.133477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:15.134003      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:16.134669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:17.135261      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:18.135835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:19.136808      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:20.137259      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 05/21/24 17:49:20.859
  I0521 17:49:20.859299 22 statefulset.go:135] Deleting all statefulset in ns statefulset-4493
  I0521 17:49:20.861805 22 rest.go:150] Scaling statefulset ss to 0
  I0521 17:49:20.869441 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0521 17:49:20.871321 22 rest.go:88] Deleting statefulset ss
  I0521 17:49:20.881497 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4493" for this suite. @ 05/21/24 17:49:20.884
• [70.992 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 05/21/24 17:49:20.891
  I0521 17:49:20.891460 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 17:49:20.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:49:20.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:49:20.906
  STEP: Creating secret with name s-test-opt-del-499f9c57-a2e8-48cf-97f1-de3196f3d0ae @ 05/21/24 17:49:20.91
  STEP: Creating secret with name s-test-opt-upd-534c4102-b78a-4434-8da0-a47144176905 @ 05/21/24 17:49:20.913
  STEP: Creating the pod @ 05/21/24 17:49:20.916
  E0521 17:49:21.138089      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:22.139092      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-499f9c57-a2e8-48cf-97f1-de3196f3d0ae @ 05/21/24 17:49:22.958
  STEP: Updating secret s-test-opt-upd-534c4102-b78a-4434-8da0-a47144176905 @ 05/21/24 17:49:22.964
  STEP: Creating secret with name s-test-opt-create-2af4ddb3-1fb1-4b43-93d6-81f1fba1a409 @ 05/21/24 17:49:22.97
  STEP: waiting to observe update in volume @ 05/21/24 17:49:22.975
  E0521 17:49:23.139180      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:24.139977      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:25.140894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:26.141553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:27.015516 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8922" for this suite. @ 05/21/24 17:49:27.018
• [6.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:342
  STEP: Creating a kubernetes client @ 05/21/24 17:49:27.025
  I0521 17:49:27.025304 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 17:49:27.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:49:27.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:49:27.04
  STEP: creating a replication controller @ 05/21/24 17:49:27.043
  I0521 17:49:27.043303 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 create -f -'
  I0521 17:49:27.125565 22 builder.go:146] stderr: ""
  I0521 17:49:27.125590 22 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/21/24 17:49:27.125
  I0521 17:49:27.125645 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0521 17:49:27.142017      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:27.172727 22 builder.go:146] stderr: ""
  I0521 17:49:27.172757 22 builder.go:147] stdout: "update-demo-nautilus-7h4dm update-demo-nautilus-zwf5n "
  I0521 17:49:27.172804 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods update-demo-nautilus-7h4dm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 17:49:27.209891 22 builder.go:146] stderr: ""
  I0521 17:49:27.209927 22 builder.go:147] stdout: ""
  I0521 17:49:27.209938 22 kubectl.go:2501] update-demo-nautilus-7h4dm is created but not running
  E0521 17:49:28.142451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:29.142534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:30.143367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:31.143621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:32.144404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:32.210623 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0521 17:49:32.251201 22 builder.go:146] stderr: ""
  I0521 17:49:32.251240 22 builder.go:147] stdout: "update-demo-nautilus-7h4dm update-demo-nautilus-zwf5n "
  I0521 17:49:32.251353 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods update-demo-nautilus-7h4dm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 17:49:32.291064 22 builder.go:146] stderr: ""
  I0521 17:49:32.291096 22 builder.go:147] stdout: ""
  I0521 17:49:32.291107 22 kubectl.go:2501] update-demo-nautilus-7h4dm is created but not running
  E0521 17:49:33.145590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:34.146661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:35.146893      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:36.147487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:37.147642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:37.292060 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0521 17:49:37.338800 22 builder.go:146] stderr: ""
  I0521 17:49:37.338841 22 builder.go:147] stdout: "update-demo-nautilus-7h4dm update-demo-nautilus-zwf5n "
  I0521 17:49:37.338887 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods update-demo-nautilus-7h4dm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 17:49:37.375904 22 builder.go:146] stderr: ""
  I0521 17:49:37.375938 22 builder.go:147] stdout: ""
  I0521 17:49:37.375949 22 kubectl.go:2501] update-demo-nautilus-7h4dm is created but not running
  E0521 17:49:38.148063      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:39.148771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:40.149733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:41.150504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:42.150994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:42.376731 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0521 17:49:42.424146 22 builder.go:146] stderr: ""
  I0521 17:49:42.424183 22 builder.go:147] stdout: "update-demo-nautilus-7h4dm update-demo-nautilus-zwf5n "
  I0521 17:49:42.424238 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods update-demo-nautilus-7h4dm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 17:49:42.464734 22 builder.go:146] stderr: ""
  I0521 17:49:42.464765 22 builder.go:147] stdout: "true"
  I0521 17:49:42.464815 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods update-demo-nautilus-7h4dm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0521 17:49:42.502462 22 builder.go:146] stderr: ""
  I0521 17:49:42.502495 22 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0521 17:49:42.502508 22 kubectl.go:2392] validating pod update-demo-nautilus-7h4dm
  I0521 17:49:42.504431 22 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0521 17:49:42.504478 22 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0521 17:49:42.504492 22 kubectl.go:2519] update-demo-nautilus-7h4dm is verified up and running
  I0521 17:49:42.504526 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods update-demo-nautilus-zwf5n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 17:49:42.550582 22 builder.go:146] stderr: ""
  I0521 17:49:42.550616 22 builder.go:147] stdout: "true"
  I0521 17:49:42.550661 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods update-demo-nautilus-zwf5n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0521 17:49:42.587289 22 builder.go:146] stderr: ""
  I0521 17:49:42.587323 22 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0521 17:49:42.587341 22 kubectl.go:2392] validating pod update-demo-nautilus-zwf5n
  I0521 17:49:42.589113 22 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0521 17:49:42.589150 22 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0521 17:49:42.589161 22 kubectl.go:2519] update-demo-nautilus-zwf5n is verified up and running
  STEP: using delete to clean up resources @ 05/21/24 17:49:42.589
  I0521 17:49:42.589223 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 delete --grace-period=0 --force -f -'
  I0521 17:49:42.628077 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0521 17:49:42.628112 22 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0521 17:49:42.628154 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get rc,svc -l name=update-demo --no-headers'
  I0521 17:49:42.680666 22 builder.go:146] stderr: "No resources found in kubectl-341 namespace.\n"
  I0521 17:49:42.680709 22 builder.go:147] stdout: ""
  I0521 17:49:42.680742 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-341 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0521 17:49:42.720388 22 builder.go:146] stderr: ""
  I0521 17:49:42.720425 22 builder.go:147] stdout: ""
  I0521 17:49:42.720510 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-341" for this suite. @ 05/21/24 17:49:42.722
• [15.700 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2203
  STEP: Creating a kubernetes client @ 05/21/24 17:49:42.725
  I0521 17:49:42.725726 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 17:49:42.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:49:42.732
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:49:42.734
  STEP: creating service in namespace services-3744 @ 05/21/24 17:49:42.736
  STEP: creating service affinity-clusterip-transition in namespace services-3744 @ 05/21/24 17:49:42.736
  STEP: creating replication controller affinity-clusterip-transition in namespace services-3744 @ 05/21/24 17:49:42.745
  I0521 17:49:42.751492      22 runners.go:198] Created replication controller with name: affinity-clusterip-transition, namespace: services-3744, replica count: 3
  E0521 17:49:43.151671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:44.152511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:45.153068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:45.802548      22 runners.go:198] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0521 17:49:45.809576 22 resource.go:361] Creating new exec pod
  E0521 17:49:46.153994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:47.154492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:48.155351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:48.821587 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-3744 exec execpod-affinity74h5t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I0521 17:49:48.919497 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  I0521 17:49:48.919557 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:49:48.919649 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-3744 exec execpod-affinity74h5t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.105.58.209 80'
  I0521 17:49:49.021842 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.105.58.209 80\nConnection to 10.105.58.209 80 port [tcp/http] succeeded!\n"
  I0521 17:49:49.021924 22 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0521 17:49:49.031426 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-3744 exec execpod-affinity74h5t -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.105.58.209:80/ ; done'
  E0521 17:49:49.155830      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:49.170305 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n"
  I0521 17:49:49.170336 22 builder.go:147] stdout: "\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-pt76s\naffinity-clusterip-transition-pt76s\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-pt76s\naffinity-clusterip-transition-pt76s\naffinity-clusterip-transition-vcljp\naffinity-clusterip-transition-pt76s\naffinity-clusterip-transition-pt76s\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-vcljp\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-vcljp\naffinity-clusterip-transition-vcljp\naffinity-clusterip-transition-nsb5q"
  I0521 17:49:49.170348 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.170353 22 service.go:242] Received response from host: affinity-clusterip-transition-pt76s
  I0521 17:49:49.170358 22 service.go:242] Received response from host: affinity-clusterip-transition-pt76s
  I0521 17:49:49.170362 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.170366 22 service.go:242] Received response from host: affinity-clusterip-transition-pt76s
  I0521 17:49:49.170370 22 service.go:242] Received response from host: affinity-clusterip-transition-pt76s
  I0521 17:49:49.170374 22 service.go:242] Received response from host: affinity-clusterip-transition-vcljp
  I0521 17:49:49.170377 22 service.go:242] Received response from host: affinity-clusterip-transition-pt76s
  I0521 17:49:49.170382 22 service.go:242] Received response from host: affinity-clusterip-transition-pt76s
  I0521 17:49:49.170385 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.170389 22 service.go:242] Received response from host: affinity-clusterip-transition-vcljp
  I0521 17:49:49.170394 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.170398 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.170402 22 service.go:242] Received response from host: affinity-clusterip-transition-vcljp
  I0521 17:49:49.170405 22 service.go:242] Received response from host: affinity-clusterip-transition-vcljp
  I0521 17:49:49.170409 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.175163 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-3744 exec execpod-affinity74h5t -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.105.58.209:80/ ; done'
  I0521 17:49:49.332549 22 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.105.58.209:80/\n"
  I0521 17:49:49.332616 22 builder.go:147] stdout: "\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q\naffinity-clusterip-transition-nsb5q"
  I0521 17:49:49.332642 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332659 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332675 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332693 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332706 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332718 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332729 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332743 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332754 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332768 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332779 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332793 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332804 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332816 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332827 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332839 22 service.go:242] Received response from host: affinity-clusterip-transition-nsb5q
  I0521 17:49:49.332917 22 service.go:4014] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3744, will wait for the garbage collector to delete the pods @ 05/21/24 17:49:49.344
  I0521 17:49:49.405666 22 resources.go:139] Deleting ReplicationController affinity-clusterip-transition took: 8.036869ms
  I0521 17:49:49.506087 22 resources.go:163] Terminating ReplicationController affinity-clusterip-transition pods took: 100.413872ms
  E0521 17:49:50.156886      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:51.157322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:52.157324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:52.223416 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3744" for this suite. @ 05/21/24 17:49:52.227
• [9.507 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:237
  STEP: Creating a kubernetes client @ 05/21/24 17:49:52.233
  I0521 17:49:52.233833 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/21/24 17:49:52.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:49:52.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:49:52.25
  I0521 17:49:52.253271 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:49:53.157987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/21/24 17:49:53.396
  I0521 17:49:53.396481 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-6572 --namespace=crd-publish-openapi-6572 create -f -'
  E0521 17:49:54.158981      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:55.159927      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:55.460132 22 builder.go:146] stderr: ""
  I0521 17:49:55.460238 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8692-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0521 17:49:55.460311 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-6572 --namespace=crd-publish-openapi-6572 delete e2e-test-crd-publish-openapi-8692-crds test-cr'
  I0521 17:49:55.515073 22 builder.go:146] stderr: ""
  I0521 17:49:55.515101 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8692-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I0521 17:49:55.515127 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-6572 --namespace=crd-publish-openapi-6572 apply -f -'
  I0521 17:49:55.557587 22 builder.go:146] stderr: ""
  I0521 17:49:55.557624 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8692-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0521 17:49:55.557670 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-6572 --namespace=crd-publish-openapi-6572 delete e2e-test-crd-publish-openapi-8692-crds test-cr'
  I0521 17:49:55.597869 22 builder.go:146] stderr: ""
  I0521 17:49:55.597902 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8692-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/21/24 17:49:55.597
  I0521 17:49:55.597965 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-6572 explain e2e-test-crd-publish-openapi-8692-crds'
  I0521 17:49:55.636871 22 builder.go:146] stderr: ""
  I0521 17:49:55.636931 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-8692-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0521 17:49:56.160652      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:56.773599 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6572" for this suite. @ 05/21/24 17:49:56.777
• [4.547 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 05/21/24 17:49:56.78
  I0521 17:49:56.780596 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename custom-resource-definition @ 05/21/24 17:49:56.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:49:56.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:49:56.788
  I0521 17:49:56.790547 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:49:57.160736      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:58.161468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:49:59.161610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:49:59.875417 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3809" for this suite. @ 05/21/24 17:49:59.879
• [3.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 05/21/24 17:49:59.886
  I0521 17:49:59.886749 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename field-validation @ 05/21/24 17:49:59.887
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:49:59.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:49:59.903
  STEP: apply creating a deployment @ 05/21/24 17:49:59.906
  I0521 17:49:59.918128 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4690" for this suite. @ 05/21/24 17:49:59.92
• [0.038 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 05/21/24 17:49:59.925
  I0521 17:49:59.925467 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 17:49:59.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:49:59.936
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:49:59.939
  STEP: Creating a pod to test downward api env vars @ 05/21/24 17:49:59.941
  E0521 17:50:00.162496      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:01.163507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:02.163870      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:03.164570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:50:03.958
  I0521 17:50:03.961168 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downward-api-3cee6b55-223d-4fd5-b471-19899fcf7a47 container dapi-container: <nil>
  STEP: delete the pod @ 05/21/24 17:50:03.968
  I0521 17:50:03.980375 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8731" for this suite. @ 05/21/24 17:50:03.983
• [4.062 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 05/21/24 17:50:03.988
  I0521 17:50:03.988244 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 17:50:03.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:03.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:03.999
  STEP: Creating a pod to test emptydir volume type on node default medium @ 05/21/24 17:50:04.001
  E0521 17:50:04.165139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:05.166444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:06.166353      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:07.166816      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:50:08.018
  I0521 17:50:08.021388 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-c80540ac-515d-403d-90d2-590b6db3eef0 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:50:08.028
  I0521 17:50:08.045204 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9075" for this suite. @ 05/21/24 17:50:08.048
• [4.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 05/21/24 17:50:08.053
  I0521 17:50:08.053527 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 17:50:08.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:08.064
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:08.067
  STEP: Creating configMap configmap-7214/configmap-test-a1d956b8-682d-4d77-aea1-44411c2ee92f @ 05/21/24 17:50:08.069
  STEP: Creating a pod to test consume configMaps @ 05/21/24 17:50:08.072
  E0521 17:50:08.167340      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:09.167947      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:10.168277      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:11.168416      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:50:12.09
  I0521 17:50:12.093894 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-09c3ceab-041e-42ef-a73f-7269ace6a329 container env-test: <nil>
  STEP: delete the pod @ 05/21/24 17:50:12.1
  I0521 17:50:12.116089 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7214" for this suite. @ 05/21/24 17:50:12.119
• [4.069 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 05/21/24 17:50:12.122
  I0521 17:50:12.122950 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 17:50:12.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:12.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:12.139
  STEP: Creating configMap with name configmap-test-volume-f263571e-5d1a-477f-9373-69edc1d28aa5 @ 05/21/24 17:50:12.142
  STEP: Creating a pod to test consume configMaps @ 05/21/24 17:50:12.146
  E0521 17:50:12.168570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:13.169417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:14.169786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:15.170672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:16.170697      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:50:16.17
  I0521 17:50:16.173660 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-80b07f3d-7e34-4fed-a36f-a7e708d13dc0 container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 17:50:16.18
  I0521 17:50:16.193506 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9221" for this suite. @ 05/21/24 17:50:16.196
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 05/21/24 17:50:16.201
  I0521 17:50:16.201312 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename security-context @ 05/21/24 17:50:16.202
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:16.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:16.213
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/21/24 17:50:16.215
  E0521 17:50:17.171400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:18.172013      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:19.172139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:20.173085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:50:20.233
  I0521 17:50:20.237089 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod security-context-6356084d-066b-440d-8501-020a98c44909 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:50:20.244
  I0521 17:50:20.257979 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-9078" for this suite. @ 05/21/24 17:50:20.26
• [4.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 05/21/24 17:50:20.265
  I0521 17:50:20.265746 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pv @ 05/21/24 17:50:20.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:20.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:20.279
  STEP: Creating initial PV and PVC @ 05/21/24 17:50:20.281
  I0521 17:50:20.281979 22 pv.go:390] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-3834" @ 05/21/24 17:50:20.292
  STEP: Listing PVCs in namespace "pv-3834" @ 05/21/24 17:50:20.294
  STEP: Reading "pvc-llq9k" Status @ 05/21/24 17:50:20.295
  STEP: Reading "pv-3834-7l8n5" Status @ 05/21/24 17:50:20.301
  STEP: Patching "pvc-llq9k" Status @ 05/21/24 17:50:20.305
  STEP: Patching "pv-3834-7l8n5" Status @ 05/21/24 17:50:20.308
  STEP: Updating "pvc-llq9k" Status @ 05/21/24 17:50:20.311
  STEP: Updating "pv-3834-7l8n5" Status @ 05/21/24 17:50:20.315
  I0521 17:50:20.339206 22 persistent_volumes.go:407] AfterEach: deleting 1 PVCs and 1 PVs...
  I0521 17:50:20.339244 22 pv.go:201] Deleting PersistentVolumeClaim "pvc-llq9k"
  I0521 17:50:20.344379 22 pv.go:189] Deleting PersistentVolume "pv-3834-7l8n5"
  I0521 17:50:20.351088 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-3834" for this suite. @ 05/21/24 17:50:20.354
• [0.092 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 05/21/24 17:50:20.358
  I0521 17:50:20.358179 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 17:50:20.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:20.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:20.369
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 17:50:20.371
  E0521 17:50:21.173617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:22.174766      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:50:22.381
  I0521 17:50:22.384579 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-ec90467a-4f0c-4d31-94d3-80d3fd1580b0 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 17:50:22.39
  I0521 17:50:22.402050 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3668" for this suite. @ 05/21/24 17:50:22.404
• [2.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 05/21/24 17:50:22.409
  I0521 17:50:22.409026 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 17:50:22.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:22.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:22.421
  STEP: Create set of pods @ 05/21/24 17:50:22.424
  I0521 17:50:22.431970 22 pods.go:871] created test-pod-1
  I0521 17:50:22.438290 22 pods.go:871] created test-pod-2
  I0521 17:50:22.445167 22 pods.go:871] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 05/21/24 17:50:22.445
  E0521 17:50:23.175698      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:24.175924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 05/21/24 17:50:24.484
  I0521 17:50:24.488840 22 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  E0521 17:50:25.176464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:50:25.488341 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8666" for this suite. @ 05/21/24 17:50:25.491
• [3.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 05/21/24 17:50:25.495
  I0521 17:50:25.495652 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 17:50:25.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:25.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:25.508
  STEP: Creating secret with name secret-test-e3842892-3867-4b12-8651-e848a4d3117e @ 05/21/24 17:50:25.524
  STEP: Creating a pod to test consume secrets @ 05/21/24 17:50:25.527
  E0521 17:50:26.177048      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:27.177852      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:50:27.539
  I0521 17:50:27.540821 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-secrets-211d9724-f41a-42b5-8391-9a6dbd203abe container secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 17:50:27.548
  I0521 17:50:27.560534 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6651" for this suite. @ 05/21/24 17:50:27.565
  STEP: Destroying namespace "secret-namespace-3842" for this suite. @ 05/21/24 17:50:27.576
• [2.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 05/21/24 17:50:27.601
  I0521 17:50:27.601153 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 17:50:27.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:27.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:27.608
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/21/24 17:50:27.61
  E0521 17:50:28.178060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:29.178907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:50:29.62
  I0521 17:50:29.623182 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-6edd4c47-4104-4134-aa55-cd9a737dbb55 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:50:29.63
  I0521 17:50:29.644178 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4955" for this suite. @ 05/21/24 17:50:29.647
• [2.051 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 05/21/24 17:50:29.651
  I0521 17:50:29.652013 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename ingress @ 05/21/24 17:50:29.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:29.665
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:29.668
  STEP: getting /apis @ 05/21/24 17:50:29.671
  STEP: getting /apis/networking.k8s.io @ 05/21/24 17:50:29.675
  STEP: getting /apis/networking.k8s.iov1 @ 05/21/24 17:50:29.676
  STEP: creating @ 05/21/24 17:50:29.677
  STEP: getting @ 05/21/24 17:50:29.691
  STEP: listing @ 05/21/24 17:50:29.693
  STEP: watching @ 05/21/24 17:50:29.695
  I0521 17:50:29.695579 22 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 05/21/24 17:50:29.696
  STEP: cluster-wide watching @ 05/21/24 17:50:29.698
  I0521 17:50:29.698471 22 ingress.go:198] starting watch
  STEP: patching @ 05/21/24 17:50:29.699
  STEP: updating @ 05/21/24 17:50:29.704
  I0521 17:50:29.710102 22 ingress.go:221] waiting for watch events with expected annotations
  I0521 17:50:29.710160 22 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 05/21/24 17:50:29.71
  STEP: updating /status @ 05/21/24 17:50:29.715
  STEP: get /status @ 05/21/24 17:50:29.721
  STEP: deleting @ 05/21/24 17:50:29.723
  STEP: deleting a collection @ 05/21/24 17:50:29.731
  I0521 17:50:29.741313 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-3854" for this suite. @ 05/21/24 17:50:29.744
• [0.097 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 05/21/24 17:50:29.748
  I0521 17:50:29.748801 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename subpath @ 05/21/24 17:50:29.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:29.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:29.763
  STEP: Setting up data @ 05/21/24 17:50:29.767
  STEP: Creating pod pod-subpath-test-configmap-4wwx @ 05/21/24 17:50:29.776
  STEP: Creating a pod to test atomic-volume-subpath @ 05/21/24 17:50:29.776
  E0521 17:50:30.179224      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:31.179676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:32.180499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:33.180962      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:34.182147      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:35.182984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:36.183060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:37.183490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:38.184648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:39.185408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:40.186232      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:41.187124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:42.187367      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:43.187953      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:44.188298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:45.188313      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:46.189096      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:47.189924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:48.190155      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:49.190449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:50.191752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:51.192105      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:50:51.841
  I0521 17:50:51.844377 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-subpath-test-configmap-4wwx container test-container-subpath-configmap-4wwx: <nil>
  STEP: delete the pod @ 05/21/24 17:50:51.854
  STEP: Deleting pod pod-subpath-test-configmap-4wwx @ 05/21/24 17:50:51.869
  I0521 17:50:51.869517 22 delete.go:62] Deleting pod "pod-subpath-test-configmap-4wwx" in namespace "subpath-7611"
  I0521 17:50:51.872219 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7611" for this suite. @ 05/21/24 17:50:51.875
• [22.132 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 05/21/24 17:50:51.881
  I0521 17:50:51.881646 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename statefulset @ 05/21/24 17:50:51.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:50:51.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:50:51.897
  STEP: Creating service test in namespace statefulset-3908 @ 05/21/24 17:50:51.899
  STEP: Creating statefulset ss in namespace statefulset-3908 @ 05/21/24 17:50:51.902
  I0521 17:50:51.908790 22 wait.go:40] Found 0 stateful pods, waiting for 1
  E0521 17:50:52.192446      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:53.193271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:54.193540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:55.193560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:56.194059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:57.194321      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:58.194671      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:50:59.195038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:00.196230      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:01.196587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:01.912449 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 05/21/24 17:51:01.917
  STEP: updating a scale subresource @ 05/21/24 17:51:01.919
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/21/24 17:51:01.926
  STEP: Patch a scale subresource @ 05/21/24 17:51:01.928
  STEP: verifying the statefulset Spec.Replicas was modified @ 05/21/24 17:51:01.935
  I0521 17:51:01.938815 22 statefulset.go:135] Deleting all statefulset in ns statefulset-3908
  I0521 17:51:01.942291 22 rest.go:150] Scaling statefulset ss to 0
  E0521 17:51:02.197494      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:03.197383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:04.197585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:05.197768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:06.198277      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:07.198299      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:08.198521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:09.199251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:10.199899      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:11.200400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:11.961120 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0521 17:51:11.964230 22 rest.go:88] Deleting statefulset ss
  I0521 17:51:11.976950 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3908" for this suite. @ 05/21/24 17:51:11.98
• [20.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 05/21/24 17:51:11.985
  I0521 17:51:11.986006 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 17:51:11.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:51:11.996
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:51:11.999
  STEP: creating a ConfigMap @ 05/21/24 17:51:12.002
  STEP: fetching the ConfigMap @ 05/21/24 17:51:12.006
  STEP: patching the ConfigMap @ 05/21/24 17:51:12.009
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 05/21/24 17:51:12.014
  STEP: deleting the ConfigMap by collection with a label selector @ 05/21/24 17:51:12.016
  STEP: listing all ConfigMaps in test namespace @ 05/21/24 17:51:12.02
  I0521 17:51:12.021702 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-743" for this suite. @ 05/21/24 17:51:12.023
• [0.041 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 05/21/24 17:51:12.027
  I0521 17:51:12.027565 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 17:51:12.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:51:12.039
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:51:12.041
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 05/21/24 17:51:12.043
  E0521 17:51:12.200980      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:13.201427      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:51:14.054
  I0521 17:51:14.056567 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-f6e16d4b-7f34-48cd-a840-664a2e982d53 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:51:14.063
  I0521 17:51:14.075506 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4069" for this suite. @ 05/21/24 17:51:14.078
• [2.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 05/21/24 17:51:14.084
  I0521 17:51:14.084351 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 17:51:14.085
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:51:14.095
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:51:14.099
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 17:51:14.102
  E0521 17:51:14.201815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:15.202343      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:51:16.118
  I0521 17:51:16.121656 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-2218acb4-d66a-4ca5-869d-cf6abeaa8b25 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 17:51:16.128
  I0521 17:51:16.142487 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7743" for this suite. @ 05/21/24 17:51:16.145
• [2.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 05/21/24 17:51:16.151
  I0521 17:51:16.151658 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename deployment @ 05/21/24 17:51:16.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:51:16.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:51:16.163
  I0521 17:51:16.173268 22 resource.go:87] Pod name cleanup-pod: Found 0 pods out of 1
  E0521 17:51:16.202474      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:17.202700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:18.203627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:19.204420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:20.204774      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:21.177878 22 resource.go:87] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/21/24 17:51:21.177
  I0521 17:51:21.177970 22 deployment.go:841] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 05/21/24 17:51:21.186
  I0521 17:51:21.200946 22 deployment.go:633] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3583",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "25e512ae-05ec-4ff6-9f45-9a65a6b1ea2a",
      ResourceVersion: (string) (len=5) "25571",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910681,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910681,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  E0521 17:51:21.205580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:21.206771 22 deployment.go:41] New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  I0521 17:51:21.206849 22 deployment.go:44] All old ReplicaSets of Deployment "test-cleanup-deployment":
  I0521 17:51:21.207530 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3583",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8232b7b2-c704-4b16-8575-5773635e0b9b",
      ResourceVersion: (string) (len=5) "25572",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "25e512ae-05ec-4ff6-9f45-9a65a6b1ea2a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910681,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 32 35 65 35 31 32 61  |"uid\":\"25e512a|
              00000040  65 2d 30 35 65 63 2d 34  66 66 36 2d 39 66 34 35  |e-05ec-4ff6-9f45|
              00000050  2d 39 61 36 35 61 36 62  31 65 61 32 61 5c 22 7d  |-9a65a6b1ea2a\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 17:51:21.216995 22 deployment.go:67] Pod "test-cleanup-controller-h56tf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-h56tf",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-3583",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dd637747-8142-496f-a8bc-6ba006a4451c",
      ResourceVersion: (string) (len=5) "25533",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "8232b7b2-c704-4b16-8575-5773635e0b9b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  38 32 33 32 62 37 62 32  |uid\":\"8232b7b2|
              00000080  2d 63 37 30 34 2d 34 62  31 36 2d 38 35 37 35 2d  |-c704-4b16-8575-|
              00000090  35 37 37 33 36 33 35 65  30 62 39 62 5c 22 7d 22  |5773635e0b9b\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 31  39 36 5c 22 7d 22 3a 7b  |.244.1.196\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-chj2n",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-chj2n",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=12) "10.244.1.196",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.196"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851910676,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=127) "docker-pullable://registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=73) "docker://519a04d287932bb9790fa32376a7a1d080733b245612977d2cc2198f882d427e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 17:51:21.220575 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3583" for this suite. @ 05/21/24 17:51:21.226
• [5.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 05/21/24 17:51:21.235
  I0521 17:51:21.235216 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename var-expansion @ 05/21/24 17:51:21.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:51:21.246
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:51:21.248
  E0521 17:51:22.205465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:23.206467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:23.263229 22 delete.go:62] Deleting pod "var-expansion-35b9d0ed-cf35-4909-9a66-b13a101ccbf2" in namespace "var-expansion-9878"
  I0521 17:51:23.271886 22 delete.go:70] Wait up to 5m0s for pod "var-expansion-35b9d0ed-cf35-4909-9a66-b13a101ccbf2" to be fully deleted
  E0521 17:51:24.207512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:25.208532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:25.281457 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9878" for this suite. @ 05/21/24 17:51:25.285
• [4.056 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 05/21/24 17:51:25.291
  I0521 17:51:25.291529 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename deployment @ 05/21/24 17:51:25.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:51:25.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:51:25.307
  I0521 17:51:25.317042 22 resource.go:87] Pod name rollover-pod: Found 0 pods out of 1
  E0521 17:51:26.209438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:27.210505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:28.211043      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:29.211483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:30.212439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:30.319996 22 resource.go:87] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/21/24 17:51:30.32
  I0521 17:51:30.320093 22 deployment.go:911] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0521 17:51:31.213412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:32.214535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:32.326161 22 deployment.go:921] Creating deployment "test-rollover-deployment"
  I0521 17:51:32.335344 22 deployment.go:934] Make sure deployment "test-rollover-deployment" performs scaling operations
  E0521 17:51:33.214789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:34.215260      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:34.343861 22 deployment.go:939] Check revision of new replica set for deployment "test-rollover-deployment"
  I0521 17:51:34.349374 22 deployment.go:943] Ensure that both replica sets have 1 created replica
  I0521 17:51:34.358339 22 deployment.go:952] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0521 17:51:34.366827 22 deployment.go:313] Updating deployment test-rollover-deployment
  I0521 17:51:34.366871 22 deployment.go:961] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0521 17:51:35.216068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:36.216435      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:36.371456 22 deployment.go:966] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0521 17:51:36.373899 22 deployment.go:970] Make sure deployment "test-rollover-deployment" is complete
  I0521 17:51:36.375930 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0521 17:51:36.375963 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:51:37.217453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:38.217651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:38.380832 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0521 17:51:38.380885 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:51:39.218571      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:40.219623      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:40.383636 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0521 17:51:40.383728 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:51:41.220457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:42.221542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:42.384514 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0521 17:51:42.384609 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:51:43.222574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:44.223607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:44.385380 22 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I0521 17:51:44.385466 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 17, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 17, 51, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-679c966bdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 17:51:45.223810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:46.224544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:51:46.385033 22 deployment.go:94] 
  I0521 17:51:46.385103 22 deployment.go:974] Ensure that both old replica sets have no replicas
  I0521 17:51:46.391498 22 deployment.go:633] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4002",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "229c3960-1aad-4a34-9863-c93cd5546467",
      ResourceVersion: (string) (len=5) "25737",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910692,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910694,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910705,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910692,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910692,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910705,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910692,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-679c966bdf\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0521 17:51:46.395399 22 deployment.go:39] New ReplicaSet "test-rollover-deployment-679c966bdf" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-679c966bdf",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4002",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "30bea98f-f70d-45a2-bd29-e6ca1f489a9d",
      ResourceVersion: (string) (len=5) "25727",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910694,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "229c3960-1aad-4a34-9863-c93cd5546467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910694,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 32 39 63 33 39  36 30 2d 31 61 61 64 2d  |\"229c3960-1aad-|
              00000120  34 61 33 34 2d 39 38 36  33 2d 63 39 33 63 64 35  |4a34-9863-c93cd5|
              00000130  35 34 36 34 36 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |546467\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910705,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 17:51:46.396468 22 deployment.go:44] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0521 17:51:46.396773 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4002",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d0b750de-a91d-4948-a35a-00d8b8e1d878",
      ResourceVersion: (string) (len=5) "25736",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910685,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "229c3960-1aad-4a34-9863-c93cd5546467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910685,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910705,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  32 32 39 63 33 39 36 30  2d 31 61 61 64 2d 34 61  |229c3960-1aad-4a|
              000000c0  33 34 2d 39 38 36 33 2d  63 39 33 63 64 35 35 34  |34-9863-c93cd554|
              000000d0  36 34 36 37 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |6467\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910705,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 17:51:46.398046 22 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-65bd487b4b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4002",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0d4127de-ef05-494e-b000-20a8b075d8c4",
      ResourceVersion: (string) (len=5) "25705",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910692,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "229c3960-1aad-4a34-9863-c93cd5546467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910694,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 32 39 63 33 39  36 30 2d 31 61 61 64 2d  |\"229c3960-1aad-|
              00000120  34 61 33 34 2d 39 38 36  33 2d 63 39 33 63 64 35  |4a34-9863-c93cd5|
              00000130  35 34 36 34 36 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |546467\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910694,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "65bd487b4b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0521 17:51:46.401432 22 deployment.go:67] Pod "test-rollover-deployment-679c966bdf-z4wmk" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-679c966bdf-z4wmk",
      GenerateName: (string) (len=36) "test-rollover-deployment-679c966bdf-",
      Namespace: (string) (len=15) "deployment-4002",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2631083f-1d1f-4273-84c8-cc71d8c3279e",
      ResourceVersion: (string) (len=5) "25715",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910694,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "679c966bdf"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-679c966bdf",
          UID: (types.UID) (len=36) "30bea98f-f70d-45a2-bd29-e6ca1f489a9d",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910694,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 30  62 65 61 39 38 66 2d 66  |d\":\"30bea98f-f|
              00000090  37 30 64 2d 34 35 61 32  2d 62 64 32 39 2d 65 36  |70d-45a2-bd29-e6|
              000000a0  63 61 31 66 34 38 39 61  39 64 5c 22 7d 22 3a 7b  |ca1f489a9d\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 32 34 34 2e 31 2e 32  30 30 5c 22 7d 22 3a 7b  |.244.1.200\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fq65g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fq65g",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=18) "k8sconformance-m02",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910694,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63851910694,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "192.168.67.3",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "192.168.67.3"
        }
      },
      PodIP: (string) (len=12) "10.244.1.200",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.244.1.200"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63851910694,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63851910695,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=129) "docker-pullable://registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=73) "docker://2f9eb6877607f86af4f3a2d84530240bca1683927133048d3c6fdd5b6ecb178e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0521 17:51:46.402769 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4002" for this suite. @ 05/21/24 17:51:46.404
• [21.118 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 05/21/24 17:51:46.409
  I0521 17:51:46.409057 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 17:51:46.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:51:46.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:51:46.419
  E0521 17:51:47.225634      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:48.226230      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:49.226574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:50.226689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:51.226709      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:52.227183      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:53.227259      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:54.227467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:55.228007      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:56.228276      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:57.228413      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:58.228936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:51:59.229656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:00.229741      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:01.229855      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:02.230383      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:03.230528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:04.230558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:05.230889      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:06.231630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:07.232454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:08.233009      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:52:08.499146 22 container_probe.go:92] Container started at 2024-05-21 17:51:47 +0000 UTC, pod became ready at 2024-05-21 17:52:06 +0000 UTC
  I0521 17:52:08.499324 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2676" for this suite. @ 05/21/24 17:52:08.502
• [22.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 05/21/24 17:52:08.508
  I0521 17:52:08.508824 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 17:52:08.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:52:08.519
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:52:08.522
  STEP: creating the pod @ 05/21/24 17:52:08.524
  STEP: submitting the pod to kubernetes @ 05/21/24 17:52:08.524
  STEP: verifying QOS class is set on the pod @ 05/21/24 17:52:08.528
  I0521 17:52:08.530800 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8127" for this suite. @ 05/21/24 17:52:08.534
• [0.031 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 05/21/24 17:52:08.539
  I0521 17:52:08.539876 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 17:52:08.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:52:08.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:52:08.553
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 05/21/24 17:52:08.555
  E0521 17:52:09.233705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:10.233823      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:11.234947      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:12.235526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:52:12.57
  I0521 17:52:12.573345 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-9672c033-71a3-4fa5-9a50-a80f73fb28ed container test-container: <nil>
  STEP: delete the pod @ 05/21/24 17:52:12.58
  I0521 17:52:12.596001 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6495" for this suite. @ 05/21/24 17:52:12.599
• [4.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 05/21/24 17:52:12.604
  I0521 17:52:12.604133 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 17:52:12.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:52:12.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:52:12.618
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 17:52:12.621
  E0521 17:52:13.236480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:14.236622      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:15.236692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:16.237601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:52:16.639
  I0521 17:52:16.641794 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-1de20b97-4029-4630-8f3c-fef6cf049ed2 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 17:52:16.649
  I0521 17:52:16.669079 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2462" for this suite. @ 05/21/24 17:52:16.67
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:277
  STEP: Creating a kubernetes client @ 05/21/24 17:52:16.675
  I0521 17:52:16.675482 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/21/24 17:52:16.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:52:16.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:52:16.685
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 05/21/24 17:52:16.687
  I0521 17:52:16.687875 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:52:17.238143      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:52:17.842444 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:52:18.238458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:19.238795      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:20.238936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:21.239237      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:22.240339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:52:22.496871 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5145" for this suite. @ 05/21/24 17:52:22.502
• [5.830 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:195
  STEP: Creating a kubernetes client @ 05/21/24 17:52:22.505
  I0521 17:52:22.505377 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/21/24 17:52:22.505
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:52:22.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:52:22.517
  I0521 17:52:22.519656 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:52:23.240642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 05/21/24 17:52:23.655
  I0521 17:52:23.655970 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-8000 --namespace=crd-publish-openapi-8000 create -f -'
  E0521 17:52:24.241080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:25.242041      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:52:25.716625 22 builder.go:146] stderr: ""
  I0521 17:52:25.716697 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5937-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0521 17:52:25.716780 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-8000 --namespace=crd-publish-openapi-8000 delete e2e-test-crd-publish-openapi-5937-crds test-cr'
  I0521 17:52:25.759824 22 builder.go:146] stderr: ""
  I0521 17:52:25.759860 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5937-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I0521 17:52:25.759903 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-8000 --namespace=crd-publish-openapi-8000 apply -f -'
  I0521 17:52:25.806652 22 builder.go:146] stderr: ""
  I0521 17:52:25.806698 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5937-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0521 17:52:25.806749 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-8000 --namespace=crd-publish-openapi-8000 delete e2e-test-crd-publish-openapi-5937-crds test-cr'
  I0521 17:52:25.847183 22 builder.go:146] stderr: ""
  I0521 17:52:25.847236 22 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5937-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 05/21/24 17:52:25.847
  I0521 17:52:25.847323 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=crd-publish-openapi-8000 explain e2e-test-crd-publish-openapi-5937-crds'
  I0521 17:52:25.882400 22 builder.go:146] stderr: ""
  I0521 17:52:25.882444 22 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-5937-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0521 17:52:26.242771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:52:27.012566 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8000" for this suite. @ 05/21/24 17:52:27.016
• [4.515 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 05/21/24 17:52:27.021
  I0521 17:52:27.021050 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename runtimeclass @ 05/21/24 17:52:27.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:52:27.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:52:27.029
  STEP: getting /apis @ 05/21/24 17:52:27.03
  STEP: getting /apis/node.k8s.io @ 05/21/24 17:52:27.032
  STEP: getting /apis/node.k8s.io/v1 @ 05/21/24 17:52:27.032
  STEP: creating @ 05/21/24 17:52:27.033
  STEP: watching @ 05/21/24 17:52:27.04
  I0521 17:52:27.040211 22 runtimeclass.go:275] starting watch
  STEP: getting @ 05/21/24 17:52:27.043
  STEP: listing @ 05/21/24 17:52:27.045
  STEP: patching @ 05/21/24 17:52:27.046
  STEP: updating @ 05/21/24 17:52:27.049
  I0521 17:52:27.052628 22 runtimeclass.go:305] waiting for watch events with expected annotations
  STEP: deleting @ 05/21/24 17:52:27.052
  STEP: deleting a collection @ 05/21/24 17:52:27.058
  I0521 17:52:27.066350 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2792" for this suite. @ 05/21/24 17:52:27.068
• [0.051 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 05/21/24 17:52:27.072
  I0521 17:52:27.072067 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename chunking @ 05/21/24 17:52:27.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:52:27.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:52:27.088
  STEP: creating a large number of resources @ 05/21/24 17:52:27.09
  E0521 17:52:27.243646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:28.244685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:29.244967      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:30.245602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:31.246406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:32.247348      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:33.247468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:34.247530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:35.247637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:36.248621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:37.248836      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:38.249768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:39.250447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:40.250480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:41.251605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:42.252225      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:43.252976      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:44.254073      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 05/21/24 17:52:44.78
  I0521 17:52:44.829616 22 chunking.go:163] Retrieved 40/40 results with rv 26384 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 05/21/24 17:52:44.829
  E0521 17:52:45.255232      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:46.255648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:47.256542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:48.257077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:49.258004      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:50.258423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:51.258926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:52.259612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:53.260546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:54.261695      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:55.262818      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:56.263388      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:57.263757      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:58.264184      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:52:59.264806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:00.265602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:01.266657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:02.267804      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:03.268692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:04.269444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:53:04.835874 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:53:05.269641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:06.270168      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:07.270818      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:08.270925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:09.271495      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:10.272559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:11.272813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:12.273576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:13.274648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:14.275261      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:15.275762      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:16.276607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:17.276802      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:18.277598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:19.278627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:20.279066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:21.279988      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:22.280621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:23.281708      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:24.282237      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:53:24.836407 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:53:25.282523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:26.282853      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:27.283755      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:28.284317      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:29.284604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:30.285621      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:31.286162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:32.286598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:33.286965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:34.287807      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:35.288698      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:36.289145      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:37.289408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:38.289313      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:39.289539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:40.290608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:41.291697      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:42.292616      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:43.292751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:44.293348      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:53:44.836611 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:53:45.293686      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:46.294151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:47.294401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:48.294429      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:49.295429      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:50.295906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:51.296456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:52.297298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:53.297754      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:54.298469      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:55.299479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:56.299651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:57.300540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:58.301500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:53:59.302512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:00.303580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:01.304112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:02.304570      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:03.305050      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:04.305592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:54:04.836756 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:54:05.305682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:06.306687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:07.307770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:08.308437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:09.309505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:10.310230      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:11.310510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:12.311565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:13.311663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:14.312018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:15.312987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:16.313744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:17.314535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:18.314906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:19.315288      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:20.316349      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:21.316438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:22.316895      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:23.317291      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:24.318023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:54:24.836715 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:54:25.318741      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:26.319170      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:27.319727      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:28.320706      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:29.321249      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:30.321799      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:31.321926      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:32.322357      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:33.322540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:34.323675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:35.323760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:36.324317      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:37.324442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:38.324793      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:39.325806      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:40.326281      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:41.326477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:42.326627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:43.327126      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:44.327497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:54:44.837090 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:54:45.328361      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:46.328957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:47.329487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:48.329971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:49.330593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:50.331611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:51.332582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:52.333428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:53.334459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:54.334891      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:55.335526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:56.335992      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:57.336016      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:58.336378      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:54:59.336678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:00.337657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:01.338659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:02.339247      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:03.339707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:04.340050      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:55:04.836436 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:55:05.340923      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:06.342059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:07.342457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:08.343082      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:09.344247      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:10.345336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:11.345704      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:12.346392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:13.347578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:14.348052      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:15.348973      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:16.349662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:17.349961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:18.350529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:19.351566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:20.351888      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:21.352352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:22.352468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:23.352624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:24.353567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:55:24.837551 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:55:25.354590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:26.355422      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:27.356444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:28.356515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:29.357520      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:30.358322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:31.358437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:32.359526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:33.360442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:34.361437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:35.361948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:36.362456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:37.363515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:38.364545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:39.364940      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:40.366066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:41.366438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:42.366732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:43.367142      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:44.367482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:55:44.836978 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:55:45.367753      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:46.368278      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:47.368540      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:48.369133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:49.369504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:50.370053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:51.370366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:52.370485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:53.370692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:54.371783      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:55.371928      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:56.372408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:57.372587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:58.373586      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:55:59.374098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:00.374936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:01.375116      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:02.375397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:03.375894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:04.376555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:56:04.837279 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:56:05.377295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:06.377500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:07.378046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:08.378517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:09.379666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:10.379931      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:11.380215      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:12.381094      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:13.381379      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:14.382272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:15.382554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:16.383070      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:17.384103      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:18.384504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:19.384598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:20.385041      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:21.385488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:22.386560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:23.387568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:24.388588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:56:24.836526 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:56:25.388626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:26.389596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:27.390670      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:28.391138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:29.391553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:30.392219      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:31.392452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:32.392821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:33.393240      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:34.393580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:35.394361      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:36.394482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:37.394563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:38.395037      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:39.395501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:40.396100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:41.396580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:42.397105      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:43.397787      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:44.398558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:56:44.836686 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:56:45.398892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:46.399465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:47.400447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:48.401503      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:49.401964      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:50.402076      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:51.402606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:52.403627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:53.403819      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:54.404698      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:55.404935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:56.405647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:57.405883      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:58.406488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:56:59.406899      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:00.407608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:01.408049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:02.408444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:03.408921      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:04.409569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:57:04.836776 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:57:05.410041      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:06.410812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:07.411344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:08.411776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:09.412666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:10.412907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:11.413470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:12.413812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:13.414662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:14.414821      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:15.415877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:16.416366      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:17.416890      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:18.417898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:19.418530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:20.419152      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:21.419543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:22.419862      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:23.420415      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:24.420776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:57:24.832916 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:57:25.421864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:26.422452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:27.422872      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:28.423100      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:29.423541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:30.424419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:31.424753      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:32.425276      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:33.425711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:34.426097      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:35.427257      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:36.427748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:37.427826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:38.428438      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:39.428963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:40.429721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:41.430183      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:42.430511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:43.430875      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:44.431579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:57:44.836607 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:57:45.432319      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:46.432504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:47.432925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:48.433557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:49.434280      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:50.434663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:51.434640      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:52.435717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:53.436185      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:54.436468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:55.437382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:56.437493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:57.438592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:58.438675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:57:59.439804      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:00.440552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:01.440655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:02.440839      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:03.441595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:04.442082      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:58:04.836361 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:58:05.443020      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:06.443577      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:07.444035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:08.444317      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:09.445432      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:10.445391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:11.445807      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:12.446284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:13.446463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:14.446831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:15.447923      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:16.449046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:17.449491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:18.450536      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:19.451467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:20.452049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:21.452569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:22.453001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:23.453458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:24.453498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:58:24.836749 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:58:25.454575      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:26.455025      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:27.455859      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:28.456133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:29.456482      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:30.457315      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:31.457680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:32.458688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:33.459034      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:34.459661      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:35.460597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:36.461462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:37.462554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:38.463079      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:39.463433      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:40.464351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:41.464689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:42.465129      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:43.465420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:44.466623      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:58:44.835536 22 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjYzODQsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0521 17:58:45.467691      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:46.468249      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:47.468776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:48.469382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:49.469690      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:50.470001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:51.470569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:52.471001      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:53.471404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:54.472548      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:55.473689      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:56.474655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:57.475656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:58.476272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:58:59.476373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:00.477430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:01.477667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:02.478705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:03.479601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:04.480657      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:59:04.834342 22 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0521 17:59:04.834404 22 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 05/21/24 17:59:04.834
  STEP: retrieving all remaining pages @ 05/21/24 17:59:04.838
  I0521 17:59:04.843123 22 chunking.go:221] Retrieved 40/40 results with rv 26726 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY3MjYsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  I0521 17:59:04.847487 22 chunking.go:221] Retrieved 40/40 results with rv 26726 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY3MjYsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  I0521 17:59:04.851393 22 chunking.go:221] Retrieved 40/40 results with rv 26726 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY3MjYsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  I0521 17:59:04.855024 22 chunking.go:221] Retrieved 40/40 results with rv 26726 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY3MjYsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  I0521 17:59:04.858882 22 chunking.go:221] Retrieved 40/40 results with rv 26726 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY3MjYsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  I0521 17:59:04.862834 22 chunking.go:221] Retrieved 40/40 results with rv 26726 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY3MjYsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  I0521 17:59:04.866649 22 chunking.go:221] Retrieved 40/40 results with rv 26726 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjY3MjYsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  I0521 17:59:04.870111 22 chunking.go:221] Retrieved 40/40 results with rv 26726 and continue 
  I0521 17:59:04.870252 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-491" for this suite. @ 05/21/24 17:59:04.872
• [397.805 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 05/21/24 17:59:04.877
  I0521 17:59:04.877613 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename csi-storageclass @ 05/21/24 17:59:04.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:59:04.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:59:04.892
  STEP: Creating a StorageClass @ 05/21/24 17:59:04.894
  STEP: Get StorageClass "e2e-rsqkx" @ 05/21/24 17:59:04.898
  STEP: Patching the StorageClass "e2e-rsqkx" @ 05/21/24 17:59:04.899
  STEP: Delete StorageClass "e2e-rsqkx" @ 05/21/24 17:59:04.905
  STEP: Confirm deletion of StorageClass "e2e-rsqkx" @ 05/21/24 17:59:04.908
  STEP: Create a replacement StorageClass @ 05/21/24 17:59:04.911
  STEP: Updating StorageClass "e2e-v2-8f28d" @ 05/21/24 17:59:04.914
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-8f28d=updated" @ 05/21/24 17:59:04.918
  STEP: Deleting StorageClass "e2e-v2-8f28d" via DeleteCollection @ 05/21/24 17:59:04.919
  STEP: Confirm deletion of StorageClass "e2e-v2-8f28d" @ 05/21/24 17:59:04.922
  I0521 17:59:04.924062 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-7493" for this suite. @ 05/21/24 17:59:04.925
• [0.051 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 05/21/24 17:59:04.928
  I0521 17:59:04.928783 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-runtime @ 05/21/24 17:59:04.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:59:04.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:59:04.941
  STEP: create the container @ 05/21/24 17:59:04.943
  W0521 17:59:04.948286      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/21/24 17:59:04.948
  E0521 17:59:05.481457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:06.481680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:07.481750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/21/24 17:59:07.966
  STEP: the container should be terminated @ 05/21/24 17:59:07.969
  STEP: the termination message should be set @ 05/21/24 17:59:07.969
  I0521 17:59:07.969768 22 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 05/21/24 17:59:07.969
  I0521 17:59:07.985855 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4307" for this suite. @ 05/21/24 17:59:07.989
• [3.065 seconds]
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 05/21/24 17:59:07.994
  I0521 17:59:07.994405 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 17:59:07.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:59:08.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:59:08.01
  STEP: Creating configMap configmap-2411/configmap-test-2329875f-6244-46ed-8fc9-fda29c50a4fa @ 05/21/24 17:59:08.012
  STEP: Creating a pod to test consume configMaps @ 05/21/24 17:59:08.016
  E0521 17:59:08.481760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:09.482029      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 17:59:10.028
  I0521 17:59:10.030741 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-configmaps-61b63cd7-5a79-49d3-9186-02fb8e0cf29a container env-test: <nil>
  STEP: delete the pod @ 05/21/24 17:59:10.044
  I0521 17:59:10.053029 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2411" for this suite. @ 05/21/24 17:59:10.054
• [2.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:392
  STEP: Creating a kubernetes client @ 05/21/24 17:59:10.058
  I0521 17:59:10.058600 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename crd-publish-openapi @ 05/21/24 17:59:10.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:59:10.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:59:10.071
  STEP: set up a multi version CRD @ 05/21/24 17:59:10.073
  I0521 17:59:10.074159 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 17:59:10.482294      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:11.483028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:12.483924      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 05/21/24 17:59:13.057
  STEP: check the new version name is served @ 05/21/24 17:59:13.064
  E0521 17:59:13.484710      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 05/21/24 17:59:13.704
  STEP: check the other version is not changed @ 05/21/24 17:59:14.289
  E0521 17:59:14.485538      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:15.485559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:16.486305      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 17:59:16.637298 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7469" for this suite. @ 05/21/24 17:59:16.64
• [6.587 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 05/21/24 17:59:16.645
  I0521 17:59:16.645644 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename cronjob @ 05/21/24 17:59:16.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 17:59:16.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 17:59:16.656
  STEP: Creating a ForbidConcurrent cronjob @ 05/21/24 17:59:16.657
  STEP: Ensuring a job is scheduled @ 05/21/24 17:59:16.662
  E0521 17:59:17.486714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:18.487679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:19.488462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:20.489450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:21.489489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:22.490608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:23.491077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:24.491568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:25.491602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:26.492653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:27.493436      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:28.493545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:29.493847      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:30.494734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:31.495598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:32.496642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:33.496563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:34.497606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:35.497693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:36.498617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:37.499471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:38.499394      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:39.500462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:40.500624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:41.501515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:42.501759      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:43.502374      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:44.503017      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:45.503915      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:46.504151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:47.504403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:48.504565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:49.505544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:50.506302      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:51.507057      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:52.507725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:53.508574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:54.509018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:55.509823      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:56.510547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:57.510484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:58.510884      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 17:59:59.510892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:00.511630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 05/21/24 18:00:00.665
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/21/24 18:00:00.667
  STEP: Ensuring no more jobs are scheduled @ 05/21/24 18:00:00.669
  STEP: Removing cronjob @ 05/21/24 18:00:00.671
  I0521 18:00:00.675683 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1385" for this suite. @ 05/21/24 18:00:00.678
• [44.037 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 05/21/24 18:00:00.683
  I0521 18:00:00.683398 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename security-context-test @ 05/21/24 18:00:00.684
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:00.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:00.7
  E0521 18:00:01.512507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:02.513611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:03.514534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:04.515647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:04.727486 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-1338" for this suite. @ 05/21/24 18:00:04.73
• [4.055 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 05/21/24 18:00:04.738
  I0521 18:00:04.738858 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 18:00:04.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:04.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:04.757
  STEP: Creating secret with name secret-test-map-f8e79951-ae07-4b22-8426-108fac36b5e3 @ 05/21/24 18:00:04.759
  STEP: Creating a pod to test consume secrets @ 05/21/24 18:00:04.765
  E0521 18:00:05.516594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:06.516965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:07.517966      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:08.518699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:00:08.785
  I0521 18:00:08.788892 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-secrets-e597da7a-8e12-41e9-90c7-0b5b00939a83 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 18:00:08.796
  I0521 18:00:08.812236 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2813" for this suite. @ 05/21/24 18:00:08.815
• [4.081 seconds]
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 05/21/24 18:00:08.819
  I0521 18:00:08.819733 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename endpointslice @ 05/21/24 18:00:08.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:08.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:08.834
  I0521 18:00:08.842593 22 endpointslice.go:1045] Endpoints addresses: [192.168.67.2] , ports: [8443]
  I0521 18:00:08.842620 22 endpointslice.go:1075] EndpointSlices addresses: [192.168.67.2] , ports: [8443]
  I0521 18:00:08.842677 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8988" for this suite. @ 05/21/24 18:00:08.844
• [0.029 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 05/21/24 18:00:08.848
  I0521 18:00:08.848702 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename aggregateddiscovery @ 05/21/24 18:00:08.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:08.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:08.861
  I0521 18:00:08.866651 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-2433" for this suite. @ 05/21/24 18:00:08.868
• [0.025 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 05/21/24 18:00:08.873
  I0521 18:00:08.873631 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename daemonsets @ 05/21/24 18:00:08.874
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:08.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:08.884
  I0521 18:00:08.902735 22 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I0521 18:00:08.906814 22 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I0521 18:00:08.914397 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 18:00:08.914470 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  E0521 18:00:09.518808      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:09.915694 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 18:00:09.915744 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  E0521 18:00:10.519923      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:10.914196 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0521 18:00:10.914250 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  I0521 18:00:10.914279 22 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I0521 18:00:10.922308 22 daemon_set.go:102] Updating DaemonSet daemon-set
  E0521 18:00:11.521030      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:12.521853      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:12.931863 22 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I0521 18:00:12.941157 22 daemon_set.go:102] Updating DaemonSet daemon-set
  I0521 18:00:12.941260 22 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I0521 18:00:12.944494 22 daemon_set.go:1178] Wrong image for pod: daemon-set-dnt6c. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I0521 18:00:12.944540 22 daemon_set.go:1183] Pod daemon-set-dnt6c is not available
  E0521 18:00:13.522775      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:14.523391      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:15.524447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:15.945332 22 daemon_set.go:1183] Pod daemon-set-rlt5b is not available
  STEP: Deleting DaemonSet "daemon-set" @ 05/21/24 18:00:15.952
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7582, will wait for the garbage collector to delete the pods @ 05/21/24 18:00:15.952
  I0521 18:00:16.008517 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 3.142403ms
  I0521 18:00:16.109072 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.551462ms
  E0521 18:00:16.524916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:17.525437      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:17.613935 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 18:00:17.613989 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0521 18:00:17.616359 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27459"},"items":null}

  I0521 18:00:17.618130 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27459"},"items":null}

  I0521 18:00:17.624670 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7582" for this suite. @ 05/21/24 18:00:17.627
• [8.758 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:817
  STEP: Creating a kubernetes client @ 05/21/24 18:00:17.631
  I0521 18:00:17.631456 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 18:00:17.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:17.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:17.647
  STEP: Setting up server cert @ 05/21/24 18:00:17.667
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 18:00:17.899
  STEP: Deploying the webhook pod @ 05/21/24 18:00:17.902
  STEP: Wait for the deployment to be ready @ 05/21/24 18:00:17.909
  I0521 18:00:17.911471 22 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0521 18:00:18.526368      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:19.526443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 18:00:19.921
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 18:00:19.932
  E0521 18:00:20.527498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:20.933081 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 05/21/24 18:00:20.941
  I0521 18:00:20.969919 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-57" for this suite. @ 05/21/24 18:00:20.972
  STEP: Destroying namespace "webhook-markers-5343" for this suite. @ 05/21/24 18:00:20.977
• [3.350 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 05/21/24 18:00:20.981
  I0521 18:00:20.981700 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename namespaces @ 05/21/24 18:00:20.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:20.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:20.991
  STEP: Creating a test namespace @ 05/21/24 18:00:20.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:21
  STEP: Creating a service in the namespace @ 05/21/24 18:00:21.001
  STEP: Deleting the namespace @ 05/21/24 18:00:21.011
  STEP: Waiting for the namespace to be removed. @ 05/21/24 18:00:21.017
  E0521 18:00:21.528000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:22.529035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:23.529243      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:24.529539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:25.530517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:26.531450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 05/21/24 18:00:27.021
  STEP: Verifying there is no service in the namespace @ 05/21/24 18:00:27.033
  I0521 18:00:27.036116 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9474" for this suite. @ 05/21/24 18:00:27.038
  STEP: Destroying namespace "nsdeletetest-9479" for this suite. @ 05/21/24 18:00:27.042
  I0521 18:00:27.043934 22 framework.go:370] Namespace nsdeletetest-9479 was already deleted
  STEP: Destroying namespace "nsdeletetest-8770" for this suite. @ 05/21/24 18:00:27.043
• [6.065 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 05/21/24 18:00:27.047
  I0521 18:00:27.047081 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 18:00:27.048
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:27.056
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:27.058
  STEP: Creating secret with name secret-test-d5e97737-a5bb-407e-86a1-38e74d77ce79 @ 05/21/24 18:00:27.061
  STEP: Creating a pod to test consume secrets @ 05/21/24 18:00:27.064
  E0521 18:00:27.532377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:28.532550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:29.533111      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:30.533557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:00:31.086
  I0521 18:00:31.089349 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-secrets-93f5ba31-2624-44cc-b40d-ca58bf7d527c container secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 18:00:31.098
  I0521 18:00:31.111893 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8900" for this suite. @ 05/21/24 18:00:31.115
• [4.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 05/21/24 18:00:31.12
  I0521 18:00:31.120256 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 18:00:31.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:31.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:31.137
  STEP: Creating secret with name secret-test-d7f55c2e-1fd3-410c-aa61-824b520a6c05 @ 05/21/24 18:00:31.14
  STEP: Creating a pod to test consume secrets @ 05/21/24 18:00:31.143
  E0521 18:00:31.534219      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:32.534755      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:33.535089      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:34.535544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:00:35.163
  I0521 18:00:35.167135 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-secrets-cf2156cd-d99c-4f3d-9b4c-f0f47986c427 container secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 18:00:35.175
  I0521 18:00:35.190997 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8498" for this suite. @ 05/21/24 18:00:35.194
• [4.078 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:341
  STEP: Creating a kubernetes client @ 05/21/24 18:00:35.198
  I0521 18:00:35.198534 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename cronjob @ 05/21/24 18:00:35.199
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:35.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:35.213
  STEP: Creating a cronjob @ 05/21/24 18:00:35.216
  STEP: creating @ 05/21/24 18:00:35.216
  STEP: getting @ 05/21/24 18:00:35.221
  STEP: listing @ 05/21/24 18:00:35.224
  STEP: watching @ 05/21/24 18:00:35.226
  I0521 18:00:35.226357 22 cronjob.go:370] starting watch
  STEP: cluster-wide listing @ 05/21/24 18:00:35.227
  STEP: cluster-wide watching @ 05/21/24 18:00:35.229
  I0521 18:00:35.229455 22 cronjob.go:382] starting watch
  STEP: patching @ 05/21/24 18:00:35.23
  STEP: updating @ 05/21/24 18:00:35.236
  I0521 18:00:35.243645 22 cronjob.go:406] waiting for watch events with expected annotations
  I0521 18:00:35.243711 22 cronjob.go:420] saw patched and updated annotations
  STEP: patching /status @ 05/21/24 18:00:35.243
  STEP: updating /status @ 05/21/24 18:00:35.25
  STEP: get /status @ 05/21/24 18:00:35.257
  STEP: deleting @ 05/21/24 18:00:35.26
  STEP: deleting a collection @ 05/21/24 18:00:35.271
  I0521 18:00:35.296061 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5789" for this suite. @ 05/21/24 18:00:35.303
• [0.108 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 05/21/24 18:00:35.306
  I0521 18:00:35.306961 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 18:00:35.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:35.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:35.315
  STEP: Creating configMap with name projected-configmap-test-volume-map-b094e587-0f02-4399-92b0-e930afe4b62f @ 05/21/24 18:00:35.316
  STEP: Creating a pod to test consume configMaps @ 05/21/24 18:00:35.319
  E0521 18:00:35.536595      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:36.537673      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:37.538078      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:38.538786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:00:39.34
  I0521 18:00:39.343401 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-configmaps-e16606ab-3fef-4f3a-85e5-d7f7f34e219e container agnhost-container: <nil>
  STEP: delete the pod @ 05/21/24 18:00:39.35
  I0521 18:00:39.367540 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2689" for this suite. @ 05/21/24 18:00:39.369
• [4.065 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1284
  STEP: Creating a kubernetes client @ 05/21/24 18:00:39.372
  I0521 18:00:39.372494 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 18:00:39.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:39.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:39.381
  STEP: creating service nodeport-test with type=NodePort in namespace services-1533 @ 05/21/24 18:00:39.383
  STEP: creating replication controller nodeport-test in namespace services-1533 @ 05/21/24 18:00:39.395
  I0521 18:00:39.403071      22 runners.go:198] Created replication controller with name: nodeport-test, namespace: services-1533, replica count: 2
  E0521 18:00:39.539133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:40.540284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:41.540891      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:42.454472      22 runners.go:198] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0521 18:00:42.454579 22 resource.go:361] Creating new exec pod
  E0521 18:00:42.540998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:43.541528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:44.542101      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:45.472602 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1533 exec execpodbkrz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  E0521 18:00:45.542183      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:45.563706 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I0521 18:00:45.563747 22 builder.go:147] stdout: "nodeport-test-gmxjf"
  I0521 18:00:45.563811 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1533 exec execpodbkrz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.101.80.173 80'
  I0521 18:00:45.648797 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.101.80.173 80\nConnection to 10.101.80.173 80 port [tcp/http] succeeded!\n"
  I0521 18:00:45.648845 22 builder.go:147] stdout: "nodeport-test-gmxjf"
  I0521 18:00:45.648931 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1533 exec execpodbkrz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.2 31434'
  I0521 18:00:45.741100 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.2 31434\nConnection to 192.168.67.2 31434 port [tcp/*] succeeded!\n"
  I0521 18:00:45.741164 22 builder.go:147] stdout: "nodeport-test-gmxjf"
  I0521 18:00:45.741286 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-1533 exec execpodbkrz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.67.3 31434'
  I0521 18:00:45.831537 22 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.67.3 31434\nConnection to 192.168.67.3 31434 port [tcp/*] succeeded!\n"
  I0521 18:00:45.831590 22 builder.go:147] stdout: "nodeport-test-d94kk"
  I0521 18:00:45.831704 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1533" for this suite. @ 05/21/24 18:00:45.834
• [6.467 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 05/21/24 18:00:45.839
  I0521 18:00:45.839894 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pod-network-test @ 05/21/24 18:00:45.84
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:00:45.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:00:45.854
  STEP: Performing setup for networking test in namespace pod-network-test-5935 @ 05/21/24 18:00:45.855
  STEP: creating a selector @ 05/21/24 18:00:45.855
  STEP: Creating the service pods in kubernetes @ 05/21/24 18:00:45.855
  I0521 18:00:45.855862 22 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0521 18:00:46.542628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:47.543594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:48.544594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:49.545454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:50.546655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:51.546984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:52.547613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:53.548384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:54.548255      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:55.548501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:56.549580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:57.549974      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 05/21/24 18:00:57.912
  E0521 18:00:58.550098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:00:59.550251      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:00:59.926929 22 utils.go:779] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0521 18:00:59.926974 22 networking.go:42] Breadth first check of 10.244.0.216 on host 192.168.67.2...
  I0521 18:00:59.929420 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.217:9080/dial?request=hostname&protocol=http&host=10.244.0.216&port=8083&tries=1'] Namespace:pod-network-test-5935 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 18:00:59.929462 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 18:00:59.929988 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 18:00:59.930043 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5935/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.217%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.0.216%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0521 18:00:59.986038 22 utils.go:331] Waiting for responses: map[]
  I0521 18:00:59.986064 22 utils.go:335] reached 10.244.0.216 after 0/1 tries
  I0521 18:00:59.986072 22 networking.go:42] Breadth first check of 10.244.1.216 on host 192.168.67.3...
  I0521 18:00:59.988273 22 exec_util.go:55] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.217:9080/dial?request=hostname&protocol=http&host=10.244.1.216&port=8083&tries=1'] Namespace:pod-network-test-5935 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0521 18:00:59.988303 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  I0521 18:00:59.988751 22 exec_util.go:62] ExecWithOptions: Clientset creation
  I0521 18:00:59.988804 22 exec_util.go:79] ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5935/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.217%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.1.216%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I0521 18:01:00.045388 22 utils.go:331] Waiting for responses: map[]
  I0521 18:01:00.045414 22 utils.go:335] reached 10.244.1.216 after 0/1 tries
  I0521 18:01:00.045421 22 networking.go:53] Going to retry 0 out of 2 pods....
  I0521 18:01:00.045482 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-5935" for this suite. @ 05/21/24 18:01:00.047
• [14.212 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 05/21/24 18:01:00.052
  I0521 18:01:00.052415 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename watch @ 05/21/24 18:01:00.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:01:00.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:01:00.063
  STEP: getting a starting resourceVersion @ 05/21/24 18:01:00.065
  STEP: starting a background goroutine to produce watch events @ 05/21/24 18:01:00.067
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 05/21/24 18:01:00.067
  E0521 18:01:00.550929      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:01.551658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:02.551760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:01:02.860150 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5028" for this suite. @ 05/21/24 18:01:02.908
• [2.908 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:707
  STEP: Creating a kubernetes client @ 05/21/24 18:01:02.96
  I0521 18:01:02.960974 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-pred @ 05/21/24 18:01:02.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:01:02.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:01:02.976
  I0521 18:01:02.979940 22 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0521 18:01:02.985454 22 util.go:400] Waiting for terminating namespaces to be deleted...
  I0521 18:01:02.987410 22 predicates.go:121] 
  Logging pods the apiserver thinks is on node k8sconformance before test
  I0521 18:01:02.991072 22 predicates.go:887] coredns-7db6d8ff4d-5h9wx from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.991106 22 predicates.go:889] 	Container coredns ready: true, restart count 1
  I0521 18:01:02.991124 22 predicates.go:887] etcd-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.991138 22 predicates.go:889] 	Container etcd ready: true, restart count 0
  I0521 18:01:02.991153 22 predicates.go:887] kindnet-x4z6c from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.991164 22 predicates.go:889] 	Container kindnet-cni ready: true, restart count 0
  I0521 18:01:02.991176 22 predicates.go:887] kube-apiserver-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.991204 22 predicates.go:889] 	Container kube-apiserver ready: true, restart count 0
  I0521 18:01:02.991217 22 predicates.go:887] kube-controller-manager-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.991228 22 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 0
  I0521 18:01:02.991242 22 predicates.go:887] kube-proxy-bk2bg from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.991256 22 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0521 18:01:02.991268 22 predicates.go:887] kube-scheduler-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.991280 22 predicates.go:889] 	Container kube-scheduler ready: true, restart count 0
  I0521 18:01:02.991293 22 predicates.go:887] storage-provisioner from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.991303 22 predicates.go:889] 	Container storage-provisioner ready: true, restart count 1
  I0521 18:01:02.991315 22 predicates.go:887] netserver-0 from pod-network-test-5935 started at 2024-05-21 18:00:45 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.991325 22 predicates.go:889] 	Container webserver ready: true, restart count 0
  I0521 18:01:02.991338 22 predicates.go:887] sonobuoy-systemd-logs-daemon-set-05530e69374c4820-8kzzl from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 18:01:02.991351 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 18:01:02.991363 22 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0521 18:01:02.991374 22 predicates.go:121] 
  Logging pods the apiserver thinks is on node k8sconformance-m02 before test
  I0521 18:01:02.995170 22 predicates.go:887] kindnet-d54l7 from kube-system started at 2024-05-21 17:40:08 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.995205 22 predicates.go:889] 	Container kindnet-cni ready: true, restart count 0
  I0521 18:01:02.995215 22 predicates.go:887] kube-proxy-8nnv4 from kube-system started at 2024-05-21 16:34:28 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.995221 22 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0521 18:01:02.995228 22 predicates.go:887] netserver-1 from pod-network-test-5935 started at 2024-05-21 18:00:45 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.995234 22 predicates.go:889] 	Container webserver ready: true, restart count 0
  I0521 18:01:02.995241 22 predicates.go:887] test-container-pod from pod-network-test-5935 started at 2024-05-21 18:00:57 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.995247 22 predicates.go:889] 	Container webserver ready: true, restart count 0
  I0521 18:01:02.995258 22 predicates.go:887] sonobuoy from sonobuoy started at 2024-05-21 16:38:41 +0000 UTC (1 container statuses recorded)
  I0521 18:01:02.995266 22 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0521 18:01:02.995273 22 predicates.go:887] sonobuoy-e2e-job-6986495216344806 from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 18:01:02.995279 22 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0521 18:01:02.995285 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 18:01:02.995291 22 predicates.go:887] sonobuoy-systemd-logs-daemon-set-05530e69374c4820-9t6gh from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 18:01:02.995296 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 18:01:02.995303 22 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/21/24 18:01:02.995
  E0521 18:01:03.551770      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:04.552037      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/21/24 18:01:05.013
  STEP: Trying to apply a random label on the found node. @ 05/21/24 18:01:05.03
  STEP: verifying the node has the label kubernetes.io/e2e-172ea3b8-fdfd-4106-8ca0-abce211cbe8a 95 @ 05/21/24 18:01:05.04
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 05/21/24 18:01:05.043
  E0521 18:01:05.552223      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:06.552586      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.67.3 on the node which pod4 resides and expect not scheduled @ 05/21/24 18:01:07.057
  E0521 18:01:07.553406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:08.553476      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:09.553912      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:10.554157      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:11.554894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:12.555056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:13.555378      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:14.555460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:15.556176      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:16.556450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:17.556512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:18.556612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:19.557424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:20.557784      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:21.557965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:22.558581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:23.559051      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:24.559426      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:25.560336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:26.560462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:27.561399      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:28.561494      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:29.561887      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:30.562138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:31.563280      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:32.563429      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:33.564236      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:34.564532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:35.565517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:36.565864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:37.566096      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:38.566487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:39.566866      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:40.567143      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:41.567487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:42.568598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:43.569172      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:44.569762      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:45.570318      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:46.570564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:47.571572      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:48.572663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:49.572857      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:50.573597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:51.574667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:52.575498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:53.576573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:54.577428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:55.578234      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:56.578558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:57.579398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:58.579831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:01:59.580341      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:00.581522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:01.582249      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:02.582563      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:03.582646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:04.583091      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:05.583644      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:06.584285      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:07.584627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:08.585163      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:09.585607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:10.586677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:11.587229      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:12.587526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:13.587680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:14.588181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:15.589373      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:16.589816      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:17.589942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:18.590872      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:19.591584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:20.592292      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:21.592349      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:22.592715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:23.593571      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:24.594705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:25.595725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:26.596300      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:27.597440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:28.597583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:29.598402      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:30.599250      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:31.600273      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:32.600583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:33.600788      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:34.601313      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:35.601776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:36.602260      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:37.602565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:38.602660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:39.603346      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:40.604349      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:41.605000      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:42.605490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:43.606564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:44.607254      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:45.607530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:46.608607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:47.608919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:48.609490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:49.609789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:50.610865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:51.611715      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:52.612308      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:53.613039      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:54.613553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:55.614474      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:56.614730      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:57.615516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:58.616171      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:02:59.616963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:00.617142      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:01.617506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:02.618081      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:03.618768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:04.619664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:05.620458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:06.621588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:07.622608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:08.623583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:09.624417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:10.625328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:11.625478      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:12.625721      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:13.626610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:14.627182      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:15.627546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:16.628102      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:17.628272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:18.628594      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:19.629712      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:20.629943      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:21.630920      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:22.631529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:23.632631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:24.633506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:25.634398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:26.634593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:27.635484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:28.635626      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:29.636231      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:30.637060      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:31.638053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:32.638617      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:33.638904      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:34.639523      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:35.640467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:36.641554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:37.642162      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:38.642668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:39.643424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:40.643996      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:41.644931      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:42.645693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:43.646656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:44.647148      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:45.647148      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:46.647638      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:47.647898      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:48.648529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:49.648655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:50.649501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:51.649654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:52.650080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:53.650714      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:54.651642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:55.652682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:56.653713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:57.654468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:58.654800      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:03:59.655484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:00.656016      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:01.656326      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:02.656722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:03.657295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:04.657546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:05.657629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:06.657957      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:07.659119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:08.659514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:09.659885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:10.660559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:11.660870      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:12.661179      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:13.661862      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:14.662442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:15.663304      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:16.663444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:17.663937      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:18.664675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:19.665227      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:20.665018      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:21.665817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:22.666486      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:23.666813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:24.667265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:25.667724      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:26.668138      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:27.668700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:28.669270      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:29.669852      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:30.670668      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:31.671005      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:32.671354      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:33.672420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:34.672782      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:35.673687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:36.674051      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:37.674751      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:38.675449      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:39.675627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:40.676654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:41.677597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:42.678466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:43.679646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:44.680435      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:45.681313      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:46.681803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:47.681852      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:48.682421      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:49.682962      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:50.683896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:51.684655      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:52.685660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:53.685931      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:54.686402      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:55.687440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:56.687542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:57.687863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:58.688456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:04:59.689282      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:00.689842      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:01.690041      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:02.690554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:03.690892      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:04.691662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:05.692692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:06.693174      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:07.693760      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:08.694385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:09.694925      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:10.695504      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:11.696011      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:12.696763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:13.697684      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:14.697996      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:15.698555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:16.698905      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:17.699038      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:18.699439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:19.699559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:20.700310      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:21.700558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:22.701490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:23.701877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:24.702241      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:25.702457      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:26.703545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:27.703839      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:28.704074      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:29.704677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:30.705733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:31.706139      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:32.706630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:33.707477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:34.708678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:35.708979      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:36.709635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:37.710087      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:38.711173      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:39.711398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:40.711790      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:41.712346      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:42.713081      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:43.713459      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:44.713672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:45.714404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:46.715556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:47.715654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:48.716133      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:49.716505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:50.717455      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:51.717803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:52.718690      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:53.719646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:54.720593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:55.721528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:56.722525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:57.723688      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:58.724627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:05:59.725172      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:00.725572      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:01.726132      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:02.726379      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:03.726583      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:04.727424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:05.728451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:06.728676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-172ea3b8-fdfd-4106-8ca0-abce211cbe8a off the node k8sconformance-m02 @ 05/21/24 18:06:07.07
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-172ea3b8-fdfd-4106-8ca0-abce211cbe8a @ 05/21/24 18:06:07.087
  I0521 18:06:07.090731 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5565" for this suite. @ 05/21/24 18:06:07.094
• [304.139 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 05/21/24 18:06:07.1
  I0521 18:06:07.100590 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replicaset @ 05/21/24 18:06:07.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:06:07.111
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:06:07.115
  STEP: Create a Replicaset @ 05/21/24 18:06:07.119
  STEP: Verify that the required pods have come up. @ 05/21/24 18:06:07.122
  I0521 18:06:07.124975 22 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0521 18:06:07.729453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:08.729686      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:09.730093      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:10.730983      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:11.731289      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:12.128995 22 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 05/21/24 18:06:12.129
  STEP: Getting /status @ 05/21/24 18:06:12.129
  I0521 18:06:12.132400 22 replica_set.go:643] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 05/21/24 18:06:12.132
  I0521 18:06:12.137464 22 replica_set.go:663] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 05/21/24 18:06:12.137
  I0521 18:06:12.139129 22 replica_set.go:689] Observed &ReplicaSet event: ADDED
  I0521 18:06:12.139232 22 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0521 18:06:12.139303 22 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0521 18:06:12.139369 22 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0521 18:06:12.139392 22 replica_set.go:682] Found replicaset test-rs in namespace replicaset-8346 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0521 18:06:12.139404 22 replica_set.go:693] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 05/21/24 18:06:12.139
  I0521 18:06:12.139435 22 replica_set.go:697] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0521 18:06:12.144784 22 replica_set.go:701] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 05/21/24 18:06:12.144
  I0521 18:06:12.146323 22 replica_set.go:725] Observed &ReplicaSet event: ADDED
  I0521 18:06:12.146396 22 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0521 18:06:12.146445 22 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0521 18:06:12.146659 22 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0521 18:06:12.146687 22 replica_set.go:721] Observed replicaset test-rs in namespace replicaset-8346 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0521 18:06:12.146769 22 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0521 18:06:12.146788 22 replica_set.go:718] Found replicaset test-rs in namespace replicaset-8346 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0521 18:06:12.146800 22 replica_set.go:729] Replicaset test-rs has a patched status
  I0521 18:06:12.146865 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8346" for this suite. @ 05/21/24 18:06:12.148
• [5.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 05/21/24 18:06:12.151
  I0521 18:06:12.151305 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubelet-test @ 05/21/24 18:06:12.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:06:12.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:06:12.161
  STEP: Waiting for pod completion @ 05/21/24 18:06:12.166
  E0521 18:06:12.732382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:13.732752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:14.733542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:15.734317      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:16.196922 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6561" for this suite. @ 05/21/24 18:06:16.199
• [4.052 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 05/21/24 18:06:16.203
  I0521 18:06:16.203272 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename dns @ 05/21/24 18:06:16.204
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:06:16.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:06:16.216
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1027.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1027.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 05/21/24 18:06:16.218
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1027.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1027.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 05/21/24 18:06:16.218
  STEP: creating a pod to probe /etc/hosts @ 05/21/24 18:06:16.218
  STEP: submitting the pod to kubernetes @ 05/21/24 18:06:16.218
  E0521 18:06:16.734375      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:17.734609      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/21/24 18:06:18.235
  STEP: looking for the results for each expected name from probers @ 05/21/24 18:06:18.238
  I0521 18:06:18.248097 22 dns_common.go:527] DNS probes using dns-1027/dns-test-c91def15-3c29-4978-a923-0cd534df9569 succeeded

  STEP: deleting the pod @ 05/21/24 18:06:18.248
  I0521 18:06:18.260338 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-1027" for this suite. @ 05/21/24 18:06:18.264
• [2.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 05/21/24 18:06:18.27
  I0521 18:06:18.270605 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename security-context @ 05/21/24 18:06:18.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:06:18.284
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:06:18.286
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 05/21/24 18:06:18.288
  E0521 18:06:18.734812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:19.735271      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:20.735371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:21.735902      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:06:22.306
  I0521 18:06:22.308785 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod security-context-bb61dde9-72b7-4d56-bb17-bab8ca961c50 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 18:06:22.315
  I0521 18:06:22.332505 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-1868" for this suite. @ 05/21/24 18:06:22.335
• [4.069 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 05/21/24 18:06:22.34
  I0521 18:06:22.340041 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 18:06:22.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:06:22.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:06:22.356
  STEP: Creating configMap with name configmap-projected-all-test-volume-7d197727-86f3-47a3-bc0f-38532e287085 @ 05/21/24 18:06:22.359
  STEP: Creating secret with name secret-projected-all-test-volume-a7489456-45e4-4cb6-a9f2-10b053ebfb3b @ 05/21/24 18:06:22.363
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 05/21/24 18:06:22.367
  E0521 18:06:22.736430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:23.736843      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:24.737644      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:25.738387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:06:26.388
  I0521 18:06:26.390628 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod projected-volume-15179c99-55df-4c6c-bc72-0e74187d5111 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 18:06:26.397
  I0521 18:06:26.412234 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2640" for this suite. @ 05/21/24 18:06:26.415
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 05/21/24 18:06:26.422
  I0521 18:06:26.422276 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename statefulset @ 05/21/24 18:06:26.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:06:26.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:06:26.437
  STEP: Creating service test in namespace statefulset-4658 @ 05/21/24 18:06:26.439
  STEP: Creating stateful set ss in namespace statefulset-4658 @ 05/21/24 18:06:26.443
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4658 @ 05/21/24 18:06:26.45
  I0521 18:06:26.452871 22 wait.go:40] Found 0 stateful pods, waiting for 1
  E0521 18:06:26.739512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:27.739834      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:28.740761      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:29.741407      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:30.742467      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:31.742843      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:32.742966      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:33.743023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:34.743552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:35.744124      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:36.456776 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 05/21/24 18:06:36.456
  I0521 18:06:36.460158 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4658 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 18:06:36.557933 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 18:06:36.557974 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 18:06:36.557991 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0521 18:06:36.560310 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0521 18:06:36.744565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:37.745581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:38.746378      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:39.747377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:40.747589      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:41.747748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:42.748531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:43.749435      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:44.750448      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:45.751382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:46.562345 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0521 18:06:46.562405 22 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0521 18:06:46.578542 22 resource.go:168] POD   NODE                PHASE    GRACE  CONDITIONS
  I0521 18:06:46.578638 22 resource.go:175] ss-0  k8sconformance-m02  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:27 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:26 +0000 UTC  }]
  I0521 18:06:46.578656 22 resource.go:178] 
  I0521 18:06:46.578672 22 statefulset.go:2147] StatefulSet ss has not reached scale 3, at 1
  E0521 18:06:46.751569      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:47.585412 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 8.996174446s
  E0521 18:06:47.752495      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:48.591811 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 7.989090665s
  E0521 18:06:48.753321      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:49.598077 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 6.983145501s
  E0521 18:06:49.754322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:50.603955 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 5.976809944s
  E0521 18:06:50.755293      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:51.609524 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 4.9711897s
  E0521 18:06:51.755750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:52.615153 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 3.96496411s
  E0521 18:06:52.756692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:53.618546 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 2.95916509s
  E0521 18:06:53.756687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:54.625225 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 1.955988965s
  E0521 18:06:54.757410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:55.630849 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 3 for another 949.501605ms
  E0521 18:06:55.758377      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4658 @ 05/21/24 18:06:56.631
  I0521 18:06:56.637147 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4658 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0521 18:06:56.753387 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0521 18:06:56.753441 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0521 18:06:56.753474 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0521 18:06:56.753538 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4658 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0521 18:06:56.758855      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:06:56.849245 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0521 18:06:56.849299 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0521 18:06:56.849318 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0521 18:06:56.849378 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4658 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0521 18:06:56.950607 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0521 18:06:56.950658 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0521 18:06:56.950678 22 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0521 18:06:56.953802 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0521 18:06:56.953841 22 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0521 18:06:56.953860 22 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 05/21/24 18:06:56.953
  I0521 18:06:56.956591 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4658 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 18:06:57.057590 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 18:06:57.057647 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 18:06:57.057671 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0521 18:06:57.057739 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4658 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 18:06:57.138815 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 18:06:57.138864 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 18:06:57.138883 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0521 18:06:57.138939 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-4658 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 18:06:57.219658 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 18:06:57.219700 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 18:06:57.219715 22 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0521 18:06:57.219727 22 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0521 18:06:57.221477 22 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0521 18:06:57.759335      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:58.759573      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:06:59.759579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:00.760406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:01.760596      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:02.761653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:03.762544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:04.763558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:05.763771      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:06.764237      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:07.228389 22 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0521 18:07:07.228443 22 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0521 18:07:07.228462 22 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0521 18:07:07.243003 22 resource.go:168] POD   NODE                PHASE    GRACE  CONDITIONS
  I0521 18:07:07.243083 22 resource.go:175] ss-0  k8sconformance-m02  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:27 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:26 +0000 UTC  }]
  I0521 18:07:07.243115 22 resource.go:175] ss-1  k8sconformance-m02  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:48 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:46 +0000 UTC  }]
  I0521 18:07:07.243143 22 resource.go:175] ss-2  k8sconformance      Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:48 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:46 +0000 UTC  }]
  I0521 18:07:07.243154 22 resource.go:178] 
  I0521 18:07:07.243165 22 statefulset.go:2147] StatefulSet ss has not reached scale 0, at 3
  E0521 18:07:07.764526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:08.248708 22 resource.go:168] POD   NODE                PHASE      GRACE  CONDITIONS
  I0521 18:07:08.248794 22 resource.go:175] ss-0  k8sconformance-m02  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:07:07 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:26 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:26 +0000 UTC  }]
  I0521 18:07:08.248830 22 resource.go:175] ss-1  k8sconformance-m02  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:07:07 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:46 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:46 +0000 UTC  }]
  I0521 18:07:08.248862 22 resource.go:175] ss-2  k8sconformance      Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:07:07 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:46 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:57 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-05-21 18:06:46 +0000 UTC  }]
  I0521 18:07:08.248874 22 resource.go:178] 
  I0521 18:07:08.248903 22 statefulset.go:2147] StatefulSet ss has not reached scale 0, at 3
  E0521 18:07:08.765585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:09.254530 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 7.989936909s
  E0521 18:07:09.766451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:10.258267 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 6.983966093s
  E0521 18:07:10.766514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:11.262738 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 5.980370781s
  E0521 18:07:11.767319      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:12.267789 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 4.976420876s
  E0521 18:07:12.767412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:13.272904 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 3.971340258s
  E0521 18:07:13.768700      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:14.277892 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 2.965869884s
  E0521 18:07:14.769599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:15.283385 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 1.960772647s
  E0521 18:07:15.770326      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:16.289006 22 statefulset.go:2152] Verifying statefulset ss doesn't scale past 0 for another 955.465408ms
  E0521 18:07:16.770694      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4658 @ 05/21/24 18:07:17.289
  I0521 18:07:17.291774 22 rest.go:150] Scaling statefulset ss to 0
  I0521 18:07:17.298443 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0521 18:07:17.299730 22 statefulset.go:135] Deleting all statefulset in ns statefulset-4658
  I0521 18:07:17.300962 22 rest.go:150] Scaling statefulset ss to 0
  I0521 18:07:17.305333 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0521 18:07:17.307564 22 rest.go:88] Deleting statefulset ss
  I0521 18:07:17.316490 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4658" for this suite. @ 05/21/24 18:07:17.321
• [50.908 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 05/21/24 18:07:17.33
  I0521 18:07:17.330271 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 18:07:17.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:07:17.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:07:17.344
  STEP: Creating pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693 @ 05/21/24 18:07:17.345
  E0521 18:07:17.771389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:18.772409      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 05/21/24 18:07:19.358
  I0521 18:07:19.360971 22 container_probe.go:1749] Initial restart count of pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 is 0
  I0521 18:07:19.363239 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:19.772683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:20.773355      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:21.365653 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:21.773965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:22.774811      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:23.368339 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:23.775718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:24.776143      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:25.373136 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:25.776410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:26.777536      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:27.378679 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:27.778351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:28.778489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:29.384084 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:29.779642      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:30.779598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:31.389798 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:31.780264      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:32.780743      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:33.395297 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:33.781396      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:34.781703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:35.401211 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:35.782711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:36.783322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:37.407719 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:37.784320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:38.784524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:39.413340 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:39.784899      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:40.785536      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:41.419656 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:41.786094      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:42.786632      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:43.425576 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:43.787683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:44.788392      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:45.429809 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:45.789220      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:46.789512      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:47.435340 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:47.790398      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:48.791344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:49.437513 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:49.791833      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:50.792053      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:51.442898 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:51.792451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:52.792994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:53.449347 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:53.793672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:54.794683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:55.454899 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:55.795521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:56.795991      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:57.460661 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:57.797050      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:07:58.797542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:07:59.462940 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:07:59.798329      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:00.798328      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:01.467831 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:01.799274      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:02.799556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:03.473584 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:03.800052      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:04.800660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:05.479307 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:05.800887      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:06.801709      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:07.485311 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:07.801835      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:08.802533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:09.491386 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:09.802895      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:10.803600      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:11.497478 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:11.803861      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:12.804593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:13.503792 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:13.805161      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:14.805530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:15.509028 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:15.806458      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:16.806863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:17.514531 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:17.807779      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:18.808536      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:19.518755 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:19.809091      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:20.809514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:21.523303 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:21.809763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:22.810676      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:23.528628 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:23.811091      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:24.811509      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:25.533272 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:25.812648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:26.812756      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:27.539335 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:27.813796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:28.814561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:29.544116 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:29.815550      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:30.815950      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:31.546153 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:31.816922      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:32.817498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:33.551559 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:33.817885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:34.818488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:35.555523 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:35.819023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:36.819531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:37.560082 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:37.820587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:38.821109      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:39.564155 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:39.821631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:40.822529      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:41.569302 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:41.823565      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:42.824579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:43.574874 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:43.825288      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:44.825812      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:45.579750 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:45.826068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:46.826552      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:47.586503 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:47.826840      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:48.827295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:49.591993 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:49.828406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:50.828351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:51.597791 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:51.828971      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:52.829667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:53.603374 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:53.830831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:54.831026      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:55.609116 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:55.831535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:56.832545      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:57.614695 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:57.833375      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:08:58.833849      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:08:59.620423 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:08:59.834664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:00.835324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:01.626554 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:01.835927      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:02.836546      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:03.632647 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:03.836929      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:04.837250      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:05.637141 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:05.837339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:06.837490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:07.643524 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:07.837736      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:08.838345      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:09.649026 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:09.838519      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:10.839574      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:11.655021 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:11.840492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:12.840562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:13.659711 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:13.841062      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:14.841597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:15.665247 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:15.842679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:16.843282      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:17.670446 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:17.843739      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:18.844266      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:19.676045 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:19.844423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:20.845098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:21.680663 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:21.846013      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:22.846553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:23.686439 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:23.846581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:24.847652      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:25.691637 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:25.847880      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:26.848423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:27.695830 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:27.849111      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:28.849646      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:29.701323 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:29.850743      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:30.851471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:31.706788 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:31.851718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:32.852066      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:33.710471 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:33.852786      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:34.853382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:35.718850 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:35.853487      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:36.853865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:37.725300 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:37.854584      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:38.854841      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:39.731529 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:39.855826      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:40.856534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:41.737784 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:41.857008      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:42.857444      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:43.743845 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:43.858312      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:44.859095      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:45.748986 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:45.859248      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:46.859747      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:47.755624 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:47.859811      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:48.860406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:49.761283 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:49.860397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:50.861513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:51.766881 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:51.862142      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:52.862480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:53.772798 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:53.862997      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:54.864077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:55.778523 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:55.864635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:56.865021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:57.781601 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:57.865730      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:09:58.866439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:09:59.787661 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:09:59.866717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:00.867679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:01.789899 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:01.868028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:02.868389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:03.792150 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:03.869423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:04.870056      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:05.797065 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:05.870241      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:06.870757      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:07.803709 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:07.870846      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:08.871725      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:09.808059 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:09.872514      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:10.873543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:11.813721 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:11.873946      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:12.874807      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:13.819503 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:13.875830      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:14.876864      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:15.823495 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:15.876894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:16.877381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:17.829580 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:17.877644      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:18.878599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:19.833640 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:19.878961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:20.879764      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:21.838996 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:21.880153      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:22.880627      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:23.845317 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:23.881635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:24.882451      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:25.851583 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:25.882775      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:26.882817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:27.856655 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:27.883833      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:28.884597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:29.862949 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:29.885032      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:30.885518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:31.868300 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:31.886418      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:32.887576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:33.872991 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:33.888258      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:34.888967      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:35.878123 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:35.888948      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:36.889264      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:37.884645 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:37.889745      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:38.889867      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:39.889137 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:39.890232      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:40.890491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:41.890590      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:41.894904 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:42.890758      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:43.891900      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:43.901024 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:44.892400      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:45.892511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:45.906924 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:46.893491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:47.893673      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:47.913924 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:48.894601      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:49.894813      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:49.919118 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:50.895500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:51.895591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:51.925456 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:52.896558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:53.897592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:53.931132 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:54.897664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:55.898659      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:55.937378 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:56.899445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:57.899579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:57.942396 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:10:58.900525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:10:59.901629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:10:59.946264 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:00.902578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:01.903649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:01.952241 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:02.904591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:03.905412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:03.957544 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:04.905996      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:05.906582      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:05.963130 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:06.906682      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:07.907268      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:07.969374 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:08.908096      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:09.908680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:09.974764 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:10.909170      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:11.909607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:11.979960 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:12.909963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:13.910104      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:13.986048 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:14.910158      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:15.911099      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:15.990600 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:16.911425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:17.912608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:17.996660 22 container_probe.go:1759] Get pod busybox-04f9ede0-adbe-41af-a7d0-04f43e38ed39 in namespace container-probe-1693
  E0521 18:11:18.913499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:19.913685      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 05/21/24 18:11:19.997
  I0521 18:11:20.015277 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1693" for this suite. @ 05/21/24 18:11:20.019
• [242.694 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 05/21/24 18:11:20.024
  I0521 18:11:20.024274 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename daemonsets @ 05/21/24 18:11:20.025
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:11:20.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:11:20.045
  STEP: Creating simple DaemonSet "daemon-set" @ 05/21/24 18:11:20.064
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/21/24 18:11:20.07
  I0521 18:11:20.075083 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 18:11:20.075126 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  E0521 18:11:20.914517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:21.079137 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 18:11:21.079180 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  E0521 18:11:21.915046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:22.078770 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0521 18:11:22.078815 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 05/21/24 18:11:22.08
  I0521 18:11:22.083485 22 daemon_set.go:912] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 05/21/24 18:11:22.083
  I0521 18:11:22.093427 22 daemon_set.go:932] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 05/21/24 18:11:22.093
  I0521 18:11:22.095660 22 daemon_set.go:957] Observed &DaemonSet event: ADDED
  I0521 18:11:22.095824 22 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0521 18:11:22.095954 22 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0521 18:11:22.096071 22 daemon_set.go:957] Observed &DaemonSet event: MODIFIED
  I0521 18:11:22.096109 22 daemon_set.go:950] Found daemon set daemon-set in namespace daemonsets-9665 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0521 18:11:22.096129 22 daemon_set.go:961] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 05/21/24 18:11:22.096
  STEP: watching for the daemon set status to be patched @ 05/21/24 18:11:22.102
  I0521 18:11:22.104349 22 daemon_set.go:1001] Observed &DaemonSet event: ADDED
  I0521 18:11:22.104512 22 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0521 18:11:22.104639 22 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0521 18:11:22.104759 22 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0521 18:11:22.104791 22 daemon_set.go:997] Observed daemon set daemon-set in namespace daemonsets-9665 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0521 18:11:22.104914 22 daemon_set.go:1001] Observed &DaemonSet event: MODIFIED
  I0521 18:11:22.104944 22 daemon_set.go:994] Found daemon set daemon-set in namespace daemonsets-9665 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0521 18:11:22.104966 22 daemon_set.go:1005] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 05/21/24 18:11:22.109
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9665, will wait for the garbage collector to delete the pods @ 05/21/24 18:11:22.109
  I0521 18:11:22.169578 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.581308ms
  I0521 18:11:22.270497 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.885923ms
  E0521 18:11:22.915285      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:23.915651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:24.774654 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 18:11:24.774724 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0521 18:11:24.777463 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28986"},"items":null}

  I0521 18:11:24.779709 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28986"},"items":null}

  I0521 18:11:24.786405 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9665" for this suite. @ 05/21/24 18:11:24.789
• [4.769 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 05/21/24 18:11:24.794
  I0521 18:11:24.794099 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 18:11:24.795
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:11:24.805
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:11:24.808
  STEP: Setting up server cert @ 05/21/24 18:11:24.823
  E0521 18:11:24.915895      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 18:11:25.041
  STEP: Deploying the webhook pod @ 05/21/24 18:11:25.045
  STEP: Wait for the deployment to be ready @ 05/21/24 18:11:25.052
  I0521 18:11:25.056106 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 18:11:25.916838      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:26.917510      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 18:11:27.067
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 18:11:27.079
  E0521 18:11:27.917804      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:28.080296 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 05/21/24 18:11:28.088
  STEP: create a pod that should be denied by the webhook @ 05/21/24 18:11:28.106
  STEP: create a pod that causes the webhook to hang @ 05/21/24 18:11:28.114
  E0521 18:11:28.918509      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:29.919466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:30.920085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:31.920605      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:32.920748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:33.921150      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:34.921803      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:35.922729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:36.923502      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:37.924615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 05/21/24 18:11:38.122
  STEP: create a configmap that should be admitted by the webhook @ 05/21/24 18:11:38.132
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/21/24 18:11:38.143
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 05/21/24 18:11:38.15
  STEP: create a namespace that bypass the webhook @ 05/21/24 18:11:38.154
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 05/21/24 18:11:38.166
  I0521 18:11:38.204046 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1679" for this suite. @ 05/21/24 18:11:38.206
  STEP: Destroying namespace "webhook-markers-248" for this suite. @ 05/21/24 18:11:38.212
  STEP: Destroying namespace "exempted-namespace-2312" for this suite. @ 05/21/24 18:11:38.217
• [13.427 seconds]
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 05/21/24 18:11:38.22
  I0521 18:11:38.220741 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename lease-test @ 05/21/24 18:11:38.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:11:38.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:11:38.236
  I0521 18:11:38.269783 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-309" for this suite. @ 05/21/24 18:11:38.27
• [0.053 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 05/21/24 18:11:38.273
  I0521 18:11:38.273736 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename daemonsets @ 05/21/24 18:11:38.274
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:11:38.28
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:11:38.282
  I0521 18:11:38.294930 22 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 05/21/24 18:11:38.297
  I0521 18:11:38.302864 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 18:11:38.302910 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  E0521 18:11:38.925389      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:39.301503 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 18:11:39.301527 22 fixtures.go:130] Node k8sconformance is running 0 daemon pod, expected 1
  E0521 18:11:39.926515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:40.306878 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0521 18:11:40.306922 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 05/21/24 18:11:40.316
  STEP: Check that daemon pods images are updated. @ 05/21/24 18:11:40.325
  I0521 18:11:40.328965 22 daemon_set.go:1178] Wrong image for pod: daemon-set-hfmwq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0521 18:11:40.329013 22 daemon_set.go:1178] Wrong image for pod: daemon-set-wgbn4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0521 18:11:40.927337      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:41.332230 22 daemon_set.go:1178] Wrong image for pod: daemon-set-hfmwq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0521 18:11:41.927990      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:42.331247 22 daemon_set.go:1183] Pod daemon-set-fsrqw is not available
  I0521 18:11:42.331314 22 daemon_set.go:1178] Wrong image for pod: daemon-set-hfmwq. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0521 18:11:42.928929      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:43.328071 22 daemon_set.go:1183] Pod daemon-set-lvzk6 is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 05/21/24 18:11:43.329
  I0521 18:11:43.332016 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 18:11:43.332038 22 fixtures.go:130] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0521 18:11:43.929748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:44.338119 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0521 18:11:44.338163 22 fixtures.go:130] Node k8sconformance-m02 is running 0 daemon pod, expected 1
  E0521 18:11:44.930794      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:45.337810 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0521 18:11:45.337855 22 fixtures.go:135] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 05/21/24 18:11:45.349
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9584, will wait for the garbage collector to delete the pods @ 05/21/24 18:11:45.349
  I0521 18:11:45.411392 22 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.380099ms
  I0521 18:11:45.512489 22 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.09894ms
  E0521 18:11:45.930885      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:11:46.616104 22 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0521 18:11:46.616162 22 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0521 18:11:46.618587 22 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29201"},"items":null}

  I0521 18:11:46.620585 22 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29201"},"items":null}

  I0521 18:11:46.627274 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9584" for this suite. @ 05/21/24 18:11:46.629
• [8.360 seconds]
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 05/21/24 18:11:46.633
  I0521 18:11:46.633847 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename svcaccounts @ 05/21/24 18:11:46.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:11:46.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:11:46.647
  I0521 18:11:46.651678 22 service_accounts.go:754] Got root ca configmap in namespace "svcaccounts-6499"
  I0521 18:11:46.655055 22 service_accounts.go:757] Deleted root ca configmap in namespace "svcaccounts-6499"
  E0521 18:11:46.931630      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 05/21/24 18:11:47.156
  I0521 18:11:47.161678 22 service_accounts.go:771] Recreated root ca configmap in namespace "svcaccounts-6499"
  I0521 18:11:47.168283 22 service_accounts.go:782] Updated root ca configmap in namespace "svcaccounts-6499"
  STEP: waiting for the root ca configmap reconciled @ 05/21/24 18:11:47.668
  I0521 18:11:47.673470 22 service_accounts.go:800] Reconciled root ca configmap in namespace "svcaccounts-6499"
  I0521 18:11:47.673615 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6499" for this suite. @ 05/21/24 18:11:47.676
• [1.048 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 05/21/24 18:11:47.681
  I0521 18:11:47.681843 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename downward-api @ 05/21/24 18:11:47.683
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:11:47.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:11:47.698
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 18:11:47.701
  E0521 18:11:47.932055      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:48.932355      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:11:49.725
  I0521 18:11:49.726970 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-f739dea0-f104-419d-ad9c-673798281afd container client-container: <nil>
  STEP: delete the pod @ 05/21/24 18:11:49.736
  I0521 18:11:49.744549 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5317" for this suite. @ 05/21/24 18:11:49.746
• [2.068 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 05/21/24 18:11:49.749
  I0521 18:11:49.749701 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-preemption @ 05/21/24 18:11:49.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:11:49.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:11:49.757
  I0521 18:11:49.766807 22 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E0521 18:11:49.932554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:50.932784      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:51.933557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:52.933561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:53.933974      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:54.934780      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:55.935635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:56.936242      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:57.937340      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:58.937516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:11:59.938405      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:00.938632      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:01.939128      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:02.939462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:03.940303      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:04.940961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:05.941845      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:06.941915      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:07.942581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:08.943624      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:09.944489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:10.945127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:11.946272      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:12.946513      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:13.947403      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:14.948095      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:15.948869      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:16.949662      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:17.950058      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:18.950732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:19.950935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:20.951439      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:21.951503      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:22.951993      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:23.952927      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:24.953096      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:25.954185      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:26.954517      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:27.955648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:28.956538      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:29.957226      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:30.957361      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:31.958149      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:32.958684      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:33.959454      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:34.960577      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:35.960658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:36.961051      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:37.961579      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:38.962112      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:39.963068      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:40.963963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:41.965015      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:42.965516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:43.966654      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:44.966874      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:45.967320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:46.967471      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:47.967694      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:48.967879      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:12:49.772592 22 util.go:400] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 05/21/24 18:12:49.774
  I0521 18:12:49.792505 22 preemption.go:269] Created pod: pod0-0-sched-preemption-low-priority
  I0521 18:12:49.800169 22 preemption.go:269] Created pod: pod0-1-sched-preemption-medium-priority
  I0521 18:12:49.819332 22 preemption.go:269] Created pod: pod1-0-sched-preemption-medium-priority
  I0521 18:12:49.831162 22 preemption.go:269] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 05/21/24 18:12:49.831
  E0521 18:12:49.968440      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:50.969169      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 05/21/24 18:12:51.85
  E0521 18:12:51.969049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:52.970127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:53.970985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:54.971851      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:12:55.926100 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2475" for this suite. @ 05/21/24 18:12:55.928
• [66.182 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 05/21/24 18:12:55.932
  I0521 18:12:55.932034 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename resourcequota @ 05/21/24 18:12:55.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:12:55.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:12:55.945
  STEP: Creating a ResourceQuota @ 05/21/24 18:12:55.947
  STEP: Getting a ResourceQuota @ 05/21/24 18:12:55.949
  STEP: Updating a ResourceQuota @ 05/21/24 18:12:55.951
  STEP: Verifying a ResourceQuota was modified @ 05/21/24 18:12:55.957
  STEP: Deleting a ResourceQuota @ 05/21/24 18:12:55.958
  STEP: Verifying the deleted ResourceQuota @ 05/21/24 18:12:55.961
  I0521 18:12:55.963309 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-233" for this suite. @ 05/21/24 18:12:55.964
• [0.035 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 05/21/24 18:12:55.967
  I0521 18:12:55.967539 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename pods @ 05/21/24 18:12:55.968
  E0521 18:12:55.972522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:12:55.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:12:55.981
  E0521 18:12:56.972863      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:57.973498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:58.973730      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:12:59.974236      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:00.974381      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:01.974506      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:13:02.031
  I0521 18:13:02.033759 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod client-envvars-11bb0211-129b-4760-b9e4-465e1e1f080d container env3cont: <nil>
  STEP: delete the pod @ 05/21/24 18:13:02.04
  I0521 18:13:02.052364 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7321" for this suite. @ 05/21/24 18:13:02.054
• [6.091 seconds]
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 05/21/24 18:13:02.058
  I0521 18:13:02.058374 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename csiinlinevolumes @ 05/21/24 18:13:02.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:02.068
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:02.07
  STEP: creating @ 05/21/24 18:13:02.072
  STEP: getting @ 05/21/24 18:13:02.085
  STEP: listing in namespace @ 05/21/24 18:13:02.087
  STEP: patching @ 05/21/24 18:13:02.09
  STEP: deleting @ 05/21/24 18:13:02.1
  I0521 18:13:02.106165 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-6741" for this suite. @ 05/21/24 18:13:02.107
• [0.052 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 05/21/24 18:13:02.11
  I0521 18:13:02.110758 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename disruption @ 05/21/24 18:13:02.111
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:02.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:02.119
  STEP: Waiting for the pdb to be processed @ 05/21/24 18:13:02.126
  E0521 18:13:02.975484      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:03.975932      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 05/21/24 18:13:04.131
  STEP: Waiting for all pods to be running @ 05/21/24 18:13:04.14
  I0521 18:13:04.143809 22 disruption.go:578] running pods: 0 < 1
  E0521 18:13:04.976908      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:05.977707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 05/21/24 18:13:06.146
  STEP: Waiting for the pdb to be processed @ 05/21/24 18:13:06.156
  STEP: Patching PodDisruptionBudget status @ 05/21/24 18:13:06.163
  STEP: Waiting for the pdb to be processed @ 05/21/24 18:13:06.171
  I0521 18:13:06.174455 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5502" for this suite. @ 05/21/24 18:13:06.177
• [4.074 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
  STEP: Creating a kubernetes client @ 05/21/24 18:13:06.185
  I0521 18:13:06.185145 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 18:13:06.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:06.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:06.199
  STEP: create deployment with httpd image @ 05/21/24 18:13:06.2
  I0521 18:13:06.200718 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-291 create -f -'
  I0521 18:13:06.250036 22 builder.go:146] stderr: ""
  I0521 18:13:06.250072 22 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 05/21/24 18:13:06.25
  I0521 18:13:06.250141 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-291 diff -f -'
  I0521 18:13:06.326530 22 builder.go:135] rc: 1
  I0521 18:13:06.326604 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-291 delete -f -'
  I0521 18:13:06.366076 22 builder.go:146] stderr: ""
  I0521 18:13:06.366114 22 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I0521 18:13:06.366217 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-291" for this suite. @ 05/21/24 18:13:06.367
• [0.185 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
  STEP: Creating a kubernetes client @ 05/21/24 18:13:06.37
  I0521 18:13:06.370512 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 18:13:06.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:06.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:06.381
  I0521 18:13:06.382703 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-8966 version'
  I0521 18:13:06.414068 22 builder.go:146] stderr: ""
  I0521 18:13:06.414096 22 builder.go:147] stdout: "Client Version: v1.30.1\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.30.1\n"
  I0521 18:13:06.414227 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8966" for this suite. @ 05/21/24 18:13:06.415
• [0.048 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 05/21/24 18:13:06.418
  I0521 18:13:06.418566 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 18:13:06.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:06.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:06.425
  STEP: Setting up server cert @ 05/21/24 18:13:06.435
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 18:13:06.61
  STEP: Deploying the webhook pod @ 05/21/24 18:13:06.612
  STEP: Wait for the deployment to be ready @ 05/21/24 18:13:06.62
  I0521 18:13:06.622877 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 18:13:06.978356      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:07.978810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 18:13:08.634
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 18:13:08.65
  E0521 18:13:08.979336      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:13:09.650377 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/21/24 18:13:09.657
  I0521 18:13:09.676562 22 webhook.go:2672] Waiting for webhook configuration to be ready...
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 05/21/24 18:13:09.787
  STEP: Creating a dummy validating-webhook-configuration object @ 05/21/24 18:13:09.8
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 05/21/24 18:13:09.809
  STEP: Creating a dummy mutating-webhook-configuration object @ 05/21/24 18:13:09.814
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 05/21/24 18:13:09.82
  I0521 18:13:09.865123 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1585" for this suite. @ 05/21/24 18:13:09.867
  STEP: Destroying namespace "webhook-markers-1563" for this suite. @ 05/21/24 18:13:09.87
• [3.456 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 05/21/24 18:13:09.874
  I0521 18:13:09.874581 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 18:13:09.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:09.883
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:09.885
  STEP: Creating projection with secret that has name projected-secret-test-c7c34074-df2c-4817-b808-c77244e6af6a @ 05/21/24 18:13:09.887
  STEP: Creating a pod to test consume secrets @ 05/21/24 18:13:09.89
  E0521 18:13:09.980533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:10.980493      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:11.981268      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:12.981466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:13:13.908
  I0521 18:13:13.911137 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-projected-secrets-eae4b8aa-a176-4d13-85ae-932daf841265 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 18:13:13.918
  I0521 18:13:13.934697 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6319" for this suite. @ 05/21/24 18:13:13.937
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:469
  STEP: Creating a kubernetes client @ 05/21/24 18:13:13.944
  I0521 18:13:13.944925 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename sched-pred @ 05/21/24 18:13:13.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:13.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:13.962
  I0521 18:13:13.965285 22 helper.go:121] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0521 18:13:13.970746 22 util.go:400] Waiting for terminating namespaces to be deleted...
  I0521 18:13:13.973144 22 predicates.go:121] 
  Logging pods the apiserver thinks is on node k8sconformance before test
  I0521 18:13:13.977306 22 predicates.go:887] coredns-7db6d8ff4d-5h9wx from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.977342 22 predicates.go:889] 	Container coredns ready: true, restart count 1
  I0521 18:13:13.977359 22 predicates.go:887] etcd-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.977371 22 predicates.go:889] 	Container etcd ready: true, restart count 0
  I0521 18:13:13.977384 22 predicates.go:887] kindnet-x4z6c from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.977398 22 predicates.go:889] 	Container kindnet-cni ready: true, restart count 0
  I0521 18:13:13.977412 22 predicates.go:887] kube-apiserver-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.977425 22 predicates.go:889] 	Container kube-apiserver ready: true, restart count 0
  I0521 18:13:13.977438 22 predicates.go:887] kube-controller-manager-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.977449 22 predicates.go:889] 	Container kube-controller-manager ready: true, restart count 0
  I0521 18:13:13.977461 22 predicates.go:887] kube-proxy-bk2bg from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.977474 22 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0521 18:13:13.977486 22 predicates.go:887] kube-scheduler-k8sconformance from kube-system started at 2024-05-21 16:34:03 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.977497 22 predicates.go:889] 	Container kube-scheduler ready: true, restart count 0
  I0521 18:13:13.977510 22 predicates.go:887] storage-provisioner from kube-system started at 2024-05-21 16:34:17 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.977522 22 predicates.go:889] 	Container storage-provisioner ready: true, restart count 1
  I0521 18:13:13.977535 22 predicates.go:887] sonobuoy-systemd-logs-daemon-set-05530e69374c4820-8kzzl from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 18:13:13.977546 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 18:13:13.977556 22 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  I0521 18:13:13.977567 22 predicates.go:121] 
  Logging pods the apiserver thinks is on node k8sconformance-m02 before test
  E0521 18:13:13.981488      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:13:13.981802 22 predicates.go:887] kindnet-d54l7 from kube-system started at 2024-05-21 17:40:08 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.981832 22 predicates.go:889] 	Container kindnet-cni ready: true, restart count 0
  I0521 18:13:13.981848 22 predicates.go:887] kube-proxy-8nnv4 from kube-system started at 2024-05-21 16:34:28 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.981859 22 predicates.go:889] 	Container kube-proxy ready: true, restart count 0
  I0521 18:13:13.981871 22 predicates.go:887] sonobuoy from sonobuoy started at 2024-05-21 16:38:41 +0000 UTC (1 container statuses recorded)
  I0521 18:13:13.981880 22 predicates.go:889] 	Container kube-sonobuoy ready: true, restart count 0
  I0521 18:13:13.981893 22 predicates.go:887] sonobuoy-e2e-job-6986495216344806 from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 18:13:13.981904 22 predicates.go:889] 	Container e2e ready: true, restart count 0
  I0521 18:13:13.981917 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 18:13:13.981929 22 predicates.go:887] sonobuoy-systemd-logs-daemon-set-05530e69374c4820-9t6gh from sonobuoy started at 2024-05-21 16:38:46 +0000 UTC (2 container statuses recorded)
  I0521 18:13:13.981939 22 predicates.go:889] 	Container sonobuoy-worker ready: true, restart count 0
  I0521 18:13:13.981951 22 predicates.go:889] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 05/21/24 18:13:13.982
  E0521 18:13:14.981750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:15.982424      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 05/21/24 18:13:16.001
  STEP: Trying to apply a random label on the found node. @ 05/21/24 18:13:16.012
  STEP: verifying the node has the label kubernetes.io/e2e-3271611c-d035-4494-aa94-231444b53c38 42 @ 05/21/24 18:13:16.023
  STEP: Trying to relaunch the pod, now with labels. @ 05/21/24 18:13:16.026
  E0521 18:13:16.982629      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:17.983057      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-3271611c-d035-4494-aa94-231444b53c38 off the node k8sconformance-m02 @ 05/21/24 18:13:18.043
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-3271611c-d035-4494-aa94-231444b53c38 @ 05/21/24 18:13:18.055
  I0521 18:13:18.059244 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-1548" for this suite. @ 05/21/24 18:13:18.062
• [4.123 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 05/21/24 18:13:18.068
  I0521 18:13:18.068260 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename replicaset @ 05/21/24 18:13:18.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:18.08
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:18.082
  STEP: Create a ReplicaSet @ 05/21/24 18:13:18.084
  STEP: Verify that the required pods have come up @ 05/21/24 18:13:18.087
  I0521 18:13:18.090525 22 resource.go:87] Pod name sample-pod: Found 0 pods out of 3
  E0521 18:13:18.983344      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:19.983420      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:20.983805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:21.984559      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:22.985535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:13:23.093275 22 resource.go:87] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 05/21/24 18:13:23.093
  I0521 18:13:23.098526 22 replica_set.go:583] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 05/21/24 18:13:23.098
  STEP: DeleteCollection of the ReplicaSets @ 05/21/24 18:13:23.101
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 05/21/24 18:13:23.107
  I0521 18:13:23.110155 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4774" for this suite. @ 05/21/24 18:13:23.114
• [5.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 05/21/24 18:13:23.129
  I0521 18:13:23.129436 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 18:13:23.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:23.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:23.15
  STEP: Creating the pod @ 05/21/24 18:13:23.153
  E0521 18:13:23.986442      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:24.986837      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:13:25.696525 22 pod_client.go:141] Successfully updated pod "annotationupdatea461225b-ab3f-4178-ad3b-c4712e737f6f"
  E0521 18:13:25.987086      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:26.987608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:27.988483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:28.989678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:13:29.727793 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-943" for this suite. @ 05/21/24 18:13:29.731
• [6.610 seconds]
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1537
  STEP: Creating a kubernetes client @ 05/21/24 18:13:29.739
  I0521 18:13:29.739119 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename services @ 05/21/24 18:13:29.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:29.751
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:29.754
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-8013 @ 05/21/24 18:13:29.757
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 05/21/24 18:13:29.772
  STEP: creating service externalsvc in namespace services-8013 @ 05/21/24 18:13:29.772
  STEP: creating replication controller externalsvc in namespace services-8013 @ 05/21/24 18:13:29.785
  I0521 18:13:29.791713      22 runners.go:198] Created replication controller with name: externalsvc, namespace: services-8013, replica count: 2
  E0521 18:13:29.990606      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:30.991628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:31.992479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:13:32.843426      22 runners.go:198] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 05/21/24 18:13:32.847
  I0521 18:13:32.865567 22 resource.go:361] Creating new exec pod
  E0521 18:13:32.993428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:33.993461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:13:34.880031 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=services-8013 exec execpodhfjvp -- /bin/sh -x -c nslookup nodeport-service.services-8013.svc.cluster.local'
  I0521 18:13:34.974261 22 builder.go:146] stderr: "+ nslookup nodeport-service.services-8013.svc.cluster.local\n"
  I0521 18:13:34.974290 22 builder.go:147] stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-8013.svc.cluster.local\tcanonical name = externalsvc.services-8013.svc.cluster.local.\nName:\texternalsvc.services-8013.svc.cluster.local\nAddress: 10.106.103.110\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-8013, will wait for the garbage collector to delete the pods @ 05/21/24 18:13:34.974
  E0521 18:13:34.993692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:13:35.033738 22 resources.go:139] Deleting ReplicationController externalsvc took: 5.809544ms
  I0521 18:13:35.134385 22 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.633037ms
  E0521 18:13:35.994524      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:36.995404      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:37.995693      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:13:38.255331 22 service.go:1548] Cleaning up the NodePort to ExternalName test service
  I0521 18:13:38.263722 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8013" for this suite. @ 05/21/24 18:13:38.265
• [8.531 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 05/21/24 18:13:38.269
  I0521 18:13:38.269798 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-runtime @ 05/21/24 18:13:38.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:38.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:38.28
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 05/21/24 18:13:38.287
  E0521 18:13:38.996432      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:39.997376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:40.998360      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:41.999557      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:43.000071      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:44.000961      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:45.001004      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:46.001241      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:47.001293      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:48.001982      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:49.002181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:50.002468      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:51.003408      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:52.004566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 05/21/24 18:13:52.351
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 05/21/24 18:13:52.354
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 05/21/24 18:13:52.359
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 05/21/24 18:13:52.359
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 05/21/24 18:13:52.376
  E0521 18:13:53.005339      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:54.005916      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 05/21/24 18:13:54.384
  E0521 18:13:55.006942      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 05/21/24 18:13:55.391
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 05/21/24 18:13:55.395
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 05/21/24 18:13:55.395
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 05/21/24 18:13:55.413
  E0521 18:13:56.007371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 05/21/24 18:13:56.42
  E0521 18:13:57.008413      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 05/21/24 18:13:57.429
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 05/21/24 18:13:57.434
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 05/21/24 18:13:57.434
  I0521 18:13:57.453756 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9448" for this suite. @ 05/21/24 18:13:57.456
• [19.191 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 05/21/24 18:13:57.461
  I0521 18:13:57.461471 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename projected @ 05/21/24 18:13:57.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:57.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:57.476
  STEP: Creating a pod to test downward API volume plugin @ 05/21/24 18:13:57.478
  E0521 18:13:58.008249      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:13:59.008322      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:13:59.494
  I0521 18:13:59.497624 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod downwardapi-volume-8be38589-f19a-4f56-8947-861dc1efff71 container client-container: <nil>
  STEP: delete the pod @ 05/21/24 18:13:59.504
  I0521 18:13:59.518291 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7096" for this suite. @ 05/21/24 18:13:59.521
• [2.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:355
  STEP: Creating a kubernetes client @ 05/21/24 18:13:59.526
  I0521 18:13:59.526847 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 18:13:59.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:13:59.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:13:59.541
  STEP: creating a replication controller @ 05/21/24 18:13:59.544
  I0521 18:13:59.544578 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 create -f -'
  I0521 18:13:59.624952 22 builder.go:146] stderr: ""
  I0521 18:13:59.624987 22 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/21/24 18:13:59.625
  I0521 18:13:59.625071 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0521 18:13:59.690066 22 builder.go:146] stderr: ""
  I0521 18:13:59.690105 22 builder.go:147] stdout: "update-demo-nautilus-9n485 update-demo-nautilus-rh6xq "
  I0521 18:13:59.690149 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-9n485 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 18:13:59.728359 22 builder.go:146] stderr: ""
  I0521 18:13:59.728410 22 builder.go:147] stdout: ""
  I0521 18:13:59.728421 22 kubectl.go:2501] update-demo-nautilus-9n485 is created but not running
  E0521 18:14:00.008994      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:01.010009      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:02.010816      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:03.011748      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:04.012501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:04.729388 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0521 18:14:04.768681 22 builder.go:146] stderr: ""
  I0521 18:14:04.768717 22 builder.go:147] stdout: "update-demo-nautilus-9n485 update-demo-nautilus-rh6xq "
  I0521 18:14:04.768759 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-9n485 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 18:14:04.805442 22 builder.go:146] stderr: ""
  I0521 18:14:04.805474 22 builder.go:147] stdout: "true"
  I0521 18:14:04.805512 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-9n485 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0521 18:14:04.839553 22 builder.go:146] stderr: ""
  I0521 18:14:04.839579 22 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0521 18:14:04.839586 22 kubectl.go:2392] validating pod update-demo-nautilus-9n485
  I0521 18:14:04.841481 22 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0521 18:14:04.841525 22 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0521 18:14:04.841537 22 kubectl.go:2519] update-demo-nautilus-9n485 is verified up and running
  I0521 18:14:04.841579 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-rh6xq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 18:14:04.881623 22 builder.go:146] stderr: ""
  I0521 18:14:04.881657 22 builder.go:147] stdout: "true"
  I0521 18:14:04.881699 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-rh6xq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0521 18:14:04.915862 22 builder.go:146] stderr: ""
  I0521 18:14:04.915894 22 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0521 18:14:04.915906 22 kubectl.go:2392] validating pod update-demo-nautilus-rh6xq
  I0521 18:14:04.917813 22 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0521 18:14:04.917843 22 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0521 18:14:04.917851 22 kubectl.go:2519] update-demo-nautilus-rh6xq is verified up and running
  STEP: scaling down the replication controller @ 05/21/24 18:14:04.917
  I0521 18:14:04.918398 22 kubectl.go:324] scanned /root for discovery docs: <nil>
  I0521 18:14:04.918415 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0521 18:14:05.012802      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:05.976949 22 builder.go:146] stderr: ""
  I0521 18:14:05.976995 22 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/21/24 18:14:05.977
  I0521 18:14:05.977093 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0521 18:14:06.013434      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:06.017302 22 builder.go:146] stderr: ""
  I0521 18:14:06.017322 22 builder.go:147] stdout: "update-demo-nautilus-9n485 "
  I0521 18:14:06.017347 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-9n485 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 18:14:06.054720 22 builder.go:146] stderr: ""
  I0521 18:14:06.054761 22 builder.go:147] stdout: "true"
  I0521 18:14:06.054804 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-9n485 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0521 18:14:06.090426 22 builder.go:146] stderr: ""
  I0521 18:14:06.090460 22 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0521 18:14:06.090476 22 kubectl.go:2392] validating pod update-demo-nautilus-9n485
  I0521 18:14:06.091722 22 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0521 18:14:06.091759 22 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0521 18:14:06.091770 22 kubectl.go:2519] update-demo-nautilus-9n485 is verified up and running
  STEP: scaling up the replication controller @ 05/21/24 18:14:06.091
  I0521 18:14:06.092680 22 kubectl.go:324] scanned /root for discovery docs: <nil>
  I0521 18:14:06.092704 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0521 18:14:07.014023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:07.152092 22 builder.go:146] stderr: ""
  I0521 18:14:07.152147 22 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 05/21/24 18:14:07.152
  I0521 18:14:07.152301 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0521 18:14:07.197250 22 builder.go:146] stderr: ""
  I0521 18:14:07.197281 22 builder.go:147] stdout: "update-demo-nautilus-9n485 update-demo-nautilus-x6ltl "
  I0521 18:14:07.197325 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-9n485 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 18:14:07.232633 22 builder.go:146] stderr: ""
  I0521 18:14:07.232674 22 builder.go:147] stdout: "true"
  I0521 18:14:07.232713 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-9n485 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0521 18:14:07.268222 22 builder.go:146] stderr: ""
  I0521 18:14:07.268256 22 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0521 18:14:07.268273 22 kubectl.go:2392] validating pod update-demo-nautilus-9n485
  I0521 18:14:07.269734 22 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0521 18:14:07.269771 22 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0521 18:14:07.269783 22 kubectl.go:2519] update-demo-nautilus-9n485 is verified up and running
  I0521 18:14:07.269820 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-x6ltl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 18:14:07.303545 22 builder.go:146] stderr: ""
  I0521 18:14:07.303582 22 builder.go:147] stdout: ""
  I0521 18:14:07.303592 22 kubectl.go:2501] update-demo-nautilus-x6ltl is created but not running
  E0521 18:14:08.014713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:09.015073      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:10.015527      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:11.016450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:12.016985      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:12.304562 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0521 18:14:12.358328 22 builder.go:146] stderr: ""
  I0521 18:14:12.358361 22 builder.go:147] stdout: "update-demo-nautilus-9n485 update-demo-nautilus-x6ltl "
  I0521 18:14:12.358400 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-9n485 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 18:14:12.392209 22 builder.go:146] stderr: ""
  I0521 18:14:12.392242 22 builder.go:147] stdout: "true"
  I0521 18:14:12.392290 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-9n485 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0521 18:14:12.428324 22 builder.go:146] stderr: ""
  I0521 18:14:12.428359 22 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0521 18:14:12.428372 22 kubectl.go:2392] validating pod update-demo-nautilus-9n485
  I0521 18:14:12.429564 22 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0521 18:14:12.429601 22 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0521 18:14:12.429613 22 kubectl.go:2519] update-demo-nautilus-9n485 is verified up and running
  I0521 18:14:12.429648 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-x6ltl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0521 18:14:12.473879 22 builder.go:146] stderr: ""
  I0521 18:14:12.473912 22 builder.go:147] stdout: "true"
  I0521 18:14:12.473955 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods update-demo-nautilus-x6ltl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0521 18:14:12.513274 22 builder.go:146] stderr: ""
  I0521 18:14:12.513306 22 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0521 18:14:12.513340 22 kubectl.go:2392] validating pod update-demo-nautilus-x6ltl
  I0521 18:14:12.515262 22 kubectl.go:2412] got data: {
    "image": "nautilus.jpg"
  }

  I0521 18:14:12.515299 22 kubectl.go:2417] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0521 18:14:12.515311 22 kubectl.go:2519] update-demo-nautilus-x6ltl is verified up and running
  STEP: using delete to clean up resources @ 05/21/24 18:14:12.515
  I0521 18:14:12.515370 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 delete --grace-period=0 --force -f -'
  I0521 18:14:12.554022 22 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0521 18:14:12.554057 22 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0521 18:14:12.554114 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get rc,svc -l name=update-demo --no-headers'
  I0521 18:14:12.602670 22 builder.go:146] stderr: "No resources found in kubectl-4173 namespace.\n"
  I0521 18:14:12.602710 22 builder.go:147] stdout: ""
  I0521 18:14:12.602751 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-4173 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0521 18:14:12.644927 22 builder.go:146] stderr: ""
  I0521 18:14:12.644971 22 builder.go:147] stdout: ""
  I0521 18:14:12.645074 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4173" for this suite. @ 05/21/24 18:14:12.647
• [13.124 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 05/21/24 18:14:12.65
  I0521 18:14:12.650600 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 18:14:12.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:14:12.659
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:14:12.661
  STEP: Creating secret with name secret-test-2aa81681-2331-435c-af64-70b9c358fc6a @ 05/21/24 18:14:12.662
  STEP: Creating a pod to test consume secrets @ 05/21/24 18:14:12.665
  E0521 18:14:13.017958      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:14.018554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:14:14.678
  I0521 18:14:14.681268 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-secrets-5b658fb9-9f41-4997-bd4b-39ee94bbfbde container secret-volume-test: <nil>
  STEP: delete the pod @ 05/21/24 18:14:14.688
  I0521 18:14:14.703443 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8286" for this suite. @ 05/21/24 18:14:14.706
• [2.061 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:406
  STEP: Creating a kubernetes client @ 05/21/24 18:14:14.712
  I0521 18:14:14.712276 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/21/24 18:14:14.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:14:14.724
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:14:14.728
  STEP: getting /apis @ 05/21/24 18:14:14.735
  STEP: getting /apis/admissionregistration.k8s.io @ 05/21/24 18:14:14.739
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 05/21/24 18:14:14.74
  STEP: creating @ 05/21/24 18:14:14.741
  STEP: getting @ 05/21/24 18:14:14.754
  STEP: listing @ 05/21/24 18:14:14.756
  STEP: watching @ 05/21/24 18:14:14.758
  I0521 18:14:14.758990 22 validatingadmissionpolicy.go:523] starting watch
  STEP: patching @ 05/21/24 18:14:14.759
  STEP: updating @ 05/21/24 18:14:14.762
  I0521 18:14:14.785973 22 validatingadmissionpolicy.go:552] waiting for watch events with expected annotations
  I0521 18:14:14.786018 22 validatingadmissionpolicy.go:568] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 05/21/24 18:14:14.786
  STEP: patching /status @ 05/21/24 18:14:14.787
  STEP: updating /status @ 05/21/24 18:14:14.79
  STEP: deleting @ 05/21/24 18:14:14.814
  STEP: deleting a collection @ 05/21/24 18:14:14.822
  I0521 18:14:14.833574 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-3362" for this suite. @ 05/21/24 18:14:14.836
• [0.128 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 05/21/24 18:14:14.84
  I0521 18:14:14.840253 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-runtime @ 05/21/24 18:14:14.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:14:14.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:14:14.853
  STEP: create the container @ 05/21/24 18:14:14.856
  W0521 18:14:14.862215      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/21/24 18:14:14.862
  E0521 18:14:15.018735      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:16.019911      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:17.020792      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/21/24 18:14:17.88
  STEP: the container should be terminated @ 05/21/24 18:14:17.883
  STEP: the termination message should be set @ 05/21/24 18:14:17.883
  I0521 18:14:17.883114 22 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 05/21/24 18:14:17.883
  I0521 18:14:17.895905 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1771" for this suite. @ 05/21/24 18:14:17.899
• [3.063 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:350
  STEP: Creating a kubernetes client @ 05/21/24 18:14:17.903
  I0521 18:14:17.903907 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename security-context-test @ 05/21/24 18:14:17.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:14:17.917
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:14:17.921
  E0521 18:14:18.021511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:19.022384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:20.021769      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:21.022526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:21.940058 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-166" for this suite. @ 05/21/24 18:14:21.943
• [4.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 05/21/24 18:14:21.951
  I0521 18:14:21.951332 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename proxy @ 05/21/24 18:14:21.952
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:14:21.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:14:21.967
  I0521 18:14:21.971237 22 proxy.go:293] Creating pod...
  E0521 18:14:22.022884      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:23.024499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:23.986425 22 proxy.go:317] Creating service...
  I0521 18:14:24.002783 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/pods/agnhost/proxy/some/path/with/DELETE
  I0521 18:14:24.007621 22 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0521 18:14:24.007707 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/pods/agnhost/proxy/some/path/with/GET
  I0521 18:14:24.011521 22 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0521 18:14:24.011601 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/pods/agnhost/proxy/some/path/with/HEAD
  I0521 18:14:24.014262 22 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0521 18:14:24.014297 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/pods/agnhost/proxy/some/path/with/OPTIONS
  I0521 18:14:24.016305 22 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0521 18:14:24.016350 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/pods/agnhost/proxy/some/path/with/PATCH
  I0521 18:14:24.018814 22 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0521 18:14:24.018872 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/pods/agnhost/proxy/some/path/with/POST
  I0521 18:14:24.021235 22 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0521 18:14:24.021275 22 proxy.go:354] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/pods/agnhost/proxy/some/path/with/PUT
  I0521 18:14:24.023022 22 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0521 18:14:24.023061 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/services/test-service/proxy/some/path/with/DELETE
  E0521 18:14:24.025232      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:24.025369 22 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0521 18:14:24.025415 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/services/test-service/proxy/some/path/with/GET
  I0521 18:14:24.027586 22 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0521 18:14:24.027622 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/services/test-service/proxy/some/path/with/HEAD
  I0521 18:14:24.030008 22 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0521 18:14:24.030046 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/services/test-service/proxy/some/path/with/OPTIONS
  I0521 18:14:24.032676 22 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0521 18:14:24.032715 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/services/test-service/proxy/some/path/with/PATCH
  I0521 18:14:24.035359 22 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0521 18:14:24.035435 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/services/test-service/proxy/some/path/with/POST
  I0521 18:14:24.039588 22 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0521 18:14:24.039658 22 proxy.go:365] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2784/services/test-service/proxy/some/path/with/PUT
  I0521 18:14:24.043521 22 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0521 18:14:24.043653 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2784" for this suite. @ 05/21/24 18:14:24.045
• [2.098 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 05/21/24 18:14:24.049
  I0521 18:14:24.049288 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 18:14:24.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:14:24.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:14:24.063
  STEP: Setting up server cert @ 05/21/24 18:14:24.075
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 18:14:24.215
  STEP: Deploying the webhook pod @ 05/21/24 18:14:24.219
  STEP: Wait for the deployment to be ready @ 05/21/24 18:14:24.226
  I0521 18:14:24.230477 22 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0521 18:14:25.025612      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:26.026531      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 18:14:26.239
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 18:14:26.249
  E0521 18:14:27.027460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:27.250129 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 05/21/24 18:14:27.315
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/21/24 18:14:27.338
  STEP: Deleting the collection of validation webhooks @ 05/21/24 18:14:27.359
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 05/21/24 18:14:27.387
  I0521 18:14:27.425556 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3513" for this suite. @ 05/21/24 18:14:27.428
  STEP: Destroying namespace "webhook-markers-9251" for this suite. @ 05/21/24 18:14:27.433
• [3.390 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 05/21/24 18:14:27.439
  I0521 18:14:27.439485 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 18:14:27.44
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:14:27.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:14:27.45
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/21/24 18:14:27.453
  E0521 18:14:28.028500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:29.029518      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:30.030699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:31.031172      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:14:31.473
  I0521 18:14:31.475898 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-ffba3429-cae9-47a7-a7ed-36f24dbb1210 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 18:14:31.482
  I0521 18:14:31.497261 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8678" for this suite. @ 05/21/24 18:14:31.5
• [4.066 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 05/21/24 18:14:31.505
  I0521 18:14:31.505630 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename statefulset @ 05/21/24 18:14:31.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:14:31.513
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:14:31.515
  STEP: Creating service test in namespace statefulset-3967 @ 05/21/24 18:14:31.516
  STEP: Creating a new StatefulSet @ 05/21/24 18:14:31.52
  I0521 18:14:31.525032 22 wait.go:40] Found 0 stateful pods, waiting for 3
  E0521 18:14:32.031410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:33.031741      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:34.032041      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:35.032998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:36.033808      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:37.034351      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:38.034511      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:39.035566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:40.036093      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:41.036610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:14:41.529673 22 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0521 18:14:41.529734 22 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0521 18:14:41.529754 22 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0521 18:14:41.537024 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-3967 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 18:14:41.634723 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 18:14:41.634774 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 18:14:41.634795 22 statefulset.go:2184] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0521 18:14:42.037613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:43.038181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:44.038739      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:45.039477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:46.039987      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:47.040380      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:48.040607      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:49.041562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:50.042121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:51.042475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/21/24 18:14:51.644
  I0521 18:14:51.666968 22 statefulset.go:2241] Updating stateful set ss2
  STEP: Creating a new revision @ 05/21/24 18:14:51.667
  E0521 18:14:52.042744      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:53.042955      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:54.043098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:55.043304      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:56.043443      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:57.043913      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:58.044581      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:14:59.045554      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:00.046561      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:01.047490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 05/21/24 18:15:01.674
  I0521 18:15:01.678861 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-3967 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0521 18:15:01.778311 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0521 18:15:01.778358 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0521 18:15:01.778379 22 statefulset.go:2208] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0521 18:15:02.048447      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:03.048578      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:04.049658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:05.049785      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:06.050401      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:07.050516      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:08.051555      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:09.051711      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:10.052490      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:11.052839      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:12.052894      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:13.053475      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:14.053817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:15.054077      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:16.054479      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:17.054625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:18.055107      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:19.055480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:20.056350      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:21.056852      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:15:21.789914 22 wait.go:158] Waiting for StatefulSet statefulset-3967/ss2 to complete update
  I0521 18:15:21.789980 22 wait.go:165] Waiting for Pod statefulset-3967/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0521 18:15:22.057414      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:23.057384      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:24.057692      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:25.058338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:26.058539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:27.058998      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:28.059501      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:29.060547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:30.061022      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:31.061822      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 05/21/24 18:15:31.794
  I0521 18:15:31.795058 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-3967 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0521 18:15:31.898212 22 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0521 18:15:31.898254 22 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0521 18:15:31.898266 22 statefulset.go:2184] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0521 18:15:32.062752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:33.063290      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:34.063847      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:35.064599      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:36.064733      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:37.064984      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:38.065887      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:39.066385      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:40.066585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:41.067532      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:15:41.931860 22 statefulset.go:2241] Updating stateful set ss2
  E0521 18:15:42.067610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:43.068127      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:44.068745      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:45.069369      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:46.069481      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:47.070074      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:48.070023      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:49.070503      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:50.071085      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:51.071906      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 05/21/24 18:15:51.941
  I0521 18:15:51.943816 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=statefulset-3967 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0521 18:15:52.047913 22 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0521 18:15:52.047976 22 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0521 18:15:52.047999 22 statefulset.go:2208] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0521 18:15:52.071977      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:53.072647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:54.073539      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:55.073625      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:56.074334      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:57.074729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:58.074919      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:15:59.075331      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:00.075783      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:01.076764      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:16:02.061204 22 statefulset.go:135] Deleting all statefulset in ns statefulset-3967
  I0521 18:16:02.063102 22 rest.go:150] Scaling statefulset ss2 to 0
  E0521 18:16:02.076699      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:03.077179      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:04.077660      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:05.078265      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:06.078503      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:07.078983      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:08.079560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:09.080131      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:10.080460      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:11.081461      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:16:12.076610 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0521 18:16:12.080855 22 rest.go:88] Deleting statefulset ss2
  E0521 18:16:12.081934      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:16:12.092867 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3967" for this suite. @ 05/21/24 18:16:12.095
• [100.596 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 05/21/24 18:16:12.101
  I0521 18:16:12.101588 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename namespaces @ 05/21/24 18:16:12.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:16:12.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:16:12.114
  STEP: Read namespace status @ 05/21/24 18:16:12.116
  I0521 18:16:12.117953 22 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 05/21/24 18:16:12.117
  I0521 18:16:12.121585 22 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 05/21/24 18:16:12.121
  I0521 18:16:12.127000 22 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0521 18:16:12.127099 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9211" for this suite. @ 05/21/24 18:16:12.128
• [0.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 05/21/24 18:16:12.132
  I0521 18:16:12.132413 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename secrets @ 05/21/24 18:16:12.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:16:12.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:16:12.144
  STEP: Creating secret with name secret-test-dd5ec783-2d26-42d2-b743-c1ff2f89db31 @ 05/21/24 18:16:12.146
  STEP: Creating a pod to test consume secrets @ 05/21/24 18:16:12.149
  E0521 18:16:13.082614      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:14.082768      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:16:14.164
  I0521 18:16:14.167252 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-secrets-88247515-6029-437e-adaa-2f4a02902e7d container secret-env-test: <nil>
  STEP: delete the pod @ 05/21/24 18:16:14.182
  I0521 18:16:14.191333 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3998" for this suite. @ 05/21/24 18:16:14.193
• [2.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 05/21/24 18:16:14.199
  I0521 18:16:14.199371 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename watch @ 05/21/24 18:16:14.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:16:14.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:16:14.213
  STEP: creating a watch on configmaps with a certain label @ 05/21/24 18:16:14.216
  STEP: creating a new configmap @ 05/21/24 18:16:14.217
  STEP: modifying the configmap once @ 05/21/24 18:16:14.222
  STEP: changing the label value of the configmap @ 05/21/24 18:16:14.228
  STEP: Expecting to observe a delete notification for the watched object @ 05/21/24 18:16:14.234
  I0521 18:16:14.234772 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9494  cf7c02ea-bf55-45f4-81a0-cf5528530b9b 30888 0 2024-05-21 18:16:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-21 18:16:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 18:16:14.234983 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9494  cf7c02ea-bf55-45f4-81a0-cf5528530b9b 30889 0 2024-05-21 18:16:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-21 18:16:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 18:16:14.235110 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9494  cf7c02ea-bf55-45f4-81a0-cf5528530b9b 30890 0 2024-05-21 18:16:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-21 18:16:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 05/21/24 18:16:14.235
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 05/21/24 18:16:14.241
  E0521 18:16:15.082815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:16.083597      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:17.084691      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:18.084850      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:19.084888      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:20.085508      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:21.086029      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:22.086537      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:23.086587      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:24.086963      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 05/21/24 18:16:24.242
  STEP: modifying the configmap a third time @ 05/21/24 18:16:24.255
  STEP: deleting the configmap @ 05/21/24 18:16:24.262
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 05/21/24 18:16:24.266
  I0521 18:16:24.267023 22 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9494  cf7c02ea-bf55-45f4-81a0-cf5528530b9b 30977 0 2024-05-21 18:16:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-21 18:16:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 18:16:24.267180 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9494  cf7c02ea-bf55-45f4-81a0-cf5528530b9b 30978 0 2024-05-21 18:16:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-21 18:16:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 18:16:24.267294 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9494  cf7c02ea-bf55-45f4-81a0-cf5528530b9b 30979 0 2024-05-21 18:16:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-05-21 18:16:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 18:16:24.267386 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9494" for this suite. @ 05/21/24 18:16:24.27
• [10.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 05/21/24 18:16:24.277
  I0521 18:16:24.277750 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-probe @ 05/21/24 18:16:24.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:16:24.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:16:24.292
  E0521 18:16:25.087933      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:26.088463      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:27.089526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:28.090591      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:29.090905      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:30.091651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:31.091805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:32.092521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:33.093178      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:34.093776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:35.094414      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:36.094469      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:37.095525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:38.096453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:39.096860      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:40.097228      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:41.098453      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:42.098542      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:43.099631      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:44.099860      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:45.100059      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:46.100410      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:47.101283      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:48.101673      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:49.102758      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:50.103067      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:51.103262      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:52.103789      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:53.104534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:54.104641      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:55.104996      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:56.105261      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:57.105515      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:58.106483      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:16:59.106913      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:00.107505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:01.108054      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:02.108633      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:03.109370      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:04.110052      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:05.110355      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:06.110995      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:07.111541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:08.112151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:09.112713      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:10.113717      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:11.113908      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:12.114472      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:13.114664      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:14.115619      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:15.116304      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:16.116556      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:17.117298      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:18.118470      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:19.119019      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:20.119525      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:21.120477      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:22.120973      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:23.121543      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:24.121669      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:17:24.308629 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1128" for this suite. @ 05/21/24 18:17:24.311
• [60.039 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 05/21/24 18:17:24.316
  I0521 18:17:24.316974 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename validating-admission-policy @ 05/21/24 18:17:24.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:17:24.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:17:24.331
  STEP: creating a policy with variables @ 05/21/24 18:17:24.338
  STEP: waiting until the marker is denied @ 05/21/24 18:17:24.346
  STEP: testing a replicated Deployment to be allowed @ 05/21/24 18:17:25.055
  STEP: testing a non-replicated ReplicaSet not to be denied @ 05/21/24 18:17:25.066
  I0521 18:17:25.114210 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-9160" for this suite. @ 05/21/24 18:17:25.117
  E0521 18:17:25.121750      22 retrywatcher.go:129] "Watch failed" err="context canceled"
• [0.806 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 05/21/24 18:17:25.123
  I0521 18:17:25.123121 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename disruption @ 05/21/24 18:17:25.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:17:25.133
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:17:25.134
  STEP: Creating a kubernetes client @ 05/21/24 18:17:25.136
  I0521 18:17:25.136173 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename disruption-2 @ 05/21/24 18:17:25.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:17:25.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:17:25.143
  STEP: Waiting for the pdb to be processed @ 05/21/24 18:17:25.159
  E0521 18:17:26.122810      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:27.123376      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/21/24 18:17:27.172
  E0521 18:17:28.124039      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:29.124637      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 05/21/24 18:17:29.182
  E0521 18:17:30.125558      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:31.126610      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 05/21/24 18:17:31.188
  STEP: listing a collection of PDBs in namespace disruption-864 @ 05/21/24 18:17:31.191
  STEP: deleting a collection of PDBs @ 05/21/24 18:17:31.193
  STEP: Waiting for the PDB collection to be deleted @ 05/21/24 18:17:31.201
  I0521 18:17:31.204551 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-5294" for this suite. @ 05/21/24 18:17:31.207
  I0521 18:17:31.213708 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-864" for this suite. @ 05/21/24 18:17:31.216
• [6.098 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 05/21/24 18:17:31.221
  I0521 18:17:31.221985 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename statefulset @ 05/21/24 18:17:31.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:17:31.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:17:31.237
  STEP: Creating service test in namespace statefulset-807 @ 05/21/24 18:17:31.239
  STEP: Creating a new StatefulSet @ 05/21/24 18:17:31.243
  I0521 18:17:31.253048 22 wait.go:40] Found 0 stateful pods, waiting for 3
  E0521 18:17:32.127285      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:33.127335      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:34.127763      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:35.128707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:36.129507      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:37.129709      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:38.130598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:39.130602      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:40.131111      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:41.131346      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:17:41.255795 22 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0521 18:17:41.255842 22 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0521 18:17:41.255854 22 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 05/21/24 18:17:41.262
  I0521 18:17:41.283006 22 statefulset.go:2241] Updating stateful set ss2
  STEP: Creating a new revision @ 05/21/24 18:17:41.283
  E0521 18:17:42.132062      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:43.132526      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:44.133326      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:45.134084      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:46.134576      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:47.135564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:48.136533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:49.136588      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:50.136936      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:51.137302      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 05/21/24 18:17:51.29
  STEP: Performing a canary update @ 05/21/24 18:17:51.29
  I0521 18:17:51.311092 22 statefulset.go:2241] Updating stateful set ss2
  I0521 18:17:51.316992 22 wait.go:74] Waiting for Pod statefulset-807/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0521 18:17:52.138466      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:53.138674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:54.138815      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:55.139462      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:56.140533      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:57.141679      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:58.141943      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:17:59.142844      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:00.143397      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:01.143672      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 05/21/24 18:18:01.319
  I0521 18:18:01.366258 22 wait.go:40] Found 2 stateful pods, waiting for 3
  E0521 18:18:02.144098      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:03.144409      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:04.144752      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:05.144982      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:06.145505      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:07.145604      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:08.146093      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:09.146292      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:10.147028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:11.147485      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:18:11.365476 22 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0521 18:18:11.365519 22 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0521 18:18:11.365532 22 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 05/21/24 18:18:11.37
  I0521 18:18:11.390029 22 statefulset.go:2241] Updating stateful set ss2
  I0521 18:18:11.399220 22 wait.go:74] Waiting for Pod statefulset-807/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0521 18:18:12.148489      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:13.148794      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:14.149308      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:15.149382      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:16.149823      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:17.150603      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:18.151522      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:19.152776      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:20.153718      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:21.154035      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:18:21.421109 22 statefulset.go:2241] Updating stateful set ss2
  I0521 18:18:21.428572 22 wait.go:56] Waiting for StatefulSet statefulset-807/ss2 to complete update
  I0521 18:18:21.428661 22 wait.go:63] Waiting for Pod statefulset-807/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0521 18:18:22.154380      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:23.154833      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:24.155653      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:25.156080      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:26.157115      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:27.157585      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:28.158043      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:29.158651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:30.159125      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:31.159535      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:18:31.430581 22 statefulset.go:135] Deleting all statefulset in ns statefulset-807
  I0521 18:18:31.432939 22 rest.go:150] Scaling statefulset ss2 to 0
  E0521 18:18:32.160452      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:33.160769      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:34.161324      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:35.162412      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:36.163295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:37.163567      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:38.163649      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:39.164703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:40.165141      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:41.165560      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:18:41.447254 22 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0521 18:18:41.449979 22 rest.go:88] Deleting statefulset ss2
  I0521 18:18:41.459858 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-807" for this suite. @ 05/21/24 18:18:41.462
• [70.246 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 05/21/24 18:18:41.468
  I0521 18:18:41.468753 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename svcaccounts @ 05/21/24 18:18:41.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:18:41.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:18:41.486
  STEP: creating a ServiceAccount @ 05/21/24 18:18:41.489
  STEP: watching for the ServiceAccount to be added @ 05/21/24 18:18:41.495
  STEP: patching the ServiceAccount @ 05/21/24 18:18:41.496
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 05/21/24 18:18:41.502
  STEP: deleting the ServiceAccount @ 05/21/24 18:18:41.504
  I0521 18:18:41.511402 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3428" for this suite. @ 05/21/24 18:18:41.514
• [0.049 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 05/21/24 18:18:41.517
  I0521 18:18:41.517942 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 18:18:41.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:18:41.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:18:41.531
  STEP: Setting up server cert @ 05/21/24 18:18:41.546
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 18:18:41.679
  STEP: Deploying the webhook pod @ 05/21/24 18:18:41.683
  STEP: Wait for the deployment to be ready @ 05/21/24 18:18:41.689
  I0521 18:18:41.692061 22 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0521 18:18:42.165430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:43.166674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 18:18:43.703
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 18:18:43.715
  E0521 18:18:44.166877      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:18:44.715737 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 05/21/24 18:18:44.722
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 05/21/24 18:18:44.74
  STEP: Creating a configMap that should not be mutated @ 05/21/24 18:18:44.747
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 05/21/24 18:18:44.758
  STEP: Creating a configMap that should be mutated @ 05/21/24 18:18:44.766
  I0521 18:18:44.813272 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9130" for this suite. @ 05/21/24 18:18:44.815
  STEP: Destroying namespace "webhook-markers-9642" for this suite. @ 05/21/24 18:18:44.823
• [3.309 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 05/21/24 18:18:44.827
  I0521 18:18:44.827246 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 18:18:44.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:18:44.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:18:44.837
  STEP: Setting up server cert @ 05/21/24 18:18:44.851
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 18:18:44.99
  STEP: Deploying the webhook pod @ 05/21/24 18:18:44.993
  STEP: Wait for the deployment to be ready @ 05/21/24 18:18:45.002
  I0521 18:18:45.004428 22 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0521 18:18:45.167935      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:46.168900      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:18:47.015180 22 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.May, 21, 18, 18, 45, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 18, 18, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.May, 21, 18, 18, 45, 0, time.Local), LastTransitionTime:time.Date(2024, time.May, 21, 18, 18, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6b869959d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0521 18:18:47.169729      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:48.170663      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 18:18:49.021
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 18:18:49.033
  E0521 18:18:49.171445      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:18:50.033723 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0521 18:18:50.041524 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 18:18:50.171674      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 05/21/24 18:18:50.552
  STEP: Creating a custom resource that should be denied by the webhook @ 05/21/24 18:18:50.571
  E0521 18:18:51.172464      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:52.173074      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 05/21/24 18:18:52.594
  STEP: Updating the custom resource with disallowed data should be denied @ 05/21/24 18:18:52.601
  STEP: Deleting the custom resource should be denied @ 05/21/24 18:18:52.608
  STEP: Remove the offending key and value from the custom resource data @ 05/21/24 18:18:52.612
  STEP: Deleting the updated custom resource should be successful @ 05/21/24 18:18:52.621
  E0521 18:18:53.173592      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:18:53.176046 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6765" for this suite. @ 05/21/24 18:18:53.18
  STEP: Destroying namespace "webhook-markers-9170" for this suite. @ 05/21/24 18:18:53.187
• [8.369 seconds]
------------------------------
S
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 05/21/24 18:18:53.196
  I0521 18:18:53.196809 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename proxy @ 05/21/24 18:18:53.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:18:53.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:18:53.214
  I0521 18:18:53.217777 22 proxy.go:387] Creating pod...
  E0521 18:18:54.174638      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:55.175465      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:18:55.229725 22 proxy.go:411] Creating service...
  I0521 18:18:55.239410 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/pods/agnhost/proxy?method=DELETE
  I0521 18:18:55.241513 22 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0521 18:18:55.241550 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/pods/agnhost/proxy?method=OPTIONS
  I0521 18:18:55.243842 22 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0521 18:18:55.243883 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/pods/agnhost/proxy?method=PATCH
  I0521 18:18:55.245419 22 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0521 18:18:55.245443 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/pods/agnhost/proxy?method=POST
  I0521 18:18:55.246586 22 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0521 18:18:55.246608 22 proxy.go:448] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/pods/agnhost/proxy?method=PUT
  I0521 18:18:55.247770 22 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0521 18:18:55.247797 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/services/e2e-proxy-test-service/proxy?method=DELETE
  I0521 18:18:55.249425 22 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0521 18:18:55.249451 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0521 18:18:55.251087 22 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0521 18:18:55.251114 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/services/e2e-proxy-test-service/proxy?method=PATCH
  I0521 18:18:55.252680 22 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0521 18:18:55.252704 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/services/e2e-proxy-test-service/proxy?method=POST
  I0521 18:18:55.254242 22 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0521 18:18:55.254268 22 proxy.go:459] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/services/e2e-proxy-test-service/proxy?method=PUT
  I0521 18:18:55.256067 22 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0521 18:18:55.256094 22 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/pods/agnhost/proxy?method=GET
  I0521 18:18:55.257115 22 proxy.go:487] http.Client request:GET StatusCode:301
  I0521 18:18:55.257134 22 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/services/e2e-proxy-test-service/proxy?method=GET
  I0521 18:18:55.258228 22 proxy.go:487] http.Client request:GET StatusCode:301
  I0521 18:18:55.258244 22 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/pods/agnhost/proxy?method=HEAD
  I0521 18:18:55.259110 22 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0521 18:18:55.259127 22 proxy.go:479] Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-670/services/e2e-proxy-test-service/proxy?method=HEAD
  I0521 18:18:55.260489 22 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0521 18:18:55.260552 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-670" for this suite. @ 05/21/24 18:18:55.262
• [2.069 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 05/21/24 18:18:55.265
  I0521 18:18:55.265508 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 18:18:55.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:18:55.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:18:55.277
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 05/21/24 18:18:55.278
  E0521 18:18:56.176497      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:57.176989      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:58.177722      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:18:59.178425      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:18:59.296
  I0521 18:18:59.299830 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-54218976-88f6-4967-97e9-09b62590bae8 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 18:18:59.314
  I0521 18:18:59.334668 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2937" for this suite. @ 05/21/24 18:18:59.337
• [4.077 seconds]
------------------------------
SS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 05/21/24 18:18:59.343
  I0521 18:18:59.343088 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename runtimeclass @ 05/21/24 18:18:59.344
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:18:59.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:18:59.355
  I0521 18:18:59.360034 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9217" for this suite. @ 05/21/24 18:18:59.361
• [0.023 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 05/21/24 18:18:59.365
  I0521 18:18:59.365858 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename emptydir @ 05/21/24 18:18:59.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:18:59.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:18:59.377
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 05/21/24 18:18:59.379
  E0521 18:19:00.178896      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:01.179615      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:02.179914      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:03.180593      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 05/21/24 18:19:03.399
  I0521 18:19:03.402972 22 output.go:196] Trying to get logs from node k8sconformance-m02 pod pod-03e9125c-b4eb-433d-9c6c-7cbf51ea2f82 container test-container: <nil>
  STEP: delete the pod @ 05/21/24 18:19:03.41
  I0521 18:19:03.425576 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-863" for this suite. @ 05/21/24 18:19:03.428
• [4.071 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:882
  STEP: Creating a kubernetes client @ 05/21/24 18:19:03.437
  I0521 18:19:03.437583 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 18:19:03.438
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:19:03.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:19:03.452
  STEP: validating api versions @ 05/21/24 18:19:03.455
  I0521 18:19:03.455700 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-7612 api-versions'
  I0521 18:19:03.500238 22 builder.go:146] stderr: ""
  I0521 18:19:03.500285 22 builder.go:147] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I0521 18:19:03.500372 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7612" for this suite. @ 05/21/24 18:19:03.502
• [0.070 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 05/21/24 18:19:03.507
  I0521 18:19:03.507274 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename dns @ 05/21/24 18:19:03.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:19:03.516
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:19:03.518
  STEP: Creating a test headless service @ 05/21/24 18:19:03.52
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8149 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8149;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8149 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8149;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8149.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8149.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8149.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8149.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8149.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8149.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8149.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8149.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8149.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8149.svc;check="$$(dig +notcp +noall +answer +search 159.119.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.119.159_udp@PTR;check="$$(dig +tcp +noall +answer +search 159.119.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.119.159_tcp@PTR;sleep 1; done
   @ 05/21/24 18:19:03.536
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8149 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8149;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8149 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8149;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8149.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8149.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8149.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8149.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8149.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8149.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8149.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8149.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8149.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8149.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8149.svc;check="$$(dig +notcp +noall +answer +search 159.119.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.119.159_udp@PTR;check="$$(dig +tcp +noall +answer +search 159.119.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.119.159_tcp@PTR;sleep 1; done
   @ 05/21/24 18:19:03.536
  STEP: creating a pod to probe DNS @ 05/21/24 18:19:03.536
  STEP: submitting the pod to kubernetes @ 05/21/24 18:19:03.536
  E0521 18:19:04.181580      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:05.182732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 05/21/24 18:19:05.551
  STEP: looking for the results for each expected name from probers @ 05/21/24 18:19:05.553
  I0521 18:19:05.554709 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.556232 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.557522 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.558758 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.560012 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.562391 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.563588 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.564859 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.570558 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.571600 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.572585 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.573565 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.574656 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.575641 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.576597 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.577793 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:05.582000 22 dns_common.go:489] Lookups using dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8149 wheezy_tcp@dns-test-service.dns-8149 wheezy_udp@dns-test-service.dns-8149.svc wheezy_tcp@dns-test-service.dns-8149.svc wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8149 jessie_tcp@dns-test-service.dns-8149 jessie_udp@dns-test-service.dns-8149.svc jessie_tcp@dns-test-service.dns-8149.svc jessie_udp@_http._tcp.dns-test-service.dns-8149.svc jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc]

  I0521 18:19:05.585647 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 18:19:05.589529 22 dns_common.go:495] Pod client logs for querier: 
  I0521 18:19:05.592546 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 18:19:06.183600      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:07.183796      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:08.184121      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:09.185046      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:10.186142      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:19:10.557349 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.559944 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.562312 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.564370 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.566340 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.568300 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.570507 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.572606 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.582398 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.584167 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.585902 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.587950 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.589692 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.591647 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.593482 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.595238 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:10.602299 22 dns_common.go:489] Lookups using dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8149 wheezy_tcp@dns-test-service.dns-8149 wheezy_udp@dns-test-service.dns-8149.svc wheezy_tcp@dns-test-service.dns-8149.svc wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8149 jessie_tcp@dns-test-service.dns-8149 jessie_udp@dns-test-service.dns-8149.svc jessie_tcp@dns-test-service.dns-8149.svc jessie_udp@_http._tcp.dns-test-service.dns-8149.svc jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc]

  I0521 18:19:10.606080 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 18:19:10.609764 22 dns_common.go:495] Pod client logs for querier: 
  I0521 18:19:10.613815 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 18:19:11.186767      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:12.187492      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:13.188125      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:14.188628      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:15.189009      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:19:15.558154 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.561017 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.563538 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.565710 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.567816 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.569724 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.573389 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.576324 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.587347 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.588749 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.589866 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.590937 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.592167 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.593251 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.594230 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.595168 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:15.599742 22 dns_common.go:489] Lookups using dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8149 wheezy_tcp@dns-test-service.dns-8149 wheezy_udp@dns-test-service.dns-8149.svc wheezy_tcp@dns-test-service.dns-8149.svc wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8149 jessie_tcp@dns-test-service.dns-8149 jessie_udp@dns-test-service.dns-8149.svc jessie_tcp@dns-test-service.dns-8149.svc jessie_udp@_http._tcp.dns-test-service.dns-8149.svc jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc]

  I0521 18:19:15.603710 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 18:19:15.607505 22 dns_common.go:495] Pod client logs for querier: 
  I0521 18:19:15.611099 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 18:19:16.189809      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:17.189884      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:18.189817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:19.190406      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:20.191062      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:19:20.556669 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.559089 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.561215 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.563431 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.565691 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.568024 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.570216 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.572422 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.584815 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.586934 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.588973 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.590980 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.593032 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.595047 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.597359 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.599353 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:20.608135 22 dns_common.go:489] Lookups using dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8149 wheezy_tcp@dns-test-service.dns-8149 wheezy_udp@dns-test-service.dns-8149.svc wheezy_tcp@dns-test-service.dns-8149.svc wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8149 jessie_tcp@dns-test-service.dns-8149 jessie_udp@dns-test-service.dns-8149.svc jessie_tcp@dns-test-service.dns-8149.svc jessie_udp@_http._tcp.dns-test-service.dns-8149.svc jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc]

  I0521 18:19:20.614133 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 18:19:20.620053 22 dns_common.go:495] Pod client logs for querier: 
  I0521 18:19:20.625477 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 18:19:21.192151      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:22.192683      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:23.192974      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:24.193503      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:25.194288      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:19:25.557469 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.560108 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.562498 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.564898 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.567130 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.569283 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.571559 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.573725 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.584603 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.586711 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.588858 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.591051 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.593357 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.595619 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.597885 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.599959 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:25.608646 22 dns_common.go:489] Lookups using dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8149 wheezy_tcp@dns-test-service.dns-8149 wheezy_udp@dns-test-service.dns-8149.svc wheezy_tcp@dns-test-service.dns-8149.svc wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8149 jessie_tcp@dns-test-service.dns-8149 jessie_udp@dns-test-service.dns-8149.svc jessie_tcp@dns-test-service.dns-8149.svc jessie_udp@_http._tcp.dns-test-service.dns-8149.svc jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc]

  I0521 18:19:25.615381 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 18:19:25.622037 22 dns_common.go:495] Pod client logs for querier: 
  I0521 18:19:25.627521 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 18:19:26.195553      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:27.195953      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:28.196307      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:29.196608      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:30.197026      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:19:30.557507 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.560282 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.562819 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.565397 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.568053 22 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.570684 22 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.573157 22 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.575648 22 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.586004 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.587969 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.589992 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.591961 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149 from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.593746 22 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.595422 22 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.597576 22 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.599449 22 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc from pod dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091: the server could not find the requested resource (get pods dns-test-1482e9b3-407d-419e-91c5-a48b23bec091)
  I0521 18:19:30.608145 22 dns_common.go:489] Lookups using dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8149 wheezy_tcp@dns-test-service.dns-8149 wheezy_udp@dns-test-service.dns-8149.svc wheezy_tcp@dns-test-service.dns-8149.svc wheezy_udp@_http._tcp.dns-test-service.dns-8149.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8149.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8149 jessie_tcp@dns-test-service.dns-8149 jessie_udp@dns-test-service.dns-8149.svc jessie_tcp@dns-test-service.dns-8149.svc jessie_udp@_http._tcp.dns-test-service.dns-8149.svc jessie_tcp@_http._tcp.dns-test-service.dns-8149.svc]

  I0521 18:19:30.613319 22 dns_common.go:495] Pod client logs for webserver: 
  I0521 18:19:30.617459 22 dns_common.go:495] Pod client logs for querier: 
  I0521 18:19:30.621554 22 dns_common.go:495] Pod client logs for jessie-querier: 
  E0521 18:19:31.197491      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:32.197547      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:33.198499      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:34.198687      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:35.199667      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:19:35.610972 22 dns_common.go:527] DNS probes using dns-8149/dns-test-1482e9b3-407d-419e-91c5-a48b23bec091 succeeded

  STEP: deleting the pod @ 05/21/24 18:19:35.611
  STEP: deleting the test service @ 05/21/24 18:19:35.624
  STEP: deleting the test headless service @ 05/21/24 18:19:35.648
  I0521 18:19:35.657138 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8149" for this suite. @ 05/21/24 18:19:35.659
• [32.156 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 05/21/24 18:19:35.663
  I0521 18:19:35.663506 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename configmap @ 05/21/24 18:19:35.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:19:35.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:19:35.675
  I0521 18:19:35.694778 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2315" for this suite. @ 05/21/24 18:19:35.696
• [0.040 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 05/21/24 18:19:35.703
  I0521 18:19:35.703780 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename cronjob @ 05/21/24 18:19:35.704
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:19:35.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:19:35.712
  STEP: Creating a ReplaceConcurrent cronjob @ 05/21/24 18:19:35.713
  STEP: Ensuring a job is scheduled @ 05/21/24 18:19:35.717
  E0521 18:19:36.200430      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:37.201413      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:38.201907      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:39.202456      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:40.203119      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:41.203338      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:42.203534      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:43.204049      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:44.204480      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:45.204831      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:46.205867      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:47.206498      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:48.206528      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:49.207678      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:50.208695      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:51.209104      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:52.209613      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:53.209666      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:54.210805      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:55.211303      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:56.211734      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:57.212387      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:58.213284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:19:59.213541      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:00.214169      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:01.214720      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 05/21/24 18:20:01.723
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 05/21/24 18:20:01.726
  STEP: Ensuring the job is replaced with a new one @ 05/21/24 18:20:01.728
  E0521 18:20:02.215651      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:03.216320      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:04.216417      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:05.216598      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:06.217675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:07.218352      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:08.219428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:09.219568      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:10.219871      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:11.220450      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:12.221731      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:13.222378      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:14.223218      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:15.223658      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:16.224675      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:17.225636      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:18.226519      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:19.227500      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:20.228611      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:21.229292      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:22.229635      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:23.230544      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:24.231589      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:25.232705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:26.232852      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:27.233223      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:28.234147      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:29.234707      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:30.235566      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:31.236021      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:32.236876      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:33.237769      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:34.238703      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:35.239284      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:36.239371      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:37.239736      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:38.239817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:39.240310      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:40.241176      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:41.241648      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:42.242028      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:43.242428      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:44.243577      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:45.244521      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:46.244712      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:47.244865      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:48.245562      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:49.246564      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:50.246741      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:51.247530      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:52.248156      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:53.248728      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:54.249853      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:55.250705      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:56.251331      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:57.251817      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:58.252680      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:20:59.253306      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:00.254245      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:01.254677      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 05/21/24 18:21:01.733
  I0521 18:21:01.738887 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-326" for this suite. @ 05/21/24 18:21:01.742
• [86.044 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 05/21/24 18:21:01.748
  I0521 18:21:01.748654 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename watch @ 05/21/24 18:21:01.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:21:01.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:21:01.77
  STEP: creating a new configmap @ 05/21/24 18:21:01.771
  STEP: modifying the configmap once @ 05/21/24 18:21:01.773
  STEP: modifying the configmap a second time @ 05/21/24 18:21:01.778
  STEP: deleting the configmap @ 05/21/24 18:21:01.783
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 05/21/24 18:21:01.788
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 05/21/24 18:21:01.789
  I0521 18:21:01.789761 22 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7655  7e8d7c6b-714e-4f41-9afc-4538d83be24b 32173 0 2024-05-21 18:21:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-21 18:21:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 18:21:01.789945 22 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7655  7e8d7c6b-714e-4f41-9afc-4538d83be24b 32174 0 2024-05-21 18:21:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-05-21 18:21:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0521 18:21:01.790041 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7655" for this suite. @ 05/21/24 18:21:01.793
• [0.049 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 05/21/24 18:21:01.797
  I0521 18:21:01.797667 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubelet-test @ 05/21/24 18:21:01.798
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:21:01.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:21:01.812
  E0521 18:21:02.254945      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:03.255295      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:04.255732      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:05.256754      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:21:05.829532 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1095" for this suite. @ 05/21/24 18:21:05.833
• [4.041 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 05/21/24 18:21:05.838
  I0521 18:21:05.838587 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename webhook @ 05/21/24 18:21:05.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:21:05.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:21:05.855
  STEP: Setting up server cert @ 05/21/24 18:21:05.874
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 05/21/24 18:21:06.029
  STEP: Deploying the webhook pod @ 05/21/24 18:21:06.033
  STEP: Wait for the deployment to be ready @ 05/21/24 18:21:06.039
  I0521 18:21:06.041698 22 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0521 18:21:06.257423      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:07.258096      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 05/21/24 18:21:08.052
  STEP: Verifying the service has paired with the endpoint @ 05/21/24 18:21:08.069
  E0521 18:21:08.258922      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:21:09.070369 22 util.go:427] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0521 18:21:09.075333 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  E0521 18:21:09.260011      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8685-crds.webhook.example.com via the AdmissionRegistration API @ 05/21/24 18:21:09.589
  STEP: Creating a custom resource that should be mutated by the webhook @ 05/21/24 18:21:09.608
  E0521 18:21:10.261024      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:11.261419      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:21:12.212238 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4182" for this suite. @ 05/21/24 18:21:12.215
  STEP: Destroying namespace "webhook-markers-6189" for this suite. @ 05/21/24 18:21:12.221
• [6.388 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1533
  STEP: Creating a kubernetes client @ 05/21/24 18:21:12.227
  I0521 18:21:12.227239 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename kubectl @ 05/21/24 18:21:12.228
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:21:12.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:21:12.244
  STEP: creating Agnhost RC @ 05/21/24 18:21:12.247
  I0521 18:21:12.247821 22 kubectl.go:1540] namespace kubectl-981
  I0521 18:21:12.247879 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-981 create -f -'
  E0521 18:21:12.262253      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:21:12.319928 22 builder.go:146] stderr: ""
  I0521 18:21:12.319964 22 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 05/21/24 18:21:12.319
  E0521 18:21:13.262647      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:21:13.326144 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 18:21:13.326212 22 framework.go:733] Found 0 / 1
  E0521 18:21:14.263290      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:21:14.326279 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 18:21:14.326343 22 framework.go:733] Found 1 / 1
  I0521 18:21:14.326375 22 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0521 18:21:14.329962 22 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0521 18:21:14.330013 22 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0521 18:21:14.330032 22 kubectl.go:1547] wait on agnhost-primary startup in kubectl-981 
  I0521 18:21:14.330097 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-981 logs agnhost-primary-9zgcl agnhost-primary'
  I0521 18:21:14.393922 22 builder.go:146] stderr: ""
  I0521 18:21:14.393975 22 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 05/21/24 18:21:14.394
  I0521 18:21:14.394068 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-981 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I0521 18:21:14.446636 22 builder.go:146] stderr: ""
  I0521 18:21:14.446713 22 builder.go:147] stdout: "service/rm2 exposed\n"
  I0521 18:21:14.449411 22 utils.go:1179] Service rm2 in namespace kubectl-981 found.
  E0521 18:21:15.263965      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:16.264774      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 05/21/24 18:21:16.456
  I0521 18:21:16.456741 22 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-118508493 --namespace=kubectl-981 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I0521 18:21:16.505071 22 builder.go:146] stderr: ""
  I0521 18:21:16.505111 22 builder.go:147] stdout: "service/rm3 exposed\n"
  I0521 18:21:16.507184 22 utils.go:1179] Service rm3 in namespace kubectl-981 found.
  E0521 18:21:17.264684      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:18.265166      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0521 18:21:18.515578 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-981" for this suite. @ 05/21/24 18:21:18.518
• [6.296 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 05/21/24 18:21:18.523
  I0521 18:21:18.523066 22 util.go:506] >>> kubeConfig: /tmp/kubeconfig-118508493
  STEP: Building a namespace api object, basename container-runtime @ 05/21/24 18:21:18.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 05/21/24 18:21:18.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 05/21/24 18:21:18.536
  STEP: create the container @ 05/21/24 18:21:18.54
  W0521 18:21:18.546252      22 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 05/21/24 18:21:18.546
  E0521 18:21:19.265708      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:20.266656      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0521 18:21:21.267181      22 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 05/21/24 18:21:21.561
  STEP: the container should be terminated @ 05/21/24 18:21:21.563
  STEP: the termination message should be set @ 05/21/24 18:21:21.563
  I0521 18:21:21.563778 22 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 05/21/24 18:21:21.563
  I0521 18:21:21.578396 22 helper.go:121] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6788" for this suite. @ 05/21/24 18:21:21.581
• [3.064 seconds]
------------------------------
SSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0521 18:21:21.587418 22 suites.go:34] Running AfterSuite actions on node 1
  I0521 18:21:21.587447 22 util.go:614] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:612
[ReportAfterSuite] PASSED [0.030 seconds]
------------------------------

Ran 402 of 7197 Specs in 6116.315 seconds
SUCCESS! -- 402 Passed | 0 Failed | 0 Pending | 6795 Skipped
PASS

Ginkgo ran 1 suite in 1h41m56.785550358s
Test Suite Passed
